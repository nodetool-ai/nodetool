# nodetool.nodes.replicate.video.generate

## AnimateDiff

ðŸŽ¨ AnimateDiff (w/ MotionLoRAs for Panning, Zooming, etc): Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning

**Fields:**
seed: int
steps: int
width: int
frames: int
height: int
prompt: str
base_model: Base_model
output_format: Output_format
guidance_scale: float
negative_prompt: str
pan_up_motion_strength: float
zoom_in_motion_strength: float
pan_down_motion_strength: float
pan_left_motion_strength: float
zoom_out_motion_strength: float
pan_right_motion_strength: float
rolling_clockwise_motion_strength: float
rolling_anticlockwise_motion_strength: float

## AnimateDiffIllusions

Monster Labs' Controlnet QR Code Monster v2 For SD-1.5 on top of AnimateDiff Prompt Travel (Motion Module SD 1.5 v2)

**Fields:**
loop: bool
seed: int | None
steps: int
width: int
frames: int
height: int
context: int
clip_skip: int
scheduler: Scheduler
base_model: Base_model
prompt_map: str
head_prompt: str
tail_prompt: str
output_format: Output_format
guidance_scale: float
negative_prompt: str
controlnet_video: VideoRef
film_interpolation: bool
prompt_fixed_ratio: float
custom_base_model_url: str
num_interpolation_steps: int
enable_qr_code_monster_v2: bool
playback_frames_per_second: int
controlnet_conditioning_scale: float
qr_code_monster_v2_guess_mode: bool
qr_code_monster_v2_preprocessor: bool

## AudioToWaveform

Create a waveform video from audio

**Fields:**
audio: AudioRef
bg_color: str
fg_alpha: float
bar_count: int
bar_width: float
bars_color: str
caption_text: str

## HotshotXL

ðŸ˜Š Hotshot-XL is an AI text-to-GIF model trained to work alongside Stable Diffusion XL

**Fields:**
mp4: bool
seed: int | None
steps: int
width: Width
height: Height
prompt: str
scheduler: Scheduler
negative_prompt: str

## RobustVideoMatting

extract foreground of a video

**Fields:**
input_video: VideoRef
output_type: Output_type

## StableDiffusionInfiniteZoom

Use Runway's Stable-diffusion inpainting model to create an infinite loop video

**Fields:**
prompt: str | None
inpaint_iter: int
output_format: Output_format

## Tooncrafter

Create videos from illustrated input images

**Fields:**
loop: bool
seed: int | None
prompt: str
image_1: ImageRef
image_2: ImageRef
image_3: ImageRef
image_4: ImageRef
image_5: ImageRef
image_6: ImageRef
image_7: ImageRef
image_8: ImageRef
image_9: ImageRef
image_10: ImageRef
max_width: int
max_height: int
interpolate: bool
negative_prompt: str
color_correction: bool

## VideoMorpher

Generate a video that morphs between subjects, with an optional style

**Fields:**
mode: Mode
seed: int | None
prompt: str
checkpoint: Checkpoint
style_image: ImageRef
aspect_ratio: Aspect_ratio
style_strength: float
use_controlnet: bool
negative_prompt: str
subject_image_1: ImageRef
subject_image_2: ImageRef
subject_image_3: ImageRef
subject_image_4: ImageRef

## Zeroscope_V2_XL

Zeroscope V2 XL & 576w

**Fields:**
fps: int
seed: int | None
model: Model
width: int
height: int
prompt: str
batch_size: int
init_video: str | None
num_frames: int
init_weight: float
guidance_scale: float
negative_prompt: str | None
remove_watermark: bool
num_inference_steps: int

