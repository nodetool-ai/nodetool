import asyncio
import json
import os
from typing import Any, AsyncGenerator, Mapping
import PIL
import ollama
import readline
from pydantic import BaseModel

import chromadb

from nodetool.providers.ollama.ollama_service import get_ollama_client
from nodetool.chat.tools import Tool, sanitize_node_name
from nodetool.common.environment import Environment
from nodetool.metadata.types import (
    ImageRef,
    Message,
    MessageImageContent,
    MessageTextContent,
)
from nodetool.workflows.base_node import (
    BaseNode,
    get_registered_node_classes,
)
from nodetool.workflows.processing_context import ProcessingContext
from nodetool.workflows.examples import load_examples
from jsonschema import validators


doc_folder = os.path.join(os.path.dirname(__file__), "docs")
examples = None
documentation = None

log = Environment.get_logger()


def validate_schema(schema):
    meta_schema = validators.Draft7Validator.META_SCHEMA

    # Create a validator
    validator = validators.Draft7Validator(meta_schema)

    try:
        # Validate the schema
        validator.validate(schema)
        print("The schema is valid.")
        return True
    except Exception as e:
        print(f"The schema is invalid. Error: {e}")
        return False


def get_collection(name) -> chromadb.Collection:
    """
    Get or create a collection with the given name.

    Args:
        context: The processing context.
        name: The name of the collection to get or create.
    """
    from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction  # type: ignore
    from chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT

    log.info(f"Using collection {name} from {Environment.get_chroma_path()}")

    client = chromadb.PersistentClient(
        path=Environment.get_chroma_path(),
        tenant=DEFAULT_TENANT,
        database=DEFAULT_DATABASE,
    )

    embedding_function = SentenceTransformerEmbeddingFunction()

    return client.get_or_create_collection(
        name=name,
        embedding_function=embedding_function,  # type: ignore
    )


def index_documentation(collection: chromadb.Collection):
    """
    Index the documentation if it doesn't exist yet.
    """
    import nodetool.nodes.aime
    import nodetool.nodes.anthropic

    # import nodetool.nodes.comfy
    import nodetool.nodes.elevenlabs
    import nodetool.nodes.fal
    import nodetool.nodes.google
    import nodetool.nodes.huggingface
    import nodetool.nodes.lib
    import nodetool.nodes.nodetool
    import nodetool.nodes.ollama
    import nodetool.nodes.openai
    import nodetool.nodes.replicate

    if not Environment.is_production():
        import nodetool.nodes.chroma
        import nodetool.nodes.apple

    print("Indexing documentation")

    def doc_for(c: type[BaseNode]):
        return f"{c.get_title()}: {c.get_description()}"

    def metadata_for(c: type[BaseNode]):
        return {
            "title": c.get_title(),
            "node_type": c.get_node_type(),
            "json_schema": json.dumps(c.get_json_schema()),
        }

    classes = get_registered_node_classes()
    ids = [c.get_node_type() for c in classes]
    docs = [doc_for(c) for c in classes]
    metadata = [dict(metadata_for(c)) for c in classes]

    collection.add(ids, documents=docs, metadatas=metadata)  # type: ignore
    return collection


def index_examples(collection: chromadb.Collection):
    """
    Index the examples if they don't exist yet.
    """
    print("Indexing examples")

    examples = load_examples()
    ids = [example.id for example in examples]
    docs = [example.model_dump_json() for example in examples]

    collection.add(ids, documents=docs)
    print("Indexed examples")


def get_doc_collection():
    collection = get_collection("docs")
    if collection.count() == 0:
        index_documentation(collection)
    return collection


def get_example_collection():
    collection = get_collection("examples")
    if collection.count() == 0:
        index_examples(collection)

    return collection


class SearchResult(BaseModel):
    id: str
    content: str
    metadata: dict | None = None


def search_documentation(query: str) -> list[SearchResult]:
    """
    Search the documentation for the given query string.

    Args:
        query: The query to search for.
        n_results: The number of results to return.

    Returns:
        A string of the documentation for the given query.
    """
    docs = get_doc_collection().query(query_texts=[query], n_results=10)
    if len(docs["ids"]) == 0 or docs["documents"] is None:
        return []
    metadata = docs["metadatas"][0] if docs["metadatas"] else None
    return [
        SearchResult(
            id=docs["ids"][0][i],
            content=docs["documents"][0][i],
            metadata=metadata[i] if metadata else None,  # type: ignore
        )
        for i in range(len(docs["ids"][0]))
    ]


def search_examples(query: str) -> list[SearchResult]:
    """
    Search the examples for the given query string.

    Args:
        query: The query to search for.
        n_results: The number of results to return.

    Returns:
        A tuple of the ids and documents that match the query.
    """
    res = get_example_collection().query(query_texts=[query], n_results=2)
    if len(res["ids"]) == 0 or res["documents"] is None:
        return []
    return [
        SearchResult(
            id=res["ids"][0][i],
            content=res["documents"][0][i],
        )
        for i in range(len(res["ids"][0]))
    ]


def search_docs(query: str) -> list[SearchResult]:
    """
    Search the documentation and examples for the given query string.
    """
    return search_documentation(query) + search_examples(query)


"""
Workflow Tool:
You have access to a powerful tool called "workflow_tool". This tool allows 
you to design new workflows for the user.

Here's how to use it:

1. When a user requests a new workflow or you identify an opportunity to 
   create one, design the workflow using your knowledge of Nodetool nodes 
   and their connections.

2. Structure the workflow as a JSON object with the following properties:
   - name: A descriptive name for the workflow
   - description: A brief explanation of what the workflow does
   - graph: An object containing two arrays:
     - nodes: Each node should have an id, type, data (properties), and 
              ui_properties
     - edges: Connections between nodes, each with an id, source, target, 
              sourceHandle, and targetHandle

3. Make sure all nodes are connected properly and the workflow is logically
    sound. Important: Only use existing Nodetool nodes in the workflow.

4. Call the "workflow_tool" with this JSON object as its parameter.

This feature allows you to not only suggest workflows but actually implement 
them, greatly enhancing your ability to assist users. Be creative in 
designing workflows that solve user problems or demonstrate Nodetool 
capabilities.

Example usage:
User: "Can you create a workflow that generates an image and then applies a 
sepia filter?"
You: "Yes, here it is:"

Then proceed to design the workflow by calling the tool with the name, description
and graph properties, including all necessary nodes and edges.
"""


CORE_DOCS = [
    {
        "id": "models",
        "title": "Models",
        "content": """
        Local Models:
        - Local models need a GPU or MPS to run fast, smaller models can run on CPU
        - Model files can be large, please check your disk space before downloading
        - Remote models require API keys, you can set them in the settings menu

        Remote Models:
        - Remote API Providers require an account and API keys
        - Fal.ai gives access to a wide range of image and video models
        - Replicate gives access to a wide range of models
        - OpenAI and Anthropic models give access to worlds' most powerful language models
        """,
    },
    {
        "id": "assets",
        "title": "Assets",
        "content": """
        Assets:
        - Assets are either uploaded by the user or generated by nodes
        - Drag images, videos, audio, text, or any other files (from FileExplorer / Finder) onto the Asset panel on the right to import them
        - Drag images, videos, audio, text, or any other files onto the canvas to create constant asset nodes
        - Double-click on any asset in a node or inside the ASSETS panel to open it in the AssetViewer
        - Right-click on any asset to open the Asset Menu for more options
        - Select multiple assets by holding CTRL or SHIFT
        - Move assets between folders by dragging them onto the desired folder,
        - or use the right click menu for moving them into nested folders
        - Search for assets by typing in the search bar
        - Sort assets by clicking on the name or date buttons
        - Download: select one or more assets and use the right click menu
        - Delete: right click menu or X button
        - Rename: right click menu or press F2 key (also works with multiple assets)
        """,
    },
    {
        "id": "workflow_basics",
        "title": "Workflow Basics",
        "content": """
        ## Creating Workflows
        - Start with an empty canvas in the workflow editor
        - Add nodes by double-clicking or using CTRL+Space
        - Connect nodes by dragging from output to input handles
        - Configure node parameters in the right panel
        - Save your workflow using the save button
        - Run workflows with the play button
        
        ## Best Practices
        - Name your nodes descriptively
        - Group related nodes together
        - Test workflows incrementally
        - Use comments to document complex parts
        - Back up important workflows
        """,
    },
    {
        "id": "keyboard_shortcuts",
        "title": "Keyboard Shortcuts",
        "content": """
        ## Essential Shortcuts
        - Node Menu: Double-click canvas or Space
        - Run Workflow: CTRL+Enter / Cmd+Enter
        - Stop Workflow: ESC
        - Save: CTRL+S / Cmd+S
        - Undo/Redo: CTRL+Z / Cmd+Z
        - Delete Node: Delete or Backspace
        - Copy/Paste: CTRL+C / CTRL+V / Cmd+C / Cmd+V
        - Select All: CTRL+A / Cmd+A
        - Copy selected nodes: Shift + C and Paste selected nodes with Shift + V
        - Select multiple Nodes: Drag area with left click, Shift + Left Click if using LMB for panning
        - Select multiple nodes: click on nodes with CTRL key or draw a rectangle around nodes
        """,
    },
    {
        "id": "troubleshooting",
        "title": "Troubleshooting",
        "content": """
        ## Common Issues
        - Check model requirements before downloading
        - Verify API keys are correctly set for remote services
        - Ensure sufficient disk space for models
        - Monitor GPU memory usage
        - Check node connections for errors
        
        ## Getting Help
        - Use the help menu (? icon)
        - Check documentation
        - Visit the community forum
        - Report bugs through GitHub
        """,
    },
]


def index_core_docs(collection: chromadb.Collection):
    collection.add(
        [doc["id"] for doc in CORE_DOCS],
        documents=[doc["content"] for doc in CORE_DOCS],
    )


SYSTEM_PROMPT = """
You're an AI assistant for Nodetool, a no-code AI workflow platform. 
YOU ARE CONFIDENT AND KNOWLEDGEABLE.
DO NOT QUESTION YOURSELF.
        
NodeTool enables you to create custom AI workflows on your computer.

## Features âœ¨
- **Visual Editor**: 
  Create AI workflows visually without coding.
  A workflow is a graph of nodes.
  Each node has a name, type, and a set of parameters.
  Nodes can have multiple inputs and outputs.
  The node editor is a canvas that you can use to create your workflows.
  You can connect nodes by dragging from output to input handles.
  You can configure node parameters in the node itself.
  The workflow is executed by evaluating the graph from start to end.
  You can run the workflow by clicking the play button.
  Nodes can take strings, numbers, images, audio, video, and documents as input or output.
  One node is like a python function, it takes input, does something, and produces output.
  Many nodes run AI models, for example a text generation node runs a language model.
- **Local Models**: 
  Run models on your hardware.
  Nodetool's model manager can download models from Hugging Face and other sources.
  AI models need a NVidia GPU or Apple MPS to run fast.
  Nodetool offers many libraries for working with data, images, audio, video, and more.
  For example, image can be edited, audio can be transcribed, and documents can be summarized.
- **Integration with AI Platforms**:
  For more procesing power you can use remote models from OpenAI, Hugging Face, Ollama, Replicate, ElevenLabs, Google, Anthropic, and more.
- **Asset Browser**: 
  Import and manage media assets.
  The assets can be used as input or output for nodes.
  
IMPORTANT NODES:
- Preview Node: Renders any data as a preview, like images, videos, audio, documents, and more.
- Input Nodes: These nodes take user input, like text, images, audio, video, and more.
- Chat Input Node: This node takes user input from a chat interface, including audio, image or documents.
- Constant Node: This node takes a constant value as input, like a string, number, or image.
- Output Node: This node takes any data as input and displays it to the user.
- Loop Node: This node takes list or dataframes and applies a sub graph to each element of the list.
- Text Generation: There are many nodes from different providers for text generation, like OpenAI, Ollama, Google, Anthropic, and more.
- Image Generation: There are many nodes from different providers for image generation, like OpenAI, Hugging Face, Replicate, and more.

NODE HIERARCHY:
ALWAYS use the documentation tool to find the correct node type.
.
â”œâ”€â”€ aime
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ audio.py
â”‚   â”œâ”€â”€ image.py
â”‚   â”œâ”€â”€ text.py
â”‚   â””â”€â”€ translate.py
â”œâ”€â”€ anthropic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ text.py
â”œâ”€â”€ apple
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ calendar.py
â”‚   â”œâ”€â”€ exportnotes.applescript
â”‚   â”œâ”€â”€ messages.py
â”‚   â”œâ”€â”€ notes.py
â”‚   â””â”€â”€ speech.py
â”œâ”€â”€ chroma
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ chroma_node.py
â”‚   â”œâ”€â”€ collections.py
â”‚   â”œâ”€â”€ index.py
â”‚   â””â”€â”€ query.py
â”œâ”€â”€ comfy
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ _for_testing.py
â”‚   â”œâ”€â”€ advanced
â”‚   â”‚   â”œâ”€â”€ conditioning.py
â”‚   â”‚   â”œâ”€â”€ loaders.py
â”‚   â”‚   â””â”€â”€ model.py
â”‚   â”œâ”€â”€ basic.py
â”‚   â”œâ”€â”€ conditioning.py
â”‚   â”œâ”€â”€ controlnet
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ faces_and_poses.py
â”‚   â”‚   â”œâ”€â”€ line_extractors.py
â”‚   â”‚   â”œâ”€â”€ normal_and_depth.py
â”‚   â”‚   â”œâ”€â”€ others.py
â”‚   â”‚   â”œâ”€â”€ semantic_segmentation.py
â”‚   â”‚   â””â”€â”€ t2i.py
â”‚   â”œâ”€â”€ enums.py
â”‚   â”œâ”€â”€ essentials
â”‚   â”‚   â”œâ”€â”€ conditioning.py
â”‚   â”‚   â”œâ”€â”€ image.py
â”‚   â”‚   â”œâ”€â”€ mask.py
â”‚   â”‚   â”œâ”€â”€ misc.py
â”‚   â”‚   â”œâ”€â”€ sampling.py
â”‚   â”‚   â”œâ”€â”€ segmentation.py
â”‚   â”‚   â””â”€â”€ text.py
â”‚   â”œâ”€â”€ flux.py
â”‚   â”œâ”€â”€ generate.py
â”‚   â”œâ”€â”€ image
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ animation.py
â”‚   â”‚   â”œâ”€â”€ batch.py
â”‚   â”‚   â”œâ”€â”€ transform.py
â”‚   â”‚   â””â”€â”€ upscaling.py
â”‚   â”œâ”€â”€ ipadapter.py
â”‚   â”œâ”€â”€ latent
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ advanced.py
â”‚   â”‚   â”œâ”€â”€ batch.py
â”‚   â”‚   â”œâ”€â”€ inpaint.py
â”‚   â”‚   â”œâ”€â”€ stable_cascade.py
â”‚   â”‚   â”œâ”€â”€ transform.py
â”‚   â”‚   â””â”€â”€ video.py
â”‚   â”œâ”€â”€ loaders.py
â”‚   â”œâ”€â”€ mask
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ compositing.py
â”‚   â””â”€â”€ sampling
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ guiders.py
â”‚       â”œâ”€â”€ noise.py
â”‚       â”œâ”€â”€ samplers.py
â”‚       â”œâ”€â”€ schedulers.py
â”‚       â””â”€â”€ sigmas.py
â”œâ”€â”€ elevenlabs
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ text_to_speech.py
â”œâ”€â”€ fal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ fal_node.py
â”‚   â”œâ”€â”€ image_to_image.py
â”‚   â”œâ”€â”€ image_to_video.py
â”‚   â”œâ”€â”€ llm.py
â”‚   â”œâ”€â”€ speech_to_text.py
â”‚   â”œâ”€â”€ text_to_audio.py
â”‚   â””â”€â”€ text_to_image.py
â”œâ”€â”€ google
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agents.py
â”‚   â”œâ”€â”€ gemini.py
â”‚   â””â”€â”€ mail.py
â”œâ”€â”€ huggingface
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ audio_classification.py
â”‚   â”œâ”€â”€ automatic_speech_recognition.py
â”‚   â”œâ”€â”€ depth_estimation.py
â”‚   â”œâ”€â”€ feature_extraction.py
â”‚   â”œâ”€â”€ fill_mask.py
â”‚   â”œâ”€â”€ huggingface_pipeline.py
â”‚   â”œâ”€â”€ image_classification.py
â”‚   â”œâ”€â”€ image_segmentation.py
â”‚   â”œâ”€â”€ image_to_image.py
â”‚   â”œâ”€â”€ lora.py
â”‚   â”œâ”€â”€ multimodal.py
â”‚   â”œâ”€â”€ object_detection.py
â”‚   â”œâ”€â”€ question_answering.py
â”‚   â”œâ”€â”€ ranking.py
â”‚   â”œâ”€â”€ sentence_similarity.py
â”‚   â”œâ”€â”€ stable_diffusion_base.py
â”‚   â”œâ”€â”€ summarization.py
â”‚   â”œâ”€â”€ text_classification.py
â”‚   â”œâ”€â”€ text_generation.py
â”‚   â”œâ”€â”€ text_to_audio.py
â”‚   â”œâ”€â”€ text_to_image.py
â”‚   â”œâ”€â”€ text_to_speech.py
â”‚   â”œâ”€â”€ text_to_text.py
â”‚   â”œâ”€â”€ token_classification.py
â”‚   â”œâ”€â”€ translation.py
â”‚   â””â”€â”€ video.py
â”œâ”€â”€ lib
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ audio
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ audio_helpers.py
â”‚   â”‚   â”œâ”€â”€ conversion.py
â”‚   â”‚   â”œâ”€â”€ librosa
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ analysis.py
â”‚   â”‚   â”‚   â””â”€â”€ segmentation.py
â”‚   â”‚   â”œâ”€â”€ pedalboard.py
â”‚   â”‚   â”œâ”€â”€ synthesis.py
â”‚   â”‚   â””â”€â”€ transform.py
â”‚   â”œâ”€â”€ data
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ langchain.py
â”‚   â”‚   â”œâ”€â”€ llama_index.py
â”‚   â”‚   â”œâ”€â”€ numpy
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pandas
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ dataframe.py
â”‚   â”‚   â””â”€â”€ seaborn.py
â”‚   â”œâ”€â”€ file
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ docx.py
â”‚   â”‚   â”œâ”€â”€ excel.py
â”‚   â”‚   â”œâ”€â”€ markdown.py
â”‚   â”‚   â”œâ”€â”€ markitdown.py
â”‚   â”‚   â”œâ”€â”€ pandoc.py
â”‚   â”‚   â”œâ”€â”€ pdfplumber.py
â”‚   â”‚   â””â”€â”€ pymupdf.py
â”‚   â”œâ”€â”€ image
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ grid.py
â”‚   â”‚   â”œâ”€â”€ pillow
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ draw.py
â”‚   â”‚   â”‚   â”œâ”€â”€ enhance.py
â”‚   â”‚   â”‚   â””â”€â”€ filter.py
â”‚   â”‚   â””â”€â”€ svg.py
â”‚   â”œâ”€â”€ json.py
â”‚   â”œâ”€â”€ ml
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ sklearn
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ cluster.py
â”‚   â”‚   â”‚   â”œâ”€â”€ compose.py
â”‚   â”‚   â”‚   â”œâ”€â”€ datasets.py
â”‚   â”‚   â”‚   â”œâ”€â”€ decomposition.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ensemble.py
â”‚   â”‚   â”‚   â”œâ”€â”€ feature_selection.py
â”‚   â”‚   â”‚   â”œâ”€â”€ impute.py
â”‚   â”‚   â”‚   â”œâ”€â”€ inspection.py
â”‚   â”‚   â”‚   â”œâ”€â”€ linear_model.py
â”‚   â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â”‚   â”œâ”€â”€ model_selection.py
â”‚   â”‚   â”‚   â”œâ”€â”€ naive_bayes.py
â”‚   â”‚   â”‚   â”œâ”€â”€ neighbors.py
â”‚   â”‚   â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”‚   â”‚   â”œâ”€â”€ svm.py
â”‚   â”‚   â”‚   â”œâ”€â”€ tree.py
â”‚   â”‚   â”‚   â””â”€â”€ visualization.py
â”‚   â”‚   â””â”€â”€ statsmodels
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ discrete.py
â”‚   â”‚       â”œâ”€â”€ glm.py
â”‚   â”‚       â”œâ”€â”€ mixed.py
â”‚   â”‚       â”œâ”€â”€ regression.py
â”‚   â”‚       â””â”€â”€ robust.py
â”‚   â”œâ”€â”€ network
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ beautifulsoup.py
â”‚   â”‚   â”œâ”€â”€ http.py
â”‚   â”‚   â”œâ”€â”€ imap.py
â”‚   â”‚   â””â”€â”€ rss.py
â”‚   â””â”€â”€ ui
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ tk.py
â”œâ”€â”€ nodetool
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ audio.py
â”‚   â”œâ”€â”€ boolean.py
â”‚   â”œâ”€â”€ code.py
â”‚   â”œâ”€â”€ constant.py
â”‚   â”œâ”€â”€ control.py
â”‚   â”œâ”€â”€ date.py
â”‚   â”œâ”€â”€ dictionary.py
â”‚   â”œâ”€â”€ group.py
â”‚   â”œâ”€â”€ image.py
â”‚   â”œâ”€â”€ input.py
â”‚   â”œâ”€â”€ list.py
â”‚   â”œâ”€â”€ math.py
â”‚   â”œâ”€â”€ os.py
â”‚   â”œâ”€â”€ output.py
â”‚   â”œâ”€â”€ text.py
â”‚   â””â”€â”€ video.py
â”œâ”€â”€ ollama
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agents.py
â”‚   â””â”€â”€ text.py
â”œâ”€â”€ openai
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agents.py
â”‚   â”œâ”€â”€ audio.py
â”‚   â”œâ”€â”€ image.py
â”‚   â””â”€â”€ text.py
â””â”€â”€ replicate
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ audio
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ enhance.py
    â”‚   â”œâ”€â”€ generate.py
    â”‚   â”œâ”€â”€ separate.py
    â”‚   â””â”€â”€ transcribe.py
    â”œâ”€â”€ gencode.py
    â”œâ”€â”€ image
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ analyze.py
    â”‚   â”œâ”€â”€ enhance.py
    â”‚   â”œâ”€â”€ face.py
    â”‚   â”œâ”€â”€ generate.py
    â”‚   â”œâ”€â”€ ocr.py
    â”‚   â”œâ”€â”€ process.py
    â”‚   â””â”€â”€ upscale.py
    â”œâ”€â”€ text
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ generate.py
    â””â”€â”€ video
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ analyze.py
        â””â”€â”€ generate.py

## Use Cases ðŸŽ¨
- ðŸŽ¨ **Personal Learning Assistant**: Create chatbots that read and explain your PDFs, e-books, or academic papers
- ðŸ“ **Note Summarization**: Extract key insights from Obsidian or Apple Notes
- ðŸŽ¤ **Voice Memo to Presentation**: Convert recorded ideas into documents
- ðŸ”§ï¸ **Image Generation & Editing**: Create and modify images with advanced AI models
- ðŸŽµ **Audio Processing**: Generate and edit audio content with AI assistance
- ðŸŽ¬ **Video Creation**: Produce and manipulate video content using AI tools
- âš¡ **Automation**: Streamline repetitive tasks with AI-powered scripts

Key Guidelines:
- **Reference Valid Nodes:** When mentioning a node, only reference existing ones. Use the format [Node Type](/help/node_type) for clarity.
- **Use Documentation Search:** Use the documentation search tool to find information about nodes.
- **Use Example Search:** Use the example search tool to find examples of how to use nodes.
- **Answer Precisely:** Be concise, clear, and creative in your responses. Utilize ASCII diagrams if they help explain complex workflows.
- **Focus on Nodetool Features:** Emphasize the visual editor, asset management, model management, workflow execution, and keyboard shortcuts (for example, the help menu in the top right corner).

REFERENCE NODES:
- Format any reference to a node as: [Node Type](/help/node_type)
- Example node link: [Text Generation](/help/huggingface.text.TextGeneration)
- DO NOT ADD http/domain to URLs.

HOW TO ANSWER QUESTIONS:
- Explain any necessary Nodetool features
- KEEP IT BRIEF
- DO NOT OVERTHINK
- BE CONCISE
"""


import PIL.Image


async def create_message(message: Message) -> Mapping[str, str | list[str]]:
    ollama_message: dict[str, str | list[str]] = {
        "role": message.role,
    }

    if isinstance(message.content, list):
        ollama_message["content"] = "\n".join(
            content.text
            for content in message.content
            if isinstance(content, MessageTextContent)
        )
    else:
        ollama_message["content"] = str(message.content)

    return ollama_message


available_functions = {
    "search_docs": search_docs,
}


def convert_results_to_json(obj: Any) -> str:
    if isinstance(obj, BaseModel):
        return obj.model_dump_json()
    elif isinstance(obj, list):
        return json.dumps([convert_results_to_json(item) for item in obj])
    elif isinstance(obj, dict):
        return json.dumps({k: convert_results_to_json(v) for k, v in obj.items()})
    elif isinstance(obj, str):
        return obj
    elif isinstance(obj, bool):
        return str(obj).lower()
    elif isinstance(obj, int):
        return str(obj)
    elif isinstance(obj, float):
        return str(obj)
    else:
        return json.dumps(obj)


async def create_help_answer(
    messages: list[Message], available_tutorials: list[str]
) -> AsyncGenerator[str, None]:
    assert len(messages) > 0

    client = get_ollama_client()

    system_message = ollama.Message(role="system", content=SYSTEM_PROMPT)

    ollama_messages = [await create_message(m) for m in messages]
    all_messages = [system_message] + ollama_messages

    res = await client.chat(
        model="llama3.2:3b",
        messages=all_messages,
        options={"num_ctx": 20000},
        tools=[search_docs],
        stream=True,
    )

    async for part in res:
        if part.message.tool_calls:
            for tool in part.message.tool_calls:
                yield f"Calling tool: {tool.function.name}\n"
                if function_to_call := available_functions.get(tool.function.name):
                    results = function_to_call(**tool.function.arguments)

                    # Add tool results to messages
                    all_messages.append(part.message)
                    all_messages.append(
                        {
                            "role": "tool",
                            "content": convert_results_to_json(results),
                            "name": tool.function.name,
                        }
                    )

                    # Get final response with tool results
                    final_res = await client.chat(
                        model="deepseek-r1:7b",
                        messages=all_messages,
                        options={"num_ctx": 20000},
                        stream=True,
                    )
                    async for chunk in final_res:
                        yield chunk.message.content or ""
        else:
            yield part.message.content or ""


async def test_chat():
    """Simple terminal-based chat tester with readline support"""
    print("Starting chat test (type 'exit' to quit)")
    messages = []

    # Configure readline
    readline.parse_and_bind("tab: complete")
    readline.set_completer(lambda text, state: None)  # Disable default completion

    while True:
        try:
            user_input = input("\n> ")
            if user_input.lower() == "exit":
                break

            messages.append(Message(role="user", content=user_input))

            async for chunk in create_help_answer(messages, available_tutorials=[]):
                print(chunk, end="", flush=True)
            print()

        except KeyboardInterrupt:
            print("\nUse 'exit' to quit")
            continue
        except EOFError:
            break


if __name__ == "__main__":
    # index_core_docs(get_doc_collection())
    # index_documentation(get_doc_collection())
    # index_examples(get_example_collection())
    asyncio.run(test_chat())
