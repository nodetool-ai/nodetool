[
  {
    "title": "Group",
    "description": "A special node type that can contain a subgraph of nodes.\n    group, workflow, structure, organize\n\n    This node type allows for hierarchical structuring of workflows.",
    "namespace": "nodetool.workflows.base_node",
    "node_type": "nodetool.workflows.base_node.Group",
    "layout": "default",
    "properties": [],
    "outputs": [
      {
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": []
  },
  {
    "title": "Llama 3 Chat",
    "description": "Run chat models using the Aime API with Llama 3.1.\n    llm, text generation, language model, ai assistant\n\n    Use cases:\n    - Chat with an AI assistant using Llama 3.1\n    - Generate responses for conversational workflows\n    - Integrate with chat-based applications",
    "namespace": "aime.text",
    "node_type": "aime.text.Llama3Chat",
    "layout": "default",
    "properties": [
      {
        "name": "system_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "You are a friendly assistant.",
        "title": "System Prompt",
        "description": "System prompt that defines the assistant's behavior.",
        "min": null,
        "max": null
      },
      {
        "name": "messages",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "message",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Messages",
        "description": "History of messages in the conversation.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "Prompt to send to the model. If provided, it will add a new message to the conversation.",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Temperature",
        "description": "The temperature to use for response generation.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 40,
        "title": "Top K",
        "description": "The number of highest probability tokens to consider.",
        "min": 1.0,
        "max": null
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.9,
        "title": "Top P",
        "description": "The cumulative probability threshold for token sampling.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "max_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 500,
        "title": "Max Tokens",
        "description": "Maximum number of tokens to generate.",
        "min": 1.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "system_prompt",
      "messages",
      "prompt",
      "temperature",
      "top_k",
      "top_p",
      "max_tokens"
    ]
  },
  {
    "title": "Mixtral Chat",
    "description": "Run chat models using the Aime API with Mixtral.\n    llm, text generation, language model, ai assistant\n\n    Use cases:\n    - Chat with an AI assistant using Mixtral\n    - Generate responses for conversational workflows\n    - Integrate with chat-based applications",
    "namespace": "aime.text",
    "node_type": "aime.text.MixtralChat",
    "layout": "default",
    "properties": [
      {
        "name": "system_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "You are a friendly assistant.",
        "title": "System Prompt",
        "description": "System prompt that defines the assistant's behavior.",
        "min": null,
        "max": null
      },
      {
        "name": "messages",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "message",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Messages",
        "description": "History of messages in the conversation.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "Prompt to send to the model. If provided, it will add a new message to the conversation.",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Temperature",
        "description": "The temperature to use for response generation.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 40,
        "title": "Top K",
        "description": "The number of highest probability tokens to consider.",
        "min": 1.0,
        "max": null
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.9,
        "title": "Top P",
        "description": "The cumulative probability threshold for token sampling.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "max_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 500,
        "title": "Max Tokens",
        "description": "Maximum number of tokens to generate.",
        "min": 1.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "system_prompt",
      "messages",
      "prompt",
      "temperature",
      "top_k",
      "top_p",
      "max_tokens"
    ]
  },
  {
    "title": "Stable Diffusion 3",
    "description": "Generate images using Stable Diffusion 3 through the Aime API.\n    image generation, ai art, stable diffusion\n\n    Use cases:\n    - Generate high-quality images from text descriptions\n    - Create artistic variations of prompts\n    - Produce realistic or stylized imagery",
    "namespace": "aime.image",
    "node_type": "aime.image.StableDiffusion3",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The text prompt describing the desired image.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "out of frame, lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers",
        "title": "Negative Prompt",
        "description": "Text prompt describing elements to avoid in the image.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "An image to use as a starting point for generation.",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "Height of the generated image.",
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "Width of the generated image.",
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "Random seed for generation. Use -1 for random seed.",
        "min": null,
        "max": null
      },
      {
        "name": "num_samples",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Samples",
        "description": "Number of images to generate.",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Steps",
        "description": "Number of denoising steps.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "cfg_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5.0,
        "title": "Cfg Scale",
        "description": "Classifier free guidance scale.",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "denoise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.6,
        "title": "Denoise",
        "description": "Denoising strength.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "negative_prompt",
      "image",
      "height",
      "width",
      "seed",
      "num_samples",
      "steps",
      "cfg_scale",
      "denoise"
    ]
  },
  {
    "title": "Flux",
    "description": "Generate images using Flux through the Aime API.\n    image generation, ai art, flux\n\n    Use cases:\n    - Generate high-quality images from text descriptions\n    - Create artistic variations of prompts\n    - Produce realistic or stylized imagery",
    "namespace": "aime.image",
    "node_type": "aime.image.Flux",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The text prompt describing the desired image.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "An image to use as a starting point for generation.",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "Height of the generated image.",
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "Width of the generated image.",
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "Random seed for generation. Use -1 for random seed.",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Steps",
        "description": "Number of denoising steps.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "guidance",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance",
        "description": "Guidance scale for generation.",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "image2image_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Image2Image Strength",
        "description": "Strength of image-to-image transformation.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image",
      "height",
      "width",
      "seed",
      "steps",
      "guidance",
      "image2image_strength"
    ]
  },
  {
    "title": "Seamless Communication",
    "description": "Translates text from one language to another using the AIME API.",
    "namespace": "aime.translate",
    "node_type": "aime.translate.SeamlessCommunication",
    "layout": "default",
    "properties": [
      {
        "name": "src_lang",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "arb",
            "ben",
            "cat",
            "ces",
            "cmn",
            "cym",
            "dan",
            "deu",
            "eng",
            "est",
            "fin",
            "fra",
            "hin",
            "ind",
            "ita",
            "jpn",
            "kor",
            "mlt",
            "nld",
            "pes",
            "pol",
            "por",
            "ron",
            "rus",
            "slk",
            "spa",
            "swe",
            "swh",
            "tam",
            "tel",
            "tgl",
            "tha",
            "tur",
            "ukr",
            "urd",
            "uzn",
            "vie"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.aime.translate.Language"
        },
        "default": "deu",
        "title": "Source Language",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "tgt_lang",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "arb",
            "ben",
            "cat",
            "ces",
            "cmn",
            "cym",
            "dan",
            "deu",
            "eng",
            "est",
            "fin",
            "fra",
            "hin",
            "ind",
            "ita",
            "jpn",
            "kor",
            "mlt",
            "nld",
            "pes",
            "pol",
            "por",
            "ron",
            "rus",
            "slk",
            "spa",
            "swe",
            "swh",
            "tam",
            "tel",
            "tgl",
            "tha",
            "tur",
            "ukr",
            "urd",
            "uzn",
            "vie"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.aime.translate.Language"
        },
        "default": "eng",
        "title": "Target Language",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "generate_audio",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Generate Audio",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "text_input",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text to Translate",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "text",
        "stream": false
      },
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "audio",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "src_lang",
      "tgt_lang",
      "generate_audio",
      "text_input"
    ]
  },
  {
    "title": "Tortoise TTS",
    "description": "Generate audio from text using the Tortoise TTS API.",
    "namespace": "aime.audio",
    "node_type": "aime.audio.TortoiseTTS",
    "layout": "default",
    "properties": [
      {
        "name": "voice",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "train_grace",
            "train_daws",
            "angie",
            "emma",
            "freeman",
            "jlaw",
            "deniro",
            "train_atkins",
            "train_dreams",
            "train_empire",
            "train_kennard",
            "train_lescault",
            "train_mouse"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.aime.audio.VoiceType"
        },
        "default": "train_grace",
        "title": "Voice",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "preset",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "ultra_fast",
            "fast",
            "standard",
            "high_quality"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.aime.audio.PresetType"
        },
        "default": "standard",
        "title": "Preset",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "text_input",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text to Translate",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "voice",
      "preset",
      "text_input"
    ]
  },
  {
    "title": "Create Note",
    "description": "Create a new note in Apple Notes via AppleScript\n    notes, automation, macos, productivity\n\n    Use cases:\n    - Automatically save information to Notes\n    - Create documentation or records\n    - Save workflow outputs as notes",
    "namespace": "apple.notes",
    "node_type": "apple.notes.CreateNote",
    "layout": "default",
    "properties": [
      {
        "name": "title",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Title",
        "description": "Title of the note",
        "min": null,
        "max": null
      },
      {
        "name": "body",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Body",
        "description": "Content of the note",
        "min": null,
        "max": null
      },
      {
        "name": "folder",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Notes",
        "title": "Folder",
        "description": "Notes folder to save to",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "title",
      "body",
      "folder"
    ]
  },
  {
    "title": "Read Notes",
    "description": "Read notes from Apple Notes via AppleScript using temporary files\n    notes, automation, macos, productivity\n\n    Use cases:\n    - Access your Apple Notes content programmatically\n    - Search through notes using keywords\n    - Get notes content for further processing",
    "namespace": "apple.notes",
    "node_type": "apple.notes.ReadNotes",
    "layout": "default",
    "properties": [
      {
        "name": "search_term",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Search Term",
        "description": "Optional search term to filter notes",
        "min": null,
        "max": null
      },
      {
        "name": "note_limit",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10,
        "title": "Note Limit",
        "description": "Maximum number of notes to export (0 for unlimited)",
        "min": null,
        "max": null
      },
      {
        "name": "note_limit_per_folder",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10,
        "title": "Note Limit Per Folder",
        "description": "Maximum notes per folder (0 for unlimited)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "search_term",
      "note_limit",
      "note_limit_per_folder"
    ]
  },
  {
    "title": "Create Calendar Event",
    "description": "Create a new event in Apple Calendar via AppleScript\n    calendar, automation, macos, productivity\n\n    Use cases:\n    - Automate event creation\n    - Schedule meetings programmatically\n    - Create recurring events",
    "namespace": "apple.calendar",
    "node_type": "apple.calendar.CreateCalendarEvent",
    "layout": "default",
    "properties": [
      {
        "name": "title",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "New Event",
        "title": "Title",
        "description": "Title of the calendar event",
        "min": null,
        "max": null
      },
      {
        "name": "start_date",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 0,
          "month": 0,
          "day": 0,
          "hour": 0,
          "minute": 0,
          "second": 0,
          "microsecond": 0,
          "tzinfo": "UTC",
          "utc_offset": 0
        },
        "title": "Start Date",
        "description": "Start date and time of the event",
        "min": null,
        "max": null
      },
      {
        "name": "end_date",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 0,
          "month": 0,
          "day": 0,
          "hour": 0,
          "minute": 0,
          "second": 0,
          "microsecond": 0,
          "tzinfo": "UTC",
          "utc_offset": 0
        },
        "title": "End Date",
        "description": "End date and time of the event",
        "min": null,
        "max": null
      },
      {
        "name": "calendar_name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Calendar",
        "title": "Calendar Name",
        "description": "Name of the calendar",
        "min": null,
        "max": null
      },
      {
        "name": "location",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Location",
        "description": "Location of the event",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "Description/notes for the event",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "title",
      "start_date",
      "end_date",
      "calendar_name"
    ]
  },
  {
    "title": "Send Message",
    "description": "Send messages using macOS Messages.app via AppleScript\n    messages, imessage, automation, macos, communication\n\n    Use cases:\n    - Send automated notifications via iMessage\n    - Integrate messaging into workflows\n    - Send workflow results to yourself or others",
    "namespace": "apple.messages",
    "node_type": "apple.messages.SendMessage",
    "layout": "default",
    "properties": [
      {
        "name": "recipient",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Recipient",
        "description": "Phone number, email, or contact name to send message to",
        "min": null,
        "max": null
      },
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "Message content to send",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "recipient",
      "text"
    ]
  },
  {
    "title": "Say Text",
    "description": "Speak text using macOS's built-in text-to-speech via AppleScript\n    speech, automation, macos, accessibility\n\n    Use cases:\n    - Add voice notifications to workflows\n    - Create audio feedback\n    - Accessibility features",
    "namespace": "apple.speech",
    "node_type": "apple.speech.SayText",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "Text to be spoken",
        "min": null,
        "max": null
      },
      {
        "name": "rate",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 175,
        "title": "Rate",
        "description": "Speaking rate (words per minute)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "rate"
    ]
  },
  {
    "title": "Claude",
    "description": "Generate natural language responses using Claude AI models.\n    text, llm, chat, generation, anthropic\n\n    Use cases:\n    1. Generate creative writing based on prompts\n    2. Answer questions and provide explanations on various topics\n    3. Assist with tasks like summarization, translation, or code generation\n    4. Engage in multi-turn conversations with context retention\n    5. Analyze and describe images when provided as input",
    "namespace": "anthropic.text",
    "node_type": "anthropic.text.Claude",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "claude-3-opus-20240229",
            "claude-3-haiku-20240307",
            "claude-3-5-sonnet-20240620"
          ],
          "type_args": [],
          "type_name": "nodetool.metadata.types.AnthropicModel"
        },
        "default": "claude-3-5-sonnet-20240620",
        "title": "Model",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "system",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "You are a friendly assistant.",
        "title": "System",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "max_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Max Tokens",
        "description": null,
        "min": 1.0,
        "max": 10000.0
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Temperature",
        "description": null,
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 40,
        "title": "Top K",
        "description": null,
        "min": 1.0,
        "max": 2048.0
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Top P",
        "description": null,
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "system",
      "prompt",
      "image"
    ]
  },
  {
    "title": "Count",
    "description": "Count the number of documents in a collection.\n    chroma, embedding, collection, RAG",
    "namespace": "chroma.collections",
    "node_type": "chroma.collections.Count",
    "layout": "default",
    "properties": [
      {
        "name": "collection",
        "type": {
          "type": "collection",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "collection",
          "name": ""
        },
        "title": "Collection",
        "description": "The collection to count",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "collection"
    ]
  },
  {
    "title": "Get Documents",
    "description": "Get documents from a chroma collection.\n    chroma, embedding, collection, RAG, retrieve",
    "namespace": "chroma.collections",
    "node_type": "chroma.collections.GetDocuments",
    "layout": "default",
    "properties": [
      {
        "name": "collection",
        "type": {
          "type": "collection",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "collection",
          "name": ""
        },
        "title": "Collection",
        "description": "The collection to get",
        "min": null,
        "max": null
      },
      {
        "name": "ids",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Ids",
        "description": "The ids of the documents to get",
        "min": null,
        "max": null
      },
      {
        "name": "limit",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Limit",
        "description": "The limit of the documents to get",
        "min": null,
        "max": null
      },
      {
        "name": "offset",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Offset",
        "description": "The offset of the documents to get",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "collection",
      "ids",
      "limit",
      "offset"
    ]
  },
  {
    "title": "Peek",
    "description": "Peek at the documents in a collection.\n    chroma, embedding, collection, RAG, preview",
    "namespace": "chroma.collections",
    "node_type": "chroma.collections.Peek",
    "layout": "default",
    "properties": [
      {
        "name": "collection",
        "type": {
          "type": "collection",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "collection",
          "name": ""
        },
        "title": "Collection",
        "description": "The collection to peek",
        "min": null,
        "max": null
      },
      {
        "name": "limit",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Limit",
        "description": "The limit of the documents to peek",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "collection",
      "limit"
    ]
  },
  {
    "title": "Index Images",
    "description": "Index a list of image assets or files.\n    chroma, embedding, collection, RAG, index, image, batch",
    "namespace": "chroma.index",
    "node_type": "chroma.index.IndexImages",
    "layout": "default",
    "properties": [
      {
        "name": "collection",
        "type": {
          "type": "collection",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "collection",
          "name": ""
        },
        "title": "Collection",
        "description": "The collection to index",
        "min": null,
        "max": null
      },
      {
        "name": "images",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Images",
        "description": "List of image assets to index",
        "min": null,
        "max": null
      },
      {
        "name": "upsert",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Upsert",
        "description": "Whether to upsert the images",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "collection",
      "images",
      "upsert"
    ]
  },
  {
    "title": "Index Texts",
    "description": "Index a list of text assets or files.\n    chroma, embedding, collection, RAG, index, text, batch",
    "namespace": "chroma.index",
    "node_type": "chroma.index.IndexTexts",
    "layout": "default",
    "properties": [
      {
        "name": "collection",
        "type": {
          "type": "collection",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "collection",
          "name": ""
        },
        "title": "Collection",
        "description": "The collection to index",
        "min": null,
        "max": null
      },
      {
        "name": "docs",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "text",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Docs",
        "description": "Dictionary of ID to text content pairs to index",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "collection",
      "docs"
    ]
  },
  {
    "title": "Index Image",
    "description": "Index a single image asset.\n    chroma, embedding, collection, RAG, index, image",
    "namespace": "chroma.index",
    "node_type": "chroma.index.IndexImage",
    "layout": "default",
    "properties": [
      {
        "name": "collection",
        "type": {
          "type": "collection",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "collection",
          "name": ""
        },
        "title": "Collection",
        "description": "The collection to index",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Image asset to index",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "collection",
      "image"
    ]
  },
  {
    "title": "Index Text",
    "description": "Index a single text asset.\n    chroma, embedding, collection, RAG, index, text",
    "namespace": "chroma.index",
    "node_type": "chroma.index.IndexText",
    "layout": "default",
    "properties": [
      {
        "name": "collection",
        "type": {
          "type": "collection",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "collection",
          "name": ""
        },
        "title": "Collection",
        "description": "The collection to index",
        "min": null,
        "max": null
      },
      {
        "name": "text",
        "type": {
          "type": "text",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "text",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Text",
        "description": "Text asset to index",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "collection",
      "text"
    ]
  },
  {
    "title": "Index Text Chunk",
    "description": "Index a single text chunk.\n    chroma, embedding, collection, RAG, index, text, chunk",
    "namespace": "chroma.index",
    "node_type": "chroma.index.IndexTextChunk",
    "layout": "default",
    "properties": [
      {
        "name": "collection",
        "type": {
          "type": "collection",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "collection",
          "name": ""
        },
        "title": "Collection",
        "description": "The collection to index",
        "min": null,
        "max": null
      },
      {
        "name": "text_chunk",
        "type": {
          "type": "text_chunk",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "text_chunk",
          "text": "",
          "source_id": "",
          "start_index": 0
        },
        "title": "Text Chunk",
        "description": "Text chunk to index",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "collection",
      "text_chunk"
    ]
  },
  {
    "title": "Index Text Chunks",
    "description": "Index multiple text chunks at once.\n    chroma, embedding, collection, RAG, index, text, chunk, batch",
    "namespace": "chroma.index",
    "node_type": "chroma.index.IndexTextChunks",
    "layout": "default",
    "properties": [
      {
        "name": "collection",
        "type": {
          "type": "collection",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "collection",
          "name": ""
        },
        "title": "Collection",
        "description": "The collection to index",
        "min": null,
        "max": null
      },
      {
        "name": "text_chunks",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "text_chunk",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Text Chunks",
        "description": "List of text chunks to index",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "collection",
      "text_chunks"
    ]
  },
  {
    "title": "Index String",
    "description": "Index a string with a Document ID to a collection.\n    chroma, embedding, collection, RAG, index, text, string\n\n    Use cases:\n    - Index documents for a vector search",
    "namespace": "chroma.index",
    "node_type": "chroma.index.IndexString",
    "layout": "default",
    "properties": [
      {
        "name": "collection",
        "type": {
          "type": "collection",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "collection",
          "name": ""
        },
        "title": "Collection",
        "description": "The collection to index",
        "min": null,
        "max": null
      },
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "Text content to index",
        "min": null,
        "max": null
      },
      {
        "name": "document_id",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Document Id",
        "description": "Document ID to associate with the text content",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "collection",
      "text",
      "document_id"
    ]
  },
  {
    "title": "Query Image",
    "description": "Query the index for similar images.",
    "namespace": "chroma.query",
    "node_type": "chroma.query.QueryImage",
    "layout": "default",
    "properties": [
      {
        "name": "collection",
        "type": {
          "type": "collection",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "collection",
          "name": ""
        },
        "title": "Collection",
        "description": "The collection to query",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to query",
        "min": null,
        "max": null
      },
      {
        "name": "n_results",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "N Results",
        "description": "The number of results to return",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "ids",
        "stream": false
      },
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "documents",
        "stream": false
      },
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "metadatas",
        "stream": false
      },
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "distances",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "collection",
      "image",
      "n_results"
    ]
  },
  {
    "title": "Query Text",
    "description": "Query the index for similar text.",
    "namespace": "chroma.query",
    "node_type": "chroma.query.QueryText",
    "layout": "default",
    "properties": [
      {
        "name": "collection",
        "type": {
          "type": "collection",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "collection",
          "name": ""
        },
        "title": "Collection",
        "description": "The collection to query",
        "min": null,
        "max": null
      },
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "The text to query",
        "min": null,
        "max": null
      },
      {
        "name": "n_results",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "N Results",
        "description": "The number of results to return",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "ids",
        "stream": false
      },
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "documents",
        "stream": false
      },
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "metadatas",
        "stream": false
      },
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "distances",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "collection",
      "text",
      "n_results"
    ]
  },
  {
    "title": "CLIPText Encode SDXLRefiner",
    "description": "Encodes text using CLIP for the SDXL refiner model.\n    clip, text, encode, sdxl, refiner\n\n    Use cases:\n    - Prepare text prompts for SDXL refiner model\n    - Incorporate aesthetic scores in text encoding\n    - Generate conditionings for high-resolution image refinement",
    "namespace": "comfy.advanced.conditioning",
    "node_type": "comfy.advanced.conditioning.CLIPTextEncodeSDXLRefiner",
    "layout": "default",
    "properties": [
      {
        "name": "ascore",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 6.0,
        "title": "Ascore",
        "description": "The ascore to use.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "The width to use.",
        "min": null,
        "max": 2048.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "The height to use.",
        "min": null,
        "max": 2048.0
      },
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "The text to encode.",
        "min": null,
        "max": null
      },
      {
        "name": "clip",
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip",
          "name": "",
          "model": null
        },
        "title": "Clip",
        "description": "The CLIP to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "ascore",
      "width",
      "height",
      "text",
      "clip"
    ]
  },
  {
    "title": "CLIPText Encode SDXL",
    "description": "Encodes text using CLIP for the base SDXL model.\n    clip, text, encode, sdxl, base\n\n    Use cases:\n    - Prepare text prompts for base SDXL model\n    - Handle separate global and local text prompts\n    - Generate conditionings with specific crop and target dimensions",
    "namespace": "comfy.advanced.conditioning",
    "node_type": "comfy.advanced.conditioning.CLIPTextEncodeSDXL",
    "layout": "default",
    "properties": [
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "The width to use.",
        "min": null,
        "max": 2048.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "The height to use.",
        "min": null,
        "max": 2048.0
      },
      {
        "name": "crop_w",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Crop W",
        "description": "The crop width to use.",
        "min": null,
        "max": 2048.0
      },
      {
        "name": "crop_h",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Crop H",
        "description": "The crop height to use.",
        "min": null,
        "max": 2048.0
      },
      {
        "name": "target_width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Target Width",
        "description": "The target width to use.",
        "min": null,
        "max": 2048.0
      },
      {
        "name": "target_height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Target Height",
        "description": "The target height to use.",
        "min": null,
        "max": 2048.0
      },
      {
        "name": "text_g",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "CLIP_G",
        "title": "Text G",
        "description": "The global text to encode.",
        "min": null,
        "max": null
      },
      {
        "name": "text_l",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "CLIP_L",
        "title": "Text L",
        "description": "The local text to encode.",
        "min": null,
        "max": null
      },
      {
        "name": "clip",
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip",
          "name": "",
          "model": null
        },
        "title": "Clip",
        "description": "The CLIP to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "width",
      "height",
      "crop_w",
      "crop_h",
      "target_width",
      "target_height",
      "text_g",
      "text_l",
      "clip"
    ]
  },
  {
    "title": "Triple CLIP Loader",
    "description": "Loads three CLIP models.",
    "namespace": "comfy.advanced.loaders",
    "node_type": "comfy.advanced.loaders.TripleCLIPLoader",
    "layout": "default",
    "properties": [
      {
        "name": "clip_name1",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Clip Name1",
        "description": "The name of the first CLIP model to load.",
        "min": null,
        "max": null
      },
      {
        "name": "clip_name2",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Clip Name2",
        "description": "The name of the second CLIP model to load.",
        "min": null,
        "max": null
      },
      {
        "name": "clip_name3",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Clip Name3",
        "description": "The name of the third CLIP model to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "clip",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "clip_name1",
      "clip_name2",
      "clip_name3"
    ]
  },
  {
    "title": "CLIP Text Encode SD3",
    "description": "Encodes text using CLIP for the SD3 model.",
    "namespace": "comfy.advanced.loaders",
    "node_type": "comfy.advanced.loaders.CLIPTextEncodeSD3",
    "layout": "default",
    "properties": [
      {
        "name": "clip",
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip",
          "name": "",
          "model": null
        },
        "title": "Clip",
        "description": "The CLIP model to use for encoding.",
        "min": null,
        "max": null
      },
      {
        "name": "clip_l",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Clip L",
        "description": "The local text to encode.",
        "min": null,
        "max": null
      },
      {
        "name": "clip_g",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Clip G",
        "description": "The global text to encode.",
        "min": null,
        "max": null
      },
      {
        "name": "t5xxl",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "T5Xxl",
        "description": "The T5-XXL text to encode.",
        "min": null,
        "max": null
      },
      {
        "name": "empty_padding",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "none",
            "empty_prompt"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.advanced.loaders.EmptyPaddingEnum"
        },
        "default": "none",
        "title": "Empty Padding",
        "description": "The empty padding method.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "clip",
      "clip_l",
      "clip_g",
      "t5xxl",
      "empty_padding"
    ]
  },
  {
    "title": "ControlNet Apply SD3",
    "description": "Applies a ControlNet to the image.",
    "namespace": "comfy.advanced.loaders",
    "node_type": "comfy.advanced.loaders.ControlNetApplySD3",
    "layout": "default",
    "properties": [
      {
        "name": "positive",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Positive",
        "description": "The positive conditioning.",
        "min": null,
        "max": null
      },
      {
        "name": "negative",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Negative",
        "description": "The negative conditioning.",
        "min": null,
        "max": null
      },
      {
        "name": "control_net",
        "type": {
          "type": "comfy.control_net",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.control_net",
          "name": "",
          "model": null
        },
        "title": "Control Net",
        "description": "The ControlNet to apply.",
        "min": null,
        "max": null
      },
      {
        "name": "vae",
        "type": {
          "type": "comfy.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.vae",
          "name": "",
          "model": null
        },
        "title": "Vae",
        "description": "The VAE to use.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to apply the ControlNet to.",
        "min": null,
        "max": null
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength",
        "description": "The strength of the ControlNet application.",
        "min": 0.0,
        "max": 10.0
      },
      {
        "name": "start_percent",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Start Percent",
        "description": "The start percentage for the ControlNet application.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "end_percent",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "End Percent",
        "description": "The end percentage for the ControlNet application.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "positive",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "negative",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "positive",
      "negative",
      "control_net",
      "vae",
      "image",
      "strength",
      "start_percent",
      "end_percent"
    ]
  },
  {
    "title": "Model Sampling Base",
    "description": "",
    "namespace": "comfy.advanced.model",
    "node_type": "comfy.advanced.model.ModelSamplingBase",
    "layout": "default",
    "properties": [],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": []
  },
  {
    "title": "Model Sampling Discrete",
    "description": "Patches a model for discrete sampling.\n    advanced, model, sampling, discrete\n\n    Use cases:\n    - Apply different sampling methods to a model\n    - Enable zero SNR sampling",
    "namespace": "comfy.advanced.model",
    "node_type": "comfy.advanced.model.ModelSamplingDiscrete",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to patch.",
        "min": null,
        "max": null
      },
      {
        "name": "sampling",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "eps",
            "v_prediction",
            "lcm",
            "x0"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.advanced.model.SamplingEnum"
        },
        "default": "eps",
        "title": "Sampling",
        "description": "The sampling method to use.",
        "min": null,
        "max": null
      },
      {
        "name": "zsnr",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Zsnr",
        "description": "Whether to use zero SNR.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "sampling",
      "zsnr"
    ]
  },
  {
    "title": "Model Sampling Stable Cascade",
    "description": "Patches a model for stable cascade sampling.\n    advanced, model, sampling, stable, cascade\n\n    Use cases:\n    - Apply stable cascade sampling to a model\n    - Adjust shift parameters for stable cascade sampling",
    "namespace": "comfy.advanced.model",
    "node_type": "comfy.advanced.model.ModelSamplingStableCascade",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to patch.",
        "min": null,
        "max": null
      },
      {
        "name": "shift",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2.0,
        "title": "Shift",
        "description": "The shift parameter.",
        "min": 0.0,
        "max": 100.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "shift"
    ]
  },
  {
    "title": "Model Sampling SD3",
    "description": "Patches a model for SD3 sampling.\n    advanced, model, sampling, sd3\n\n    Use cases:\n    - Apply SD3 sampling to a model\n    - Adjust shift parameters for SD3 sampling",
    "namespace": "comfy.advanced.model",
    "node_type": "comfy.advanced.model.ModelSamplingSD3",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to patch.",
        "min": null,
        "max": null
      },
      {
        "name": "shift",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.0,
        "title": "Shift",
        "description": "The shift parameter.",
        "min": 0.0,
        "max": 100.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "shift"
    ]
  },
  {
    "title": "Model Sampling Aura Flow",
    "description": "Patches a model for Aura Flow sampling.\n    advanced, model, sampling, aura, flow\n\n    Use cases:\n    - Apply Aura Flow sampling to a model\n    - Adjust shift parameters for Aura Flow sampling",
    "namespace": "comfy.advanced.model",
    "node_type": "comfy.advanced.model.ModelSamplingAuraFlow",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to patch.",
        "min": null,
        "max": null
      },
      {
        "name": "shift",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.73,
        "title": "Shift",
        "description": "The shift parameter.",
        "min": 0.0,
        "max": 100.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "shift"
    ]
  },
  {
    "title": "Model Sampling Flux",
    "description": "Patches a model for Flux sampling.\n    advanced, model, sampling, flux\n\n    Use cases:\n    - Apply Flux sampling to a model\n    - Adjust shift parameters for Flux sampling",
    "namespace": "comfy.advanced.model",
    "node_type": "comfy.advanced.model.ModelSamplingFlux",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to patch.",
        "min": null,
        "max": null
      },
      {
        "name": "max_shift",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.15,
        "title": "Max Shift",
        "description": "The maximum shift parameter.",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "base_shift",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Base Shift",
        "description": "The base shift parameter.",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "The width of the image.",
        "min": 16.0,
        "max": 16384.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "The height of the image.",
        "min": 16.0,
        "max": 16384.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "max_shift",
      "base_shift",
      "width",
      "height"
    ]
  },
  {
    "title": "Model Sampling Continuous EDM",
    "description": "Patches a model for continuous EDM sampling.\n    advanced, model, sampling, edm, continuous\n\n    Use cases:\n    - Apply continuous EDM sampling to a model\n    - Adjust sigma parameters for continuous EDM sampling",
    "namespace": "comfy.advanced.model",
    "node_type": "comfy.advanced.model.ModelSamplingContinuousEDM",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to patch.",
        "min": null,
        "max": null
      },
      {
        "name": "sampling",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "v_prediction",
            "edm_playground_v2.5",
            "eps"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.advanced.model.SamplingEnumEDM"
        },
        "default": "v_prediction",
        "title": "Sampling",
        "description": "The sampling method to use.",
        "min": null,
        "max": null
      },
      {
        "name": "sigma_max",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 120.0,
        "title": "Sigma Max",
        "description": "The maximum sigma value.",
        "min": 0.0,
        "max": 1000.0
      },
      {
        "name": "sigma_min",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.002,
        "title": "Sigma Min",
        "description": "The minimum sigma value.",
        "min": 0.0,
        "max": 1000.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "sampling",
      "sigma_max",
      "sigma_min"
    ]
  },
  {
    "title": "Model Sampling Continuous V",
    "description": "Patches a model for continuous V sampling.\n    advanced, model, sampling, v, continuous\n\n    Use cases:\n    - Apply continuous V sampling to a model\n    - Adjust sigma parameters for continuous V sampling",
    "namespace": "comfy.advanced.model",
    "node_type": "comfy.advanced.model.ModelSamplingContinuousV",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to patch.",
        "min": null,
        "max": null
      },
      {
        "name": "sampling",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "v_prediction",
            "edm_playground_v2.5",
            "eps"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.advanced.model.SamplingEnumEDM"
        },
        "default": "v_prediction",
        "title": "Sampling",
        "description": "The sampling method to use.",
        "min": null,
        "max": null
      },
      {
        "name": "sigma_max",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 500.0,
        "title": "Sigma Max",
        "description": "The maximum sigma value.",
        "min": 0.0,
        "max": 1000.0
      },
      {
        "name": "sigma_min",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.03,
        "title": "Sigma Min",
        "description": "The minimum sigma value.",
        "min": 0.0,
        "max": 1000.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "sampling",
      "sigma_max",
      "sigma_min"
    ]
  },
  {
    "title": "Rescale CFG",
    "description": "Patches a model for rescale CFG.\n    advanced, model, rescale, cfg\n\n    Use cases:\n    - Adjust the CFG multiplier for a model\n    - Apply rescale CFG to a model",
    "namespace": "comfy.advanced.model",
    "node_type": "comfy.advanced.model.RescaleCFG",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to patch.",
        "min": null,
        "max": null
      },
      {
        "name": "multiplier",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.7,
        "title": "Multiplier",
        "description": "The rescale multiplier.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "multiplier"
    ]
  },
  {
    "title": "Model Sampling LTXV",
    "description": "Patches a model for LTXV sampling.\n    advanced, model, sampling, ltxv\n\n    Use cases:\n    - Modify a model for LTXV sampling\n    - Adjust shift parameters based on latent tokens\n    - Enable advanced sampling techniques",
    "namespace": "comfy.advanced.model",
    "node_type": "comfy.advanced.model.ModelSamplingLTXV",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Model",
        "description": "The model to patch.",
        "min": null,
        "max": null
      },
      {
        "name": "max_shift",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2.05,
        "title": "Max Shift",
        "description": "Maximum shift parameter.",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "base_shift",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.95,
        "title": "Base Shift",
        "description": "Base shift parameter.",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "latent",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Latent",
        "description": "Optional latent input.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "max_shift",
      "base_shift",
      "latent"
    ]
  },
  {
    "title": "CLIP Text Encode (Prompt)",
    "description": "The CLIP Text Encode node can be used to encode a text prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images.",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.CLIPTextEncode",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "The prompt to use.",
        "min": null,
        "max": null
      },
      {
        "name": "clip",
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip",
          "name": "",
          "model": null
        },
        "title": "Clip",
        "description": "The CLIP model to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "clip"
    ]
  },
  {
    "title": "Conditioning (Combine)",
    "description": "The Conditioning (Combine) node can be used to combine multiple conditionings by averaging the predicted noise of the diffusion model. Note that this is different from the Conditioning (Average) node. Here outputs of the diffusion model conditioned on different conditionings (i.e. all parts that make up the conditioning) are averaged out, while the Conditioning (Average) node interpolates the text embeddings that are stored inside the conditioning.",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.ConditioningCombine",
    "layout": "default",
    "properties": [
      {
        "name": "conditioning_1",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning 1",
        "description": "The first conditioning input.",
        "min": null,
        "max": null
      },
      {
        "name": "conditioning_2",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning 2",
        "description": "The second conditioning input.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "conditioning_1",
      "conditioning_2"
    ]
  },
  {
    "title": "Conditioning (Average)",
    "description": "The Conditioning (Average) node can be used to interpolate between two text embeddings according to a strength factor set in conditioning_to_strength.",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.ConditioningAverage",
    "layout": "default",
    "properties": [
      {
        "name": "conditioning_to",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning To",
        "description": "The target conditioning.",
        "min": null,
        "max": null
      },
      {
        "name": "conditioning_from",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning From",
        "description": "The source conditioning.",
        "min": null,
        "max": null
      },
      {
        "name": "conditioning_to_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Conditioning To Strength",
        "description": "The strength of the target conditioning.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "conditioning_to",
      "conditioning_from",
      "conditioning_to_strength"
    ]
  },
  {
    "title": "Conditioning (Concat)",
    "description": "The Conditioning (Concat) node can be used to concatenate two conditionings. This allows for combining different conditioning inputs sequentially, which can be useful for creating more complex guidance for the diffusion model.",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.ConditioningConcat",
    "layout": "default",
    "properties": [
      {
        "name": "conditioning_to",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning To",
        "description": "The conditioning to concatenate to.",
        "min": null,
        "max": null
      },
      {
        "name": "conditioning_from",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning From",
        "description": "The conditioning to concatenate from.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "conditioning_to",
      "conditioning_from"
    ]
  },
  {
    "title": "Conditioning (Set Area)",
    "description": "The Conditioning (Set Area) node can be used to limit a conditioning to a specified area of the image. Together with the Conditioning (Combine) node this can be used to add more control over the composition of the final image.",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.ConditioningSetArea",
    "layout": "default",
    "properties": [
      {
        "name": "conditioning",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning",
        "description": "The conditioning to modify.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 64,
        "title": "Width",
        "description": "The width of the area.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 64,
        "title": "Height",
        "description": "The height of the area.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "x",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "X",
        "description": "The x-coordinate of the top-left corner of the area.",
        "min": 0.0,
        "max": 16384.0
      },
      {
        "name": "y",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Y",
        "description": "The y-coordinate of the top-left corner of the area.",
        "min": 0.0,
        "max": 16384.0
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength",
        "description": "The strength of the conditioning in the set area.",
        "min": 0.0,
        "max": 10.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "conditioning",
      "width",
      "height",
      "x",
      "y",
      "strength"
    ]
  },
  {
    "title": "Conditioning (Set Area with Percentage)",
    "description": "",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.ConditioningSetAreaPercentage",
    "layout": "default",
    "properties": [
      {
        "name": "conditioning",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning",
        "description": "The conditioning to modify.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Width",
        "description": "The width of the area as a percentage of the total width.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "height",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Height",
        "description": "The height of the area as a percentage of the total height.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "x",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "X",
        "description": "The x-coordinate of the top-left corner of the area as a percentage.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "y",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Y",
        "description": "The y-coordinate of the top-left corner of the area as a percentage.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength",
        "description": "The strength of the conditioning in the set area.",
        "min": 0.0,
        "max": 10.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "conditioning",
      "width",
      "height",
      "x",
      "y",
      "strength"
    ]
  },
  {
    "title": "Conditioning (Set Mask)",
    "description": "The Conditioning (Set Mask) node can be used to limit a conditioning to a specified mask. Together with the Conditioning (Combine) node this can be used to add more control over the composition of the final image.",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.ConditioningSetMask",
    "layout": "default",
    "properties": [
      {
        "name": "conditioning",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning",
        "description": "The conditioning to modify.",
        "min": null,
        "max": null
      },
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask",
        "description": "The mask to use for setting the conditioning.",
        "min": null,
        "max": null
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength",
        "description": "The strength of the conditioning within the mask.",
        "min": 0.0,
        "max": 10.0
      },
      {
        "name": "set_cond_area",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "default",
            "mask bounds"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.conditioning.SetConditioningAreaEnum"
        },
        "default": "default",
        "title": "Set Cond Area",
        "description": "Method to determine the area for setting conditioning.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "conditioning",
      "mask",
      "strength",
      "set_cond_area"
    ]
  },
  {
    "title": "Conditioning (Zero Out)",
    "description": "The Conditioning (Zero Out) node can be used to zero out a conditioning. This effectively removes the influence of the conditioning on the diffusion process, which can be useful for creating areas of the image that are not influenced by the prompt or other conditioning inputs.",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.ConditioningZeroOut",
    "layout": "default",
    "properties": [
      {
        "name": "conditioning",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning",
        "description": "The conditioning to be zeroed out.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "conditioning"
    ]
  },
  {
    "title": "Conditioning (Set Timestep Range)",
    "description": "",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.ConditioningSetTimestepRange",
    "layout": "default",
    "properties": [
      {
        "name": "conditioning",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning",
        "description": "The conditioning to set timestep range.",
        "min": null,
        "max": null
      },
      {
        "name": "start",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Start",
        "description": "The start of the timestep range.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "end",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "End",
        "description": "The end of the timestep range.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "conditioning",
      "start",
      "end"
    ]
  },
  {
    "title": "CLIPVision Encode",
    "description": "The CLIP Vision Encode node can be used to encode an image using a CLIP vision model into an embedding that can be used to guide unCLIP diffusion models or as input to style models.",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.CLIPVisionEncode",
    "layout": "default",
    "properties": [
      {
        "name": "clip_vision",
        "type": {
          "type": "comfy.clip_vision",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip_vision",
          "name": "",
          "model": null
        },
        "title": "Clip Vision",
        "description": "The CLIP vision model to use for encoding.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to encode with the CLIP vision model.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.clip_vision_output",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "clip_vision_output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "clip_vision",
      "image"
    ]
  },
  {
    "title": "CLIPSet Last Layer",
    "description": "The CLIP Set Last Layer node can be used to set the CLIP output layer from which to take the text embeddings. Encoding text into an embedding happens by the text being transformed by various layers in the CLIP model. Although traditionally diffusion models are conditioned on the output of the last layer in CLIP, some diffusion models have been conditioned on earlier layers and might not work as well when using the output of the last layer.",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.CLIPSetLastLayer",
    "layout": "default",
    "properties": [
      {
        "name": "clip",
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip",
          "name": "",
          "model": null
        },
        "title": "Clip",
        "description": "The CLIP model to modify.",
        "min": null,
        "max": null
      },
      {
        "name": "stop_at_clip_layer",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Stop At Clip Layer",
        "description": "The index of the last CLIP layer to use.",
        "min": -24.0,
        "max": -1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "clip",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "clip",
      "stop_at_clip_layer"
    ]
  },
  {
    "title": "Apply ControlNet",
    "description": "The Apply ControlNet node can be used to provide further visual guidance to a diffusion model. Unlike unCLIP embeddings, controlnets and T2I adaptors work on any model. By chaining together multiple nodes it is possible to guide the diffusion model using multiple controlNets or T2I adaptors. This can be useful to e.g. hint at the diffusion model where the edges in the final image should be by providing an image containing edge detections along with a controlNet trained on edge detection images to this node.",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.ControlNetApply",
    "layout": "default",
    "properties": [
      {
        "name": "conditioning",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning",
        "description": "The conditioning to apply.",
        "min": null,
        "max": null
      },
      {
        "name": "control_net",
        "type": {
          "type": "comfy.control_net",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.control_net",
          "name": "",
          "model": null
        },
        "title": "Control Net",
        "description": "The control net to apply.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Image",
        "description": "The image to apply to.",
        "min": null,
        "max": null
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength",
        "description": "The strength of the controlnet.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "conditioning",
      "control_net",
      "image",
      "strength"
    ]
  },
  {
    "title": "Apply ControlNet (Advanced)",
    "description": "The Apply ControlNet (Advanced) node provides more fine-grained control over the application of a ControlNet to the diffusion process. It allows for separate positive and negative conditioning, as well as control over the strength and range of application of the ControlNet.",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.ControlNetApplyAdvanced",
    "layout": "default",
    "properties": [
      {
        "name": "positive",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Positive",
        "description": "The positive conditioning to apply.",
        "min": null,
        "max": null
      },
      {
        "name": "negative",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Negative",
        "description": "The negative conditioning to apply.",
        "min": null,
        "max": null
      },
      {
        "name": "control_net",
        "type": {
          "type": "comfy.control_net",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.control_net",
          "name": "",
          "model": null
        },
        "title": "Control Net",
        "description": "The ControlNet to use.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to apply conditioning adjustments to.",
        "min": null,
        "max": null
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength",
        "description": "The strength of conditioning.",
        "min": 0.0,
        "max": 10.0
      },
      {
        "name": "start_percent",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Start Percent",
        "description": "The start percentage from which to apply conditioning.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "end_percent",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "End Percent",
        "description": "The end percentage until which to apply conditioning.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "positive",
      "negative",
      "control_net",
      "image",
      "strength",
      "start_percent",
      "end_percent"
    ]
  },
  {
    "title": "un CLIPConditioning",
    "description": "The unCLIP Conditioning node can be used to incorporate CLIP vision output into the conditioning process. This allows for image-guided generation, where the content and style of an input image can influence the output of the diffusion model.",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.unCLIPConditioning",
    "layout": "default",
    "properties": [
      {
        "name": "conditioning",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning",
        "description": "The conditioning to modify.",
        "min": null,
        "max": null
      },
      {
        "name": "clip_vision_output",
        "type": {
          "type": "comfy.clip_vision_output",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip_vision_output",
          "data": null
        },
        "title": "Clip Vision Output",
        "description": "The CLIP vision output to associate.",
        "min": null,
        "max": null
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength",
        "description": "The strength of the association with the CLIP vision output.",
        "min": -10.0,
        "max": 10.0
      },
      {
        "name": "noise_augmentation",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Noise Augmentation",
        "description": "The amount of noise augmentation to apply.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "conditioning",
      "clip_vision_output",
      "strength",
      "noise_augmentation"
    ]
  },
  {
    "title": "GLIGENText Box Apply",
    "description": "The GLIGEN Textbox Apply node can be used to provide further spatial guidance to a diffusion model, guiding it to generate the specified parts of the prompt in a specific region of the image. Although the text input will accept any text, GLIGEN works best if the input to it is an object that is part of the text prompt.",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.GLIGENTextBoxApply",
    "layout": "default",
    "properties": [
      {
        "name": "conditioning_to",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning To",
        "description": "The input conditioning to modify.",
        "min": null,
        "max": null
      },
      {
        "name": "clip",
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip",
          "name": "",
          "model": null
        },
        "title": "Clip",
        "description": "The CLIP instance to use.",
        "min": null,
        "max": null
      },
      {
        "name": "gligen_textbox_model",
        "type": {
          "type": "comfy.gligen",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.gligen",
          "name": "",
          "model": null
        },
        "title": "Gligen Textbox Model",
        "description": "The GLIGEN textbox model to apply.",
        "min": null,
        "max": null
      },
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "The text to apply.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 64,
        "title": "Width",
        "description": "The width of the text box.",
        "min": 8.0,
        "max": 16384.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 64,
        "title": "Height",
        "description": "The height of the text box.",
        "min": 8.0,
        "max": 16384.0
      },
      {
        "name": "x",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "X",
        "description": "The x position of the text box.",
        "min": 0.0,
        "max": 16384.0
      },
      {
        "name": "y",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Y",
        "description": "The y position of the text box.",
        "min": 0.0,
        "max": 16384.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "conditioning_to",
      "clip",
      "gligen_textbox_model",
      "text",
      "width",
      "height",
      "x",
      "y"
    ]
  },
  {
    "title": "SVD img 2 vid Conditioning",
    "description": "The SVD Image to Video Conditioning node prepares conditioning for transforming a single image into a video sequence. It utilizes CLIP vision encoding and VAE processing to create appropriate conditioning for video generation models.",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.SVD_img2vid_Conditioning",
    "layout": "default",
    "properties": [
      {
        "name": "clip_vision",
        "type": {
          "type": "comfy.clip_vision",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip_vision",
          "name": "",
          "model": null
        },
        "title": "Clip Vision",
        "description": "The CLIP vision model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "init_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Init Image",
        "description": "The initial image to condition on.",
        "min": null,
        "max": null
      },
      {
        "name": "vae",
        "type": {
          "type": "comfy.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.vae",
          "name": "",
          "model": null
        },
        "title": "Vae",
        "description": "The VAE model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "The width of the output.",
        "min": 16.0,
        "max": 16384.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 576,
        "title": "Height",
        "description": "The height of the output.",
        "min": 16.0,
        "max": 16384.0
      },
      {
        "name": "video_frames",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 14,
        "title": "Video Frames",
        "description": "The number of video frames to generate.",
        "min": 1.0,
        "max": 4096.0
      },
      {
        "name": "motion_bucket_id",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 127,
        "title": "Motion Bucket Id",
        "description": "The motion bucket ID.",
        "min": 1.0,
        "max": 1023.0
      },
      {
        "name": "fps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 6,
        "title": "Fps",
        "description": "Frames per second.",
        "min": 1.0,
        "max": 1024.0
      },
      {
        "name": "augmentation_level",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Augmentation Level",
        "description": "The level of augmentation to apply.",
        "min": 0.0,
        "max": 10.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "positive",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "negative",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "clip_vision",
      "init_image",
      "vae",
      "width",
      "height",
      "video_frames",
      "motion_bucket_id",
      "fps",
      "augmentation_level"
    ]
  },
  {
    "title": "Inpaint Model Conditioning",
    "description": "The Inpaint Model Conditioning node prepares conditioning for inpainting models by combining the input image, mask, and conditioning information.",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.InpaintModelConditioning",
    "layout": "default",
    "properties": [
      {
        "name": "positive",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Positive",
        "description": "The positive conditioning to apply.",
        "min": null,
        "max": null
      },
      {
        "name": "negative",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Negative",
        "description": "The negative conditioning to apply.",
        "min": null,
        "max": null
      },
      {
        "name": "vae",
        "type": {
          "type": "comfy.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.vae",
          "name": "",
          "model": null
        },
        "title": "Vae",
        "description": "The VAE model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "pixels",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Pixels",
        "description": "The input image to inpaint.",
        "min": null,
        "max": null
      },
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask",
        "description": "The mask indicating areas to inpaint.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "positive",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "negative",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "positive",
      "negative",
      "vae",
      "pixels",
      "mask"
    ]
  },
  {
    "title": "Apply Style Model",
    "description": "The Style Model Apply node applies a style model to the conditioning using CLIP vision output,\n    allowing for style transfer effects in the generation process.",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.StyleModelApply",
    "layout": "default",
    "properties": [
      {
        "name": "conditioning",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning",
        "description": "The conditioning to modify.",
        "min": null,
        "max": null
      },
      {
        "name": "style_model",
        "type": {
          "type": "comfy.style_model",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.style_model",
          "name": "",
          "model": null
        },
        "title": "Style Model",
        "description": "The style model to apply.",
        "min": null,
        "max": null
      },
      {
        "name": "clip_vision_output",
        "type": {
          "type": "comfy.clip_vision_output",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip_vision_output",
          "data": null
        },
        "title": "Clip Vision Output",
        "description": "The CLIP vision output to use for styling.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "conditioning",
      "style_model",
      "clip_vision_output"
    ]
  },
  {
    "title": "LTXV Conditioning",
    "description": "Sets frame rate in the conditioning for LTXV video models.\n    conditioning, ltxv, frame rate\n\n    Use cases:\n    - Specify frame rate for video models\n    - Adjust temporal aspects of video generation\n    - Prepare conditioning for LTXV models",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.LTXVConditioning",
    "layout": "default",
    "properties": [
      {
        "name": "positive",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Positive",
        "description": "Positive conditioning.",
        "min": null,
        "max": null
      },
      {
        "name": "negative",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Negative",
        "description": "Negative conditioning.",
        "min": null,
        "max": null
      },
      {
        "name": "frame_rate",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25.0,
        "title": "Frame Rate",
        "description": "Frame rate for video generation.",
        "min": 0.0,
        "max": 1000.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "positive",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "negative",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "positive",
      "negative",
      "frame_rate"
    ]
  },
  {
    "title": "LTXV Image to Video",
    "description": "Converts an input image to a video latent, applying conditioning.\n    image, video, latent, ltxv\n\n    Use cases:\n    - Initialize video generation from an image\n    - Prepare conditioning for LTXV video models\n    - Transition from image to video in latent space",
    "namespace": "comfy.conditioning",
    "node_type": "comfy.conditioning.LTXVImgToVideo",
    "layout": "default",
    "properties": [
      {
        "name": "positive",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Positive",
        "description": "Positive conditioning.",
        "min": null,
        "max": null
      },
      {
        "name": "negative",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Negative",
        "description": "Negative conditioning.",
        "min": null,
        "max": null
      },
      {
        "name": "vae",
        "type": {
          "type": "comfy.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.vae",
          "name": "",
          "model": null
        },
        "title": "Vae",
        "description": "VAE model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 768,
        "title": "Width",
        "description": "Width of the output video.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Height",
        "description": "Height of the output video.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 97,
        "title": "Length",
        "description": "Length (frames) of the video.",
        "min": 9.0,
        "max": 16384.0
      },
      {
        "name": "batch_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Batch Size",
        "description": "Batch size.",
        "min": 1.0,
        "max": 4096.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "positive",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "negative",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "positive",
      "negative",
      "vae",
      "image",
      "width",
      "height",
      "length",
      "batch_size"
    ]
  },
  {
    "title": "Dense Pose Preprocessor",
    "description": "Estimates dense poses from an image.\n    controlnet, faces_and_poses, densepose",
    "namespace": "comfy.controlnet.faces_and_poses",
    "node_type": "comfy.controlnet.faces_and_poses.DensePosePreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "densepose_r50_fpn_dl.torchscript",
            "densepose_r101_fpn_dl.torchscript"
          ],
          "type_args": [],
          "type_name": "nodetool.common.comfy_node.DensePoseModel"
        },
        "default": "densepose_r50_fpn_dl.torchscript",
        "title": "Model",
        "description": "The model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "cmap",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "Viridis (MagicAnimate)",
            "Parula (CivitAI)"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.controlnet.faces_and_poses.DensePoseCMap"
        },
        "default": "Viridis (MagicAnimate)",
        "title": "Cmap",
        "description": "The color map to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "model",
      "cmap"
    ]
  },
  {
    "title": "DWPose Preprocessor",
    "description": "Estimates poses from an image.\n    controlnet, faces_and_poses, dw_pose",
    "namespace": "comfy.controlnet.faces_and_poses",
    "node_type": "comfy.controlnet.faces_and_poses.DWPose_Preprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "detect_hand",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "enable",
            "disable"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.controlnet.faces_and_poses.Toggle"
        },
        "default": "enable",
        "title": "Detect Hand",
        "description": "Toggle to enable or disable hand detection.",
        "min": null,
        "max": null
      },
      {
        "name": "detect_body",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "enable",
            "disable"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.controlnet.faces_and_poses.Toggle"
        },
        "default": "enable",
        "title": "Detect Body",
        "description": "Toggle to enable or disable body detection.",
        "min": null,
        "max": null
      },
      {
        "name": "detect_face",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "enable",
            "disable"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.controlnet.faces_and_poses.Toggle"
        },
        "default": "enable",
        "title": "Detect Face",
        "description": "Toggle to enable or disable face detection.",
        "min": null,
        "max": null
      },
      {
        "name": "bbox_detector",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "yolox_l.torchscript.pt",
            "yolox_l.onnx",
            "yolo_nas_l_fp16.onnx",
            "yolo_nas_m_fp16.onnx",
            "yolo_nas_s_fp16.onnx"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.controlnet.faces_and_poses.BBoxDetectorModel"
        },
        "default": "yolox_l.torchscript.pt",
        "title": "Bbox Detector",
        "description": "The bounding box detector model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "pose_estimator",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "dw-ll_ucoco_384_bs5.torchscript.pt",
            "dw-ll_ucoco_384.onnx",
            "dw-ll_ucoco.onnx"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.controlnet.faces_and_poses.PoseEstimatorModel"
        },
        "default": "dw-ll_ucoco_384_bs5.torchscript.pt",
        "title": "Pose Estimator",
        "description": "The pose estimator model to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "type",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "detect_hand",
      "detect_body",
      "detect_face",
      "bbox_detector",
      "pose_estimator"
    ]
  },
  {
    "title": "Openpose Preprocessor",
    "description": "Estimates poses from an image.\n    controlnet, faces_and_poses, openpose",
    "namespace": "comfy.controlnet.faces_and_poses",
    "node_type": "comfy.controlnet.faces_and_poses.OpenposePreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "detect_hand",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "enable",
            "disable"
          ],
          "type_args": [],
          "type_name": "nodetool.common.comfy_node.EnableDisable"
        },
        "default": "enable",
        "title": "Detect Hand",
        "description": "Whether to detect hands.",
        "min": null,
        "max": null
      },
      {
        "name": "detect_body",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "enable",
            "disable"
          ],
          "type_args": [],
          "type_name": "nodetool.common.comfy_node.EnableDisable"
        },
        "default": "enable",
        "title": "Detect Body",
        "description": "Whether to detect bodies.",
        "min": null,
        "max": null
      },
      {
        "name": "detect_face",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "enable",
            "disable"
          ],
          "type_args": [],
          "type_name": "nodetool.common.comfy_node.EnableDisable"
        },
        "default": "enable",
        "title": "Detect Face",
        "description": "Whether to detect faces.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "detect_hand",
      "detect_body",
      "detect_face"
    ]
  },
  {
    "title": "SAMPreprocessor",
    "description": "SAM preprocessor.",
    "namespace": "comfy.controlnet.semantic_segmentation",
    "node_type": "comfy.controlnet.semantic_segmentation.SAMPreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution"
    ]
  },
  {
    "title": "Anime Face Sem Seg Preprocessor",
    "description": "AnimeFace semantic segmentation preprocessor.",
    "namespace": "comfy.controlnet.semantic_segmentation",
    "node_type": "comfy.controlnet.semantic_segmentation.AnimeFace_SemSegPreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 512.0,
        "max": 512.0
      },
      {
        "name": "remove_background_using_abgr",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Remove Background Using Abgr",
        "description": "Whether to remove the background.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "remove_background_using_abgr"
    ]
  },
  {
    "title": "One Former COCOSem Seg Preprocessor",
    "description": "OneFormer COCO semantic segmentation preprocessor.",
    "namespace": "comfy.controlnet.semantic_segmentation",
    "node_type": "comfy.controlnet.semantic_segmentation.OneFormerCOCOSemSegPreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution"
    ]
  },
  {
    "title": "One Former ADE 20 K Sem Seg Preprocessor",
    "description": "OneFormer ADE20K semantic segmentation preprocessor.",
    "namespace": "comfy.controlnet.semantic_segmentation",
    "node_type": "comfy.controlnet.semantic_segmentation.OneFormer_ADE20K_SemSegPreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution"
    ]
  },
  {
    "title": "Uniformer Sem Seg Preprocessor",
    "description": "Uniformer semantic segmentation preprocessor.",
    "namespace": "comfy.controlnet.semantic_segmentation",
    "node_type": "comfy.controlnet.semantic_segmentation.UniformerSemSegPreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution"
    ]
  },
  {
    "title": "Le Re SDepth Map Preprocessor",
    "description": "Preprocesses an image for LeReS depth map detection.",
    "namespace": "comfy.controlnet.normal_and_depth",
    "node_type": "comfy.controlnet.normal_and_depth.LeReSDepthMapPreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "rm_nearest",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Rm Nearest",
        "description": "The nearest depth to remove.",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "rm_background",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Rm Background",
        "description": "The background depth to remove.",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "boost",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "enable",
            "disable"
          ],
          "type_args": [],
          "type_name": "nodetool.common.comfy_node.EnableDisable"
        },
        "default": "disable",
        "title": "Boost",
        "description": "Whether to boost the depth map.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "rm_nearest",
      "rm_background",
      "boost"
    ]
  },
  {
    "title": "Inpaint Preprocessor",
    "description": "",
    "namespace": "comfy.controlnet.normal_and_depth",
    "node_type": "comfy.controlnet.normal_and_depth.InpaintPreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to inpaint.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask",
        "description": "The mask to use for inpainting.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "mask"
    ]
  },
  {
    "title": "MIDASNormal Map Preprocessor",
    "description": "Preprocesses an image for MIDAS normal map detection.",
    "namespace": "comfy.controlnet.normal_and_depth",
    "node_type": "comfy.controlnet.normal_and_depth.MIDASNormalMapPreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "a",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 6.283185307179586,
        "title": "A",
        "description": "Parameter 'a' for the MIDAS Normal Map Preprocessor.",
        "min": 0.0,
        "max": 15.707963267948966
      },
      {
        "name": "bg_threshold",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.1,
        "title": "Bg Threshold",
        "description": "Background threshold for the MIDAS Normal Map Preprocessor.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "a",
      "bg_threshold"
    ]
  },
  {
    "title": "MIDASDepth Map Preprocessor",
    "description": "MIDAS depth map detection preprocessor.",
    "namespace": "comfy.controlnet.normal_and_depth",
    "node_type": "comfy.controlnet.normal_and_depth.MIDASDepthMapPreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "a",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 6.283185307179586,
        "title": "A",
        "description": "Parameter 'a' for the MIDAS Depth Map Preprocessor.",
        "min": 0.0,
        "max": 15.707963267948966
      },
      {
        "name": "bg_threshold",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.1,
        "title": "Bg Threshold",
        "description": "Background threshold for the MIDAS Depth Map Preprocessor.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "a",
      "bg_threshold"
    ]
  },
  {
    "title": "BAE Normal Map Preprocessor",
    "description": "BAE normal map detection preprocessor.",
    "namespace": "comfy.controlnet.normal_and_depth",
    "node_type": "comfy.controlnet.normal_and_depth.BAE_Normal_Map_Preprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution"
    ]
  },
  {
    "title": "Zoe Depth Map Preprocessor",
    "description": "Zoe depth map detection preprocessor.",
    "namespace": "comfy.controlnet.normal_and_depth",
    "node_type": "comfy.controlnet.normal_and_depth.ZoeDepthMapPreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution"
    ]
  },
  {
    "title": "Depth Anything V 2 Preprocessor",
    "description": "Depth Anything V2 preprocessor.",
    "namespace": "comfy.controlnet.normal_and_depth",
    "node_type": "comfy.controlnet.normal_and_depth.DepthAnythingV2Preprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "ckpt_name",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "depth_anything_v2_vitl.pth",
            "depth_anything_v2_vitb.pth",
            "depth_anything_v2_vits.pth"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.controlnet.normal_and_depth.DepthAnythingModel"
        },
        "default": "depth_anything_v2_vits.pth",
        "title": "Ckpt Name",
        "description": "The checkpoint name to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "ckpt_name"
    ]
  },
  {
    "title": "Zoe Depth Anything Preprocessor",
    "description": "Zoe depth anything preprocessor.",
    "namespace": "comfy.controlnet.normal_and_depth",
    "node_type": "comfy.controlnet.normal_and_depth.Zoe_DepthAnythingPreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "environment",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "indoor",
            "outdoor"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.controlnet.normal_and_depth.ZoeDepthAnythingEnvironment"
        },
        "default": "indoor",
        "title": "Environment",
        "description": "The environment to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "environment"
    ]
  },
  {
    "title": "DSINE Normal Map Preprocessor",
    "description": "DSINE normal map preprocessor.",
    "namespace": "comfy.controlnet.normal_and_depth",
    "node_type": "comfy.controlnet.normal_and_depth.DSINE_Normal_Map_Preprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "fov",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 60.0,
        "title": "Fov",
        "description": "The field of view to use.",
        "min": 0.0,
        "max": 365.0
      },
      {
        "name": "iterations",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5,
        "title": "Iterations",
        "description": "The number of iterations to use.",
        "min": 1.0,
        "max": 20.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "fov",
      "iterations"
    ]
  },
  {
    "title": "Metric 3 D Depth Map Preprocessor",
    "description": "",
    "namespace": "comfy.controlnet.normal_and_depth",
    "node_type": "comfy.controlnet.normal_and_depth.Metric3D_Depth_Map_Preprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "backbone",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "vit-small",
            "vit-large",
            "vit-giant2"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.controlnet.normal_and_depth.Metric3D_Depth_Map_Backbone"
        },
        "default": "vit-small",
        "title": "Backbone",
        "description": "The backbone to use.",
        "min": null,
        "max": null
      },
      {
        "name": "fx",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1000,
        "title": "Fx",
        "description": "The fx to use.",
        "min": 1.0,
        "max": 16384.0
      },
      {
        "name": "fy",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1000,
        "title": "Fy",
        "description": "The fy to use.",
        "min": 1.0,
        "max": 16384.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "backbone",
      "fx",
      "fy"
    ]
  },
  {
    "title": "Tile Preprocessor",
    "description": "Tile preprocessor.",
    "namespace": "comfy.controlnet.others",
    "node_type": "comfy.controlnet.others.TilePreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "pyrUp_iters",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Pyrup Iters",
        "description": "The number of times to apply pyrUp.",
        "min": 1.0,
        "max": 10.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "pyrUp_iters"
    ]
  },
  {
    "title": "Image Luminance",
    "description": "Detect the luminance of an image.",
    "namespace": "comfy.controlnet.others",
    "node_type": "comfy.controlnet.others.ImageLuminanceDetector",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "gamma_correction",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Gamma Correction",
        "description": "The gamma correction value.",
        "min": 0.1,
        "max": 2.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "gamma_correction"
    ]
  },
  {
    "title": "Image Intensity",
    "description": "Detect the intensity of an image.",
    "namespace": "comfy.controlnet.others",
    "node_type": "comfy.controlnet.others.ImageIntensityDetector",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "gamma_correction",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Gamma Correction",
        "description": "The gamma correction value.",
        "min": 0.1,
        "max": 2.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "gamma_correction"
    ]
  },
  {
    "title": "Binary Preprocessor",
    "description": "",
    "namespace": "comfy.controlnet.line_extractors",
    "node_type": "comfy.controlnet.line_extractors.BinaryPreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "bin_threshold",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Bin Threshold",
        "description": "The threshold for the binary image.",
        "min": 0.0,
        "max": 255.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "bin_threshold"
    ]
  },
  {
    "title": "Canny Edge Preprocessor",
    "description": "Preprocesses an image for canny edge detection.",
    "namespace": "comfy.controlnet.line_extractors",
    "node_type": "comfy.controlnet.line_extractors.CannyEdgePreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "low_threshold",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Low Threshold",
        "description": "The low threshold to use.",
        "min": null,
        "max": null
      },
      {
        "name": "high_threshold",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 200,
        "title": "High Threshold",
        "description": "The high threshold to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "low_threshold",
      "high_threshold"
    ]
  },
  {
    "title": "Lineart Preprocessor",
    "description": "",
    "namespace": "comfy.controlnet.line_extractors",
    "node_type": "comfy.controlnet.line_extractors.LineartPreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "coarse",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "enable",
            "disable"
          ],
          "type_args": [],
          "type_name": "nodetool.common.comfy_node.EnableDisable"
        },
        "default": "disable",
        "title": "Coarse",
        "description": "Whether to use coarse lineart.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "coarse"
    ]
  },
  {
    "title": "Manga 2 Anime Line Art Preprocessor",
    "description": "Preprocesses an image for manga to anime lineart.",
    "namespace": "comfy.controlnet.line_extractors",
    "node_type": "comfy.controlnet.line_extractors.Manga2Anime_LineArt_Preprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution"
    ]
  },
  {
    "title": "Lineart Standard Preprocessor",
    "description": "Preprocesses an image for standard lineart.",
    "namespace": "comfy.controlnet.line_extractors",
    "node_type": "comfy.controlnet.line_extractors.LineartStandardPreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "guassian_sigma",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 6.0,
        "title": "Guassian Sigma",
        "description": "The Gaussian sigma value for preprocessing.",
        "min": null,
        "max": null
      },
      {
        "name": "intensity_threshold",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8,
        "title": "Intensity Threshold",
        "description": "The intensity threshold value for preprocessing.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "guassian_sigma",
      "intensity_threshold"
    ]
  },
  {
    "title": "Pi Di Net Preprocessor",
    "description": "Preprocesses an image for PiDiNet lineart.",
    "namespace": "comfy.controlnet.line_extractors",
    "node_type": "comfy.controlnet.line_extractors.PiDiNetPreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "safe",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "enable",
            "disable"
          ],
          "type_args": [],
          "type_name": "nodetool.common.comfy_node.EnableDisable"
        },
        "default": "enable",
        "title": "Safe",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "safe"
    ]
  },
  {
    "title": "Anime Line Art Preprocessor",
    "description": "Preprocesses an image for anime lineart.",
    "namespace": "comfy.controlnet.line_extractors",
    "node_type": "comfy.controlnet.line_extractors.AnimeLineArtPreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution"
    ]
  },
  {
    "title": "HEDPreprocessor",
    "description": "Preprocesses an image for HED lineart.",
    "namespace": "comfy.controlnet.line_extractors",
    "node_type": "comfy.controlnet.line_extractors.HEDPreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "safe",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "enable",
            "disable"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.controlnet.line_extractors.SafeMode"
        },
        "default": "enable",
        "title": "Safe",
        "description": "Whether to use safe mode.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "safe"
    ]
  },
  {
    "title": "Scribble Preprocessor",
    "description": "Preprocesses an image for scribble lineart.",
    "namespace": "comfy.controlnet.line_extractors",
    "node_type": "comfy.controlnet.line_extractors.ScribblePreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution"
    ]
  },
  {
    "title": "Scribble XDo GPreprocessor",
    "description": "Preprocesses an image for scribble lineart.",
    "namespace": "comfy.controlnet.line_extractors",
    "node_type": "comfy.controlnet.line_extractors.ScribbleXDoGPreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "threshold",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 32,
        "title": "Threshold",
        "description": null,
        "min": 1.0,
        "max": 64.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "threshold"
    ]
  },
  {
    "title": "Any Line Preprocessor",
    "description": "Preprocesses an image for any lineart.",
    "namespace": "comfy.controlnet.line_extractors",
    "node_type": "comfy.controlnet.line_extractors.AnyLinePreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "merge_with_lineart",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "lineart_standard",
        "title": "Merge With Lineart",
        "description": "The lineart to merge with.",
        "min": null,
        "max": null
      },
      {
        "name": "lineart_lower_bound",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Lineart Lower Bound",
        "description": "The lower bound for lineart.",
        "min": null,
        "max": null
      },
      {
        "name": "lineart_upper_bound",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Lineart Upper Bound",
        "description": "The upper bound for lineart.",
        "min": null,
        "max": null
      },
      {
        "name": "object_min_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 36,
        "title": "Object Min Size",
        "description": "The minimum size for objects.",
        "min": null,
        "max": null
      },
      {
        "name": "object_connectivity",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Object Connectivity",
        "description": "The connectivity for objects.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "merge_with_lineart",
      "lineart_lower_bound",
      "lineart_upper_bound",
      "object_min_size",
      "object_connectivity"
    ]
  },
  {
    "title": "Diffusion Edge Preprocessor",
    "description": "Preprocesses an image for diffusion edge detection.",
    "namespace": "comfy.controlnet.line_extractors",
    "node_type": "comfy.controlnet.line_extractors.DiffusionEdge_Preprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "environment",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "indoor",
            "urban",
            "neutral"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.controlnet.line_extractors.DiffusionEdge_Preprocessor_Environment"
        },
        "default": "indoor",
        "title": "Environment",
        "description": "The environment to use.",
        "min": null,
        "max": null
      },
      {
        "name": "patch_batch_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Patch Batch Size",
        "description": "The patch batch size to use.",
        "min": 1.0,
        "max": 16.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution",
      "environment",
      "patch_batch_size"
    ]
  },
  {
    "title": "Color Preprocessor",
    "description": "Color preprocessor.",
    "namespace": "comfy.controlnet.t2i",
    "node_type": "comfy.controlnet.t2i.ColorPreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution"
    ]
  },
  {
    "title": "Shuffle Preprocessor",
    "description": "Shuffle preprocessor.",
    "namespace": "comfy.controlnet.t2i",
    "node_type": "comfy.controlnet.t2i.ShufflePreprocessor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to preprocess.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Resolution",
        "description": "The width of the image to generate.",
        "min": 64.0,
        "max": 16384.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "resolution"
    ]
  },
  {
    "title": "CLIPText Encode SDXLSimplified",
    "description": "Encode text for SDXL models with simplified parameters.\n    text, encoding, SDXL\n\n    Use cases:\n    - Generate SDXL-compatible text embeddings\n    - Prepare text inputs for SDXL image generation\n    - Customize text encoding for SDXL workflows",
    "namespace": "comfy.essentials.conditioning",
    "node_type": "comfy.essentials.conditioning.CLIPTextEncodeSDXLSimplified",
    "layout": "default",
    "properties": [
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "Width of the target image.",
        "min": 0.0,
        "max": 8192.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "Height of the target image.",
        "min": 0.0,
        "max": 8192.0
      },
      {
        "name": "size_cond_factor",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Size Cond Factor",
        "description": "Size conditioning factor.",
        "min": 1.0,
        "max": 16.0
      },
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "Input text to encode.",
        "min": null,
        "max": null
      },
      {
        "name": "clip",
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip",
          "name": "",
          "model": null
        },
        "title": "Clip",
        "description": "CLIP model to use for encoding.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "width",
      "height",
      "size_cond_factor",
      "text",
      "clip"
    ]
  },
  {
    "title": "Conditioning Combine Multiple",
    "description": "Combine multiple conditioning inputs.\n    conditioning, combine, merge\n\n    Use cases:\n    - Merge different text embeddings\n    - Combine various conditioning signals\n    - Create complex conditioning for advanced image generation",
    "namespace": "comfy.essentials.conditioning",
    "node_type": "comfy.essentials.conditioning.ConditioningCombineMultiple",
    "layout": "default",
    "properties": [
      {
        "name": "conditioning_1",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning 1",
        "description": "First conditioning input.",
        "min": null,
        "max": null
      },
      {
        "name": "conditioning_2",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning 2",
        "description": "Second conditioning input.",
        "min": null,
        "max": null
      },
      {
        "name": "conditioning_3",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Conditioning 3",
        "description": "Optional third conditioning input.",
        "min": null,
        "max": null
      },
      {
        "name": "conditioning_4",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Conditioning 4",
        "description": "Optional fourth conditioning input.",
        "min": null,
        "max": null
      },
      {
        "name": "conditioning_5",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Conditioning 5",
        "description": "Optional fifth conditioning input.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "conditioning_1",
      "conditioning_2",
      "conditioning_3",
      "conditioning_4",
      "conditioning_5"
    ]
  },
  {
    "title": "SD 3 Negative Conditioning",
    "description": "Generate negative conditioning for Stable Diffusion 3 models.\n    conditioning, negative, SD3\n\n    Use cases:\n    - Create negative prompts for SD3\n    - Fine-tune image generation by specifying what not to include\n    - Implement advanced prompt engineering techniques for SD3",
    "namespace": "comfy.essentials.conditioning",
    "node_type": "comfy.essentials.conditioning.SD3NegativeConditioning",
    "layout": "default",
    "properties": [
      {
        "name": "conditioning",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning",
        "description": "Input conditioning to modify.",
        "min": null,
        "max": null
      },
      {
        "name": "end",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.1,
        "title": "End",
        "description": "End point for negative conditioning.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "conditioning",
      "end"
    ]
  },
  {
    "title": "Image Enhance Difference",
    "description": "Enhance the difference between two images.\n    image, difference, comparison\n\n    Use cases:\n    - Highlight changes between image versions\n    - Analyze image modifications\n    - Create visual effects based on image differences",
    "namespace": "comfy.essentials.image",
    "node_type": "comfy.essentials.image.ImageEnhanceDifference",
    "layout": "default",
    "properties": [
      {
        "name": "image1",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image1",
        "description": "The first image",
        "min": null,
        "max": null
      },
      {
        "name": "image2",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image2",
        "description": "The second image",
        "min": null,
        "max": null
      },
      {
        "name": "exponent",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.75,
        "title": "Exponent",
        "description": "Exponent for difference calculation",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image1",
      "image2",
      "exponent"
    ]
  },
  {
    "title": "Image Batch Multiple",
    "description": "Combine multiple images into a batch.\n    batch, combine, multiple\n\n    Use cases:\n    - Prepare image sets for batch processing\n    - Merge images from different sources\n    - Create image collections for analysis",
    "namespace": "comfy.essentials.image",
    "node_type": "comfy.essentials.image.ImageBatchMultiple",
    "layout": "default",
    "properties": [
      {
        "name": "image_1",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image 1",
        "description": "First image in the batch",
        "min": null,
        "max": null
      },
      {
        "name": "method",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "lanczos",
        "title": "Method",
        "description": "Interpolation method for resizing",
        "min": null,
        "max": null
      },
      {
        "name": "image_2",
        "type": {
          "type": "image",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Image 2",
        "description": "Second image (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "image_3",
        "type": {
          "type": "image",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Image 3",
        "description": "Third image (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "image_4",
        "type": {
          "type": "image",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Image 4",
        "description": "Fourth image (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "image_5",
        "type": {
          "type": "image",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Image 5",
        "description": "Fifth image (optional)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image_1",
      "method",
      "image_2",
      "image_3",
      "image_4",
      "image_5"
    ]
  },
  {
    "title": "Image Expand Batch",
    "description": "Expand an image batch to a specified size.\n    batch, expand, resize\n\n    Use cases:\n    - Increase batch size for processing\n    - Duplicate images to meet batch requirements\n    - Adjust batch size for model input",
    "namespace": "comfy.essentials.image",
    "node_type": "comfy.essentials.image.ImageExpandBatch",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image batch",
        "min": null,
        "max": null
      },
      {
        "name": "size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 16,
        "title": "Size",
        "description": "Target batch size",
        "min": 1.0,
        "max": null
      },
      {
        "name": "method",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "expand",
        "title": "Method",
        "description": "Method for expanding the batch",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "size",
      "method"
    ]
  },
  {
    "title": "Image From Batch",
    "description": "Extract a subset of images from a batch.\n    batch, extract, subset\n\n    Use cases:\n    - Select specific images from a larger batch\n    - Divide a batch into smaller sets\n    - Isolate images for individual processing",
    "namespace": "comfy.essentials.image",
    "node_type": "comfy.essentials.image.ImageFromBatch",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image batch",
        "min": null,
        "max": null
      },
      {
        "name": "start",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Start",
        "description": "Starting index",
        "min": 0.0,
        "max": null
      },
      {
        "name": "length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Length",
        "description": "Number of images to extract",
        "min": -1.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "start",
      "length"
    ]
  },
  {
    "title": "Image List To Batch",
    "description": "Convert a list of images to an image batch.\n    list, batch, convert\n\n    Use cases:\n    - Prepare individual images for batch processing\n    - Combine images from different sources into a batch\n    - Standardize image formats for model input",
    "namespace": "comfy.essentials.image",
    "node_type": "comfy.essentials.image.ImageListToBatch",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Image",
        "description": "List of input images",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Image Composite From Mask Batch",
    "description": "Create a composite image from two images and a mask in batch.\n    composite, mask, batch\n\n    Use cases:\n    - Blend multiple image pairs using masks\n    - Create layered effects for image sets\n    - Batch process image compositions",
    "namespace": "comfy.essentials.image",
    "node_type": "comfy.essentials.image.ImageCompositeFromMaskBatch",
    "layout": "default",
    "properties": [
      {
        "name": "image_from",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image From",
        "description": "Source image batch",
        "min": null,
        "max": null
      },
      {
        "name": "image_to",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image To",
        "description": "Destination image batch",
        "min": null,
        "max": null
      },
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask",
        "description": "Mask for compositing",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image_from",
      "image_to",
      "mask"
    ]
  },
  {
    "title": "Image Composite",
    "description": "Composite one image onto another at specified coordinates.\n    composite, overlay, position\n\n    Use cases:\n    - Add watermarks or logos to images\n    - Create collages or image layouts\n    - Overlay elements on background images",
    "namespace": "comfy.essentials.image",
    "node_type": "comfy.essentials.image.ImageComposite",
    "layout": "default",
    "properties": [
      {
        "name": "destination",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Destination",
        "description": "Destination image",
        "min": null,
        "max": null
      },
      {
        "name": "source",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Source",
        "description": "Source image to composite",
        "min": null,
        "max": null
      },
      {
        "name": "x",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "X",
        "description": "X coordinate for placement",
        "min": null,
        "max": null
      },
      {
        "name": "y",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Y",
        "description": "Y coordinate for placement",
        "min": null,
        "max": null
      },
      {
        "name": "offset_x",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Offset X",
        "description": "X offset",
        "min": null,
        "max": null
      },
      {
        "name": "offset_y",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Offset Y",
        "description": "Y offset",
        "min": null,
        "max": null
      },
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Mask",
        "description": "Optional mask for compositing",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "destination",
      "source",
      "x",
      "y",
      "offset_x",
      "offset_y",
      "mask"
    ]
  },
  {
    "title": "Image Resize",
    "description": "Resize an image to specified dimensions.\n    resize, scale, dimensions\n\n    Use cases:\n    - Standardize image sizes for processing\n    - Create thumbnails or previews\n    - Adjust images for specific display requirements",
    "namespace": "comfy.essentials.image",
    "node_type": "comfy.essentials.image.ImageResize",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Width",
        "description": "Target width",
        "min": 0.0,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Height",
        "description": "Target height",
        "min": 0.0,
        "max": null
      },
      {
        "name": "interpolation",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "nearest",
        "title": "Interpolation",
        "description": "Interpolation method",
        "min": null,
        "max": null
      },
      {
        "name": "method",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "stretch",
        "title": "Method",
        "description": "Resizing method",
        "min": null,
        "max": null
      },
      {
        "name": "condition",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "always",
        "title": "Condition",
        "description": "Condition for resizing",
        "min": null,
        "max": null
      },
      {
        "name": "multiple_of",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Multiple Of",
        "description": "Ensure dimensions are multiple of this value",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "width",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "height",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "width",
      "height",
      "interpolation",
      "method",
      "condition",
      "multiple_of"
    ]
  },
  {
    "title": "Image Flip",
    "description": "Flip an image horizontally or vertically.\n    flip, mirror, rotate\n\n    Use cases:\n    - Create mirror images\n    - Augment data for machine learning\n    - Correct image orientations",
    "namespace": "comfy.essentials.image",
    "node_type": "comfy.essentials.image.ImageFlip",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      },
      {
        "name": "axis",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "x",
        "title": "Axis",
        "description": "Axis to flip (x, y, or xy)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "axis"
    ]
  },
  {
    "title": "Image Crop",
    "description": "Crop an image to specified dimensions and position.\n    crop, trim, extract\n\n    Use cases:\n    - Focus on specific areas of images\n    - Remove unwanted parts of images\n    - Create uniform image sizes from varied inputs",
    "namespace": "comfy.essentials.image",
    "node_type": "comfy.essentials.image.ImageCrop",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 256,
        "title": "Width",
        "description": "Crop width",
        "min": 0.0,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 256,
        "title": "Height",
        "description": "Crop height",
        "min": 0.0,
        "max": null
      },
      {
        "name": "position",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "center",
        "title": "Position",
        "description": "Crop position",
        "min": null,
        "max": null
      },
      {
        "name": "x_offset",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "X Offset",
        "description": "X offset for cropping",
        "min": null,
        "max": null
      },
      {
        "name": "y_offset",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Y Offset",
        "description": "Y offset for cropping",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "x",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "y",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "width",
      "height",
      "position",
      "x_offset",
      "y_offset"
    ]
  },
  {
    "title": "Image Tile",
    "description": "Divide an image into tiles.\n    tile, grid, partition\n\n    Use cases:\n    - Prepare images for tiled processing\n    - Create image mosaics\n    - Analyze image sections separately",
    "namespace": "comfy.essentials.image",
    "node_type": "comfy.essentials.image.ImageTile",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      },
      {
        "name": "rows",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Rows",
        "description": "Number of rows",
        "min": 1.0,
        "max": 256.0
      },
      {
        "name": "cols",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Cols",
        "description": "Number of columns",
        "min": 1.0,
        "max": 256.0
      },
      {
        "name": "overlap",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Overlap",
        "description": "Overlap between tiles",
        "min": 0.0,
        "max": 0.5
      },
      {
        "name": "overlap_x",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Overlap X",
        "description": "X overlap in pixels",
        "min": 0.0,
        "max": null
      },
      {
        "name": "overlap_y",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Overlap Y",
        "description": "Y overlap in pixels",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "tile_width",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "tile_height",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "overlap_x",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "overlap_y",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "rows",
      "cols",
      "overlap",
      "overlap_x",
      "overlap_y"
    ]
  },
  {
    "title": "Image Untile",
    "description": "Reconstruct an image from tiles.\n    untile, merge, reconstruct\n\n    Use cases:\n    - Combine processed image tiles\n    - Reconstruct images after tiled analysis\n    - Create panoramas from image sections",
    "namespace": "comfy.essentials.image",
    "node_type": "comfy.essentials.image.ImageUntile",
    "layout": "default",
    "properties": [
      {
        "name": "tiles",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Tiles",
        "description": "Tiled image input",
        "min": null,
        "max": null
      },
      {
        "name": "overlap_x",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Overlap X",
        "description": "X overlap between tiles",
        "min": 0.0,
        "max": null
      },
      {
        "name": "overlap_y",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Overlap Y",
        "description": "Y overlap between tiles",
        "min": 0.0,
        "max": null
      },
      {
        "name": "rows",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Rows",
        "description": "Number of rows",
        "min": 1.0,
        "max": 256.0
      },
      {
        "name": "cols",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Cols",
        "description": "Number of columns",
        "min": 1.0,
        "max": 256.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tiles",
      "overlap_x",
      "overlap_y",
      "rows",
      "cols"
    ]
  },
  {
    "title": "Image Color Match",
    "description": "Match the color distribution of one image to another.\n    color, match, transfer\n\n    Use cases:\n    - Harmonize colors across multiple images\n    - Apply color grading effects\n    - Correct color inconsistencies in image sets",
    "namespace": "comfy.essentials.image",
    "node_type": "comfy.essentials.image.ImageColorMatch",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      },
      {
        "name": "reference",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Reference",
        "description": "Reference image for color matching",
        "min": null,
        "max": null
      },
      {
        "name": "color_space",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "LAB",
        "title": "Color Space",
        "description": "Color space for matching",
        "min": null,
        "max": null
      },
      {
        "name": "factor",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Factor",
        "description": "Strength of color matching",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "device",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "auto",
        "title": "Device",
        "description": "Computation device",
        "min": null,
        "max": null
      },
      {
        "name": "batch_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Batch Size",
        "description": "Batch size for processing",
        "min": 0.0,
        "max": null
      },
      {
        "name": "reference_mask",
        "type": {
          "type": "comfy.mask",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Reference Mask",
        "description": "Optional mask for reference image",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "reference",
      "color_space",
      "factor",
      "device",
      "batch_size",
      "reference_mask"
    ]
  },
  {
    "title": "Image Smart Sharpen",
    "description": "Apply intelligent sharpening to an image.\n    sharpen, enhance, detail\n\n    Use cases:\n    - Improve image clarity and detail\n    - Enhance edges while preserving smooth areas\n    - Prepare images for high-quality display or printing",
    "namespace": "comfy.essentials.image",
    "node_type": "comfy.essentials.image.ImageSmartSharpen",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      },
      {
        "name": "noise_radius",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7,
        "title": "Noise Radius",
        "description": "Radius for noise reduction",
        "min": 1.0,
        "max": 25.0
      },
      {
        "name": "preserve_edges",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.75,
        "title": "Preserve Edges",
        "description": "Edge preservation strength",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "sharpen",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5.0,
        "title": "Sharpen",
        "description": "Sharpening intensity",
        "min": 0.0,
        "max": 25.0
      },
      {
        "name": "ratio",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Ratio",
        "description": "Blend ratio of sharpened and original image",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "noise_radius",
      "preserve_edges",
      "sharpen",
      "ratio"
    ]
  },
  {
    "title": "Image Preview From Latent",
    "description": "Generate a preview image from a latent representation.\n    preview, latent, decode\n\n    Use cases:\n    - Visualize latent space representations\n    - Debug generative model outputs\n    - Create quick previews of latent manipulations",
    "namespace": "comfy.essentials.image",
    "node_type": "comfy.essentials.image.ImagePreviewFromLatent",
    "layout": "default",
    "properties": [
      {
        "name": "latent",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Latent",
        "description": "Input latent representation",
        "min": null,
        "max": null
      },
      {
        "name": "vae",
        "type": {
          "type": "comfy.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.vae",
          "name": "",
          "model": null
        },
        "title": "Vae",
        "description": "VAE model for decoding",
        "min": null,
        "max": null
      },
      {
        "name": "tile_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Tile Size",
        "description": "Tile size for decoding",
        "min": 0.0,
        "max": 4096.0
      },
      {
        "name": "image",
        "type": {
          "type": "str",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "none",
        "title": "Image",
        "description": "Optional input image",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "width",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "height",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "latent",
      "vae",
      "tile_size",
      "image"
    ]
  },
  {
    "title": "Noise From Image",
    "description": "Generate noise based on an input image.\n    noise, generate, image-based\n\n    Use cases:\n    - Create custom noise for image processing\n    - Generate texture-like noise patterns\n    - Produce image-specific distortion effects",
    "namespace": "comfy.essentials.image",
    "node_type": "comfy.essentials.image.NoiseFromImage",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      },
      {
        "name": "noise_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Noise Strength",
        "description": "Strength of noise",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "noise_size",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Noise Size",
        "description": "Size of noise features",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "color_noise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.2,
        "title": "Color Noise",
        "description": "Amount of color noise",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "mask_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Mask Strength",
        "description": "Strength of mask application",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "mask_scale_diff",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Mask Scale Diff",
        "description": "Scale difference for mask",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "mask_contrast",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Mask Contrast",
        "description": "Contrast of mask",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "saturation",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2.0,
        "title": "Saturation",
        "description": "Saturation of noise",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "contrast",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Contrast",
        "description": "Contrast of noise",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "blur",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Blur",
        "description": "Blur amount for noise",
        "min": 0.0,
        "max": 10.0
      },
      {
        "name": "noise_mask",
        "type": {
          "type": "image",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Noise Mask",
        "description": "Optional mask for noise application",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "noise_strength",
      "noise_size",
      "color_noise",
      "mask_strength",
      "mask_scale_diff",
      "mask_contrast",
      "saturation",
      "contrast",
      "blur",
      "noise_mask"
    ]
  },
  {
    "title": "Mask Blur",
    "description": "Apply Gaussian blur to a mask.\n    mask, blur, smoothing\n\n    Use cases:\n    - Soften mask edges for smoother transitions\n    - Reduce noise or artifacts in masks\n    - Create gradient effects in masks",
    "namespace": "comfy.essentials.mask",
    "node_type": "comfy.essentials.mask.MaskBlur",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask",
        "description": "The input mask to blur.",
        "min": null,
        "max": null
      },
      {
        "name": "amount",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 6,
        "title": "Amount",
        "description": "Blur amount.",
        "min": 0.0,
        "max": 256.0
      },
      {
        "name": "device",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "auto",
        "title": "Device",
        "description": "Device to perform blur on.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "amount",
      "device"
    ]
  },
  {
    "title": "Mask Flip",
    "description": "Flip a mask along specified axis.\n    mask, flip, mirror\n\n    Use cases:\n    - Create symmetrical masks\n    - Correct orientation of imported masks\n    - Generate variations of existing masks",
    "namespace": "comfy.essentials.mask",
    "node_type": "comfy.essentials.mask.MaskFlip",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask",
        "description": "The input mask to flip.",
        "min": null,
        "max": null
      },
      {
        "name": "axis",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "x",
        "title": "Axis",
        "description": "Axis to flip along: 'x', 'y', or 'xy'.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "axis"
    ]
  },
  {
    "title": "Mask Preview",
    "description": "Generate a preview image of a mask.\n    mask, preview, visualization\n\n    Use cases:\n    - Visualize mask content during workflow\n    - Debug mask generation steps\n    - Export mask as viewable image",
    "namespace": "comfy.essentials.mask",
    "node_type": "comfy.essentials.mask.MaskPreview",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask",
        "description": "The mask to preview.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "mask"
    ]
  },
  {
    "title": "Mask Batch",
    "description": "Combine multiple masks into a batch.\n    mask, batch, combine\n\n    Use cases:\n    - Prepare multiple masks for batch processing\n    - Combine masks from different sources\n    - Create mask sequences for animations",
    "namespace": "comfy.essentials.mask",
    "node_type": "comfy.essentials.mask.MaskBatch",
    "layout": "default",
    "properties": [
      {
        "name": "mask1",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask1",
        "description": "First mask to batch.",
        "min": null,
        "max": null
      },
      {
        "name": "mask2",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask2",
        "description": "Second mask to batch.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "mask1",
      "mask2"
    ]
  },
  {
    "title": "Mask Expand Batch",
    "description": "Expand a mask batch to a specified size.\n    mask, batch, expand\n\n    Use cases:\n    - Increase the number of masks in a batch\n    - Replicate masks for extended animations\n    - Adjust mask batch size for compatibility",
    "namespace": "comfy.essentials.mask",
    "node_type": "comfy.essentials.mask.MaskExpandBatch",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask",
        "description": "The mask batch to expand.",
        "min": null,
        "max": null
      },
      {
        "name": "size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 16,
        "title": "Size",
        "description": "Target batch size.",
        "min": 1.0,
        "max": null
      },
      {
        "name": "method",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "expand",
        "title": "Method",
        "description": "Method for expanding the batch.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "size",
      "method"
    ]
  },
  {
    "title": "Mask Bounding Box",
    "description": "Compute the bounding box of a mask.\n    mask, bounding box, crop\n\n    Use cases:\n    - Focus processing on relevant parts of a mask\n    - Automatically crop masks to content\n    - Extract region of interest from masks",
    "namespace": "comfy.essentials.mask",
    "node_type": "comfy.essentials.mask.MaskBoundingBox",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask",
        "description": "The input mask.",
        "min": null,
        "max": null
      },
      {
        "name": "padding",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Padding",
        "description": "Padding around bounding box.",
        "min": 0.0,
        "max": 4096.0
      },
      {
        "name": "blur",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Blur",
        "description": "Blur amount for mask edges.",
        "min": 0.0,
        "max": 256.0
      },
      {
        "name": "image_optional",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Image Optional",
        "description": "Optional image to crop alongside mask.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      },
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "x",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "y",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "width",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "height",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "padding",
      "blur",
      "image_optional"
    ]
  },
  {
    "title": "Mask From Color",
    "description": "Create a mask from a specific color in an image.\n    mask, color, extraction\n\n    Use cases:\n    - Extract objects of a specific color\n    - Create masks for color-coded regions\n    - Isolate elements based on color information",
    "namespace": "comfy.essentials.mask",
    "node_type": "comfy.essentials.mask.MaskFromColor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image.",
        "min": null,
        "max": null
      },
      {
        "name": "red",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 255,
        "title": "Red",
        "description": "Red component of target color.",
        "min": 0.0,
        "max": 255.0
      },
      {
        "name": "green",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 255,
        "title": "Green",
        "description": "Green component of target color.",
        "min": 0.0,
        "max": 255.0
      },
      {
        "name": "blue",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 255,
        "title": "Blue",
        "description": "Blue component of target color.",
        "min": 0.0,
        "max": 255.0
      },
      {
        "name": "threshold",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Threshold",
        "description": "Color matching threshold.",
        "min": 0.0,
        "max": 127.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "red",
      "green",
      "blue",
      "threshold"
    ]
  },
  {
    "title": "Mask From Segmentation",
    "description": "Generate masks from image segmentation.\n    mask, segmentation, color quantization\n\n    Use cases:\n    - Create masks for distinct regions in an image\n    - Separate image elements based on color\n    - Prepare masks for selective processing",
    "namespace": "comfy.essentials.mask",
    "node_type": "comfy.essentials.mask.MaskFromSegmentation",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image to segment.",
        "min": null,
        "max": null
      },
      {
        "name": "segments",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 6,
        "title": "Segments",
        "description": "Number of color segments.",
        "min": 1.0,
        "max": 16.0
      },
      {
        "name": "remove_isolated_pixels",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Remove Isolated Pixels",
        "description": "Size of isolated pixel areas to remove.",
        "min": 0.0,
        "max": 32.0
      },
      {
        "name": "remove_small_masks",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Remove Small Masks",
        "description": "Relative size of small masks to remove.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "fill_holes",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Fill Holes",
        "description": "Whether to fill holes in masks.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "segments",
      "remove_isolated_pixels",
      "remove_small_masks",
      "fill_holes"
    ]
  },
  {
    "title": "Mask Fix",
    "description": "Apply various fixes and adjustments to a mask.\n    mask, fix, adjust\n\n    Use cases:\n    - Clean up noisy or imperfect masks\n    - Refine mask edges and shapes\n    - Prepare masks for specific processing requirements",
    "namespace": "comfy.essentials.mask",
    "node_type": "comfy.essentials.mask.MaskFix",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask",
        "description": "The input mask to fix.",
        "min": null,
        "max": null
      },
      {
        "name": "erode_dilate",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Erode Dilate",
        "description": "Erode (negative) or dilate (positive) mask.",
        "min": -256.0,
        "max": 256.0
      },
      {
        "name": "fill_holes",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Fill Holes",
        "description": "Size of holes to fill.",
        "min": 0.0,
        "max": 128.0
      },
      {
        "name": "remove_isolated_pixels",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Remove Isolated Pixels",
        "description": "Size of isolated pixel areas to remove.",
        "min": 0.0,
        "max": 32.0
      },
      {
        "name": "smooth",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Smooth",
        "description": "Smoothing amount for mask edges.",
        "min": 0.0,
        "max": 256.0
      },
      {
        "name": "blur",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Blur",
        "description": "Blur amount for entire mask.",
        "min": 0.0,
        "max": 256.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "erode_dilate",
      "fill_holes",
      "remove_isolated_pixels",
      "smooth",
      "blur"
    ]
  },
  {
    "title": "Transition Mask",
    "description": "Generate a sequence of transition masks.\n    mask, transition, animation\n\n    Use cases:\n    - Create smooth transitions between images or videos\n    - Generate mask sequences for special effects\n    - Produce animated mask patterns",
    "namespace": "comfy.essentials.mask",
    "node_type": "comfy.essentials.mask.TransitionMask",
    "layout": "default",
    "properties": [
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Width",
        "description": "Width of the mask.",
        "min": 1.0,
        "max": 8192.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Height",
        "description": "Height of the mask.",
        "min": 1.0,
        "max": 8192.0
      },
      {
        "name": "frames",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 16,
        "title": "Frames",
        "description": "Total number of frames.",
        "min": 1.0,
        "max": 9999.0
      },
      {
        "name": "start_frame",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Start Frame",
        "description": "Frame to start transition.",
        "min": 0.0,
        "max": null
      },
      {
        "name": "end_frame",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 9999,
        "title": "End Frame",
        "description": "Frame to end transition.",
        "min": 0.0,
        "max": null
      },
      {
        "name": "transition_type",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "horizontal slide",
        "title": "Transition Type",
        "description": "Type of transition effect.",
        "min": null,
        "max": null
      },
      {
        "name": "timing_function",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "linear",
        "title": "Timing Function",
        "description": "Timing function for transition.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "width",
      "height",
      "frames",
      "start_frame",
      "end_frame",
      "transition_type",
      "timing_function"
    ]
  },
  {
    "title": "Simple Math Float",
    "description": "Represent a floating-point number.\n    float, number, value\n\n    Use cases:\n    - Input precise decimal values\n    - Represent fractional numbers in calculations\n    - Provide flexible numeric inputs",
    "namespace": "comfy.essentials.misc",
    "node_type": "comfy.essentials.misc.SimpleMathFloat",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Value",
        "description": "Floating-point value.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "value",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "Simple Math Percent",
    "description": "Represent a percentage value.\n    percent, ratio, proportion\n\n    Use cases:\n    - Input percentage values for scaling operations\n    - Represent probabilities or ratios\n    - Control strength of effects or blending",
    "namespace": "comfy.essentials.misc",
    "node_type": "comfy.essentials.misc.SimpleMathPercent",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Value",
        "description": "Percentage value (0-1).",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "value",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "Simple Math Int",
    "description": "Represent an integer number.\n    integer, number, value\n\n    Use cases:\n    - Input whole number values\n    - Specify counts or indices\n    - Provide discrete numeric inputs",
    "namespace": "comfy.essentials.misc",
    "node_type": "comfy.essentials.misc.SimpleMathInt",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Value",
        "description": "Integer value.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "value",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "Simple Math Slider",
    "description": "Provide a slider for float input.\n    slider, float, range\n\n    Use cases:\n    - Intuitive input for ranged values\n    - Fine-tune parameters visually\n    - Provide bounded numeric inputs",
    "namespace": "comfy.essentials.misc",
    "node_type": "comfy.essentials.misc.SimpleMathSlider",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Value",
        "description": "Slider value.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "value",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "Simple Math Boolean",
    "description": "Represent a boolean value.\n    boolean, toggle, switch\n\n    Use cases:\n    - Provide on/off switches for features\n    - Control conditional logic\n    - Toggle between two states",
    "namespace": "comfy.essentials.misc",
    "node_type": "comfy.essentials.misc.SimpleMathBoolean",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Value",
        "description": "Boolean value.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "value",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "Simple Math",
    "description": "Perform custom mathematical operations.\n    math, calculation, expression\n\n    Use cases:\n    - Evaluate complex mathematical expressions\n    - Combine multiple numeric inputs\n    - Implement custom numeric logic",
    "namespace": "comfy.essentials.misc",
    "node_type": "comfy.essentials.misc.SimpleMath",
    "layout": "default",
    "properties": [
      {
        "name": "a",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 0.0,
        "title": "A",
        "description": "First optional value.",
        "min": null,
        "max": null
      },
      {
        "name": "b",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 0.0,
        "title": "B",
        "description": "Second optional value.",
        "min": null,
        "max": null
      },
      {
        "name": "c",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 0.0,
        "title": "C",
        "description": "Third optional value.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Value",
        "description": "Mathematical expression to evaluate.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "int_result",
        "stream": false
      },
      {
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "float_result",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "a",
      "b",
      "c",
      "value"
    ]
  },
  {
    "title": "Simple Math Condition",
    "description": "Perform conditional mathematical operations.\n    condition, math, branching\n\n    Use cases:\n    - Implement if-else logic with mathematical outcomes\n    - Create dynamic value selection based on conditions\n    - Combine conditional and mathematical operations",
    "namespace": "comfy.essentials.misc",
    "node_type": "comfy.essentials.misc.SimpleMathCondition",
    "layout": "default",
    "properties": [
      {
        "name": "a",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "A",
        "description": "First optional value.",
        "min": null,
        "max": null
      },
      {
        "name": "b",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "B",
        "description": "Second optional value.",
        "min": null,
        "max": null
      },
      {
        "name": "c",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "C",
        "description": "Third optional value.",
        "min": null,
        "max": null
      },
      {
        "name": "evaluate",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Evaluate",
        "description": "Condition to evaluate.",
        "min": null,
        "max": null
      },
      {
        "name": "on_true",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "On True",
        "description": "Expression to evaluate if condition is true.",
        "min": null,
        "max": null
      },
      {
        "name": "on_false",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "On False",
        "description": "Expression to evaluate if condition is false.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "int_result",
        "stream": false
      },
      {
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "float_result",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "a",
      "b",
      "c",
      "evaluate",
      "on_true",
      "on_false"
    ]
  },
  {
    "title": "Simple Condition",
    "description": "Perform a simple conditional operation.\n    condition, branching, logic\n\n    Use cases:\n    - Implement basic if-else logic\n    - Route between two possible values based on a condition\n    - Create dynamic workflows with branching",
    "namespace": "comfy.essentials.misc",
    "node_type": "comfy.essentials.misc.SimpleCondition",
    "layout": "default",
    "properties": [
      {
        "name": "evaluate",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Evaluate",
        "description": "Condition to evaluate.",
        "min": null,
        "max": null
      },
      {
        "name": "on_true",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "On True",
        "description": "Value to return if condition is true.",
        "min": null,
        "max": null
      },
      {
        "name": "on_false",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "On False",
        "description": "Value to return if condition is false.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "value",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "evaluate",
      "on_true",
      "on_false"
    ]
  },
  {
    "title": "Simple Comparison",
    "description": "Perform a comparison between two values.\n    comparison, logic, equality\n\n    Use cases:\n    - Compare numeric or other values\n    - Create boolean flags based on comparisons\n    - Implement decision logic in workflows",
    "namespace": "comfy.essentials.misc",
    "node_type": "comfy.essentials.misc.SimpleComparison",
    "layout": "default",
    "properties": [
      {
        "name": "a",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "A",
        "description": "First value to compare.",
        "min": null,
        "max": null
      },
      {
        "name": "b",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "B",
        "description": "Second value to compare.",
        "min": null,
        "max": null
      },
      {
        "name": "comparison",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "==",
        "title": "Comparison",
        "description": "Comparison operator.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "result",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "a",
      "b",
      "comparison"
    ]
  },
  {
    "title": "Console Debug",
    "description": "Output debug information to the console.\n    debug, logging, console\n\n    Use cases:\n    - Print variable values for debugging\n    - Log intermediate results in complex workflows\n    - Verify data flow through nodes",
    "namespace": "comfy.essentials.misc",
    "node_type": "comfy.essentials.misc.ConsoleDebug",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Value",
        "description": "Value to debug.",
        "min": null,
        "max": null
      },
      {
        "name": "prefix",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Value:",
        "title": "Prefix",
        "description": "Prefix for the debug output.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value",
      "prefix"
    ]
  },
  {
    "title": "Debug Tensor Shape",
    "description": "Output the shape of a tensor for debugging.\n    debug, tensor, shape\n\n    Use cases:\n    - Verify tensor dimensions in workflows\n    - Debug shape mismatches in tensor operations\n    - Inspect complex nested tensor structures",
    "namespace": "comfy.essentials.misc",
    "node_type": "comfy.essentials.misc.DebugTensorShape",
    "layout": "default",
    "properties": [
      {
        "name": "tensor",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Tensor",
        "description": "Tensor or structure containing tensors to inspect.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensor"
    ]
  },
  {
    "title": "Batch Count",
    "description": "Count the number of items in a batch.\n    batch, count, size\n\n    Use cases:\n    - Determine the size of batched data\n    - Verify batch dimensions in workflows\n    - Adapt processing based on batch size",
    "namespace": "comfy.essentials.misc",
    "node_type": "comfy.essentials.misc.BatchCount",
    "layout": "default",
    "properties": [
      {
        "name": "batch",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Batch",
        "description": "Batch to count items from.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "count",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "batch"
    ]
  },
  {
    "title": "Model Compile",
    "description": "Compile a PyTorch model for optimized execution.\n    model, compilation, optimization\n\n    Use cases:\n    - Optimize model performance\n    - Prepare models for specific execution environments\n    - Fine-tune model compilation settings",
    "namespace": "comfy.essentials.misc",
    "node_type": "comfy.essentials.misc.ModelCompile",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Model",
        "description": "Model to compile.",
        "min": null,
        "max": null
      },
      {
        "name": "fullgraph",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Fullgraph",
        "description": "Use full graph compilation.",
        "min": null,
        "max": null
      },
      {
        "name": "dynamic",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Dynamic",
        "description": "Use dynamic shape compilation.",
        "min": null,
        "max": null
      },
      {
        "name": "mode",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "default",
        "title": "Mode",
        "description": "Compilation mode.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "fullgraph",
      "dynamic",
      "mode"
    ]
  },
  {
    "title": "Remove Latent Mask",
    "description": "Remove the noise mask from a latent sample.\n    latent, mask, cleanup\n\n    Use cases:\n    - Clean up latent representations\n    - Prepare latents for specific processing steps\n    - Remove unwanted mask information",
    "namespace": "comfy.essentials.misc",
    "node_type": "comfy.essentials.misc.RemoveLatentMask",
    "layout": "default",
    "properties": [
      {
        "name": "samples",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Samples",
        "description": "Latent samples to process.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples"
    ]
  },
  {
    "title": "SDXLEmpty Latent Size Picker",
    "description": "Create empty latents with specific sizes for SDXL.\n    latent, size, SDXL\n\n    Use cases:\n    - Initialize latent spaces for SDXL UNets\n    - Prepare custom-sized latents for generation\n    - Set up batch processing with specific dimensions",
    "namespace": "comfy.essentials.misc",
    "node_type": "comfy.essentials.misc.SDXLEmptyLatentSizePicker",
    "layout": "default",
    "properties": [
      {
        "name": "resolution",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "1024x1024 (1.0)",
        "title": "Resolution",
        "description": "Predefined resolution option.",
        "min": null,
        "max": null
      },
      {
        "name": "batch_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Batch Size",
        "description": "Number of latents in the batch.",
        "min": 1.0,
        "max": 4096.0
      },
      {
        "name": "width_override",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Width Override",
        "description": "Custom width (if non-zero).",
        "min": 0.0,
        "max": 8192.0
      },
      {
        "name": "height_override",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Height Override",
        "description": "Custom height (if non-zero).",
        "min": 0.0,
        "max": 8192.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "width",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "height",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "resolution",
      "batch_size",
      "width_override",
      "height_override"
    ]
  },
  {
    "title": "KSampler Variations Stochastic",
    "description": "Generate variations of an image using stochastic sampling.\n    sampling, variations, stochastic\n\n    Use cases:\n    - Create diverse variations of an image\n    - Explore different sampling outcomes\n    - Generate multiple versions with subtle differences",
    "namespace": "comfy.essentials.sampling",
    "node_type": "comfy.essentials.sampling.KSamplerVariationsStochastic",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to use for sampling",
        "min": null,
        "max": null
      },
      {
        "name": "latent_image",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Latent Image",
        "description": "The input latent image",
        "min": null,
        "max": null
      },
      {
        "name": "noise_seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Noise Seed",
        "description": "Seed for noise generation",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Steps",
        "description": "Number of sampling steps",
        "min": null,
        "max": null
      },
      {
        "name": "cfg",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.0,
        "title": "Cfg",
        "description": "Classifier-free guidance scale",
        "min": null,
        "max": null
      },
      {
        "name": "sampler",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "euler",
        "title": "Sampler",
        "description": "Sampler to use",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "normal",
        "title": "Scheduler",
        "description": "Scheduler to use",
        "min": null,
        "max": null
      },
      {
        "name": "positive",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Positive",
        "description": "Positive conditioning",
        "min": null,
        "max": null
      },
      {
        "name": "negative",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Negative",
        "description": "Negative conditioning",
        "min": null,
        "max": null
      },
      {
        "name": "variation_seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Variation Seed",
        "description": "Seed for variations",
        "min": null,
        "max": null
      },
      {
        "name": "variation_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.2,
        "title": "Variation Strength",
        "description": "Strength of variations",
        "min": null,
        "max": null
      },
      {
        "name": "cfg_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Cfg Scale",
        "description": "Scale for classifier-free guidance",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "latent_image",
      "noise_seed",
      "steps",
      "cfg",
      "sampler",
      "scheduler",
      "positive",
      "negative",
      "variation_seed",
      "variation_strength",
      "cfg_scale"
    ]
  },
  {
    "title": "KSampler Variations With Noise",
    "description": "Generate variations by injecting noise during sampling.\n    sampling, variations, noise\n\n    Use cases:\n    - Add controlled randomness to sampling process\n    - Create variations with noise injection\n    - Fine-tune the balance between original and varied outputs",
    "namespace": "comfy.essentials.sampling",
    "node_type": "comfy.essentials.sampling.KSamplerVariationsWithNoise",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to use for sampling",
        "min": null,
        "max": null
      },
      {
        "name": "latent_image",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Latent Image",
        "description": "The input latent image",
        "min": null,
        "max": null
      },
      {
        "name": "main_seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Main Seed",
        "description": "Main seed for sampling",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Steps",
        "description": "Number of sampling steps",
        "min": null,
        "max": null
      },
      {
        "name": "cfg",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8.0,
        "title": "Cfg",
        "description": "Classifier-free guidance scale",
        "min": null,
        "max": null
      },
      {
        "name": "sampler_name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "euler",
        "title": "Sampler Name",
        "description": "Name of sampler to use",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "normal",
        "title": "Scheduler",
        "description": "Name of scheduler to use",
        "min": null,
        "max": null
      },
      {
        "name": "positive",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Positive",
        "description": "Positive conditioning",
        "min": null,
        "max": null
      },
      {
        "name": "negative",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Negative",
        "description": "Negative conditioning",
        "min": null,
        "max": null
      },
      {
        "name": "variation_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.17,
        "title": "Variation Strength",
        "description": "Strength of variations",
        "min": null,
        "max": null
      },
      {
        "name": "variation_seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 12345,
        "title": "Variation Seed",
        "description": "Seed for variations",
        "min": null,
        "max": null
      },
      {
        "name": "denoise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Denoise",
        "description": "Denoising strength",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "latent_image",
      "main_seed",
      "steps",
      "cfg",
      "sampler_name",
      "scheduler",
      "positive",
      "negative",
      "variation_strength",
      "variation_seed",
      "denoise"
    ]
  },
  {
    "title": "Inject Latent Noise",
    "description": "Inject noise into a latent image.\n    latent, noise, injection\n\n    Use cases:\n    - Add controlled randomness to latent representations\n    - Create variations of latent images\n    - Augment latent space for more diverse outputs",
    "namespace": "comfy.essentials.sampling",
    "node_type": "comfy.essentials.sampling.InjectLatentNoise",
    "layout": "default",
    "properties": [
      {
        "name": "latent",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Latent",
        "description": "The input latent image",
        "min": null,
        "max": null
      },
      {
        "name": "noise_seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Noise Seed",
        "description": "Seed for noise generation",
        "min": null,
        "max": null
      },
      {
        "name": "noise_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Noise Strength",
        "description": "Strength of injected noise",
        "min": null,
        "max": null
      },
      {
        "name": "normalize",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Normalize",
        "description": "Whether to normalize the noise",
        "min": null,
        "max": null
      },
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Mask",
        "description": "Optional mask for noise injection",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "latent",
      "noise_seed",
      "noise_strength",
      "normalize",
      "mask"
    ]
  },
  {
    "title": "Flux Sampler Params",
    "description": "Set up parameters for Flux sampler.\n    sampling, flux, parameters\n\n    Use cases:\n    - Configure advanced sampling parameters\n    - Experiment with different sampling settings\n    - Fine-tune the sampling process for specific outputs",
    "namespace": "comfy.essentials.sampling",
    "node_type": "comfy.essentials.sampling.FluxSamplerParams",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to use",
        "min": null,
        "max": null
      },
      {
        "name": "conditioning",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning",
        "description": "The conditioning to use",
        "min": null,
        "max": null
      },
      {
        "name": "latent_image",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Latent Image",
        "description": "The input latent image",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "?",
        "title": "Seed",
        "description": "Sampling seed",
        "min": null,
        "max": null
      },
      {
        "name": "sampler",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "euler",
        "title": "Sampler",
        "description": "Sampler name",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "simple",
        "title": "Scheduler",
        "description": "Scheduler name",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "20",
        "title": "Steps",
        "description": "Number of steps",
        "min": null,
        "max": null
      },
      {
        "name": "guidance",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "3.5",
        "title": "Guidance",
        "description": "Guidance scale",
        "min": null,
        "max": null
      },
      {
        "name": "max_shift",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Max Shift",
        "description": "Max shift",
        "min": null,
        "max": null
      },
      {
        "name": "base_shift",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Base Shift",
        "description": "Base shift",
        "min": null,
        "max": null
      },
      {
        "name": "denoise",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "1.0",
        "title": "Denoise",
        "description": "Denoising strength",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      },
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "params",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "conditioning",
      "latent_image",
      "seed",
      "sampler",
      "scheduler",
      "steps",
      "guidance",
      "max_shift",
      "base_shift",
      "denoise"
    ]
  },
  {
    "title": "Plot Parameters",
    "description": "Plot sampler parameters alongside generated images.\n    visualization, parameters, plot\n\n    Use cases:\n    - Visualize relationships between parameters and outputs\n    - Compare results across different sampling configurations\n    - Create visual summaries of sampling experiments",
    "namespace": "comfy.essentials.sampling",
    "node_type": "comfy.essentials.sampling.PlotParameters",
    "layout": "default",
    "properties": [
      {
        "name": "images",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Images",
        "description": "The generated images",
        "min": null,
        "max": null
      },
      {
        "name": "params",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {},
        "title": "Params",
        "description": "The sampling parameters",
        "min": null,
        "max": null
      },
      {
        "name": "order_by",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "none",
        "title": "Order By",
        "description": "Parameter to order by",
        "min": null,
        "max": null
      },
      {
        "name": "cols_value",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "none",
        "title": "Cols Value",
        "description": "Parameter for column grouping",
        "min": null,
        "max": null
      },
      {
        "name": "cols_num",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Cols Num",
        "description": "Number of columns (-1 for auto)",
        "min": null,
        "max": null
      },
      {
        "name": "add_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "false",
        "title": "Add Prompt",
        "description": "Whether to add prompt text",
        "min": null,
        "max": null
      },
      {
        "name": "add_params",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "true",
        "title": "Add Params",
        "description": "Whether to add parameter text",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "images",
      "params",
      "order_by",
      "cols_value",
      "cols_num",
      "add_prompt",
      "add_params"
    ]
  },
  {
    "title": "Text Encode For Sampler Params",
    "description": "Encode text for use with sampler parameters.\n    text, encoding, sampling\n\n    Use cases:\n    - Prepare text inputs for advanced sampling techniques\n    - Encode multiple prompts for batch processing\n    - Create structured text inputs for sampling workflows",
    "namespace": "comfy.essentials.sampling",
    "node_type": "comfy.essentials.sampling.TextEncodeForSamplerParams",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "The input text to encode",
        "min": null,
        "max": null
      },
      {
        "name": "clip",
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip",
          "name": "",
          "model": null
        },
        "title": "Clip",
        "description": "The CLIP model to use for encoding",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "clip"
    ]
  },
  {
    "title": "Sampler Select Helper",
    "description": "Helper node for selecting samplers.\n    sampling, selection, helper\n\n    Use cases:\n    - Simplify sampler selection in workflows\n    - Create preset sampler configurations\n    - Batch process with multiple samplers",
    "namespace": "comfy.essentials.sampling",
    "node_type": "comfy.essentials.sampling.SamplerSelectHelper",
    "layout": "default",
    "properties": [
      {
        "name": "samplers",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "bool",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Samplers",
        "description": "List of boolean flags for samplers",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "string",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samplers"
    ]
  },
  {
    "title": "Scheduler Select Helper",
    "description": "Helper node for selecting schedulers.\n    scheduling, selection, helper\n\n    Use cases:\n    - Simplify scheduler selection in workflows\n    - Create preset scheduler configurations\n    - Batch process with multiple schedulers",
    "namespace": "comfy.essentials.sampling",
    "node_type": "comfy.essentials.sampling.SchedulerSelectHelper",
    "layout": "default",
    "properties": [
      {
        "name": "schedulers",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "bool",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Schedulers",
        "description": "List of boolean flags for schedulers",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "string",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "schedulers"
    ]
  },
  {
    "title": "Load CLIPSeg Models",
    "description": "Load CLIP segmentation models.\n    segmentation, CLIP, model loading\n\n    Use cases:\n    - Prepare CLIP segmentation models for image analysis\n    - Load pre-trained models for semantic segmentation\n    - Initialize segmentation pipeline",
    "namespace": "comfy.essentials.segmentation",
    "node_type": "comfy.essentials.segmentation.LoadCLIPSegModels",
    "layout": "default",
    "properties": [],
    "outputs": [
      {
        "type": {
          "type": "tuple",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "clip_seg",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": []
  },
  {
    "title": "Apply CLIPSeg",
    "description": "Apply CLIP segmentation to an image.\n    segmentation, CLIP, image analysis\n\n    Use cases:\n    - Perform semantic segmentation on images\n    - Extract specific objects or regions from images\n    - Create masks based on text prompts",
    "namespace": "comfy.essentials.segmentation",
    "node_type": "comfy.essentials.segmentation.ApplyCLIPSeg",
    "layout": "default",
    "properties": [
      {
        "name": "clip_seg",
        "type": {
          "type": "tuple",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [
          null,
          null
        ],
        "title": "Clip Seg",
        "description": "The CLIP segmentation models",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image to segment",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "Text prompt for segmentation",
        "min": null,
        "max": null
      },
      {
        "name": "threshold",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.4,
        "title": "Threshold",
        "description": "Segmentation threshold",
        "min": null,
        "max": null
      },
      {
        "name": "smooth",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 9,
        "title": "Smooth",
        "description": "Smoothing factor",
        "min": null,
        "max": null
      },
      {
        "name": "dilate",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Dilate",
        "description": "Dilation factor",
        "min": null,
        "max": null
      },
      {
        "name": "blur",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Blur",
        "description": "Blur factor",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "clip_seg",
      "image",
      "prompt",
      "threshold",
      "smooth",
      "dilate",
      "blur"
    ]
  },
  {
    "title": "Draw Text",
    "description": "Draw text on an image or create a new image with text.\n    text, image, drawing\n\n    Use cases:\n    - Add captions or labels to images\n    - Create text-based images for graphics or designs\n    - Overlay text on existing images with customizable styles",
    "namespace": "comfy.essentials.text",
    "node_type": "comfy.essentials.text.DrawText",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Hello, World!",
        "title": "Text",
        "description": "The text to draw",
        "min": null,
        "max": null
      },
      {
        "name": "font",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Font",
        "description": "Font file name",
        "min": null,
        "max": null
      },
      {
        "name": "size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 56,
        "title": "Size",
        "description": "Font size",
        "min": 1.0,
        "max": 9999.0
      },
      {
        "name": "color",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "#FFFFFF",
        "title": "Color",
        "description": "Text color in hex format",
        "min": null,
        "max": null
      },
      {
        "name": "background_color",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "#00000000",
        "title": "Background Color",
        "description": "Background color in hex format",
        "min": null,
        "max": null
      },
      {
        "name": "shadow_distance",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Shadow Distance",
        "description": "Shadow distance",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "shadow_blur",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Shadow Blur",
        "description": "Shadow blur amount",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "shadow_color",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "#000000",
        "title": "Shadow Color",
        "description": "Shadow color in hex format",
        "min": null,
        "max": null
      },
      {
        "name": "horizontal_align",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "left",
            "center",
            "right"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.essentials.text.HorizontalAlign"
        },
        "default": "left",
        "title": "Horizontal Align",
        "description": "Horizontal alignment",
        "min": null,
        "max": null
      },
      {
        "name": "vertical_align",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "top",
            "center",
            "bottom"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.essentials.text.VerticalAlign"
        },
        "default": "top",
        "title": "Vertical Align",
        "description": "Vertical alignment",
        "min": null,
        "max": null
      },
      {
        "name": "offset_x",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Offset X",
        "description": "Horizontal offset",
        "min": -10000.0,
        "max": 10000.0
      },
      {
        "name": "offset_y",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Offset Y",
        "description": "Vertical offset",
        "min": -10000.0,
        "max": 10000.0
      },
      {
        "name": "direction",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "ltr",
            "rtl"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.essentials.text.Direction"
        },
        "default": "ltr",
        "title": "Direction",
        "description": "Text direction",
        "min": null,
        "max": null
      },
      {
        "name": "img_composite",
        "type": {
          "type": "image",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Img Composite",
        "description": "Optional background image",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "font",
      "size",
      "color",
      "background_color",
      "shadow_distance",
      "shadow_blur",
      "shadow_color",
      "horizontal_align",
      "vertical_align",
      "offset_x",
      "offset_y",
      "direction",
      "img_composite"
    ]
  },
  {
    "title": "CLIP Text Encode Flux",
    "description": "The CLIP Text Encode Flux node can be used to encode a text prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images.",
    "namespace": "comfy.flux",
    "node_type": "comfy.flux.CLIPTextEncodeFlux",
    "layout": "default",
    "properties": [
      {
        "name": "clip",
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip",
          "name": "",
          "model": null
        },
        "title": "Clip",
        "description": "The CLIP model to use for encoding.",
        "min": null,
        "max": null
      },
      {
        "name": "clip_l",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Clip L",
        "description": "The text to encode.",
        "min": null,
        "max": null
      },
      {
        "name": "t5xxl",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "T5Xxl",
        "description": "The text to encode.",
        "min": null,
        "max": null
      },
      {
        "name": "guidance",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance",
        "description": "The guidance value to use for encoding.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "clip",
      "clip_l",
      "t5xxl",
      "guidance"
    ]
  },
  {
    "title": "Flux Guidance",
    "description": "The Flux Guidance node can be used to append guidance to a conditioning.",
    "namespace": "comfy.flux",
    "node_type": "comfy.flux.FluxGuidance",
    "layout": "default",
    "properties": [
      {
        "name": "conditioning",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning",
        "description": "The conditioning to append guidance to.",
        "min": null,
        "max": null
      },
      {
        "name": "guidance",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance",
        "description": "The guidance value to append.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "conditioning",
      "guidance"
    ]
  },
  {
    "title": "Empty Image",
    "description": "Generates an empty image.",
    "namespace": "comfy.generate",
    "node_type": "comfy.generate.EmptyImage",
    "layout": "default",
    "properties": [
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Width",
        "description": "The width of the empty image.",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Height",
        "description": "The height of the empty image.",
        "min": null,
        "max": null
      },
      {
        "name": "batch_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Batch Size",
        "description": "The batch size for the empty images.",
        "min": null,
        "max": null
      },
      {
        "name": "color",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Color",
        "description": "The default color for the image, represented as an integer.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "width",
      "height",
      "batch_size",
      "color"
    ]
  },
  {
    "title": "Save Audio",
    "description": "Save an audio file to a specified folder.\n    audio, folder, name\n\n    Use cases:\n    - Save generated audio files with timestamps\n    - Organize outputs into specific folders\n    - Create backups of generated audio",
    "namespace": "nodetool.audio",
    "node_type": "nodetool.audio.SaveAudio",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "folder",
        "type": {
          "type": "folder",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "folder",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Folder",
        "description": "The folder to save the audio file to. ",
        "min": null,
        "max": null
      },
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "%Y-%m-%d-%H-%M-%S.opus",
        "title": "Name",
        "description": "\n        The name of the audio file.\n        You can use time and date variables to create unique names:\n        %Y - Year\n        %m - Month\n        %d - Day\n        %H - Hour\n        %M - Minute\n        %S - Second\n        ",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "folder",
      "name"
    ]
  },
  {
    "title": "Amplitude To DB",
    "description": "Converts an amplitude spectrogram to a dB-scaled spectrogram.\n    audio, analysis, spectrogram\n\n    This node is useful for:\n    - Compressing the dynamic range of spectrograms for visualization\n    - Preparing input for audio models that expect dB-scaled data",
    "namespace": "nodetool.audio.analysis",
    "node_type": "nodetool.audio.analysis.AmplitudeToDB",
    "layout": "default",
    "properties": [
      {
        "name": "tensor",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Tensor",
        "description": "The amplitude tensor to be converted to dB scale.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensor"
    ]
  },
  {
    "title": "Chroma STFT",
    "description": "This node creates a chromagram from a waveform or power spectrogram to identify different pitch classes in an audio signal.\n    audio, analysis, chromagram, pitch\n\n    Applications:\n    - Chord recognition in music\n    - Music genre classification based on pitch content",
    "namespace": "nodetool.audio.analysis",
    "node_type": "nodetool.audio.analysis.ChromaSTFT",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to extract chromagram from.",
        "min": null,
        "max": null
      },
      {
        "name": "n_fft",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2048,
        "title": "N Fft",
        "description": "The number of samples per frame.",
        "min": 0.0,
        "max": null
      },
      {
        "name": "hop_length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Hop Length",
        "description": "The number of samples between frames.",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "n_fft",
      "hop_length"
    ]
  },
  {
    "title": "DBTo Amplitude",
    "description": "The DBToAmplitude node Converts a dB-scaled spectrogram to an amplitude spectrogram.\n    audio, analysis, spectrogram\n    Useful for:\n    - Reversing dB scaling before audio synthesis\n    - Preparing data for models that expect linear amplitude scaling",
    "namespace": "nodetool.audio.analysis",
    "node_type": "nodetool.audio.analysis.DBToAmplitude",
    "layout": "default",
    "properties": [
      {
        "name": "tensor",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Tensor",
        "description": "The dB-scaled tensor to be converted to amplitude scale.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensor"
    ]
  },
  {
    "title": "DBTo Power",
    "description": "This node converts a decibel (dB) spectrogram back to power scale.\n    audio, analysis, spectrogram\n\n    Useful for:\n    - Reversing dB scaling for audio synthesis\n    - Preparing data for models that expect power-scaled data",
    "namespace": "nodetool.audio.analysis",
    "node_type": "nodetool.audio.analysis.DBToPower",
    "layout": "default",
    "properties": [
      {
        "name": "tensor",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Tensor",
        "description": "The tensor containing the decibel spectrogram.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensor"
    ]
  },
  {
    "title": "Griffin Lim",
    "description": "GriffinLim Node performs phase reconstruction on a magnitude spectrogram utilizing the Griffin-Lim algorithm.\n    audio, synthesis, phase reconstruction\n\n    Applications:\n    - Audio synthesis from spectrograms\n    - Phase reconstruction in audio processing pipelines",
    "namespace": "nodetool.audio.analysis",
    "node_type": "nodetool.audio.analysis.GriffinLim",
    "layout": "default",
    "properties": [
      {
        "name": "magnitude_spectrogram",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Magnitude Spectrogram",
        "description": "Magnitude spectrogram input for phase reconstruction.",
        "min": null,
        "max": null
      },
      {
        "name": "n_iter",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 32,
        "title": "N Iter",
        "description": "Number of iterations for the Griffin-Lim algorithm.",
        "min": null,
        "max": null
      },
      {
        "name": "hop_length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Hop Length",
        "description": "Number of samples between successive frames.",
        "min": null,
        "max": null
      },
      {
        "name": "win_length",
        "type": {
          "type": "int",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Win Length",
        "description": "Each frame of audio is windowed by `window()`. The window will be of length `win_length` and then padded with zeros to match `n_fft`.",
        "min": null,
        "max": null
      },
      {
        "name": "window",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "hann",
        "title": "Window",
        "description": "Type of window to use for Griffin-Lim transformation.",
        "min": null,
        "max": null
      },
      {
        "name": "center",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Center",
        "description": "If True, the signal `y` is padded so that frame `D[:, t]` is centered at `y[t * hop_length]`.",
        "min": null,
        "max": null
      },
      {
        "name": "length",
        "type": {
          "type": "int",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Length",
        "description": "If given, the resulting signal will be zero-padded or clipped to this length.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "magnitude_spectrogram",
      "n_iter",
      "hop_length",
      "win_length",
      "window",
      "center",
      "length"
    ]
  },
  {
    "title": "Mel Spectrogram",
    "description": "MelSpecNode computes the Mel-frequency spectrogram for an audio signal.\n    audio, analysis, spectrogram\n\n    Useful for:\n    - Audio feature extraction for machine learning\n    - Speech and music analysis tasks",
    "namespace": "nodetool.audio.analysis",
    "node_type": "nodetool.audio.analysis.MelSpectrogram",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to convert to a tensor.",
        "min": null,
        "max": null
      },
      {
        "name": "n_fft",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2048,
        "title": "N Fft",
        "description": "The number of samples per frame.",
        "min": 0.0,
        "max": null
      },
      {
        "name": "hop_length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Hop Length",
        "description": "The number of samples between frames.",
        "min": 0.0,
        "max": null
      },
      {
        "name": "n_mels",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 128,
        "title": "N Mels",
        "description": "The number of Mel bands to generate.",
        "min": 0.0,
        "max": null
      },
      {
        "name": "fmin",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Fmin",
        "description": "The lowest frequency (in Hz).",
        "min": 0.0,
        "max": null
      },
      {
        "name": "fmax",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8000,
        "title": "Fmax",
        "description": "The highest frequency (in Hz).",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "n_mels",
      "fmax"
    ]
  },
  {
    "title": "MFCC",
    "description": "MFCC Node computes the Mel-frequency cepstral coefficients (MFCCs) from an audio signal.\n    audio, analysis, frequency, MFCC, MEL",
    "namespace": "nodetool.audio.analysis",
    "node_type": "nodetool.audio.analysis.MFCC",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to extract MFCCs from.",
        "min": null,
        "max": null
      },
      {
        "name": "n_mfcc",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 13,
        "title": "N Mfcc",
        "description": "The number of MFCCs to extract.",
        "min": 0.0,
        "max": null
      },
      {
        "name": "n_fft",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2048,
        "title": "N Fft",
        "description": "The number of samples per frame.",
        "min": 0.0,
        "max": null
      },
      {
        "name": "hop_length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Hop Length",
        "description": "The number of samples between frames.",
        "min": 0.0,
        "max": null
      },
      {
        "name": "fmin",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Fmin",
        "description": "The lowest frequency (in Hz).",
        "min": 0.0,
        "max": null
      },
      {
        "name": "fmax",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8000,
        "title": "Fmax",
        "description": "The highest frequency (in Hz).",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "n_mfcc",
      "n_fft"
    ]
  },
  {
    "title": "Plot Spectrogram",
    "description": "The PlotSpectrogram node generates a visual representation of the spectrum of frequencies in an audio signal as they vary with time.\n    audio, analysis, frequency, spectrogram\n\n    #### Applications\n    - Audio Analysis: Allows users to visually see the spectrum of frequencies in their data.\n    - Machine Learning: Used as a preprocessing step for feeding data into image-based ML models.\n    - Sound engineering: Helps in identifying specific tones or frequencies in a music piece or a sound bite.",
    "namespace": "nodetool.audio.analysis",
    "node_type": "nodetool.audio.analysis.PlotSpectrogram",
    "layout": "default",
    "properties": [
      {
        "name": "tensor",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Tensor",
        "description": "The tensor containing the mel spectrogram.",
        "min": null,
        "max": null
      },
      {
        "name": "fmax",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8000,
        "title": "Fmax",
        "description": "The highest frequency (in Hz).",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensor",
      "fmax"
    ]
  },
  {
    "title": "Powert To DB",
    "description": "Converts a power spectrogram to decibel (dB) scale.\n    audio, analysis, decibel, spectrogram",
    "namespace": "nodetool.audio.analysis",
    "node_type": "nodetool.audio.analysis.PowertToDB",
    "layout": "default",
    "properties": [
      {
        "name": "tensor",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Tensor",
        "description": "The tensor containing the power spectrogram.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensor"
    ]
  },
  {
    "title": "Spectral Contrast",
    "description": "The spectral contrast measures the difference in amplitude between the most noticeable parts (peaks) and the less noticeable parts (valleys) in a sound spectrum.\n    audio, analysis, decibel, amplitude\n\n    #### Applications\n    - Music genre classification: distinguishing between different types of music based on the color of sound.\n    - Instrument recognition: recognizing different musical instruments by the difference in their spectral contrast.\n    - Audio analysis: determining various characteristics of audio files.\n\n    Useful note: The `n_fft` and `hop_length` parameters affect the resolution of the analysis. A higher `n_fft` provides better frequency resolution but worse time resolution, and vice versa for a lower `hop_length`.",
    "namespace": "nodetool.audio.analysis",
    "node_type": "nodetool.audio.analysis.SpectralContrast",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to extract spectral contrast from.",
        "min": null,
        "max": null
      },
      {
        "name": "n_fft",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2048,
        "title": "N Fft",
        "description": "The number of samples per frame.",
        "min": 0.0,
        "max": null
      },
      {
        "name": "hop_length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Hop Length",
        "description": "The number of samples between frames.",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "n_fft",
      "hop_length"
    ]
  },
  {
    "title": "STFT",
    "description": "This node computes the Short-Time Fourier Transform (STFT) matrix for an audio signal. The STFT matrix represents the signal in both time and frequency domains, forming the foundation for many audio processing tasks.\n    audio, analysis, fourier, frequency, time\n    #### Applications\n    - Audio Analysis: By transforming the audio signal into a visualizable format, it helps in understanding and analyzing the audio signal.\n    - Sound Processing: It plays a key foundational role in sound effects, tuning, compression, and more.\n    - Audio Feature Extraction: It can be used to analyze frequency-based features for sound classification.\n    - Music Information Retrieval: It helps in music transcription, rhythm and tempo analysis.",
    "namespace": "nodetool.audio.analysis",
    "node_type": "nodetool.audio.analysis.STFT",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to compute the STFT matrix from.",
        "min": null,
        "max": null
      },
      {
        "name": "n_fft",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2048,
        "title": "N Fft",
        "description": "The number of samples per frame.",
        "min": 0.0,
        "max": null
      },
      {
        "name": "hop_length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Hop Length",
        "description": "The number of samples between frames.",
        "min": 0.0,
        "max": null
      },
      {
        "name": "win_length",
        "type": {
          "type": "int",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Win Length",
        "description": "The window length. If None, it defaults to n_fft.",
        "min": null,
        "max": null
      },
      {
        "name": "window",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "hann",
        "title": "Window",
        "description": "The type of window to use.",
        "min": null,
        "max": null
      },
      {
        "name": "center",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Center",
        "description": "If True, input signal is padded so that frame D[:, t] is centered at y[t * hop_length].",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "n_fft",
      "hop_length"
    ]
  },
  {
    "title": "Spectral Centroid",
    "description": "Computes the spectral centroid of an audio file.\n    audio, analysis, spectral\n\n    The spectral centroid indicates where the \"center of mass\" of the spectrum is located.\n    Perceptually, it has a connection with the impression of \"brightness\" of a sound.\n\n    Use cases:\n    - Analyze the timbral characteristics of audio\n    - Track changes in sound brightness over time\n    - Feature extraction for music genre classification\n    - Audio effect design and sound manipulation",
    "namespace": "nodetool.audio.analysis",
    "node_type": "nodetool.audio.analysis.SpectralCentroid",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to analyze.",
        "min": null,
        "max": null
      },
      {
        "name": "n_fft",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2048,
        "title": "N Fft",
        "description": "The length of the FFT window.",
        "min": 128.0,
        "max": 8192.0
      },
      {
        "name": "hop_length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Hop Length",
        "description": "Number of samples between successive frames.",
        "min": 64.0,
        "max": 2048.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "n_fft",
      "hop_length"
    ]
  },
  {
    "title": "Trim",
    "description": "Trim an audio file to a specified duration.\n    audio, trim, cut\n\n    Use cases:\n    - Remove silence from the beginning or end of audio files\n    - Extract specific segments from audio files\n    - Prepare audio data for machine learning models",
    "namespace": "nodetool.audio.conversion",
    "node_type": "nodetool.audio.conversion.Trim",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to trim.",
        "min": null,
        "max": null
      },
      {
        "name": "start",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Start",
        "description": "The start time of the trimmed audio in seconds.",
        "min": 0.0,
        "max": null
      },
      {
        "name": "end",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "End",
        "description": "The end time of the trimmed audio in seconds.",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "start",
      "end"
    ]
  },
  {
    "title": "Convert To Tensor",
    "description": "Converts an audio file to a tensor for further processing.\n    audio, conversion, tensor\n\n    Use cases:\n    - Prepare audio data for machine learning models\n    - Enable signal processing operations on audio\n    - Convert audio to a format suitable for spectral analysisr",
    "namespace": "nodetool.audio.conversion",
    "node_type": "nodetool.audio.conversion.ConvertToTensor",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to convert to a tensor.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio"
    ]
  },
  {
    "title": "Create Silence",
    "description": "Creates a silent audio file with a specified duration.\n    audio, silence, empty\n\n    Use cases:\n    - Generate placeholder audio files\n    - Create audio segments for padding or spacing\n    - Add silence to the beginning or end of audio files",
    "namespace": "nodetool.audio.conversion",
    "node_type": "nodetool.audio.conversion.CreateSilence",
    "layout": "default",
    "properties": [
      {
        "name": "duration",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Duration",
        "description": "The duration of the silence in seconds.",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "duration"
    ]
  },
  {
    "title": "Reverb",
    "description": "Applies a reverb effect to an audio file.\n    audio, effect, reverb\n\n    Use cases:\n    - Add spatial depth to dry recordings\n    - Simulate different room acoustics\n    - Create atmospheric sound effects",
    "namespace": "nodetool.audio.effects",
    "node_type": "nodetool.audio.effects.Reverb",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to process.",
        "min": null,
        "max": null
      },
      {
        "name": "room_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Room Scale",
        "description": "Size of the simulated room. Higher values create larger spaces.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "damping",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Damping",
        "description": "Amount of high frequency absorption. Higher values create a duller sound.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "wet_level",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.15,
        "title": "Wet Level",
        "description": "Level of the reverb effect in the output.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "dry_level",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Dry Level",
        "description": "Level of the original signal in the output.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "room_scale",
      "damping",
      "wet_level",
      "dry_level"
    ]
  },
  {
    "title": "Compress",
    "description": "Applies dynamic range compression to an audio file.\n    audio, effect, dynamics\n\n    Use cases:\n    - Even out volume levels in a recording\n    - Increase perceived loudness of audio\n    - Control peaks in audio signals",
    "namespace": "nodetool.audio.effects",
    "node_type": "nodetool.audio.effects.Compress",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to process.",
        "min": null,
        "max": null
      },
      {
        "name": "threshold",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -20.0,
        "title": "Threshold",
        "description": "Threshold in dB above which compression is applied.",
        "min": -60.0,
        "max": 0.0
      },
      {
        "name": "ratio",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4.0,
        "title": "Ratio",
        "description": "Compression ratio. Higher values result in more compression.",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "attack",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5.0,
        "title": "Attack",
        "description": "Attack time in milliseconds.",
        "min": 0.1,
        "max": 100.0
      },
      {
        "name": "release",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50.0,
        "title": "Release",
        "description": "Release time in milliseconds.",
        "min": 5.0,
        "max": 1000.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "threshold",
      "ratio",
      "attack",
      "release"
    ]
  },
  {
    "title": "Time Stretch",
    "description": "Changes the speed of an audio file without altering its pitch.\n    audio, transform, time\n\n    Use cases:\n    - Adjust audio duration to fit video length\n    - Create slow-motion or fast-motion audio effects\n    - Synchronize audio tracks of different lengths",
    "namespace": "nodetool.audio.effects",
    "node_type": "nodetool.audio.effects.TimeStretch",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to process.",
        "min": null,
        "max": null
      },
      {
        "name": "rate",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Rate",
        "description": "Time stretch factor. Values > 1 speed up, < 1 slow down.",
        "min": 0.5,
        "max": 2.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "rate"
    ]
  },
  {
    "title": "Pitch Shift",
    "description": "Shifts the pitch of an audio file without changing its duration.\n    audio, effect, pitch\n\n    Use cases:\n    - Transpose audio to a different key\n    - Create harmonies or vocal effects\n    - Adjust instrument tuning",
    "namespace": "nodetool.audio.effects",
    "node_type": "nodetool.audio.effects.PitchShift",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to process.",
        "min": null,
        "max": null
      },
      {
        "name": "semitones",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Semitones",
        "description": "Number of semitones to shift the pitch. Positive values shift up, negative values shift down.",
        "min": -12.0,
        "max": 12.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "semitones"
    ]
  },
  {
    "title": "Noise Gate",
    "description": "Applies a noise gate effect to an audio file.\n    audio, effect, dynamics\n\n    Use cases:\n    - Reduce background noise in recordings\n    - Clean up audio tracks with unwanted low-level sounds\n    - Create rhythmic effects by gating sustained sounds",
    "namespace": "nodetool.audio.effects",
    "node_type": "nodetool.audio.effects.NoiseGate",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to process.",
        "min": null,
        "max": null
      },
      {
        "name": "threshold_db",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -50.0,
        "title": "Threshold Db",
        "description": "Threshold in dB below which the gate is active.",
        "min": -90.0,
        "max": 0.0
      },
      {
        "name": "attack_ms",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Attack Ms",
        "description": "Attack time in milliseconds.",
        "min": 0.1,
        "max": 100.0
      },
      {
        "name": "release_ms",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100.0,
        "title": "Release Ms",
        "description": "Release time in milliseconds.",
        "min": 5.0,
        "max": 1000.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "threshold_db",
      "attack_ms",
      "release_ms"
    ]
  },
  {
    "title": "Low Shelf Filter",
    "description": "Applies a low shelf filter to boost or cut low frequencies.\n    audio, effect, equalizer\n\n    Use cases:\n    - Enhance or reduce bass frequencies\n    - Shape the low-end response of audio\n    - Compensate for speaker or room deficiencies",
    "namespace": "nodetool.audio.effects",
    "node_type": "nodetool.audio.effects.LowShelfFilter",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to process.",
        "min": null,
        "max": null
      },
      {
        "name": "cutoff_frequency_hz",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 200.0,
        "title": "Cutoff Frequency Hz",
        "description": "The cutoff frequency of the shelf filter in Hz.",
        "min": 20.0,
        "max": 1000.0
      },
      {
        "name": "gain_db",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Gain Db",
        "description": "The gain to apply to the frequencies below the cutoff, in dB.",
        "min": -24.0,
        "max": 24.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "cutoff_frequency_hz",
      "gain_db"
    ]
  },
  {
    "title": "High Shelf Filter",
    "description": "Applies a high shelf filter to boost or cut high frequencies.\n    audio, effect, equalizer\n\n    Use cases:\n    - Enhance or reduce treble frequencies\n    - Add brightness or air to audio\n    - Tame harsh high frequencies",
    "namespace": "nodetool.audio.effects",
    "node_type": "nodetool.audio.effects.HighShelfFilter",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to process.",
        "min": null,
        "max": null
      },
      {
        "name": "cutoff_frequency_hz",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5000.0,
        "title": "Cutoff Frequency Hz",
        "description": "The cutoff frequency of the shelf filter in Hz.",
        "min": 1000.0,
        "max": 20000.0
      },
      {
        "name": "gain_db",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Gain Db",
        "description": "The gain to apply to the frequencies above the cutoff, in dB.",
        "min": -24.0,
        "max": 24.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "cutoff_frequency_hz",
      "gain_db"
    ]
  },
  {
    "title": "High Pass Filter",
    "description": "Applies a high-pass filter to attenuate frequencies below a cutoff point.\n    audio, effect, equalizer\n\n    Use cases:\n    - Remove low-frequency rumble or noise\n    - Clean up the low end of a mix\n    - Create filter sweep effects",
    "namespace": "nodetool.audio.effects",
    "node_type": "nodetool.audio.effects.HighPassFilter",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to process.",
        "min": null,
        "max": null
      },
      {
        "name": "cutoff_frequency_hz",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80.0,
        "title": "Cutoff Frequency Hz",
        "description": "The cutoff frequency of the high-pass filter in Hz.",
        "min": 20.0,
        "max": 5000.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "cutoff_frequency_hz"
    ]
  },
  {
    "title": "Low Pass Filter",
    "description": "Applies a low-pass filter to attenuate frequencies above a cutoff point.\n    audio, effect, equalizer\n\n    Use cases:\n    - Reduce high-frequency harshness\n    - Simulate muffled or distant sounds\n    - Create dub-style effects",
    "namespace": "nodetool.audio.effects",
    "node_type": "nodetool.audio.effects.LowPassFilter",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to process.",
        "min": null,
        "max": null
      },
      {
        "name": "cutoff_frequency_hz",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5000.0,
        "title": "Cutoff Frequency Hz",
        "description": "The cutoff frequency of the low-pass filter in Hz.",
        "min": 500.0,
        "max": 20000.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "cutoff_frequency_hz"
    ]
  },
  {
    "title": "Peak Filter",
    "description": "Applies a peak filter to boost or cut a specific frequency range.\n    audio, effect, equalizer\n\n    Use cases:\n    - Isolate specific frequency ranges\n    - Create telephone or radio voice effects\n    - Focus on particular instrument ranges in a mix",
    "namespace": "nodetool.audio.effects",
    "node_type": "nodetool.audio.effects.PeakFilter",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to process.",
        "min": null,
        "max": null
      },
      {
        "name": "cutoff_frequency_hz",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1000.0,
        "title": "Cutoff Frequency Hz",
        "description": "The cutoff frequency of the band-pass filter in Hz.",
        "min": 20.0,
        "max": 20000.0
      },
      {
        "name": "q_factor",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Q Factor",
        "description": "The Q factor, determining the width of the band. Higher values create narrower bands.",
        "min": 0.1,
        "max": 10.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "cutoff_frequency_hz",
      "q_factor"
    ]
  },
  {
    "title": "Distortion",
    "description": "Applies a distortion effect to an audio file.\n    audio, effect, distortion\n\n    Use cases:\n    - Add grit and character to instruments\n    - Create aggressive sound effects\n    - Simulate overdriven amplifiers",
    "namespace": "nodetool.audio.effects",
    "node_type": "nodetool.audio.effects.Distortion",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to process.",
        "min": null,
        "max": null
      },
      {
        "name": "drive_db",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25.0,
        "title": "Drive Db",
        "description": "Amount of distortion to apply in decibels.",
        "min": 0.0,
        "max": 100.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "drive_db"
    ]
  },
  {
    "title": "Phaser",
    "description": "Applies a phaser effect to an audio file.\n    audio, effect, modulation\n\n    Use cases:\n    - Create sweeping, swooshing sounds\n    - Add movement to static sounds\n    - Produce psychedelic or space-like effects",
    "namespace": "nodetool.audio.effects",
    "node_type": "nodetool.audio.effects.Phaser",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to process.",
        "min": null,
        "max": null
      },
      {
        "name": "rate_hz",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Rate Hz",
        "description": "Rate of the phaser effect in Hz.",
        "min": 0.1,
        "max": 10.0
      },
      {
        "name": "depth",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Depth",
        "description": "Depth of the phaser effect.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "centre_frequency_hz",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1300.0,
        "title": "Centre Frequency Hz",
        "description": "Centre frequency of the phaser in Hz.",
        "min": 100.0,
        "max": 5000.0
      },
      {
        "name": "feedback",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Feedback",
        "description": "Feedback of the phaser effect. Negative values invert the phase.",
        "min": -1.0,
        "max": 1.0
      },
      {
        "name": "mix",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Mix",
        "description": "Mix between the dry (original) and wet (effected) signals.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "rate_hz",
      "depth",
      "centre_frequency_hz",
      "feedback",
      "mix"
    ]
  },
  {
    "title": "Delay",
    "description": "Applies a delay effect to an audio file.\n    audio, effect, time-based\n\n    Use cases:\n    - Create echo effects\n    - Add spaciousness to sounds\n    - Produce rhythmic patterns",
    "namespace": "nodetool.audio.effects",
    "node_type": "nodetool.audio.effects.Delay",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to process.",
        "min": null,
        "max": null
      },
      {
        "name": "delay_seconds",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Delay Seconds",
        "description": "Delay time in seconds.",
        "min": 0.01,
        "max": 5.0
      },
      {
        "name": "feedback",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.3,
        "title": "Feedback",
        "description": "Amount of delayed signal fed back into the effect.",
        "min": 0.0,
        "max": 0.99
      },
      {
        "name": "mix",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Mix",
        "description": "Mix between the dry (original) and wet (delayed) signals.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "delay_seconds",
      "feedback",
      "mix"
    ]
  },
  {
    "title": "Gain",
    "description": "Applies a gain (volume adjustment) to an audio file.\n    audio, effect, volume\n\n    Use cases:\n    - Increase or decrease overall volume of audio\n    - Balance levels between different audio tracks\n    - Prepare audio for further processing",
    "namespace": "nodetool.audio.effects",
    "node_type": "nodetool.audio.effects.Gain",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to process.",
        "min": null,
        "max": null
      },
      {
        "name": "gain_db",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Gain Db",
        "description": "Gain to apply in decibels. Positive values increase volume, negative values decrease it.",
        "min": -60.0,
        "max": 24.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "gain_db"
    ]
  },
  {
    "title": "Limiter",
    "description": "Applies a limiter effect to an audio file.\n    audio, effect, dynamics\n\n    Use cases:\n    - Prevent audio clipping\n    - Increase perceived loudness without distortion\n    - Control dynamic range of audio",
    "namespace": "nodetool.audio.effects",
    "node_type": "nodetool.audio.effects.Limiter",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to process.",
        "min": null,
        "max": null
      },
      {
        "name": "threshold_db",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -2.0,
        "title": "Threshold Db",
        "description": "Threshold in dB above which the limiter is applied.",
        "min": -60.0,
        "max": 0.0
      },
      {
        "name": "release_ms",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 250.0,
        "title": "Release Ms",
        "description": "Release time in milliseconds.",
        "min": 1.0,
        "max": 1000.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "threshold_db",
      "release_ms"
    ]
  },
  {
    "title": "Bitcrush",
    "description": "Applies a bitcrushing effect to an audio file, reducing bit depth and/or sample rate.\n    audio, effect, distortion\n\n    Use cases:\n    - Create lo-fi or retro-style audio effects\n    - Simulate vintage digital audio equipment\n    - Add digital distortion and artifacts to sounds",
    "namespace": "nodetool.audio.effects",
    "node_type": "nodetool.audio.effects.Bitcrush",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to process.",
        "min": null,
        "max": null
      },
      {
        "name": "bit_depth",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8,
        "title": "Bit Depth",
        "description": "The bit depth to reduce the audio to. Lower values create more distortion.",
        "min": 1.0,
        "max": 16.0
      },
      {
        "name": "sample_rate_reduction",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Sample Rate Reduction",
        "description": "Factor by which to reduce the sample rate. Higher values create more aliasing.",
        "min": 1.0,
        "max": 100.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "bit_depth",
      "sample_rate_reduction"
    ]
  },
  {
    "title": "Detect Onsets",
    "description": "Detect onsets in an audio file.\n    audio, analysis, segmentation\n\n    Use cases:\n    - Identify beat locations in music\n    - Segment audio based on changes in energy or spectral content\n    - Prepare audio for further processing or analysis",
    "namespace": "nodetool.audio.segmentation",
    "node_type": "nodetool.audio.segmentation.DetectOnsets",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The input audio file to analyze.",
        "min": null,
        "max": null
      },
      {
        "name": "hop_length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Hop Length",
        "description": "Number of samples between successive frames.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "hop_length"
    ]
  },
  {
    "title": "Segment Audio By Onsets",
    "description": "Segment an audio file based on detected onsets.\n    audio, segmentation, processing\n\n    Use cases:\n    - Split a long audio recording into individual segments\n    - Prepare audio clips for further analysis or processing\n    - Extract specific parts of an audio file based on onset locations",
    "namespace": "nodetool.audio.segmentation",
    "node_type": "nodetool.audio.segmentation.SegmentAudioByOnsets",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The input audio file to segment.",
        "min": null,
        "max": null
      },
      {
        "name": "onsets",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Onsets",
        "description": "The onset times detected in the audio.",
        "min": null,
        "max": null
      },
      {
        "name": "min_segment_length",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.1,
        "title": "Min Segment Length",
        "description": "Minimum length of a segment in seconds.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "audio",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "onsets",
      "min_segment_length"
    ]
  },
  {
    "title": "Save Audio Segments",
    "description": "Save a list of audio segments to a specified folder.\n    audio, save, export\n\n    Use cases:\n    - Export segmented audio files for further processing or analysis\n    - Create a dataset of audio clips from a longer recording\n    - Organize audio segments into a structured format",
    "namespace": "nodetool.audio.segmentation",
    "node_type": "nodetool.audio.segmentation.SaveAudioSegments",
    "layout": "default",
    "properties": [
      {
        "name": "segments",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "audio",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Segments",
        "description": "The list of audio segments to save.",
        "min": null,
        "max": null
      },
      {
        "name": "output_folder",
        "type": {
          "type": "folder",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "folder",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Output Folder",
        "description": "The folder to save the audio segments in.",
        "min": null,
        "max": null
      },
      {
        "name": "name_prefix",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "segment",
        "title": "Name Prefix",
        "description": "Prefix for the saved audio file names.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "folder",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "segments",
      "output_folder",
      "name_prefix"
    ]
  },
  {
    "title": "Oscillator",
    "description": "Generates basic waveforms (sine, square, sawtooth, triangle).\n    audio, synthesis, waveform\n\n    Use cases:\n    - Create fundamental waveforms for synthesis\n    - Generate test signals\n    - Build complex sounds from basic waves",
    "namespace": "nodetool.audio.synthesis",
    "node_type": "nodetool.audio.synthesis.Oscillator",
    "layout": "default",
    "properties": [
      {
        "name": "waveform",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "sine",
            "square",
            "sawtooth",
            "triangle"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.audio.synthesis.OscillatorWaveform"
        },
        "default": "sine",
        "title": "Waveform",
        "description": "Type of waveform to generate (sine, square, sawtooth, triangle).",
        "min": null,
        "max": null
      },
      {
        "name": "frequency",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 440.0,
        "title": "Frequency",
        "description": "Frequency of the waveform in Hz.",
        "min": 20.0,
        "max": 20000.0
      },
      {
        "name": "amplitude",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Amplitude",
        "description": "Amplitude of the waveform.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "duration",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Duration",
        "description": "Duration in seconds.",
        "min": 0.0,
        "max": 30.0
      },
      {
        "name": "sample_rate",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 44100,
        "title": "Sample Rate",
        "description": "Sampling rate in Hz.",
        "min": null,
        "max": null
      },
      {
        "name": "pitch_envelope_amount",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Pitch Envelope Amount",
        "description": "Amount of pitch envelope in semitones",
        "min": -24.0,
        "max": 24.0
      },
      {
        "name": "pitch_envelope_time",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Pitch Envelope Time",
        "description": "Duration of pitch envelope in seconds",
        "min": 0.0,
        "max": 10.0
      },
      {
        "name": "pitch_envelope_curve",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "linear",
            "exponential"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.audio.synthesis.PitchEnvelopeCurve"
        },
        "default": "linear",
        "title": "Pitch Envelope Curve",
        "description": "Shape of pitch envelope (linear, exponential)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "waveform",
      "frequency",
      "amplitude",
      "duration",
      "sample_rate",
      "pitch_envelope_amount",
      "pitch_envelope_time",
      "pitch_envelope_curve"
    ]
  },
  {
    "title": "White Noise",
    "description": "Generates white noise.\n    audio, synthesis, noise\n\n    Use cases:\n    - Create background ambience\n    - Generate percussion sounds\n    - Test audio equipment",
    "namespace": "nodetool.audio.synthesis",
    "node_type": "nodetool.audio.synthesis.WhiteNoise",
    "layout": "default",
    "properties": [
      {
        "name": "amplitude",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Amplitude",
        "description": "Amplitude of the noise.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "duration",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Duration",
        "description": "Duration in seconds.",
        "min": 0.0,
        "max": 30.0
      },
      {
        "name": "sample_rate",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 44100,
        "title": "Sample Rate",
        "description": "Sampling rate in Hz.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "amplitude",
      "duration",
      "sample_rate"
    ]
  },
  {
    "title": "Pink Noise",
    "description": "Generates pink noise (1/f noise).\n    audio, synthesis, noise\n\n    Use cases:\n    - Create natural-sounding background noise\n    - Test speaker response\n    - Sound masking",
    "namespace": "nodetool.audio.synthesis",
    "node_type": "nodetool.audio.synthesis.PinkNoise",
    "layout": "default",
    "properties": [
      {
        "name": "amplitude",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Amplitude",
        "description": "Amplitude of the noise.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "duration",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Duration",
        "description": "Duration in seconds.",
        "min": 0.0,
        "max": 30.0
      },
      {
        "name": "sample_rate",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 44100,
        "title": "Sample Rate",
        "description": "Sampling rate in Hz.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "amplitude",
      "duration",
      "sample_rate"
    ]
  },
  {
    "title": "FM Synthesis",
    "description": "Performs FM (Frequency Modulation) synthesis.\n    audio, synthesis, modulation\n\n    Use cases:\n    - Create complex timbres\n    - Generate bell-like sounds\n    - Synthesize metallic tones",
    "namespace": "nodetool.audio.synthesis",
    "node_type": "nodetool.audio.synthesis.FM_Synthesis",
    "layout": "default",
    "properties": [
      {
        "name": "carrier_freq",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 440.0,
        "title": "Carrier Freq",
        "description": "Carrier frequency in Hz.",
        "min": 20.0,
        "max": 20000.0
      },
      {
        "name": "modulator_freq",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 110.0,
        "title": "Modulator Freq",
        "description": "Modulator frequency in Hz.",
        "min": 1.0,
        "max": 20000.0
      },
      {
        "name": "modulation_index",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5.0,
        "title": "Modulation Index",
        "description": "Modulation index (affects richness of sound).",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "amplitude",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Amplitude",
        "description": "Amplitude of the output.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "duration",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Duration",
        "description": "Duration in seconds.",
        "min": 0.0,
        "max": 30.0
      },
      {
        "name": "sample_rate",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 44100,
        "title": "Sample Rate",
        "description": "Sampling rate in Hz.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "carrier_freq",
      "modulator_freq",
      "modulation_index",
      "amplitude",
      "duration",
      "sample_rate"
    ]
  },
  {
    "title": "Envelope",
    "description": "Applies an ADR (Attack-Decay-Release) envelope to an audio signal.\n    audio, synthesis, envelope\n\n    Use cases:\n    - Shape the amplitude of synthesized sounds\n    - Create percussion-like instruments\n    - Control sound dynamics",
    "namespace": "nodetool.audio.synthesis",
    "node_type": "nodetool.audio.synthesis.Envelope",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio to apply the envelope to.",
        "min": null,
        "max": null
      },
      {
        "name": "attack",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.1,
        "title": "Attack",
        "description": "Attack time in seconds.",
        "min": 0.0,
        "max": 5.0
      },
      {
        "name": "decay",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.3,
        "title": "Decay",
        "description": "Decay time in seconds.",
        "min": 0.0,
        "max": 5.0
      },
      {
        "name": "release",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Release",
        "description": "Release time in seconds.",
        "min": 0.0,
        "max": 5.0
      },
      {
        "name": "peak_amplitude",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Peak Amplitude",
        "description": "Peak amplitude after attack phase (0-1).",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "attack",
      "decay",
      "release",
      "peak_amplitude"
    ]
  },
  {
    "title": "Concat",
    "description": "Concatenates two audio files together.\n    audio, edit, join\n\n    Use cases:\n    - Combine multiple audio clips into a single file\n    - Create longer audio tracks from shorter segments",
    "namespace": "nodetool.audio.transform",
    "node_type": "nodetool.audio.transform.Concat",
    "layout": "default",
    "properties": [
      {
        "name": "a",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "A",
        "description": "The first audio file.",
        "min": null,
        "max": null
      },
      {
        "name": "b",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "B",
        "description": "The second audio file.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "a",
      "b"
    ]
  },
  {
    "title": "Concat List",
    "description": "Concatenates multiple audio files together in sequence.\n    audio, edit, join, multiple\n\n    Use cases:\n    - Combine multiple audio clips into a single file\n    - Create longer audio tracks from multiple segments\n    - Chain multiple audio files in order",
    "namespace": "nodetool.audio.transform",
    "node_type": "nodetool.audio.transform.ConcatList",
    "layout": "default",
    "properties": [
      {
        "name": "audio_files",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "audio",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Audio Files",
        "description": "List of audio files to concatenate in sequence.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio_files"
    ]
  },
  {
    "title": "Normalize",
    "description": "Normalizes the volume of an audio file.\n    audio, fix, dynamics\n\n    Use cases:\n    - Ensure consistent volume across multiple audio files\n    - Adjust overall volume level before further processing",
    "namespace": "nodetool.audio.transform",
    "node_type": "nodetool.audio.transform.Normalize",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to normalize.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio"
    ]
  },
  {
    "title": "Overlay Audio",
    "description": "Overlays two audio files together.\n    audio, edit, transform\n\n    Use cases:\n    - Mix background music with voice recording\n    - Layer sound effects over an existing audio track",
    "namespace": "nodetool.audio.transform",
    "node_type": "nodetool.audio.transform.OverlayAudio",
    "layout": "default",
    "properties": [
      {
        "name": "a",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "A",
        "description": "The first audio file.",
        "min": null,
        "max": null
      },
      {
        "name": "b",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "B",
        "description": "The second audio file.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "a",
      "b"
    ]
  },
  {
    "title": "Remove Silence",
    "description": "Removes or shortens silence in an audio file with smooth transitions.\n    audio, edit, clean\n\n    Use cases:\n    - Trim silent parts from beginning/end of recordings\n    - Remove or shorten long pauses between speech segments\n    - Apply crossfade for smooth transitions",
    "namespace": "nodetool.audio.transform",
    "node_type": "nodetool.audio.transform.RemoveSilence",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to process.",
        "min": null,
        "max": null
      },
      {
        "name": "min_length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 200,
        "title": "Min Length",
        "description": "Minimum length of silence to be processed (in milliseconds).",
        "min": 0.0,
        "max": 10000.0
      },
      {
        "name": "threshold",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -40,
        "title": "Threshold",
        "description": "Silence threshold in dB (relative to full scale). Higher values detect more silence.",
        "min": -60.0,
        "max": 0.0
      },
      {
        "name": "reduction_factor",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Reduction Factor",
        "description": "Factor to reduce silent parts (0.0 to 1.0). 0.0 keeps silence as is, 1.0 removes it completely.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "crossfade",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10,
        "title": "Crossfade",
        "description": "Duration of crossfade in milliseconds to apply between segments for smooth transitions.",
        "min": 0.0,
        "max": 50.0
      },
      {
        "name": "min_silence_between_parts",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Min Silence Between Parts",
        "description": "Minimum silence duration in milliseconds to maintain between non-silent segments",
        "min": 0.0,
        "max": 500.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "min_length",
      "threshold",
      "reduction_factor",
      "crossfade",
      "min_silence_between_parts"
    ]
  },
  {
    "title": "Slice Audio",
    "description": "Extracts a section of an audio file.\n    audio, edit, trim\n\n    Use cases:\n    - Cut out a specific clip from a longer audio file\n    - Remove unwanted portions from beginning or end",
    "namespace": "nodetool.audio.transform",
    "node_type": "nodetool.audio.transform.SliceAudio",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file.",
        "min": null,
        "max": null
      },
      {
        "name": "start",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Start",
        "description": "The start time in seconds.",
        "min": 0.0,
        "max": null
      },
      {
        "name": "end",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "End",
        "description": "The end time in seconds.",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "start",
      "end"
    ]
  },
  {
    "title": "Tone",
    "description": "Generates a constant tone signal.\n    audio, generate, sound\n\n    Use cases:\n    - Create test tones for audio equipment calibration\n    - Produce reference pitches for musical applications",
    "namespace": "nodetool.audio.transform",
    "node_type": "nodetool.audio.transform.Tone",
    "layout": "default",
    "properties": [
      {
        "name": "frequency",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 440.0,
        "title": "Frequency",
        "description": "Frequency of the tone in Hertz.",
        "min": null,
        "max": null
      },
      {
        "name": "sampling_rate",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 44100,
        "title": "Sampling Rate",
        "description": "Sampling rate.",
        "min": 0.0,
        "max": 44100.0
      },
      {
        "name": "duration",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Duration",
        "description": "Duration of the tone in seconds.",
        "min": null,
        "max": null
      },
      {
        "name": "phi",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Phi",
        "description": "Initial phase of the waveform in radians.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "frequency",
      "sampling_rate",
      "duration",
      "phi"
    ]
  },
  {
    "title": "Mono To Stereo",
    "description": "Converts a mono audio signal to stereo.\n    audio, convert, channels\n\n    Use cases:\n    - Expand mono recordings for stereo playback systems\n    - Prepare audio for further stereo processing",
    "namespace": "nodetool.audio.transform",
    "node_type": "nodetool.audio.transform.MonoToStereo",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The mono audio file to convert.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio"
    ]
  },
  {
    "title": "Stereo To Mono",
    "description": "Converts a stereo audio signal to mono.\n    audio, convert, channels\n\n    Use cases:\n    - Reduce file size for mono-only applications\n    - Simplify audio for certain processing tasks",
    "namespace": "nodetool.audio.transform",
    "node_type": "nodetool.audio.transform.StereoToMono",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The stereo audio file to convert.",
        "min": null,
        "max": null
      },
      {
        "name": "method",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "average",
        "title": "Method",
        "description": "Method to use for conversion: 'average', 'left', or 'right'.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "method"
    ]
  },
  {
    "title": "Reverse",
    "description": "Reverses an audio file.\n    audio, edit, transform\n\n    Use cases:\n    - Create reverse audio effects\n    - Generate backwards speech or music",
    "namespace": "nodetool.audio.transform",
    "node_type": "nodetool.audio.transform.Reverse",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to reverse.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio"
    ]
  },
  {
    "title": "Fade In",
    "description": "Applies a fade-in effect to the beginning of an audio file.\n    audio, edit, transition\n\n    Use cases:\n    - Create smooth introductions to audio tracks\n    - Gradually increase volume at the start of a clip",
    "namespace": "nodetool.audio.transform",
    "node_type": "nodetool.audio.transform.FadeIn",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to apply fade-in to.",
        "min": null,
        "max": null
      },
      {
        "name": "duration",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Duration",
        "description": "Duration of the fade-in effect in seconds.",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "duration"
    ]
  },
  {
    "title": "Fade Out",
    "description": "Applies a fade-out effect to the end of an audio file.\n    audio, edit, transition\n\n    Use cases:\n    - Create smooth endings to audio tracks\n    - Gradually decrease volume at the end of a clip",
    "namespace": "nodetool.audio.transform",
    "node_type": "nodetool.audio.transform.FadeOut",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to apply fade-out to.",
        "min": null,
        "max": null
      },
      {
        "name": "duration",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Duration",
        "description": "Duration of the fade-out effect in seconds.",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "duration"
    ]
  },
  {
    "title": "Repeat",
    "description": "Loops an audio file a specified number of times.\n    audio, edit, repeat\n\n    Use cases:\n    - Create repeating background sounds or music\n    - Extend short audio clips to fill longer durations\n    - Generate rhythmic patterns from short samples",
    "namespace": "nodetool.audio.transform",
    "node_type": "nodetool.audio.transform.Repeat",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to loop.",
        "min": null,
        "max": null
      },
      {
        "name": "loops",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Loops",
        "description": "Number of times to loop the audio. Minimum 1 (plays once), maximum 100.",
        "min": 1.0,
        "max": 100.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "loops"
    ]
  },
  {
    "title": "Audio Mixer",
    "description": "Mix up to 5 audio tracks together with individual volume controls.\n    audio, mix, volume, combine\n\n    Use cases:\n    - Mix multiple audio tracks into a single output\n    - Create layered soundscapes\n    - Combine music, voice, and sound effects\n    - Adjust individual track volumes",
    "namespace": "nodetool.audio.transform",
    "node_type": "nodetool.audio.transform.AudioMixer",
    "layout": "default",
    "properties": [
      {
        "name": "track1",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Track1",
        "description": "First audio track to mix.",
        "min": null,
        "max": null
      },
      {
        "name": "track2",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Track2",
        "description": "Second audio track to mix.",
        "min": null,
        "max": null
      },
      {
        "name": "track3",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Track3",
        "description": "Third audio track to mix.",
        "min": null,
        "max": null
      },
      {
        "name": "track4",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Track4",
        "description": "Fourth audio track to mix.",
        "min": null,
        "max": null
      },
      {
        "name": "track5",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Track5",
        "description": "Fifth audio track to mix.",
        "min": null,
        "max": null
      },
      {
        "name": "volume1",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Volume1",
        "description": "Volume for track 1. 1.0 is original volume.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "volume2",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Volume2",
        "description": "Volume for track 2. 1.0 is original volume.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "volume3",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Volume3",
        "description": "Volume for track 3. 1.0 is original volume.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "volume4",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Volume4",
        "description": "Volume for track 4. 1.0 is original volume.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "volume5",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Volume5",
        "description": "Volume for track 5. 1.0 is original volume.",
        "min": 0.0,
        "max": 2.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "track1",
      "track2",
      "track3",
      "track4",
      "track5",
      "volume1",
      "volume2",
      "volume3",
      "volume4",
      "volume5"
    ]
  },
  {
    "title": "Logical Operator",
    "description": "Performs logical operations on two boolean inputs.\n    boolean, logic, operator\n\n    Use cases:\n    - Combine multiple conditions in decision-making\n    - Implement complex logical rules in workflows\n    - Create advanced filters or triggers",
    "namespace": "nodetool.boolean",
    "node_type": "nodetool.boolean.LogicalOperator",
    "layout": "default",
    "properties": [
      {
        "name": "a",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "A",
        "description": "First boolean input",
        "min": null,
        "max": null
      },
      {
        "name": "b",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "B",
        "description": "Second boolean input",
        "min": null,
        "max": null
      },
      {
        "name": "operation",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "and",
            "or",
            "xor",
            "nand",
            "nor"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.boolean.BooleanOperation"
        },
        "default": "and",
        "title": "Operation",
        "description": "Logical operation to perform",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "a",
      "b",
      "operation"
    ]
  },
  {
    "title": "Not",
    "description": "Performs logical NOT operation on a boolean input.\n    boolean, logic, not, invert\n\n    Use cases:\n    - Invert a condition's result\n    - Implement toggle functionality\n    - Create opposite logic branches",
    "namespace": "nodetool.boolean",
    "node_type": "nodetool.boolean.Not",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Value",
        "description": "Boolean input to negate",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "Compare",
    "description": "Compares two values using a specified comparison operator.\n    compare, condition, logic\n\n    Use cases:\n    - Implement decision points in workflows\n    - Filter data based on specific criteria\n    - Create dynamic thresholds or limits",
    "namespace": "nodetool.boolean",
    "node_type": "nodetool.boolean.Compare",
    "layout": "default",
    "properties": [
      {
        "name": "a",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "A",
        "description": "First value to compare",
        "min": null,
        "max": null
      },
      {
        "name": "b",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "B",
        "description": "Second value to compare",
        "min": null,
        "max": null
      },
      {
        "name": "comparison",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "==",
            "!=",
            ">",
            "<",
            ">=",
            "<="
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.boolean.Comparison"
        },
        "default": "==",
        "title": "Comparison",
        "description": "Comparison operator to use",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "a",
      "b",
      "comparison"
    ]
  },
  {
    "title": "Is None",
    "description": "Checks if a value is None.\n    null, none, check\n\n    Use cases:\n    - Validate input presence\n    - Handle optional parameters\n    - Implement null checks in data processing",
    "namespace": "nodetool.boolean",
    "node_type": "nodetool.boolean.IsNone",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Value",
        "description": "The value to check for None",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "Is In",
    "description": "Checks if a value is present in a list of options.\n    membership, contains, check\n\n    Use cases:\n    - Validate input against a set of allowed values\n    - Implement category or group checks\n    - Filter data based on inclusion criteria",
    "namespace": "nodetool.boolean",
    "node_type": "nodetool.boolean.IsIn",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Value",
        "description": "The value to check for membership",
        "min": null,
        "max": null
      },
      {
        "name": "options",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Options",
        "description": "The list of options to check against",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value",
      "options"
    ]
  },
  {
    "title": "All",
    "description": "Checks if all boolean values in a list are True.\n    boolean, all, check\n\n    Use cases:\n    - Ensure all conditions in a set are met\n    - Implement comprehensive checks\n    - Validate multiple criteria simultaneously",
    "namespace": "nodetool.boolean",
    "node_type": "nodetool.boolean.All",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "bool",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": "List of boolean values to check",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values"
    ]
  },
  {
    "title": "Some",
    "description": "Checks if any boolean value in a list is True.\n    boolean, any, check\n\n    Use cases:\n    - Check if at least one condition in a set is met\n    - Implement optional criteria checks\n    - Create flexible validation rules",
    "namespace": "nodetool.boolean",
    "node_type": "nodetool.boolean.Some",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "bool",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": "List of boolean values to check",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values"
    ]
  },
  {
    "title": "Execute Python",
    "description": "Executes Python code with safety restrictions.\n    python, code, execute\n\n    Use cases:\n    - Run custom data transformations\n    - Prototype node functionality\n    - Debug and testing workflows\n\n    IMPORTANT: Only enabled in non-production environments",
    "namespace": "nodetool.code",
    "node_type": "nodetool.code.ExecutePython",
    "layout": "default",
    "properties": [
      {
        "name": "code",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Code",
        "description": "Python code to execute. Input variables are available as locals. Assign the desired output to the 'result' variable.",
        "min": null,
        "max": null
      },
      {
        "name": "inputs",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Inputs",
        "description": "Input variables available to the code as locals.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "code",
      "inputs"
    ]
  },
  {
    "title": "Evaluate Expression",
    "description": "Evaluates a Python expression with safety restrictions.\n    python, expression, evaluate\n\n    Use cases:\n    - Calculate values dynamically\n    - Transform data with simple expressions\n    - Quick data validation\n\n    IMPORTANT: Only enabled in non-production environments",
    "namespace": "nodetool.code",
    "node_type": "nodetool.code.EvaluateExpression",
    "layout": "default",
    "properties": [
      {
        "name": "expression",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Expression",
        "description": "Python expression to evaluate. Variables are available as locals.",
        "min": null,
        "max": null
      },
      {
        "name": "variables",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Variables",
        "description": "Variables available to the expression",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "expression",
      "variables"
    ]
  },
  {
    "title": "Constant",
    "description": "",
    "namespace": "nodetool.constant",
    "node_type": "nodetool.constant.Constant",
    "layout": "default",
    "properties": [],
    "outputs": [
      {
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": []
  },
  {
    "title": "Audio",
    "description": "Represents an audio file constant in the workflow.\n    audio, file, mp3, wav\n\n    Use cases:\n    - Provide a fixed audio input for audio processing nodes\n    - Reference a specific audio file in the workflow\n    - Set default audio for testing or demonstration purposes",
    "namespace": "nodetool.constant",
    "node_type": "nodetool.constant.Audio",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "Bool",
    "description": "Represents a boolean constant in the workflow.\n    boolean, logic, flag\n\n    Use cases:\n    - Control flow decisions in conditional nodes\n    - Toggle features or behaviors in the workflow\n    - Set default boolean values for configuration",
    "namespace": "nodetool.constant",
    "node_type": "nodetool.constant.Bool",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "Data Frame",
    "description": "Represents a fixed DataFrame constant in the workflow.\n    table, data, dataframe, pandas\n\n    Use cases:\n    - Provide static data for analysis or processing\n    - Define lookup tables or reference data\n    - Set sample data for testing or demonstration",
    "namespace": "nodetool.constant",
    "node_type": "nodetool.constant.DataFrame",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "DataFrame",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "Document",
    "description": "Represents a document constant in the workflow.\n    document, pdf, word, docx",
    "namespace": "nodetool.constant",
    "node_type": "nodetool.constant.Document",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "document",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Document",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "Dict",
    "description": "Represents a dictionary constant in the workflow.\n    dictionary, key-value, mapping\n\n    Use cases:\n    - Store configuration settings\n    - Provide structured data inputs\n    - Define parameter sets for other nodes",
    "namespace": "nodetool.constant",
    "node_type": "nodetool.constant.Dict",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": {},
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "Image",
    "description": "Represents an image file constant in the workflow.\n    picture, photo, image\n\n    Use cases:\n    - Provide a fixed image input for image processing nodes\n    - Reference a specific image file in the workflow\n    - Set default image for testing or demonstration purposes",
    "namespace": "nodetool.constant",
    "node_type": "nodetool.constant.Image",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "Integer",
    "description": "Represents an integer constant in the workflow.\n    number, integer, whole\n\n    Use cases:\n    - Set numerical parameters for calculations\n    - Define counts, indices, or sizes\n    - Provide fixed numerical inputs for processing",
    "namespace": "nodetool.constant",
    "node_type": "nodetool.constant.Integer",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "List",
    "description": "Represents a list constant in the workflow.\n    array, squence, collection\n\n    Use cases:\n    - Store multiple values of the same type\n    - Provide ordered data inputs\n    - Define sequences for iteration in other nodes",
    "namespace": "nodetool.constant",
    "node_type": "nodetool.constant.List",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "Float",
    "description": "Represents a floating-point number constant in the workflow.\n    number, decimal, float\n\n    Use cases:\n    - Set numerical parameters for calculations\n    - Define thresholds or limits\n    - Provide fixed numerical inputs for processing",
    "namespace": "nodetool.constant",
    "node_type": "nodetool.constant.Float",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "String",
    "description": "Represents a string constant in the workflow.\n    text, string, characters\n\n    Use cases:\n    - Provide fixed text inputs for processing\n    - Define labels, identifiers, or names\n    - Set default text values for configuration",
    "namespace": "nodetool.constant",
    "node_type": "nodetool.constant.String",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "Text",
    "description": "Represents a text document constant in the workflow.\n    document, markdown, content\n\n    Use cases:\n    - Provide larger text inputs for natural language processing\n    - Store formatted content or documentation\n    - Set default text documents for analysis",
    "namespace": "nodetool.constant",
    "node_type": "nodetool.constant.Text",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "text",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "text",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "text",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "Video",
    "description": "Represents a video file constant in the workflow.\n    video, movie, mp4, file\n\n    Use cases:\n    - Provide a fixed video input for video processing nodes\n    - Reference a specific video file in the workflow\n    - Set default video for testing or demonstration purposes",
    "namespace": "nodetool.constant",
    "node_type": "nodetool.constant.Video",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "Date",
    "description": "Make a date object from year, month, day.\n    date, make, create",
    "namespace": "nodetool.constant",
    "node_type": "nodetool.constant.Date",
    "layout": "default",
    "properties": [
      {
        "name": "year",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2025,
        "title": "Year",
        "description": "Year of the date",
        "min": null,
        "max": null
      },
      {
        "name": "month",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Month",
        "description": "Month of the date",
        "min": null,
        "max": null
      },
      {
        "name": "day",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 13,
        "title": "Day",
        "description": "Day of the date",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "date",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "year",
      "month",
      "day"
    ]
  },
  {
    "title": "Date Time",
    "description": "Make a datetime object from year, month, day, hour, minute, second.\n    datetime, make, create",
    "namespace": "nodetool.constant",
    "node_type": "nodetool.constant.DateTime",
    "layout": "default",
    "properties": [
      {
        "name": "year",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2025,
        "title": "Year",
        "description": "Year of the datetime",
        "min": null,
        "max": null
      },
      {
        "name": "month",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Month",
        "description": "Month of the datetime",
        "min": null,
        "max": null
      },
      {
        "name": "day",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 13,
        "title": "Day",
        "description": "Day of the datetime",
        "min": null,
        "max": null
      },
      {
        "name": "hour",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Hour",
        "description": "Hour of the datetime",
        "min": null,
        "max": null
      },
      {
        "name": "minute",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Minute",
        "description": "Minute of the datetime",
        "min": null,
        "max": null
      },
      {
        "name": "second",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Second",
        "description": "Second of the datetime",
        "min": null,
        "max": null
      },
      {
        "name": "microsecond",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Microsecond",
        "description": "Microsecond of the datetime",
        "min": null,
        "max": null
      },
      {
        "name": "tzinfo",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Tzinfo",
        "description": "Timezone of the datetime",
        "min": null,
        "max": null
      },
      {
        "name": "utc_offset",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Utc Offset",
        "description": "UTC offset of the datetime",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "year",
      "month",
      "day",
      "hour",
      "minute",
      "second",
      "microsecond",
      "tzinfo",
      "utc_offset"
    ]
  },
  {
    "title": "If",
    "description": "Conditionally executes one of two branches based on a condition.\n    control, flow, condition\n\n    Use cases:\n    - Branch workflow based on conditions\n    - Handle different cases in data processing\n    - Implement decision logic",
    "namespace": "nodetool.control",
    "node_type": "nodetool.control.If",
    "layout": "default",
    "properties": [
      {
        "name": "condition",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Condition",
        "description": "The condition to evaluate",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Value",
        "description": "The value to pass to the next node",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "if_true",
        "stream": false
      },
      {
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "if_false",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "condition",
      "value"
    ]
  },
  {
    "title": "Save Dataframe",
    "description": "Save dataframe in specified folder.\n    csv, folder, save\n\n    Use cases:\n    - Export processed data for external use\n    - Create backups of dataframes",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.SaveDataframe",
    "layout": "default",
    "properties": [
      {
        "name": "df",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Df",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "folder",
        "type": {
          "type": "folder",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "folder",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Folder",
        "description": "Name of the output folder.",
        "min": null,
        "max": null
      },
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "output.csv",
        "title": "Name",
        "description": "\n        Name of the output file.\n        You can use time and date variables to create unique names:\n        %Y - Year\n        %m - Month\n        %d - Day\n        %H - Hour\n        %M - Minute\n        %S - Second\n        ",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "df",
      "folder",
      "name"
    ]
  },
  {
    "title": "Select Column",
    "description": "Select specific columns from dataframe.\n    dataframe, columns, filter\n\n    Use cases:\n    - Extract relevant features for analysis\n    - Reduce dataframe size by removing unnecessary columns\n    - Prepare data for specific visualizations or models",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.SelectColumn",
    "layout": "default",
    "properties": [
      {
        "name": "dataframe",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Dataframe",
        "description": "a dataframe from which columns are to be selected",
        "min": null,
        "max": null
      },
      {
        "name": "columns",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Columns",
        "description": "comma separated list of column names",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dataframe",
      "columns"
    ]
  },
  {
    "title": "Extract Column",
    "description": "Convert dataframe column to list.\n    dataframe, column, list\n\n    Use cases:\n    - Extract data for use in other processing steps\n    - Prepare column data for plotting or analysis\n    - Convert categorical data to list for encoding",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.ExtractColumn",
    "layout": "default",
    "properties": [
      {
        "name": "dataframe",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Dataframe",
        "description": "The input dataframe.",
        "min": null,
        "max": null
      },
      {
        "name": "column_name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Column Name",
        "description": "The name of the column to be converted to a list.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dataframe",
      "column_name"
    ]
  },
  {
    "title": "Format As Text",
    "description": "Convert dataframe rows to formatted strings.\n    dataframe, string, format\n\n    Use cases:\n    - Generate text summaries from row data\n    - Prepare data for natural language processing\n    - Create custom string representations of rows",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.FormatAsText",
    "layout": "default",
    "properties": [
      {
        "name": "dataframe",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Dataframe",
        "description": "The input dataframe.",
        "min": null,
        "max": null
      },
      {
        "name": "template",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Template",
        "description": "The template for the string representation. Each column can be referenced by {column_name}.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dataframe",
      "template"
    ]
  },
  {
    "title": "Add Column",
    "description": "Add list of values as new column to dataframe.\n    dataframe, column, list\n\n    Use cases:\n    - Incorporate external data into existing dataframe\n    - Add calculated results as new column\n    - Augment dataframe with additional features",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.AddColumn",
    "layout": "default",
    "properties": [
      {
        "name": "dataframe",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Dataframe",
        "description": "Dataframe object to add a new column to.",
        "min": null,
        "max": null
      },
      {
        "name": "column_name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Column Name",
        "description": "The name of the new column to be added to the dataframe.",
        "min": null,
        "max": null
      },
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": "A list of any type of elements which will be the new column's values.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dataframe",
      "column_name",
      "values"
    ]
  },
  {
    "title": "From List",
    "description": "Convert list of dicts to dataframe.\n    list, dataframe, convert\n\n    Use cases:\n    - Transform list data into structured dataframe\n    - Prepare list data for analysis or visualization\n    - Convert API responses to dataframe format",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.FromList",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Values",
        "description": "List of values to be converted, each value will be a row.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values"
    ]
  },
  {
    "title": "Import CSV",
    "description": "Convert CSV string to dataframe.\n    csv, dataframe, import\n\n    Use cases:\n    - Import CSV data from string input\n    - Convert CSV responses from APIs to dataframe",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.ImportCSV",
    "layout": "default",
    "properties": [
      {
        "name": "csv_data",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "CSV Data",
        "description": "String input of CSV formatted text.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "csv_data"
    ]
  },
  {
    "title": "Merge Side By Side",
    "description": "Merge two dataframes along columns.\n    merge, concat, columns\n\n    Use cases:\n    - Combine data from multiple sources\n    - Add new features to existing dataframe\n    - Merge time series data from different periods",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.MergeSideBySide",
    "layout": "default",
    "properties": [
      {
        "name": "dataframe_a",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Dataframe A",
        "description": "First DataFrame to be merged.",
        "min": null,
        "max": null
      },
      {
        "name": "dataframe_b",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Dataframe B",
        "description": "Second DataFrame to be merged.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dataframe_a",
      "dataframe_b"
    ]
  },
  {
    "title": "Combine Vertically",
    "description": "Append two dataframes along rows.\n    append, concat, rows\n\n    Use cases:\n    - Combine data from multiple time periods\n    - Merge datasets with same structure\n    - Aggregate data from different sources",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.CombineVertically",
    "layout": "default",
    "properties": [
      {
        "name": "dataframe_a",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Dataframe A",
        "description": "First DataFrame to be appended.",
        "min": null,
        "max": null
      },
      {
        "name": "dataframe_b",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Dataframe B",
        "description": "Second DataFrame to be appended.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dataframe_a",
      "dataframe_b"
    ]
  },
  {
    "title": "Join",
    "description": "Join two dataframes on specified column.\n    join, merge, column\n\n    Use cases:\n    - Combine data from related tables\n    - Enrich dataset with additional information\n    - Link data based on common identifiers",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.Join",
    "layout": "default",
    "properties": [
      {
        "name": "dataframe_a",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Dataframe A",
        "description": "First DataFrame to be merged.",
        "min": null,
        "max": null
      },
      {
        "name": "dataframe_b",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Dataframe B",
        "description": "Second DataFrame to be merged.",
        "min": null,
        "max": null
      },
      {
        "name": "join_on",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Join On",
        "description": "The column name on which to join the two dataframes.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dataframe_a",
      "dataframe_b",
      "join_on"
    ]
  },
  {
    "title": "Convert To Tensor",
    "description": "Convert dataframe to tensor.\n    dataframe, tensor, convert\n\n    Use cases:\n    - Prepare data for deep learning models\n    - Enable tensor operations on dataframe data\n    - Convert tabular data to multidimensional format",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.ConvertToTensor",
    "layout": "default",
    "properties": [
      {
        "name": "dataframe",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Dataframe",
        "description": "The input dataframe.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dataframe"
    ]
  },
  {
    "title": "Chart",
    "description": "Create line, bar, or scatter plot from dataframe.\n    plot, visualization, dataframe\n\n    Use cases:\n    - Visualize trends in time series data\n    - Compare values across categories\n    - Explore relationships between variables",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.Chart",
    "layout": "default",
    "properties": [
      {
        "name": "dataframe",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Dataframe",
        "description": "The input dataframe.",
        "min": null,
        "max": null
      },
      {
        "name": "x_column",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "X Column",
        "description": "The name of the x column to be used in the plot.",
        "min": null,
        "max": null
      },
      {
        "name": "y_column",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Y Column",
        "description": "The name of the y column to be used in the plot.",
        "min": null,
        "max": null
      },
      {
        "name": "plot_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "line",
            "bar",
            "scatter"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.dataframe.PlotType"
        },
        "default": "line",
        "title": "Plot Type",
        "description": "The type of plot to be created. Can be 'line', 'bar', or 'scatter'.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dataframe",
      "x_column",
      "y_column",
      "plot_type"
    ]
  },
  {
    "title": "Histogram",
    "description": "Plot histogram of dataframe column.\n    histogram, plot, distribution\n\n    Use cases:\n    - Visualize distribution of continuous data\n    - Identify outliers and data patterns\n    - Compare data distributions across categories",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.Histogram",
    "layout": "default",
    "properties": [
      {
        "name": "dataframe",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Dataframe",
        "description": "The input dataframe.",
        "min": null,
        "max": null
      },
      {
        "name": "column",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Column",
        "description": "The column to plot.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dataframe",
      "column"
    ]
  },
  {
    "title": "Heatmap",
    "description": "Create heatmap visualization of dataframe.\n    heatmap, plot, correlation\n\n    Use cases:\n    - Visualize correlation between variables\n    - Identify patterns in multi-dimensional data\n    - Display intensity of values across categories",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.Heatmap",
    "layout": "default",
    "properties": [
      {
        "name": "dataframe",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Dataframe",
        "description": "The input dataframe.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dataframe"
    ]
  },
  {
    "title": "Filter",
    "description": "Filter dataframe based on condition.\n    filter, query, condition\n\n    Example conditions:\n    age > 30\n    age > 30 and salary < 50000\n    name == 'John Doe'\n    100 <= price <= 200\n    status in ['Active', 'Pending']\n    not (age < 18)\n\n    Use cases:\n    - Extract subset of data meeting specific criteria\n    - Remove outliers or invalid data points\n    - Focus analysis on relevant data segments",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.Filter",
    "layout": "default",
    "properties": [
      {
        "name": "df",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Df",
        "description": "The DataFrame to filter.",
        "min": null,
        "max": null
      },
      {
        "name": "condition",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Condition",
        "description": "The filtering condition to be applied to the DataFrame, e.g. column_name > 5.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "df",
      "condition"
    ]
  },
  {
    "title": "Find One Row",
    "description": "Find the first row in a dataframe that matches a given condition.\n    filter, query, condition, single row\n\n    Example conditions:\n    age > 30\n    age > 30 and salary < 50000\n    name == 'John Doe'\n    100 <= price <= 200\n    status in ['Active', 'Pending']\n    not (age < 18)\n\n    Use cases:\n    - Retrieve specific record based on criteria\n    - Find first occurrence of a particular condition\n    - Extract single data point for further analysis",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.FindOneRow",
    "layout": "default",
    "properties": [
      {
        "name": "df",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Df",
        "description": "The DataFrame to search.",
        "min": null,
        "max": null
      },
      {
        "name": "condition",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Condition",
        "description": "The condition to filter the DataFrame, e.g. 'column_name == value'.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "df",
      "condition"
    ]
  },
  {
    "title": "Sort By Column",
    "description": "Sort dataframe by specified column.\n    sort, order, column\n\n    Use cases:\n    - Arrange data in ascending or descending order\n    - Identify top or bottom values in dataset\n    - Prepare data for rank-based analysis",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.SortByColumn",
    "layout": "default",
    "properties": [
      {
        "name": "df",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Df",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "column",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Column",
        "description": "The column to sort the DataFrame by.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "df",
      "column"
    ]
  },
  {
    "title": "Remove Duplicates",
    "description": "Remove duplicate rows from dataframe.\n    duplicates, unique, clean\n\n    Use cases:\n    - Clean dataset by removing redundant entries\n    - Ensure data integrity in analysis\n    - Prepare data for unique value operations",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.RemoveDuplicates",
    "layout": "default",
    "properties": [
      {
        "name": "df",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Df",
        "description": "The input DataFrame.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "df"
    ]
  },
  {
    "title": "Remove Incomplete Rows",
    "description": "Remove rows with NA values from dataframe.\n    na, missing, clean\n\n    Use cases:\n    - Clean dataset by removing incomplete entries\n    - Prepare data for analysis requiring complete cases\n    - Improve data quality for modeling",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.RemoveIncompleteRows",
    "layout": "default",
    "properties": [
      {
        "name": "df",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Df",
        "description": "The input DataFrame.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "df"
    ]
  },
  {
    "title": "Load Iris Dataset",
    "description": "Load Iris dataset as dataframe.\n    iris, dataset, machine learning\n\n    Use cases:\n    - Practice machine learning techniques\n    - Benchmark classification algorithms\n    - Demonstrate data analysis workflows",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.LoadIrisDataset",
    "layout": "default",
    "properties": [],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "data",
        "stream": false
      },
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "target",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": []
  },
  {
    "title": "Slice",
    "description": "Slice a dataframe by rows using start and end indices.\n    slice, subset, rows\n\n    Use cases:\n    - Extract a specific range of rows from a large dataset\n    - Create training and testing subsets for machine learning\n    - Analyze data in smaller chunks",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.Slice",
    "layout": "default",
    "properties": [
      {
        "name": "dataframe",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Dataframe",
        "description": "The input dataframe to be sliced.",
        "min": null,
        "max": null
      },
      {
        "name": "start_index",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Start Index",
        "description": "The starting index of the slice (inclusive).",
        "min": null,
        "max": null
      },
      {
        "name": "end_index",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "End Index",
        "description": "The ending index of the slice (exclusive). Use -1 for the last row.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dataframe",
      "start_index",
      "end_index"
    ]
  },
  {
    "title": "To List",
    "description": "Convert dataframe to list of dictionaries.\n    dataframe, list, convert\n\n    Use cases:\n    - Convert dataframe data for API consumption\n    - Transform data for JSON serialization\n    - Prepare data for document-based storage",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.ToList",
    "layout": "default",
    "properties": [
      {
        "name": "dataframe",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Dataframe",
        "description": "The input dataframe to convert.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dataframe"
    ]
  },
  {
    "title": "Map Template",
    "description": "Maps a template string over dataframe rows.\n    dataframe, template, format, string\n\n    Use cases:\n    - Format each row into a custom string representation\n    - Generate text summaries from structured data\n    - Create formatted output from dataframe records\n    \n    Example:\n    Template: \"Name: {name}, Age: {age}\"\n    Row: {\"name\": \"Alice\", \"age\": 30}\n    Output: \"Name: Alice, Age: 30\"",
    "namespace": "nodetool.dataframe",
    "node_type": "nodetool.dataframe.MapTemplate",
    "layout": "default",
    "properties": [
      {
        "name": "dataframe",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Dataframe",
        "description": "The input dataframe.",
        "min": null,
        "max": null
      },
      {
        "name": "template",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Template",
        "description": "Template string with placeholders matching column names (e.g., {column_name}).",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dataframe",
      "template"
    ]
  },
  {
    "title": "Today",
    "description": "Get the current date.\n    date, today, now",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.Today",
    "layout": "default",
    "properties": [],
    "outputs": [
      {
        "type": {
          "type": "date",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": []
  },
  {
    "title": "Now",
    "description": "Get the current date and time.\n    datetime, current, now",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.Now",
    "layout": "default",
    "properties": [],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": []
  },
  {
    "title": "Parse Date",
    "description": "Parse a date string into components.\n    date, parse, format",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.ParseDate",
    "layout": "default",
    "properties": [
      {
        "name": "date_string",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Date String",
        "description": "The date string to parse",
        "min": null,
        "max": null
      },
      {
        "name": "input_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "%Y-%m-%d",
            "%m/%d/%Y",
            "%d/%m/%Y",
            "%B %d, %Y",
            "%Y%m%d",
            "%Y%m%d_%H%M%S",
            "%Y-%m-%dT%H:%M:%S",
            "%Y-%m-%dT%H:%M:%S%z",
            "%Y-%m-%dT%H:%M:%S%z"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.date.DateFormat"
        },
        "default": "%Y-%m-%d",
        "title": "Input Format",
        "description": "Format of the input date string",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "date",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "date_string",
      "input_format"
    ]
  },
  {
    "title": "Parse Date Time",
    "description": "Parse a date/time string into components.\n    datetime, parse, format\n\n    Use cases:\n    - Extract date components from strings\n    - Convert between date formats",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.ParseDateTime",
    "layout": "default",
    "properties": [
      {
        "name": "datetime_string",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Datetime String",
        "description": "The datetime string to parse",
        "min": null,
        "max": null
      },
      {
        "name": "input_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "%Y-%m-%d",
            "%m/%d/%Y",
            "%d/%m/%Y",
            "%B %d, %Y",
            "%Y%m%d",
            "%Y%m%d_%H%M%S",
            "%Y-%m-%dT%H:%M:%S",
            "%Y-%m-%dT%H:%M:%S%z",
            "%Y-%m-%dT%H:%M:%S%z"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.date.DateFormat"
        },
        "default": "%Y-%m-%d",
        "title": "Input Format",
        "description": "Format of the input datetime string",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "datetime_string",
      "input_format"
    ]
  },
  {
    "title": "Add Time Delta",
    "description": "Add or subtract time from a datetime.\n    datetime, add, subtract\n\n    Use cases:\n    - Calculate future/past dates\n    - Generate date ranges",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.AddTimeDelta",
    "layout": "default",
    "properties": [
      {
        "name": "input_datetime",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 2025,
          "month": 1,
          "day": 13,
          "hour": 23,
          "minute": 44,
          "second": 4,
          "microsecond": 998420,
          "tzinfo": "UTC",
          "utc_offset": 0.0
        },
        "title": "Input Datetime",
        "description": "Starting datetime",
        "min": null,
        "max": null
      },
      {
        "name": "days",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Days",
        "description": "Number of days to add (negative to subtract)",
        "min": -3650.0,
        "max": 3650.0
      },
      {
        "name": "hours",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Hours",
        "description": "Number of hours to add (negative to subtract)",
        "min": -24.0,
        "max": 24.0
      },
      {
        "name": "minutes",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Minutes",
        "description": "Number of minutes to add (negative to subtract)",
        "min": -60.0,
        "max": 60.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input_datetime",
      "days",
      "hours",
      "minutes"
    ]
  },
  {
    "title": "Date Difference",
    "description": "Calculate the difference between two dates.\n    datetime, difference, duration\n\n    Use cases:\n    - Calculate time periods\n    - Measure durations",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.DateDifference",
    "layout": "default",
    "properties": [
      {
        "name": "start_date",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 0,
          "month": 0,
          "day": 0,
          "hour": 0,
          "minute": 0,
          "second": 0,
          "microsecond": 0,
          "tzinfo": "UTC",
          "utc_offset": 0
        },
        "title": "Start Date",
        "description": "Start datetime",
        "min": null,
        "max": null
      },
      {
        "name": "end_date",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 0,
          "month": 0,
          "day": 0,
          "hour": 0,
          "minute": 0,
          "second": 0,
          "microsecond": 0,
          "tzinfo": "UTC",
          "utc_offset": 0
        },
        "title": "End Date",
        "description": "End datetime",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "total_seconds",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "days",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "hours",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "minutes",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "seconds",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "start_date",
      "end_date"
    ]
  },
  {
    "title": "Format Date Time",
    "description": "Convert a datetime object to a formatted string.\n    datetime, format, convert\n\n    Use cases:\n    - Standardize date formats\n    - Prepare dates for different systems",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.FormatDateTime",
    "layout": "default",
    "properties": [
      {
        "name": "input_datetime",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 0,
          "month": 0,
          "day": 0,
          "hour": 0,
          "minute": 0,
          "second": 0,
          "microsecond": 0,
          "tzinfo": "UTC",
          "utc_offset": 0
        },
        "title": "Input Datetime",
        "description": "Datetime object to format",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "%Y-%m-%d",
            "%m/%d/%Y",
            "%d/%m/%Y",
            "%B %d, %Y",
            "%Y%m%d",
            "%Y%m%d_%H%M%S",
            "%Y-%m-%dT%H:%M:%S",
            "%Y-%m-%dT%H:%M:%S%z",
            "%Y-%m-%dT%H:%M:%S%z"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.date.DateFormat"
        },
        "default": "%B %d, %Y",
        "title": "Output Format",
        "description": "Desired output format",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input_datetime",
      "output_format"
    ]
  },
  {
    "title": "Get Weekday",
    "description": "Get the weekday name or number from a datetime.\n    datetime, weekday, name\n\n    Use cases:\n    - Get day names for scheduling\n    - Filter events by weekday",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.GetWeekday",
    "layout": "default",
    "properties": [
      {
        "name": "input_datetime",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 0,
          "month": 0,
          "day": 0,
          "hour": 0,
          "minute": 0,
          "second": 0,
          "microsecond": 0,
          "tzinfo": "UTC",
          "utc_offset": 0
        },
        "title": "Input Datetime",
        "description": "Input datetime",
        "min": null,
        "max": null
      },
      {
        "name": "as_name",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "As Name",
        "description": "Return weekday name instead of number (0-6)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input_datetime",
      "as_name"
    ]
  },
  {
    "title": "Date Range",
    "description": "Generate a list of dates between start and end dates.\n    datetime, range, list\n\n    Use cases:\n    - Generate date sequences\n    - Create date-based iterations",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.DateRange",
    "layout": "default",
    "properties": [
      {
        "name": "start_date",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 0,
          "month": 0,
          "day": 0,
          "hour": 0,
          "minute": 0,
          "second": 0,
          "microsecond": 0,
          "tzinfo": "UTC",
          "utc_offset": 0
        },
        "title": "Start Date",
        "description": "Start date of the range",
        "min": null,
        "max": null
      },
      {
        "name": "end_date",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 0,
          "month": 0,
          "day": 0,
          "hour": 0,
          "minute": 0,
          "second": 0,
          "microsecond": 0,
          "tzinfo": "UTC",
          "utc_offset": 0
        },
        "title": "End Date",
        "description": "End date of the range",
        "min": null,
        "max": null
      },
      {
        "name": "step_days",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Step Days",
        "description": "Number of days between each date",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "datetime",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "start_date",
      "end_date",
      "step_days"
    ]
  },
  {
    "title": "Is Date In Range",
    "description": "Check if a date falls within a specified range.\n    datetime, range, check\n\n    Use cases:\n    - Validate date ranges\n    - Filter date-based data",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.IsDateInRange",
    "layout": "default",
    "properties": [
      {
        "name": "check_date",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 0,
          "month": 0,
          "day": 0,
          "hour": 0,
          "minute": 0,
          "second": 0,
          "microsecond": 0,
          "tzinfo": "UTC",
          "utc_offset": 0
        },
        "title": "Check Date",
        "description": "Date to check",
        "min": null,
        "max": null
      },
      {
        "name": "start_date",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 0,
          "month": 0,
          "day": 0,
          "hour": 0,
          "minute": 0,
          "second": 0,
          "microsecond": 0,
          "tzinfo": "UTC",
          "utc_offset": 0
        },
        "title": "Start Date",
        "description": "Start of date range",
        "min": null,
        "max": null
      },
      {
        "name": "end_date",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 0,
          "month": 0,
          "day": 0,
          "hour": 0,
          "minute": 0,
          "second": 0,
          "microsecond": 0,
          "tzinfo": "UTC",
          "utc_offset": 0
        },
        "title": "End Date",
        "description": "End of date range",
        "min": null,
        "max": null
      },
      {
        "name": "inclusive",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Inclusive",
        "description": "Include start and end dates in range",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "check_date",
      "start_date",
      "end_date",
      "inclusive"
    ]
  },
  {
    "title": "Get Quarter",
    "description": "Get the quarter number and start/end dates for a given datetime.\n    datetime, quarter, period\n\n    Use cases:\n    - Financial reporting periods\n    - Quarterly analytics",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.GetQuarter",
    "layout": "default",
    "properties": [
      {
        "name": "input_datetime",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 0,
          "month": 0,
          "day": 0,
          "hour": 0,
          "minute": 0,
          "second": 0,
          "microsecond": 0,
          "tzinfo": "UTC",
          "utc_offset": 0
        },
        "title": "Input Datetime",
        "description": "Input datetime",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "quarter",
        "stream": false
      },
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "quarter_start",
        "stream": false
      },
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "quarter_end",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input_datetime"
    ]
  },
  {
    "title": "Date To Datetime",
    "description": "Convert a Date object to a Datetime object.\n    date, datetime, convert",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.DateToDatetime",
    "layout": "default",
    "properties": [
      {
        "name": "input_date",
        "type": {
          "type": "date",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "date",
          "year": 0,
          "month": 0,
          "day": 0
        },
        "title": "Input Date",
        "description": "Date to convert",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input_date"
    ]
  },
  {
    "title": "Datetime To Date",
    "description": "Convert a Datetime object to a Date object.\n    date, datetime, convert",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.DatetimeToDate",
    "layout": "default",
    "properties": [
      {
        "name": "input_datetime",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 0,
          "month": 0,
          "day": 0,
          "hour": 0,
          "minute": 0,
          "second": 0,
          "microsecond": 0,
          "tzinfo": "UTC",
          "utc_offset": 0
        },
        "title": "Input Datetime",
        "description": "Datetime to convert",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "date",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input_datetime"
    ]
  },
  {
    "title": "Hours Ago",
    "description": "Get datetime from specified hours ago.\n    datetime, past, hours",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.HoursAgo",
    "layout": "default",
    "properties": [
      {
        "name": "hours",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Hours",
        "description": "Number of hours ago",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "hours"
    ]
  },
  {
    "title": "Hours From Now",
    "description": "Get datetime specified hours in the future.\n    datetime, future, hours",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.HoursFromNow",
    "layout": "default",
    "properties": [
      {
        "name": "hours",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Hours",
        "description": "Number of hours in the future",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "hours"
    ]
  },
  {
    "title": "Days Ago",
    "description": "Get datetime from specified days ago.\n    datetime, past, days",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.DaysAgo",
    "layout": "default",
    "properties": [
      {
        "name": "days",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Days",
        "description": "Number of days ago",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "days"
    ]
  },
  {
    "title": "Days From Now",
    "description": "Get datetime specified days in the future.\n    datetime, future, days",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.DaysFromNow",
    "layout": "default",
    "properties": [
      {
        "name": "days",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Days",
        "description": "Number of days in the future",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "days"
    ]
  },
  {
    "title": "Months Ago",
    "description": "Get datetime from specified months ago.\n    datetime, past, months",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.MonthsAgo",
    "layout": "default",
    "properties": [
      {
        "name": "months",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Months",
        "description": "Number of months ago",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "months"
    ]
  },
  {
    "title": "Months From Now",
    "description": "Get datetime specified months in the future.\n    datetime, future, months",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.MonthsFromNow",
    "layout": "default",
    "properties": [
      {
        "name": "months",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Months",
        "description": "Number of months in the future",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "months"
    ]
  },
  {
    "title": "Start Of Day",
    "description": "Get the datetime set to the start of the day (00:00:00).\n    datetime, day, start",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.StartOfDay",
    "layout": "default",
    "properties": [
      {
        "name": "input_datetime",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 2025,
          "month": 1,
          "day": 13,
          "hour": 23,
          "minute": 44,
          "second": 5,
          "microsecond": 2361,
          "tzinfo": "UTC",
          "utc_offset": 0.0
        },
        "title": "Input Datetime",
        "description": "Input datetime",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input_datetime"
    ]
  },
  {
    "title": "End Of Day",
    "description": "Get the datetime set to the end of the day (23:59:59).\n    datetime, day, end",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.EndOfDay",
    "layout": "default",
    "properties": [
      {
        "name": "input_datetime",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 2025,
          "month": 1,
          "day": 13,
          "hour": 23,
          "minute": 44,
          "second": 5,
          "microsecond": 2596,
          "tzinfo": "UTC",
          "utc_offset": 0.0
        },
        "title": "Input Datetime",
        "description": "Input datetime",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input_datetime"
    ]
  },
  {
    "title": "Start Of Month",
    "description": "Get the datetime set to the first day of the month.\n    datetime, month, start",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.StartOfMonth",
    "layout": "default",
    "properties": [
      {
        "name": "input_datetime",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 2025,
          "month": 1,
          "day": 13,
          "hour": 23,
          "minute": 44,
          "second": 5,
          "microsecond": 2805,
          "tzinfo": "UTC",
          "utc_offset": 0.0
        },
        "title": "Input Datetime",
        "description": "Input datetime",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input_datetime"
    ]
  },
  {
    "title": "End Of Month",
    "description": "Get the datetime set to the last day of the month.\n    datetime, month, end",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.EndOfMonth",
    "layout": "default",
    "properties": [
      {
        "name": "input_datetime",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 2025,
          "month": 1,
          "day": 13,
          "hour": 23,
          "minute": 44,
          "second": 5,
          "microsecond": 3018,
          "tzinfo": "UTC",
          "utc_offset": 0.0
        },
        "title": "Input Datetime",
        "description": "Input datetime",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input_datetime"
    ]
  },
  {
    "title": "Start Of Year",
    "description": "Get the datetime set to the first day of the year.\n    datetime, year, start",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.StartOfYear",
    "layout": "default",
    "properties": [
      {
        "name": "input_datetime",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 2025,
          "month": 1,
          "day": 13,
          "hour": 23,
          "minute": 44,
          "second": 5,
          "microsecond": 3242,
          "tzinfo": "UTC",
          "utc_offset": 0.0
        },
        "title": "Input Datetime",
        "description": "Input datetime",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input_datetime"
    ]
  },
  {
    "title": "End Of Year",
    "description": "Get the datetime set to the last day of the year.\n    datetime, year, end",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.EndOfYear",
    "layout": "default",
    "properties": [
      {
        "name": "input_datetime",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 2025,
          "month": 1,
          "day": 13,
          "hour": 23,
          "minute": 44,
          "second": 5,
          "microsecond": 3480,
          "tzinfo": "UTC",
          "utc_offset": 0.0
        },
        "title": "Input Datetime",
        "description": "Input datetime",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input_datetime"
    ]
  },
  {
    "title": "Start Of Week",
    "description": "Get the datetime set to the first day of the week (Monday by default).\n    datetime, week, start",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.StartOfWeek",
    "layout": "default",
    "properties": [
      {
        "name": "input_datetime",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 2025,
          "month": 1,
          "day": 13,
          "hour": 23,
          "minute": 44,
          "second": 5,
          "microsecond": 3682,
          "tzinfo": "UTC",
          "utc_offset": 0.0
        },
        "title": "Input Datetime",
        "description": "Input datetime",
        "min": null,
        "max": null
      },
      {
        "name": "start_monday",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Start Monday",
        "description": "Consider Monday as start of week (False for Sunday)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input_datetime",
      "start_monday"
    ]
  },
  {
    "title": "End Of Week",
    "description": "Get the datetime set to the last day of the week (Sunday by default).\n    datetime, week, end",
    "namespace": "nodetool.date",
    "node_type": "nodetool.date.EndOfWeek",
    "layout": "default",
    "properties": [
      {
        "name": "input_datetime",
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "datetime",
          "year": 2025,
          "month": 1,
          "day": 13,
          "hour": 23,
          "minute": 44,
          "second": 5,
          "microsecond": 3922,
          "tzinfo": "UTC",
          "utc_offset": 0.0
        },
        "title": "Input Datetime",
        "description": "Input datetime",
        "min": null,
        "max": null
      },
      {
        "name": "start_monday",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Start Monday",
        "description": "Consider Monday as start of week (False for Sunday)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input_datetime",
      "start_monday"
    ]
  },
  {
    "title": "Get Value",
    "description": "Retrieves a value from a dictionary using a specified key.\n    dictionary, get, value, key\n\n    Use cases:\n    - Access a specific item in a configuration dictionary\n    - Retrieve a value from a parsed JSON object\n    - Extract a particular field from a data structure",
    "namespace": "nodetool.dictionary",
    "node_type": "nodetool.dictionary.GetValue",
    "layout": "small",
    "properties": [
      {
        "name": "dictionary",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": {},
        "title": "Dictionary",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "key",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Key",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "default",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Default",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dictionary",
      "key",
      "default"
    ]
  },
  {
    "title": "Update",
    "description": "Updates a dictionary with new key-value pairs.\n    dictionary, add, update\n\n    Use cases:\n    - Extend a configuration with additional settings\n    - Add new entries to a cache or lookup table\n    - Merge user input with existing data",
    "namespace": "nodetool.dictionary",
    "node_type": "nodetool.dictionary.Update",
    "layout": "small",
    "properties": [
      {
        "name": "dictionary",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": {},
        "title": "Dictionary",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "new_pairs",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": {},
        "title": "New Pairs",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dictionary",
      "new_pairs"
    ]
  },
  {
    "title": "Remove",
    "description": "Removes a key-value pair from a dictionary.\n    dictionary, remove, delete\n\n    Use cases:\n    - Delete a specific configuration option\n    - Remove sensitive information before processing\n    - Clean up temporary entries in a data structure",
    "namespace": "nodetool.dictionary",
    "node_type": "nodetool.dictionary.Remove",
    "layout": "small",
    "properties": [
      {
        "name": "dictionary",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": {},
        "title": "Dictionary",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "key",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Key",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dictionary",
      "key"
    ]
  },
  {
    "title": "Parse JSON",
    "description": "Parses a JSON string into a Python dictionary.\n    json, parse, dictionary\n\n    Use cases:\n    - Process API responses\n    - Load configuration files\n    - Deserialize stored data",
    "namespace": "nodetool.dictionary",
    "node_type": "nodetool.dictionary.ParseJSON",
    "layout": "small",
    "properties": [
      {
        "name": "json_string",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Json String",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "json_string"
    ]
  },
  {
    "title": "Zip",
    "description": "Creates a dictionary from parallel lists of keys and values.\n    dictionary, create, zip\n\n    Use cases:\n    - Convert separate data columns into key-value pairs\n    - Create lookups from parallel data structures\n    - Transform list data into associative arrays",
    "namespace": "nodetool.dictionary",
    "node_type": "nodetool.dictionary.Zip",
    "layout": "small",
    "properties": [
      {
        "name": "keys",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Keys",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "keys",
      "values"
    ]
  },
  {
    "title": "Combine",
    "description": "Merges two dictionaries, with second dictionary values taking precedence.\n    dictionary, merge, update\n\n    Use cases:\n    - Combine default and custom configurations\n    - Merge partial updates with existing data\n    - Create aggregate data structures",
    "namespace": "nodetool.dictionary",
    "node_type": "nodetool.dictionary.Combine",
    "layout": "small",
    "properties": [
      {
        "name": "dict_a",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": {},
        "title": "Dict A",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "dict_b",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": {},
        "title": "Dict B",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dict_a",
      "dict_b"
    ]
  },
  {
    "title": "Filter",
    "description": "Creates a new dictionary with only specified keys from the input.\n    dictionary, filter, select\n\n    Use cases:\n    - Extract relevant fields from a larger data structure\n    - Implement data access controls\n    - Prepare specific data subsets for processing",
    "namespace": "nodetool.dictionary",
    "node_type": "nodetool.dictionary.Filter",
    "layout": "default",
    "properties": [
      {
        "name": "dictionary",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": {},
        "title": "Dictionary",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "keys",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Keys",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dictionary",
      "keys"
    ]
  },
  {
    "title": "Reduce Dictionaries",
    "description": "Reduces a list of dictionaries into one dictionary based on a specified key field.\n    dictionary, reduce, aggregate\n\n    Use cases:\n    - Aggregate data by a specific field\n    - Create summary dictionaries from list of records\n    - Combine multiple data points into a single structure",
    "namespace": "nodetool.dictionary",
    "node_type": "nodetool.dictionary.ReduceDictionaries",
    "layout": "default",
    "properties": [
      {
        "name": "dictionaries",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [
                {
                  "type": "str",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                },
                {
                  "type": "any",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                }
              ],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Dictionaries",
        "description": "List of dictionaries to be reduced",
        "min": null,
        "max": null
      },
      {
        "name": "key_field",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Key Field",
        "description": "The field to use as the key in the resulting dictionary",
        "min": null,
        "max": null
      },
      {
        "name": "value_field",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Value Field",
        "description": "Optional field to use as the value. If not specified, the entire dictionary (minus the key field) will be used as the value.",
        "min": null,
        "max": null
      },
      {
        "name": "conflict_resolution",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "first",
            "last",
            "error"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.dictionary.ConflictResolution"
        },
        "default": "first",
        "title": "Conflict Resolution",
        "description": "How to handle conflicts when the same key appears multiple times",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dictionaries",
      "key_field",
      "value_field",
      "conflict_resolution"
    ]
  },
  {
    "title": "Make Dictionary",
    "description": "Creates a simple dictionary with up to three key-value pairs.\n    dictionary, create, simple\n\n    Use cases:\n    - Create configuration entries\n    - Initialize simple data structures\n    - Build basic key-value mappings",
    "namespace": "nodetool.dictionary",
    "node_type": "nodetool.dictionary.MakeDictionary",
    "layout": "small",
    "properties": [
      {
        "name": "key1",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Key1",
        "description": "First key",
        "min": null,
        "max": null
      },
      {
        "name": "value1",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Value1",
        "description": "First value",
        "min": null,
        "max": null
      },
      {
        "name": "key2",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Key2",
        "description": "Second key (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "value2",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Value2",
        "description": "Second value (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "key3",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Key3",
        "description": "Third key (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "value3",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Value3",
        "description": "Third value (optional)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "key1",
      "value1",
      "key2",
      "value2",
      "key3",
      "value3"
    ]
  },
  {
    "title": "Arg Max",
    "description": "Returns the label associated with the highest value in a dictionary.\n    dictionary, maximum, label, argmax\n\n    Use cases:\n    - Get the most likely class from classification probabilities\n    - Find the category with highest score\n    - Identify the winner in a voting/ranking system",
    "namespace": "nodetool.dictionary",
    "node_type": "nodetool.dictionary.ArgMax",
    "layout": "small",
    "properties": [
      {
        "name": "scores",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": {},
        "title": "Scores",
        "description": "Dictionary mapping labels to their corresponding scores/values",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "scores"
    ]
  },
  {
    "title": "File Exists",
    "description": "Check if a file or directory exists at the specified path.\n    files, check, exists\n\n    Use cases:\n    - Validate file presence before processing\n    - Implement conditional logic based on file existence",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.FileExists",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Path",
        "description": "Path to check for existence",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "List Files",
    "description": "list files in a directory matching a pattern.\n    files, list, directory\n\n    Use cases:\n    - Get files for batch processing\n    - Filter files by extension or pattern",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.ListFiles",
    "layout": "default",
    "properties": [
      {
        "name": "directory",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": "~"
        },
        "title": "Directory",
        "description": "Directory to scan",
        "min": null,
        "max": null
      },
      {
        "name": "pattern",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "*",
        "title": "Pattern",
        "description": "File pattern to match (e.g. *.txt)",
        "min": null,
        "max": null
      },
      {
        "name": "recursive",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Recursive",
        "description": "Search subdirectories",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "file_path",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "directory",
      "pattern",
      "recursive"
    ]
  },
  {
    "title": "Copy File",
    "description": "Copy a file from source to destination path.\n    files, copy, manage\n\n    Use cases:\n    - Create file backups\n    - Duplicate files for processing\n    - Copy files to new locations",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.CopyFile",
    "layout": "default",
    "properties": [
      {
        "name": "source_path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Source Path",
        "description": "Source file path",
        "min": null,
        "max": null
      },
      {
        "name": "destination_path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Destination Path",
        "description": "Destination file path",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "source_path",
      "destination_path"
    ]
  },
  {
    "title": "Move File",
    "description": "Move a file from source to destination path.\n    files, move, manage\n\n    Use cases:\n    - Organize files into directories\n    - Process and archive files\n    - Relocate completed files",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.MoveFile",
    "layout": "default",
    "properties": [
      {
        "name": "source_path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Source Path",
        "description": "Source file path",
        "min": null,
        "max": null
      },
      {
        "name": "destination_path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Destination Path",
        "description": "Destination file path",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "source_path",
      "destination_path"
    ]
  },
  {
    "title": "Create Directory",
    "description": "Create a new directory at specified path.\n    files, directory, create\n\n    Use cases:\n    - Set up directory structure for file organization\n    - Create output directories for processed files",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.CreateDirectory",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Path",
        "description": "Directory path to create",
        "min": null,
        "max": null
      },
      {
        "name": "exist_ok",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Exist Ok",
        "description": "Don't error if directory already exists",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path",
      "exist_ok"
    ]
  },
  {
    "title": "Get File Size",
    "description": "Get file size in bytes.\n    files, metadata, size",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.GetFileSize",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Path",
        "description": "Path to file",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Created Time",
    "description": "Get file creation timestamp.\n    files, metadata, created, time",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.CreatedTime",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Path",
        "description": "Path to file",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Modified Time",
    "description": "Get file last modified timestamp.\n    files, metadata, modified, time",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.ModifiedTime",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Path",
        "description": "Path to file",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Accessed Time",
    "description": "Get file last accessed timestamp.\n    files, metadata, accessed, time",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.AccessedTime",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Path",
        "description": "Path to file",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Is File",
    "description": "Check if path is a file.\n    files, metadata, type",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.IsFile",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Path",
        "description": "Path to check",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Is Directory",
    "description": "Check if path is a directory.\n    files, metadata, type",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.IsDirectory",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Path",
        "description": "Path to check",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "File Extension",
    "description": "Get file extension.\n    files, metadata, extension",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.FileExtension",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Path",
        "description": "Path to file",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "File Name",
    "description": "Get file name without path.\n    files, metadata, name",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.FileName",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Path",
        "description": "Path to file",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Get Directory",
    "description": "Get directory containing the file.\n    files, metadata, directory",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.GetDirectory",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Path",
        "description": "Path to file",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Load Document",
    "description": "Read a document from disk.\n    files, document, read, input, load, file",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.LoadDocument",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Path",
        "description": "Path to the document to read",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Save Document",
    "description": "Write a document to disk.\n    files, document, write, output, save, file\n\n    The filename can include time and date variables:\n    %Y - Year, %m - Month, %d - Day\n    %H - Hour, %M - Minute, %S - Second",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.SaveDocument",
    "layout": "default",
    "properties": [
      {
        "name": "document",
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "document",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Document",
        "description": "The document to save",
        "min": null,
        "max": null
      },
      {
        "name": "folder",
        "type": {
          "type": "folder_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "folder_path",
          "path": ""
        },
        "title": "Folder",
        "description": "Folder where the file will be saved",
        "min": null,
        "max": null
      },
      {
        "name": "filename",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Filename",
        "description": "Name of the file to save. Supports strftime format codes.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "document",
      "folder",
      "filename"
    ]
  },
  {
    "title": "Load CSV",
    "description": "Read a CSV file from disk.\n    files, csv, read, input, load, file",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.LoadCSV",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Path",
        "description": "Path to the CSV file to read",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Save CSV",
    "description": "Write a list of dictionaries to a CSV file.\n    files, csv, write, output, save, file\n\n    The filename can include time and date variables:\n    %Y - Year, %m - Month, %d - Day\n    %H - Hour, %M - Minute, %S - Second",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.SaveCSV",
    "layout": "default",
    "properties": [
      {
        "name": "data",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Data",
        "description": "list of dictionaries to write to CSV",
        "min": null,
        "max": null
      },
      {
        "name": "folder",
        "type": {
          "type": "folder_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "folder_path",
          "path": ""
        },
        "title": "Folder",
        "description": "Folder where the file will be saved",
        "min": null,
        "max": null
      },
      {
        "name": "filename",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Filename",
        "description": "Name of the CSV file to save. Supports strftime format codes.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "data",
      "folder",
      "filename"
    ]
  },
  {
    "title": "Save CSVDataframe",
    "description": "Write a pandas DataFrame to a CSV file.\n    files, csv, write, output, save, file\n\n    The filename can include time and date variables:\n    %Y - Year, %m - Month, %d - Day\n    %H - Hour, %M - Minute, %S - Second",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.SaveCSVDataframe",
    "layout": "default",
    "properties": [
      {
        "name": "dataframe",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Dataframe",
        "description": "DataFrame to write to CSV",
        "min": null,
        "max": null
      },
      {
        "name": "folder",
        "type": {
          "type": "folder_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "folder_path",
          "path": ""
        },
        "title": "Folder",
        "description": "Folder where the file will be saved",
        "min": null,
        "max": null
      },
      {
        "name": "filename",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Filename",
        "description": "Name of the CSV file to save. Supports strftime format codes.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "dataframe",
      "folder",
      "filename"
    ]
  },
  {
    "title": "Load Bytes",
    "description": "Read raw bytes from a file on disk.\n    files, bytes, read, input, load, file\n\n    Use cases:\n    - Load binary data for processing\n    - Read binary files for a workflow",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.LoadBytes",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Path",
        "description": "Path to the file to read",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bytes",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Save Bytes",
    "description": "Write raw bytes to a file on disk.\n    files, bytes, save, output\n\n    The filename can include time and date variables:\n    %Y - Year, %m - Month, %d - Day\n    %H - Hour, %M - Minute, %S - Second",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.SaveBytes",
    "layout": "default",
    "properties": [
      {
        "name": "data",
        "type": {
          "type": "bytes",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Data",
        "description": "The bytes to write to file",
        "min": null,
        "max": null
      },
      {
        "name": "folder",
        "type": {
          "type": "folder_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "folder_path",
          "path": ""
        },
        "title": "Folder",
        "description": "Folder where the file will be saved",
        "min": null,
        "max": null
      },
      {
        "name": "filename",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Filename",
        "description": "Name of the file to save. Supports strftime format codes.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "data",
      "folder",
      "filename"
    ]
  },
  {
    "title": "Load Image",
    "description": "Read an image file from disk.\n    image, input, load, file\n\n    Use cases:\n    - Load images for processing\n    - Import photos for editing\n    - Read image assets for a workflow",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.LoadImage",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Path",
        "description": "Path to the image file to read",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Save Image",
    "description": "Write an image to disk.\n    image, output, save, file\n\n    Use cases:\n    - Save processed images\n    - Export edited photos\n    - Archive image results",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.SaveImage",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to save",
        "min": null,
        "max": null
      },
      {
        "name": "folder",
        "type": {
          "type": "folder_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "folder_path",
          "path": ""
        },
        "title": "Folder",
        "description": "Folder where the file will be saved",
        "min": null,
        "max": null
      },
      {
        "name": "filename",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Filename",
        "description": "\n        The name of the image file.\n        You can use time and date variables to create unique names:\n        %Y - Year\n        %m - Month\n        %d - Day\n        %H - Hour\n        %M - Minute\n        %S - Second\n        ",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "folder",
      "filename"
    ]
  },
  {
    "title": "Load Audio",
    "description": "Read an audio file from disk.\n    audio, input, load, file\n\n    Use cases:\n    - Load audio for processing\n    - Import sound files for editing\n    - Read audio assets for a workflow",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.LoadAudio",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Path",
        "description": "Path to the audio file to read",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Save Audio",
    "description": "Write an audio file to disk.\n    audio, output, save, file\n\n    The filename can include time and date variables:\n    %Y - Year, %m - Month, %d - Day\n    %H - Hour, %M - Minute, %S - Second",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.SaveAudio",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio to save",
        "min": null,
        "max": null
      },
      {
        "name": "folder",
        "type": {
          "type": "folder_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "folder_path",
          "path": ""
        },
        "title": "Folder",
        "description": "Folder where the file will be saved",
        "min": null,
        "max": null
      },
      {
        "name": "filename",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Filename",
        "description": "\n        Name of the file to save.\n        You can use time and date variables to create unique names:\n        %Y - Year\n        %m - Month\n        %d - Day\n        %H - Hour\n        %M - Minute\n        %S - Second\n        ",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "folder",
      "filename"
    ]
  },
  {
    "title": "Load Video",
    "description": "Read a video file from disk.\n    video, input, load, file\n\n    Use cases:\n    - Load videos for processing\n    - Import video files for editing\n    - Read video assets for a workflow",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.LoadVideo",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Path",
        "description": "Path to the video file to read",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Save Video",
    "description": "Write a video file to disk.\n    video, output, save, file\n\n    The filename can include time and date variables:\n    %Y - Year, %m - Month, %d - Day\n    %H - Hour, %M - Minute, %S - Second",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.SaveVideo",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "The video to save",
        "min": null,
        "max": null
      },
      {
        "name": "folder",
        "type": {
          "type": "folder_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "folder_path",
          "path": ""
        },
        "title": "Folder",
        "description": "Folder where the file will be saved",
        "min": null,
        "max": null
      },
      {
        "name": "filename",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Filename",
        "description": "\n        Name of the file to save.\n        You can use time and date variables to create unique names:\n        %Y - Year\n        %m - Month\n        %d - Day\n        %H - Hour\n        %M - Minute\n        %S - Second\n        ",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video",
      "folder",
      "filename"
    ]
  },
  {
    "title": "File Name Match",
    "description": "Match a filename against a pattern using Unix shell-style wildcards.\n    files, pattern, match, filter\n\n    Use cases:\n    - Filter files by name pattern\n    - Validate file naming conventions\n    - Match file extensions",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.FileNameMatch",
    "layout": "default",
    "properties": [
      {
        "name": "filename",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Filename",
        "description": "Filename to check",
        "min": null,
        "max": null
      },
      {
        "name": "pattern",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "*",
        "title": "Pattern",
        "description": "Pattern to match against (e.g. *.txt, data_*.csv)",
        "min": null,
        "max": null
      },
      {
        "name": "case_sensitive",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Case Sensitive",
        "description": "Whether the pattern matching should be case-sensitive",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "filename",
      "pattern",
      "case_sensitive"
    ]
  },
  {
    "title": "Filter File Names",
    "description": "Filter a list of filenames using Unix shell-style wildcards.\n    files, pattern, filter, list\n\n    Use cases:\n    - Filter multiple files by pattern\n    - Batch process files matching criteria\n    - Select files by extension",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.FilterFileNames",
    "layout": "default",
    "properties": [
      {
        "name": "filenames",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Filenames",
        "description": "list of filenames to filter",
        "min": null,
        "max": null
      },
      {
        "name": "pattern",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "*",
        "title": "Pattern",
        "description": "Pattern to filter by (e.g. *.txt, data_*.csv)",
        "min": null,
        "max": null
      },
      {
        "name": "case_sensitive",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Case Sensitive",
        "description": "Whether the pattern matching should be case-sensitive",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "filenames",
      "pattern",
      "case_sensitive"
    ]
  },
  {
    "title": "Basename",
    "description": "Get the base name component of a file path.\n    files, path, basename\n\n    Use cases:\n    - Extract filename from full path\n    - Get file name without directory\n    - Process file names independently",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.Basename",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Path",
        "description": "File path to get basename from",
        "min": null,
        "max": null
      },
      {
        "name": "remove_extension",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Remove Extension",
        "description": "Remove file extension from basename",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path",
      "remove_extension"
    ]
  },
  {
    "title": "Dirname",
    "description": "Get the directory name component of a file path.\n    files, path, dirname\n\n    Use cases:\n    - Extract directory path from full path\n    - Get parent directory\n    - Process directory paths",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.Dirname",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Path",
        "description": "File path to get dirname from",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Join Paths",
    "description": "Joins path components.\n    path, join, combine\n\n    Use cases:\n    - Build file paths\n    - Create cross-platform paths",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.JoinPaths",
    "layout": "default",
    "properties": [
      {
        "name": "paths",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Paths",
        "description": "Path components to join",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "paths"
    ]
  },
  {
    "title": "Normalize Path",
    "description": "Normalizes a path.\n    path, normalize, clean\n\n    Use cases:\n    - Standardize paths\n    - Remove redundant separators",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.NormalizePath",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Path",
        "description": "Path to normalize",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Get Path Info",
    "description": "Gets information about a path.\n    path, info, metadata\n\n    Use cases:\n    - Extract path components\n    - Parse file paths",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.GetPathInfo",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Path",
        "description": "Path to analyze",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Absolute Path",
    "description": "Return the absolute path of a file or directory.\n    files, path, absolute\n\n    Use cases:\n    - Convert relative paths to absolute\n    - Get full system path\n    - Resolve path references",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.AbsolutePath",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Path",
        "description": "Path to convert to absolute",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Split Path",
    "description": "Split a path into directory and file components.\n    files, path, split\n\n    Use cases:\n    - Separate directory from filename\n    - Process path components separately\n    - Extract path parts",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.SplitPath",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Path",
        "description": "Path to split",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Split Extension",
    "description": "Split a path into root and extension components.\n    files, path, extension, split\n\n    Use cases:\n    - Extract file extension\n    - Process filename without extension\n    - Handle file types",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.SplitExtension",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Path",
        "description": "Path to split",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Relative Path",
    "description": "Return a relative path to a target from a start directory.\n    files, path, relative\n\n    Use cases:\n    - Create relative path references\n    - Generate portable paths\n    - Compare file locations",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.RelativePath",
    "layout": "default",
    "properties": [
      {
        "name": "target_path",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Target Path",
        "description": "Target path to convert to relative",
        "min": null,
        "max": null
      },
      {
        "name": "start_path",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": ".",
        "title": "Start Path",
        "description": "Start path for relative conversion",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "target_path",
      "start_path"
    ]
  },
  {
    "title": "Path To String",
    "description": "Convert a FilePath object to a string.\n    files, path, string, convert\n\n    Use cases:\n    - Get raw string path from FilePath object\n    - Convert FilePath for string operations\n    - Extract path string for external use",
    "namespace": "nodetool.file",
    "node_type": "nodetool.file.PathToString",
    "layout": "default",
    "properties": [
      {
        "name": "file_path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "File Path",
        "description": "FilePath object to convert to string",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "file_path"
    ]
  },
  {
    "title": "Create Document",
    "description": "Creates a new Word document\n    document, docx, file, create",
    "namespace": "nodetool.file.docx",
    "node_type": "nodetool.file.docx.CreateDocument",
    "layout": "default",
    "properties": [],
    "outputs": [
      {
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": []
  },
  {
    "title": "Load Word Document",
    "description": "Loads a Word document from disk\n    document, docx, file, load, input",
    "namespace": "nodetool.file.docx",
    "node_type": "nodetool.file.docx.LoadWordDocument",
    "layout": "default",
    "properties": [
      {
        "name": "path",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Path",
        "description": "Path to the document to load",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path"
    ]
  },
  {
    "title": "Add Heading",
    "description": "Adds a heading to the document\n    document, docx, heading, format",
    "namespace": "nodetool.file.docx",
    "node_type": "nodetool.file.docx.AddHeading",
    "layout": "default",
    "properties": [
      {
        "name": "document",
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "document",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Document",
        "description": "The document to add the heading to",
        "min": null,
        "max": null
      },
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "The heading text",
        "min": null,
        "max": null
      },
      {
        "name": "level",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Level",
        "description": "Heading level (1-9)",
        "min": 1.0,
        "max": 9.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "document",
      "text",
      "level"
    ]
  },
  {
    "title": "Add Paragraph",
    "description": "Adds a paragraph of text to the document\n    document, docx, text, format",
    "namespace": "nodetool.file.docx",
    "node_type": "nodetool.file.docx.AddParagraph",
    "layout": "default",
    "properties": [
      {
        "name": "document",
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "document",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Document",
        "description": "The document to add the paragraph to",
        "min": null,
        "max": null
      },
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "The paragraph text",
        "min": null,
        "max": null
      },
      {
        "name": "alignment",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "LEFT",
            "CENTER",
            "RIGHT",
            "JUSTIFY"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.file.docx.ParagraphAlignment"
        },
        "default": "LEFT",
        "title": "Alignment",
        "description": "Text alignment",
        "min": null,
        "max": null
      },
      {
        "name": "bold",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Bold",
        "description": "Make text bold",
        "min": null,
        "max": null
      },
      {
        "name": "italic",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Italic",
        "description": "Make text italic",
        "min": null,
        "max": null
      },
      {
        "name": "font_size",
        "type": {
          "type": "int",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Font Size",
        "description": "Font size in points",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "document",
      "text",
      "alignment",
      "bold",
      "italic",
      "font_size"
    ]
  },
  {
    "title": "Add Table",
    "description": "Adds a table to the document\n    document, docx, table, format",
    "namespace": "nodetool.file.docx",
    "node_type": "nodetool.file.docx.AddTable",
    "layout": "default",
    "properties": [
      {
        "name": "document",
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "document",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Document",
        "description": "The document to add the table to",
        "min": null,
        "max": null
      },
      {
        "name": "rows",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Rows",
        "description": "Number of rows",
        "min": 1.0,
        "max": null
      },
      {
        "name": "cols",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Cols",
        "description": "Number of columns",
        "min": 1.0,
        "max": null
      },
      {
        "name": "data",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "list",
              "optional": false,
              "values": null,
              "type_args": [
                {
                  "type": "str",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                }
              ],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Data",
        "description": "Table data as nested lists",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "document",
      "rows",
      "cols",
      "data"
    ]
  },
  {
    "title": "Add Image",
    "description": "Adds an image to the document\n    document, docx, image, format",
    "namespace": "nodetool.file.docx",
    "node_type": "nodetool.file.docx.AddImage",
    "layout": "default",
    "properties": [
      {
        "name": "document",
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "document",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Document",
        "description": "The document to add the image to",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to add",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "float",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Width",
        "description": "Image width in inches",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "float",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Height",
        "description": "Image height in inches",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "document",
      "image",
      "width",
      "height"
    ]
  },
  {
    "title": "Add Page Break",
    "description": "Adds a page break to the document\n    document, docx, format, layout",
    "namespace": "nodetool.file.docx",
    "node_type": "nodetool.file.docx.AddPageBreak",
    "layout": "default",
    "properties": [
      {
        "name": "document",
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "document",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Document",
        "description": "The document to add the page break to",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "document"
    ]
  },
  {
    "title": "Set Document Properties",
    "description": "Sets document metadata properties\n    document, docx, metadata, properties",
    "namespace": "nodetool.file.docx",
    "node_type": "nodetool.file.docx.SetDocumentProperties",
    "layout": "default",
    "properties": [
      {
        "name": "document",
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "document",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Document",
        "description": "The document to modify",
        "min": null,
        "max": null
      },
      {
        "name": "title",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Title",
        "description": "Document title",
        "min": null,
        "max": null
      },
      {
        "name": "author",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Author",
        "description": "Document author",
        "min": null,
        "max": null
      },
      {
        "name": "subject",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Subject",
        "description": "Document subject",
        "min": null,
        "max": null
      },
      {
        "name": "keywords",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Keywords",
        "description": "Document keywords",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "document",
      "title",
      "author",
      "subject",
      "keywords"
    ]
  },
  {
    "title": "Save Document",
    "description": "Writes the document to a file\n    document, docx, file, save, output",
    "namespace": "nodetool.file.docx",
    "node_type": "nodetool.file.docx.SaveDocument",
    "layout": "default",
    "properties": [
      {
        "name": "document",
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "document",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Document",
        "description": "The document to write",
        "min": null,
        "max": null
      },
      {
        "name": "path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Path",
        "description": "\n        The path to write the document to.\n        You can use time and date variables to create unique names:\n        %Y - Year\n        %m - Month\n        %d - Day\n        %H - Hour\n        %M - Minute\n        %S - Second\n        ",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "document",
      "path"
    ]
  },
  {
    "title": "Create Workbook",
    "description": "Creates a new Excel workbook.\n    excel, workbook, create\n\n    Use cases:\n    - Initialize new Excel files\n    - Start spreadsheet creation workflows",
    "namespace": "nodetool.file.excel",
    "node_type": "nodetool.file.excel.CreateWorkbook",
    "layout": "default",
    "properties": [
      {
        "name": "sheet_name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Sheet1",
        "title": "Sheet Name",
        "description": "Name for the first worksheet",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "excel",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "sheet_name"
    ]
  },
  {
    "title": "Data Frame To Excel",
    "description": "Writes a DataFrame to an Excel worksheet.\n    excel, dataframe, export\n\n    Use cases:\n    - Export data analysis results\n    - Create reports from data",
    "namespace": "nodetool.file.excel",
    "node_type": "nodetool.file.excel.DataFrameToExcel",
    "layout": "default",
    "properties": [
      {
        "name": "workbook",
        "type": {
          "type": "excel",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "excel",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Workbook",
        "description": "The Excel workbook to write to",
        "min": null,
        "max": null
      },
      {
        "name": "dataframe",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Dataframe",
        "description": "DataFrame to write",
        "min": null,
        "max": null
      },
      {
        "name": "sheet_name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Sheet1",
        "title": "Sheet Name",
        "description": "Target worksheet name",
        "min": null,
        "max": null
      },
      {
        "name": "start_cell",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "A1",
        "title": "Start Cell",
        "description": "Starting cell for data",
        "min": null,
        "max": null
      },
      {
        "name": "include_header",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Include Header",
        "description": "Include column headers",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "workbook",
      "dataframe",
      "sheet_name",
      "start_cell",
      "include_header"
    ]
  },
  {
    "title": "Excel To Data Frame",
    "description": "Reads an Excel worksheet into a pandas DataFrame.\n    excel, dataframe, import\n\n    Use cases:\n    - Import Excel data for analysis\n    - Process spreadsheet contents",
    "namespace": "nodetool.file.excel",
    "node_type": "nodetool.file.excel.ExcelToDataFrame",
    "layout": "default",
    "properties": [
      {
        "name": "workbook",
        "type": {
          "type": "excel",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "excel",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Workbook",
        "description": "The Excel workbook to read from",
        "min": null,
        "max": null
      },
      {
        "name": "sheet_name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Sheet1",
        "title": "Sheet Name",
        "description": "Source worksheet name",
        "min": null,
        "max": null
      },
      {
        "name": "has_header",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Has Header",
        "description": "First row contains headers",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "workbook",
      "sheet_name",
      "has_header"
    ]
  },
  {
    "title": "Format Cells",
    "description": "Applies formatting to a range of cells.\n    excel, format, style\n\n    Use cases:\n    - Highlight important data\n    - Create professional looking reports",
    "namespace": "nodetool.file.excel",
    "node_type": "nodetool.file.excel.FormatCells",
    "layout": "default",
    "properties": [
      {
        "name": "workbook",
        "type": {
          "type": "excel",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "excel",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Workbook",
        "description": "The Excel workbook to format",
        "min": null,
        "max": null
      },
      {
        "name": "sheet_name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Sheet1",
        "title": "Sheet Name",
        "description": "Target worksheet name",
        "min": null,
        "max": null
      },
      {
        "name": "cell_range",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "A1:B10",
        "title": "Cell Range",
        "description": "Cell range to format (e.g. 'A1:B10')",
        "min": null,
        "max": null
      },
      {
        "name": "bold",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Bold",
        "description": "Make text bold",
        "min": null,
        "max": null
      },
      {
        "name": "background_color",
        "type": {
          "type": "str",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Background Color",
        "description": "Background color in hex format (e.g. 'FFFF00' for yellow)",
        "min": null,
        "max": null
      },
      {
        "name": "text_color",
        "type": {
          "type": "str",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Text Color",
        "description": "Text color in hex format",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "workbook",
      "sheet_name",
      "cell_range",
      "bold",
      "background_color",
      "text_color"
    ]
  },
  {
    "title": "Save Workbook",
    "description": "Saves an Excel workbook to disk.\n    excel, save, export\n\n    Use cases:\n    - Export final spreadsheet\n    - Save work in progress",
    "namespace": "nodetool.file.excel",
    "node_type": "nodetool.file.excel.SaveWorkbook",
    "layout": "default",
    "properties": [
      {
        "name": "workbook",
        "type": {
          "type": "excel",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "excel",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Workbook",
        "description": "The Excel workbook to save",
        "min": null,
        "max": null
      },
      {
        "name": "filepath",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Filepath",
        "description": "\n        Path where to save the file.\n        You can use time and date variables to create unique names:\n        %Y - Year\n        %m - Month\n        %d - Day\n        %H - Hour\n        %M - Minute\n        %S - Second\n        ",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "workbook",
      "filepath"
    ]
  },
  {
    "title": "Auto Fit Columns",
    "description": "Automatically adjusts column widths to fit content.\n    excel, format, columns\n\n    Use cases:\n    - Improve spreadsheet readability\n    - Professional presentation",
    "namespace": "nodetool.file.excel",
    "node_type": "nodetool.file.excel.AutoFitColumns",
    "layout": "default",
    "properties": [
      {
        "name": "workbook",
        "type": {
          "type": "excel",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "excel",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Workbook",
        "description": "The Excel workbook to format",
        "min": null,
        "max": null
      },
      {
        "name": "sheet_name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Sheet1",
        "title": "Sheet Name",
        "description": "Target worksheet name",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "workbook",
      "sheet_name"
    ]
  },
  {
    "title": "Convert To Markdown",
    "description": "Converts various document formats to markdown using MarkItDown.\n    markdown, convert, document\n\n    Use cases:\n    - Convert Word documents to markdown\n    - Convert Excel files to markdown tables\n    - Convert PowerPoint to markdown content",
    "namespace": "nodetool.file.markitdown",
    "node_type": "nodetool.file.markitdown.ConvertToMarkdown",
    "layout": "default",
    "properties": [
      {
        "name": "document",
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "document",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Document",
        "description": "The document to convert to markdown",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "document"
    ]
  },
  {
    "title": "Extract Links",
    "description": "Extracts all links from markdown text.\n    markdown, links, extraction\n\n    Use cases:\n    - Extract references and citations from academic documents\n    - Build link graphs from markdown documentation\n    - Analyze external resources referenced in markdown files",
    "namespace": "nodetool.file.markdown",
    "node_type": "nodetool.file.markdown.ExtractLinks",
    "layout": "default",
    "properties": [
      {
        "name": "markdown",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Markdown",
        "description": "The markdown text to analyze",
        "min": null,
        "max": null
      },
      {
        "name": "include_titles",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Include Titles",
        "description": "Whether to include link titles in output",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [
                {
                  "type": "str",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                },
                {
                  "type": "str",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                }
              ],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "markdown",
      "include_titles"
    ]
  },
  {
    "title": "Extract Headers",
    "description": "Extracts headers and creates a document structure/outline.\n    markdown, headers, structure\n\n    Use cases:\n    - Generate table of contents\n    - Analyze document structure\n    - Extract main topics from documents",
    "namespace": "nodetool.file.markdown",
    "node_type": "nodetool.file.markdown.ExtractHeaders",
    "layout": "default",
    "properties": [
      {
        "name": "markdown",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Markdown",
        "description": "The markdown text to analyze",
        "min": null,
        "max": null
      },
      {
        "name": "max_level",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 6,
        "title": "Max Level",
        "description": "Maximum header level to extract (1-6)",
        "min": 1.0,
        "max": 6.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [
                {
                  "type": "str",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                },
                {
                  "type": "any",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                }
              ],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "markdown",
      "max_level"
    ]
  },
  {
    "title": "Extract Bullet Lists",
    "description": "Extracts bulleted lists from markdown.\n    markdown, lists, bullets, extraction\n\n    Use cases:\n    - Extract unordered list items\n    - Analyze bullet point structures\n    - Convert bullet lists to structured data",
    "namespace": "nodetool.file.markdown",
    "node_type": "nodetool.file.markdown.ExtractBulletLists",
    "layout": "default",
    "properties": [
      {
        "name": "markdown",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Markdown",
        "description": "The markdown text to analyze",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [
                {
                  "type": "str",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                },
                {
                  "type": "any",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                }
              ],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "markdown"
    ]
  },
  {
    "title": "Extract Numbered Lists",
    "description": "Extracts numbered lists from markdown.\n    markdown, lists, numbered, extraction\n\n    Use cases:\n    - Extract ordered list items\n    - Analyze enumerated structures\n    - Convert numbered lists to structured data",
    "namespace": "nodetool.file.markdown",
    "node_type": "nodetool.file.markdown.ExtractNumberedLists",
    "layout": "default",
    "properties": [
      {
        "name": "markdown",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Markdown",
        "description": "The markdown text to analyze",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "markdown"
    ]
  },
  {
    "title": "Extract Code Blocks",
    "description": "Extracts code blocks and their languages from markdown.\n    markdown, code, extraction\n\n    Use cases:\n    - Extract code samples for analysis\n    - Collect programming examples\n    - Analyze code snippets in documentation",
    "namespace": "nodetool.file.markdown",
    "node_type": "nodetool.file.markdown.ExtractCodeBlocks",
    "layout": "default",
    "properties": [
      {
        "name": "markdown",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Markdown",
        "description": "The markdown text to analyze",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [
                {
                  "type": "str",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                },
                {
                  "type": "str",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                }
              ],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "markdown"
    ]
  },
  {
    "title": "Extract Tables",
    "description": "Extracts tables from markdown and converts them to structured data.\n    markdown, tables, data\n\n    Use cases:\n    - Extract tabular data from markdown\n    - Convert markdown tables to structured formats\n    - Analyze tabulated information",
    "namespace": "nodetool.file.markdown",
    "node_type": "nodetool.file.markdown.ExtractTables",
    "layout": "default",
    "properties": [
      {
        "name": "markdown",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Markdown",
        "description": "The markdown text to analyze",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "markdown"
    ]
  },
  {
    "title": "Convert File",
    "description": "Converts between different document formats using pandoc.\n    convert, document, format, pandoc\n\n    Use cases:\n    - Convert between various document formats (Markdown, HTML, LaTeX, etc.)\n    - Generate documentation in different formats\n    - Create publication-ready documents",
    "namespace": "nodetool.file.pandoc",
    "node_type": "nodetool.file.pandoc.ConvertFile",
    "layout": "default",
    "properties": [
      {
        "name": "input_path",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Input Path",
        "description": "Path to the input file",
        "min": null,
        "max": null
      },
      {
        "name": "input_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "biblatex",
            "bibtex",
            "bits",
            "commonmark",
            "commonmark_x",
            "creole",
            "csljson",
            "csv",
            "djot",
            "docbook",
            "docx",
            "dokuwiki",
            "endnotexml",
            "epub",
            "fb2",
            "gfm",
            "haddock",
            "html",
            "ipynb",
            "jats",
            "jira",
            "json",
            "latex",
            "man",
            "markdown",
            "markdown_github",
            "markdown_mmd",
            "markdown_phpextra",
            "markdown_strict",
            "mdoc",
            "mediawiki",
            "muse",
            "native",
            "odt",
            "opml",
            "org",
            "ris",
            "rst",
            "rtf",
            "t2t",
            "textile",
            "tikiwiki",
            "tsv",
            "twiki",
            "typst",
            "vimwiki"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.file.pandoc.InputFormat"
        },
        "default": "markdown",
        "title": "Input Format",
        "description": "Input format",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "asciidoc",
            "asciidoctor",
            "beamer",
            "context",
            "docbook4",
            "docbook5",
            "docx",
            "epub2",
            "epub3",
            "pdf",
            "plain",
            "pptx",
            "slideous",
            "slidy",
            "dzslides",
            "revealjs",
            "s5",
            "tei",
            "texinfo",
            "zimwiki"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.file.pandoc.OutputFormat"
        },
        "default": "pdf",
        "title": "Output Format",
        "description": "Output format",
        "min": null,
        "max": null
      },
      {
        "name": "extra_args",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Extra Args",
        "description": "Additional pandoc arguments",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input_path",
      "input_format",
      "output_format",
      "extra_args"
    ]
  },
  {
    "title": "Convert Text",
    "description": "Converts text content between different document formats using pandoc.\n    convert, text, format, pandoc\n\n    Use cases:\n    - Convert text content between various formats (Markdown, HTML, LaTeX, etc.)\n    - Transform content without saving to disk\n    - Process text snippets in different formats",
    "namespace": "nodetool.file.pandoc",
    "node_type": "nodetool.file.pandoc.ConvertText",
    "layout": "default",
    "properties": [
      {
        "name": "content",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Content",
        "description": "Text content to convert",
        "min": null,
        "max": null
      },
      {
        "name": "input_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "biblatex",
            "bibtex",
            "bits",
            "commonmark",
            "commonmark_x",
            "creole",
            "csljson",
            "csv",
            "djot",
            "docbook",
            "docx",
            "dokuwiki",
            "endnotexml",
            "epub",
            "fb2",
            "gfm",
            "haddock",
            "html",
            "ipynb",
            "jats",
            "jira",
            "json",
            "latex",
            "man",
            "markdown",
            "markdown_github",
            "markdown_mmd",
            "markdown_phpextra",
            "markdown_strict",
            "mdoc",
            "mediawiki",
            "muse",
            "native",
            "odt",
            "opml",
            "org",
            "ris",
            "rst",
            "rtf",
            "t2t",
            "textile",
            "tikiwiki",
            "tsv",
            "twiki",
            "typst",
            "vimwiki"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.file.pandoc.InputFormat"
        },
        "default": null,
        "title": "Input Format",
        "description": "Input format",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "asciidoc",
            "asciidoctor",
            "beamer",
            "context",
            "docbook4",
            "docbook5",
            "docx",
            "epub2",
            "epub3",
            "pdf",
            "plain",
            "pptx",
            "slideous",
            "slidy",
            "dzslides",
            "revealjs",
            "s5",
            "tei",
            "texinfo",
            "zimwiki"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.file.pandoc.OutputFormat"
        },
        "default": null,
        "title": "Output Format",
        "description": "Output format",
        "min": null,
        "max": null
      },
      {
        "name": "extra_args",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Extra Args",
        "description": "Additional pandoc arguments",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "content",
      "input_format",
      "output_format",
      "extra_args"
    ]
  },
  {
    "title": "Extract Text",
    "description": "Extract text content from a PDF file.\n    pdf, text, extract\n\n    Use cases:\n    - Convert PDF documents to plain text\n    - Extract content for analysis\n    - Enable text search in PDF documents",
    "namespace": "nodetool.file.pdf",
    "node_type": "nodetool.file.pdf.ExtractText",
    "layout": "default",
    "properties": [
      {
        "name": "pdf",
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "document",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Pdf",
        "description": "The PDF file to extract text from",
        "min": null,
        "max": null
      },
      {
        "name": "start_page",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Start Page",
        "description": "The start page to extract. 0-based indexing",
        "min": null,
        "max": null
      },
      {
        "name": "end_page",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "End Page",
        "description": "The end page to extract. -1 for all pages",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "pdf",
      "start_page",
      "end_page"
    ]
  },
  {
    "title": "Extract Images",
    "description": "Extract images from a PDF file.\n    pdf, image, extract\n\n    Use cases:\n    - Extract embedded images from PDF documents\n    - Save PDF images as separate files\n    - Process PDF images for analysis",
    "namespace": "nodetool.file.pdf",
    "node_type": "nodetool.file.pdf.ExtractImages",
    "layout": "default",
    "properties": [
      {
        "name": "pdf",
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Pdf",
        "description": "The PDF file to extract images from",
        "min": null,
        "max": null
      },
      {
        "name": "start_page",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Start Page",
        "description": "The start page to extract",
        "min": null,
        "max": null
      },
      {
        "name": "end_page",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "End Page",
        "description": "The end page to extract",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "pdf",
      "start_page",
      "end_page"
    ]
  },
  {
    "title": "Get Page Count",
    "description": "Get the total number of pages in a PDF file.\n    pdf, pages, count\n\n    Use cases:\n    - Check document length\n    - Plan batch processing",
    "namespace": "nodetool.file.pdf",
    "node_type": "nodetool.file.pdf.GetPageCount",
    "layout": "default",
    "properties": [
      {
        "name": "pdf",
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Pdf",
        "description": "The PDF file to analyze",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "pdf"
    ]
  },
  {
    "title": "Extract Page Metadata",
    "description": "Extract metadata from PDF pages like dimensions, rotation, etc.\n    pdf, metadata, pages\n\n    Use cases:\n    - Analyze page layouts\n    - Get page dimensions\n    - Check page orientations",
    "namespace": "nodetool.file.pdf",
    "node_type": "nodetool.file.pdf.ExtractPageMetadata",
    "layout": "default",
    "properties": [
      {
        "name": "pdf",
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Pdf",
        "description": "The PDF file to analyze",
        "min": null,
        "max": null
      },
      {
        "name": "start_page",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Start Page",
        "description": "The start page to extract. 0-based indexing",
        "min": null,
        "max": null
      },
      {
        "name": "end_page",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "End Page",
        "description": "The end page to extract. -1 for all pages",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "pdf",
      "start_page",
      "end_page"
    ]
  },
  {
    "title": "Loop",
    "description": "Loops over a list of items and processes the remaining nodes for each item.\n    loop, itereate, repeat, for, each, batch\n\n    Use cases:\n    - Loop over a list of items and process the nodes inside the group",
    "namespace": "nodetool.group",
    "node_type": "nodetool.group.Loop",
    "layout": "default",
    "properties": [
      {
        "name": "input",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Input",
        "description": "The input data to loop over.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input"
    ]
  },
  {
    "title": "Base Url",
    "description": "Extract the base URL from a given URL.\n    url parsing, domain extraction, web utilities\n\n    Use cases:\n    - Get domain name from full URLs\n    - Clean up URLs for comparison\n    - Extract root website addresses\n    - Standardize URL formats",
    "namespace": "nodetool.html",
    "node_type": "nodetool.html.BaseUrl",
    "layout": "default",
    "properties": [
      {
        "name": "url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "URL",
        "description": "The URL to extract the base from",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "url"
    ]
  },
  {
    "title": "Extract Links",
    "description": "Extract links from HTML content.\n    extract, links, urls\n\n    Use cases:\n    - Analyze website structure\n    - Discover related content\n    - Build sitemaps",
    "namespace": "nodetool.html",
    "node_type": "nodetool.html.ExtractLinks",
    "layout": "default",
    "properties": [
      {
        "name": "html",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Html",
        "description": "The HTML content to extract links from.",
        "min": null,
        "max": null
      },
      {
        "name": "base_url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Base Url",
        "description": "The base URL of the page, used to determine internal/external links.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "html",
      "base_url"
    ]
  },
  {
    "title": "Extract Metadata",
    "description": "Extract metadata from HTML content.\n    extract, metadata, seo\n\n    Use cases:\n    - Analyze SEO elements\n    - Gather page information\n    - Extract structured data",
    "namespace": "nodetool.html",
    "node_type": "nodetool.html.ExtractMetadata",
    "layout": "default",
    "properties": [
      {
        "name": "html",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Html",
        "description": "The HTML content to extract metadata from.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "metadata",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "html"
    ]
  },
  {
    "title": "Extract Images",
    "description": "Extract images from HTML content.\n    extract, images, src\n\n    Use cases:\n    - Collect images from web pages\n    - Analyze image usage on websites\n    - Create image galleries",
    "namespace": "nodetool.html",
    "node_type": "nodetool.html.ExtractImages",
    "layout": "default",
    "properties": [
      {
        "name": "html",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Html",
        "description": "The HTML content to extract images from.",
        "min": null,
        "max": null
      },
      {
        "name": "base_url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Base Url",
        "description": "The base URL of the page, used to resolve relative image URLs.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "html",
      "base_url"
    ]
  },
  {
    "title": "Extract Videos",
    "description": "Extract videos from HTML content.\n    extract, videos, src\n\n    Use cases:\n    - Collect video sources from web pages\n    - Analyze video usage on websites\n    - Create video playlists",
    "namespace": "nodetool.html",
    "node_type": "nodetool.html.ExtractVideos",
    "layout": "default",
    "properties": [
      {
        "name": "html",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Html",
        "description": "The HTML content to extract videos from.",
        "min": null,
        "max": null
      },
      {
        "name": "base_url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Base Url",
        "description": "The base URL of the page, used to resolve relative video URLs.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "video",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "html",
      "base_url"
    ]
  },
  {
    "title": "Extract Audio",
    "description": "Extract audio elements from HTML content.\n    extract, audio, src\n\n    Use cases:\n    - Collect audio sources from web pages\n    - Analyze audio usage on websites\n    - Create audio playlists",
    "namespace": "nodetool.html",
    "node_type": "nodetool.html.ExtractAudio",
    "layout": "default",
    "properties": [
      {
        "name": "html",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Html",
        "description": "The HTML content to extract audio from.",
        "min": null,
        "max": null
      },
      {
        "name": "base_url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Base Url",
        "description": "The base URL of the page, used to resolve relative audio URLs.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "audio",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "html",
      "base_url"
    ]
  },
  {
    "title": "Website Content Extractor",
    "description": "Extract main content from a website, removing navigation, ads, and other non-essential elements.\n    scrape, web scraping, content extraction, text analysis\n\n    Use cases:\n    - Clean web content for further analysis\n    - Extract article text from news websites\n    - Prepare web content for summarization",
    "namespace": "nodetool.html",
    "node_type": "nodetool.html.WebsiteContentExtractor",
    "layout": "default",
    "properties": [
      {
        "name": "html_content",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Html Content",
        "description": "The raw HTML content of the website.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "html_content"
    ]
  },
  {
    "title": "Save Image",
    "description": "Save an image to specified folder with customizable name format.\n    save, image, folder, naming\n\n    Use cases:\n    - Save generated images with timestamps\n    - Organize outputs into specific folders\n    - Create backups of processed images",
    "namespace": "nodetool.image",
    "node_type": "nodetool.image.SaveImage",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to save.",
        "min": null,
        "max": null
      },
      {
        "name": "folder",
        "type": {
          "type": "folder",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "folder",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Folder",
        "description": "The folder to save the image in.",
        "min": null,
        "max": null
      },
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "%Y-%m-%d_%H-%M-%S.png",
        "title": "Name",
        "description": "\n        Name of the output file.\n        You can use time and date variables to create unique names:\n        %Y - Year\n        %m - Month\n        %d - Day\n        %H - Hour\n        %M - Minute\n        %S - Second\n        ",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "folder",
      "name"
    ]
  },
  {
    "title": "Get Metadata",
    "description": "Get metadata about the input image.\n    metadata, properties, analysis, information\n\n    Use cases:\n    - Use width and height for layout calculations\n    - Analyze image properties for processing decisions\n    - Gather information for image cataloging or organization",
    "namespace": "nodetool.image",
    "node_type": "nodetool.image.GetMetadata",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "format",
        "stream": false
      },
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mode",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "width",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "height",
        "stream": false
      },
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "channels",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Batch To List",
    "description": "Convert an image batch to a list of image references.\n    batch, list, images, processing\n\n    Use cases:\n    - Convert comfy batch outputs to list format",
    "namespace": "nodetool.image",
    "node_type": "nodetool.image.BatchToList",
    "layout": "default",
    "properties": [
      {
        "name": "batch",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Batch",
        "description": "The batch of images to convert.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "batch"
    ]
  },
  {
    "title": "Convert To Tensor",
    "description": "Convert PIL Image to normalized tensor representation.\n    image, tensor, conversion, normalization\n\n    Use cases:\n    - Prepare images for machine learning models\n    - Convert between image formats for processing\n    - Normalize image data for consistent calculations",
    "namespace": "nodetool.image",
    "node_type": "nodetool.image.ConvertToTensor",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image to convert to a tensor. The image should have either 1 (grayscale), 3 (RGB), or 4 (RGBA) channels.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Paste",
    "description": "Paste one image onto another at specified coordinates.\n    paste, composite, positioning, overlay\n\n    Use cases:\n    - Add watermarks or logos to images\n    - Combine multiple image elements\n    - Create collages or montages",
    "namespace": "nodetool.image",
    "node_type": "nodetool.image.Paste",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to paste into.",
        "min": null,
        "max": null
      },
      {
        "name": "paste",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Paste",
        "description": "The image to paste.",
        "min": null,
        "max": null
      },
      {
        "name": "left",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Left",
        "description": "The left coordinate.",
        "min": 0.0,
        "max": 4096.0
      },
      {
        "name": "top",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Top",
        "description": "The top coordinate.",
        "min": 0.0,
        "max": 4096.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "paste",
      "left",
      "top"
    ]
  },
  {
    "title": "Blend",
    "description": "Blend two images with adjustable alpha mixing.\n    blend, mix, fade, transition\n\n    Use cases:\n    - Create smooth transitions between images\n    - Adjust opacity of overlays\n    - Combine multiple exposures or effects",
    "namespace": "nodetool.image",
    "node_type": "nodetool.image.Blend",
    "layout": "default",
    "properties": [
      {
        "name": "image1",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image1",
        "description": "The first image to blend.",
        "min": null,
        "max": null
      },
      {
        "name": "image2",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image2",
        "description": "The second image to blend.",
        "min": null,
        "max": null
      },
      {
        "name": "alpha",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Alpha",
        "description": "The mix ratio.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image1",
      "image2",
      "alpha"
    ]
  },
  {
    "title": "Composite",
    "description": "Combine two images using a mask for advanced compositing.\n    composite, mask, blend, layering\n\n    Use cases:\n    - Create complex image compositions\n    - Apply selective blending or effects\n    - Implement advanced photo editing techniques",
    "namespace": "nodetool.image",
    "node_type": "nodetool.image.Composite",
    "layout": "default",
    "properties": [
      {
        "name": "image1",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image1",
        "description": "The first image to composite.",
        "min": null,
        "max": null
      },
      {
        "name": "image2",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image2",
        "description": "The second image to composite.",
        "min": null,
        "max": null
      },
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask",
        "description": "The mask to composite with.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image1",
      "image2",
      "mask"
    ]
  },
  {
    "title": "Chart Renderer",
    "description": "Node responsible for rendering chart configurations into image format using seaborn.\n    chart, seaborn, plot, visualization, data",
    "namespace": "nodetool.image.chart",
    "node_type": "nodetool.image.chart.ChartRenderer",
    "layout": "default",
    "properties": [
      {
        "name": "chart_config",
        "type": {
          "type": "chart_config",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "chart_config",
          "title": "",
          "x_label": "",
          "y_label": "",
          "legend": true,
          "data": {
            "type": "chart_data",
            "series": [],
            "row": null,
            "col": null,
            "col_wrap": null
          },
          "height": null,
          "aspect": null,
          "x_lim": null,
          "y_lim": null,
          "x_scale": null,
          "y_scale": null,
          "legend_position": "auto",
          "palette": null,
          "hue_order": null,
          "hue_norm": null,
          "sizes": null,
          "size_order": null,
          "size_norm": null,
          "marginal_kws": null,
          "joint_kws": null,
          "diag_kind": null,
          "corner": false,
          "center": null,
          "vmin": null,
          "vmax": null,
          "cmap": null,
          "annot": false,
          "fmt": ".2g",
          "square": false
        },
        "title": "Chart Config",
        "description": "The chart configuration to render.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 640,
        "title": "Width",
        "description": "The width of the chart in pixels.",
        "min": 0.0,
        "max": 10000.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 480,
        "title": "Height",
        "description": "The height of the chart in pixels.",
        "min": 0.0,
        "max": 10000.0
      },
      {
        "name": "data",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Data",
        "description": "The data to visualize as a pandas DataFrame.",
        "min": null,
        "max": null
      },
      {
        "name": "despine",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Despine",
        "description": "Whether to remove top and right spines.",
        "min": null,
        "max": null
      },
      {
        "name": "trim_margins",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Trim Margins",
        "description": "Whether to use tight layout for margins.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "chart_config",
      "width",
      "height",
      "data",
      "despine",
      "trim_margins"
    ]
  },
  {
    "title": "Auto Contrast",
    "description": "Automatically adjusts image contrast for enhanced visual quality.\n    image, contrast, balance\n\n    Use cases:\n    - Enhance image clarity for better visual perception\n    - Pre-process images for computer vision tasks\n    - Improve photo aesthetics in editing workflows",
    "namespace": "nodetool.image.enhance",
    "node_type": "nodetool.image.enhance.AutoContrast",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to adjust the contrast for.",
        "min": null,
        "max": null
      },
      {
        "name": "cutoff",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Cutoff",
        "description": "Represents the percentage of pixels to ignore at both the darkest and lightest ends of the histogram. A cutoff value of 5 means ignoring the darkest 5% and the lightest 5% of pixels, enhancing overall contrast by stretching the remaining pixel values across the full brightness range.",
        "min": 0.0,
        "max": 255.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "cutoff"
    ]
  },
  {
    "title": "Sharpness",
    "description": "Adjusts image sharpness to enhance or reduce detail clarity.\n    image, clarity, sharpness\n\n    Use cases:\n    - Enhance photo details for improved visual appeal\n    - Refine images for object detection tasks\n    - Correct slightly blurred images",
    "namespace": "nodetool.image.enhance",
    "node_type": "nodetool.image.enhance.Sharpness",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to adjust the brightness for.",
        "min": null,
        "max": null
      },
      {
        "name": "factor",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Factor",
        "description": "Factor to adjust the contrast. 1.0 means no change.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "factor"
    ]
  },
  {
    "title": "Equalize",
    "description": "Enhances image contrast by equalizing intensity distribution.\n    image, contrast, histogram\n\n    Use cases:\n    - Improve visibility in poorly lit images\n    - Enhance details for image analysis tasks\n    - Normalize image data for machine learning",
    "namespace": "nodetool.image.enhance",
    "node_type": "nodetool.image.enhance.Equalize",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to equalize.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Contrast",
    "description": "Adjusts image contrast to modify light-dark differences.\n    image, contrast, enhance\n\n    Use cases:\n    - Enhance visibility of details in low-contrast images\n    - Prepare images for visual analysis or recognition tasks\n    - Create dramatic effects in artistic photography",
    "namespace": "nodetool.image.enhance",
    "node_type": "nodetool.image.enhance.Contrast",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to adjust the brightness for.",
        "min": null,
        "max": null
      },
      {
        "name": "factor",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Factor",
        "description": "Factor to adjust the contrast. 1.0 means no change.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "factor"
    ]
  },
  {
    "title": "Edge Enhance",
    "description": "Enhances edge visibility by increasing contrast along boundaries.\n    image, edge, enhance\n\n    Use cases:\n    - Improve object boundary detection for computer vision\n    - Highlight structural elements in technical drawings\n    - Prepare images for feature extraction in image analysis",
    "namespace": "nodetool.image.enhance",
    "node_type": "nodetool.image.enhance.EdgeEnhance",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to edge enhance.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Sharpen",
    "description": "Enhances image detail by intensifying local pixel contrast.\n    image, sharpen, clarity\n\n    Use cases:\n    - Improve clarity of photographs for print or display\n    - Refine texture details in product photography\n    - Enhance readability of text in document images",
    "namespace": "nodetool.image.enhance",
    "node_type": "nodetool.image.enhance.Sharpen",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to sharpen.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Rank Filter",
    "description": "Applies rank-based filtering to enhance or smooth image features.\n    image, filter, enhance\n\n    Use cases:\n    - Reduce noise while preserving edges in images\n    - Enhance specific image features based on local intensity\n    - Pre-process images for improved segmentation results",
    "namespace": "nodetool.image.enhance",
    "node_type": "nodetool.image.enhance.RankFilter",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to rank filter.",
        "min": null,
        "max": null
      },
      {
        "name": "size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Size",
        "description": "Rank filter size.",
        "min": 1.0,
        "max": 512.0
      },
      {
        "name": "rank",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Rank",
        "description": "Rank filter rank.",
        "min": 1.0,
        "max": 512.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "size",
      "rank"
    ]
  },
  {
    "title": "Unsharp Mask",
    "description": "Sharpens images using the unsharp mask technique.\n    image, sharpen, enhance\n\n    Use cases:\n    - Enhance edge definition in photographs\n    - Improve perceived sharpness of digital artwork\n    - Prepare images for high-quality printing or display",
    "namespace": "nodetool.image.enhance",
    "node_type": "nodetool.image.enhance.UnsharpMask",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to unsharp mask.",
        "min": null,
        "max": null
      },
      {
        "name": "radius",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Radius",
        "description": "Unsharp mask radius.",
        "min": 0.0,
        "max": 512.0
      },
      {
        "name": "percent",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 150,
        "title": "Percent",
        "description": "Unsharp mask percent.",
        "min": 0.0,
        "max": 1000.0
      },
      {
        "name": "threshold",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Threshold",
        "description": "Unsharp mask threshold.",
        "min": 0.0,
        "max": 512.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "radius",
      "percent",
      "threshold"
    ]
  },
  {
    "title": "Brightness",
    "description": "Adjusts overall image brightness to lighten or darken.\n    image, brightness, enhance\n\n    Use cases:\n    - Correct underexposed or overexposed photographs\n    - Enhance visibility of dark image regions\n    - Prepare images for consistent display across devices",
    "namespace": "nodetool.image.enhance",
    "node_type": "nodetool.image.enhance.Brightness",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to adjust the brightness for.",
        "min": null,
        "max": null
      },
      {
        "name": "factor",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 1.0,
        "title": "Factor",
        "description": "Factor to adjust the brightness. 1.0 means no change.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "factor"
    ]
  },
  {
    "title": "Color",
    "description": "Adjusts color intensity of an image.\n    image, color, enhance\n\n    Use cases:\n    - Enhance color vibrancy in photographs\n    - Correct color imbalances in digital images\n    - Prepare images for consistent brand color representation",
    "namespace": "nodetool.image.enhance",
    "node_type": "nodetool.image.enhance.Color",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to adjust the brightness for.",
        "min": null,
        "max": null
      },
      {
        "name": "factor",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Factor",
        "description": "Factor to adjust the contrast. 1.0 means no change.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "factor"
    ]
  },
  {
    "title": "Detail",
    "description": "Enhances fine details in images.\n    image, detail, enhance\n\n    Use cases:\n    - Improve clarity of textural elements in photographs\n    - Enhance visibility of small features for analysis\n    - Prepare images for high-resolution display or printing",
    "namespace": "nodetool.image.enhance",
    "node_type": "nodetool.image.enhance.Detail",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to detail.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Adaptive Contrast",
    "description": "Applies localized contrast enhancement using adaptive techniques.\n    image, contrast, enhance\n\n    Use cases:\n    - Improve visibility in images with varying lighting conditions\n    - Prepare images for improved feature detection in computer vision",
    "namespace": "nodetool.image.enhance",
    "node_type": "nodetool.image.enhance.AdaptiveContrast",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to adjust the contrast for.",
        "min": null,
        "max": null
      },
      {
        "name": "clip_limit",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2.0,
        "title": "Clip Limit",
        "description": "Clip limit for adaptive contrast.",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "grid_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8,
        "title": "Grid Size",
        "description": "Grid size for adaptive contrast.",
        "min": 1.0,
        "max": 64.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "clip_limit",
      "grid_size"
    ]
  },
  {
    "title": "Slice Image Grid",
    "description": "Slice an image into a grid of tiles.\n    image, grid, slice, tiles\n\n    Use cases:\n    - Prepare large images for processing in smaller chunks\n    - Create image puzzles or mosaic effects\n    - Distribute image processing tasks across multiple workers",
    "namespace": "nodetool.image.grid",
    "node_type": "nodetool.image.grid.SliceImageGrid",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to slice into a grid.",
        "min": null,
        "max": null
      },
      {
        "name": "columns",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Columns",
        "description": "Number of columns in the grid.",
        "min": 0.0,
        "max": null
      },
      {
        "name": "rows",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Rows",
        "description": "Number of rows in the grid.",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "columns",
      "rows"
    ]
  },
  {
    "title": "Combine Image Grid",
    "description": "Combine a grid of image tiles into a single image.\n    image, grid, combine, tiles\n\n    Use cases:\n    - Reassemble processed image chunks\n    - Create composite images from smaller parts\n    - Merge tiled image data from distributed processing",
    "namespace": "nodetool.image.grid",
    "node_type": "nodetool.image.grid.CombineImageGrid",
    "layout": "default",
    "properties": [
      {
        "name": "tiles",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Tiles",
        "description": "List of image tiles to combine.",
        "min": null,
        "max": null
      },
      {
        "name": "columns",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Columns",
        "description": "Number of columns in the grid.",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tiles",
      "columns"
    ]
  },
  {
    "title": "Background",
    "description": "The Background Node creates a blank background.\n    image, background, blank, base, layer\n    This node is mainly used for generating a base layer for image processing tasks. It produces a uniform image, having a user-specified width, height and color. The color is given in a hexadecimal format, defaulting to white if not specified.\n\n    #### Applications\n    - As a base layer for creating composite images.\n    - As a starting point for generating patterns or graphics.\n    - When blank backgrounds of specific colors are required for visualization tasks.",
    "namespace": "nodetool.image.source",
    "node_type": "nodetool.image.source.Background",
    "layout": "default",
    "properties": [
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Width",
        "description": null,
        "min": 1.0,
        "max": 4096.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Height",
        "description": null,
        "min": 1.0,
        "max": 4096.0
      },
      {
        "name": "color",
        "type": {
          "type": "color",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "color",
          "value": "#FFFFFF"
        },
        "title": "Color",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "width",
      "height",
      "color"
    ]
  },
  {
    "title": "Render Text",
    "description": "This node allows you to add text to images.\n    text, font, label, title, watermark, caption, image, overlay\n    This node takes text, font updates, coordinates (where to place the text), and an image to work with. A user can use the Render Text Node to add a label or title to an image, watermark an image, or place a caption directly on an image.\n\n    The Render Text Node offers customizable options, including the ability to choose the text's font, size, color, and alignment (left, center, or right). Text placement can also be defined, providing flexibility to place the text wherever you see fit.\n\n    #### Applications\n    - Labeling images in a image gallery or database.\n    - Watermarking images for copyright protection.\n    - Adding custom captions to photographs.\n    - Creating instructional images to guide the reader's view.",
    "namespace": "nodetool.image.source",
    "node_type": "nodetool.image.source.RenderText",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "The text to render.",
        "min": null,
        "max": null
      },
      {
        "name": "font",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DejaVuSans-Bold.ttf",
            "DejaVuSans.ttf",
            "FreeSans.ttf"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.image.source.TextFont"
        },
        "default": "DejaVuSans.ttf",
        "title": "Font",
        "description": "The font to use.",
        "min": null,
        "max": null
      },
      {
        "name": "x",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "X",
        "description": "The x coordinate.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "y",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Y",
        "description": "The y coordinate.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 12,
        "title": "Size",
        "description": "The font size.",
        "min": 1.0,
        "max": 512.0
      },
      {
        "name": "color",
        "type": {
          "type": "color",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "color",
          "value": "#000000"
        },
        "title": "Color",
        "description": "The font color.",
        "min": null,
        "max": null
      },
      {
        "name": "align",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "left",
            "center",
            "right"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.image.source.TextAlignment"
        },
        "default": "left",
        "title": "Align",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to render on.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "font",
      "x",
      "y",
      "size",
      "color",
      "align",
      "image"
    ]
  },
  {
    "title": "Gaussian Noise",
    "description": "This node creates and adds Gaussian noise to an image.\n    image, noise, gaussian, distortion, artifact\n    \n    The Gaussian Noise Node is designed to simulate realistic distortions that can occur in a photographic image. It generates a noise-filled image using the Gaussian (normal) distribution. The noise level can be adjusted using the mean and standard deviation parameters.\n\n    #### Applications\n    - Simulating sensor noise in synthetic data.\n    - Testing image-processing algorithms' resilience to noise.\n    - Creating artistic effects in images.",
    "namespace": "nodetool.image.source",
    "node_type": "nodetool.image.source.GaussianNoise",
    "layout": "default",
    "properties": [
      {
        "name": "mean",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Mean",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "stddev",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Stddev",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Width",
        "description": null,
        "min": 1.0,
        "max": 1024.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Height",
        "description": null,
        "min": 1.0,
        "max": 1024.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "mean",
      "stddev",
      "width",
      "height"
    ]
  },
  {
    "title": "Rectangle",
    "description": "Generate SVG rectangle element.\n    svg, shape, vector, rectangle",
    "namespace": "nodetool.image.svg",
    "node_type": "nodetool.image.svg.Rect",
    "layout": "default",
    "properties": [
      {
        "name": "x",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "X",
        "description": "X coordinate",
        "min": null,
        "max": null
      },
      {
        "name": "y",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Y",
        "description": "Y coordinate",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Width",
        "description": "Width",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Height",
        "description": "Height",
        "min": null,
        "max": null
      },
      {
        "name": "fill",
        "type": {
          "type": "color",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "color",
          "value": "#000000"
        },
        "title": "Fill",
        "description": "Fill color",
        "min": null,
        "max": null
      },
      {
        "name": "stroke",
        "type": {
          "type": "color",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "color",
          "value": "none"
        },
        "title": "Stroke",
        "description": "Stroke color",
        "min": null,
        "max": null
      },
      {
        "name": "stroke_width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Stroke Width",
        "description": "Stroke width",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "svg_element",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "x",
      "y",
      "width",
      "height",
      "fill",
      "stroke",
      "stroke_width"
    ]
  },
  {
    "title": "Circle",
    "description": "Generate SVG circle element.\n    svg, shape, vector, circle",
    "namespace": "nodetool.image.svg",
    "node_type": "nodetool.image.svg.Circle",
    "layout": "default",
    "properties": [
      {
        "name": "cx",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Cx",
        "description": "Center X coordinate",
        "min": null,
        "max": null
      },
      {
        "name": "cy",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Cy",
        "description": "Center Y coordinate",
        "min": null,
        "max": null
      },
      {
        "name": "radius",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Radius",
        "description": "Radius",
        "min": null,
        "max": null
      },
      {
        "name": "fill",
        "type": {
          "type": "color",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "color",
          "value": "#000000"
        },
        "title": "Fill",
        "description": "Fill color",
        "min": null,
        "max": null
      },
      {
        "name": "stroke",
        "type": {
          "type": "color",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "color",
          "value": "none"
        },
        "title": "Stroke",
        "description": "Stroke color",
        "min": null,
        "max": null
      },
      {
        "name": "stroke_width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Stroke Width",
        "description": "Stroke width",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "svg_element",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "cx",
      "cy",
      "radius",
      "fill",
      "stroke",
      "stroke_width"
    ]
  },
  {
    "title": "Ellipse",
    "description": "Generate SVG ellipse element.\n    svg, shape, vector, ellipse",
    "namespace": "nodetool.image.svg",
    "node_type": "nodetool.image.svg.Ellipse",
    "layout": "default",
    "properties": [
      {
        "name": "cx",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Cx",
        "description": "Center X coordinate",
        "min": null,
        "max": null
      },
      {
        "name": "cy",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Cy",
        "description": "Center Y coordinate",
        "min": null,
        "max": null
      },
      {
        "name": "rx",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Rx",
        "description": "X radius",
        "min": null,
        "max": null
      },
      {
        "name": "ry",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Ry",
        "description": "Y radius",
        "min": null,
        "max": null
      },
      {
        "name": "fill",
        "type": {
          "type": "color",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "color",
          "value": "#000000"
        },
        "title": "Fill",
        "description": "Fill color",
        "min": null,
        "max": null
      },
      {
        "name": "stroke",
        "type": {
          "type": "color",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "color",
          "value": "none"
        },
        "title": "Stroke",
        "description": "Stroke color",
        "min": null,
        "max": null
      },
      {
        "name": "stroke_width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Stroke Width",
        "description": "Stroke width",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "svg_element",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "cx",
      "cy",
      "rx",
      "ry",
      "fill",
      "stroke",
      "stroke_width"
    ]
  },
  {
    "title": "Line",
    "description": "Generate SVG line element.\n    svg, shape, vector, line",
    "namespace": "nodetool.image.svg",
    "node_type": "nodetool.image.svg.Line",
    "layout": "default",
    "properties": [
      {
        "name": "x1",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "X1",
        "description": "Start X coordinate",
        "min": null,
        "max": null
      },
      {
        "name": "y1",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Y1",
        "description": "Start Y coordinate",
        "min": null,
        "max": null
      },
      {
        "name": "x2",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "X2",
        "description": "End X coordinate",
        "min": null,
        "max": null
      },
      {
        "name": "y2",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Y2",
        "description": "End Y coordinate",
        "min": null,
        "max": null
      },
      {
        "name": "stroke",
        "type": {
          "type": "color",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "color",
          "value": "#000000"
        },
        "title": "Stroke",
        "description": "Stroke color",
        "min": null,
        "max": null
      },
      {
        "name": "stroke_width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Stroke Width",
        "description": "Stroke width",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "svg_element",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "x1",
      "y1",
      "x2",
      "y2",
      "stroke",
      "stroke_width"
    ]
  },
  {
    "title": "Polygon",
    "description": "Generate SVG polygon element.\n    svg, shape, vector, polygon",
    "namespace": "nodetool.image.svg",
    "node_type": "nodetool.image.svg.Polygon",
    "layout": "default",
    "properties": [
      {
        "name": "points",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Points",
        "description": "Points in format 'x1,y1 x2,y2 x3,y3...'",
        "min": null,
        "max": null
      },
      {
        "name": "fill",
        "type": {
          "type": "color",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "color",
          "value": "#000000"
        },
        "title": "Fill",
        "description": "Fill color",
        "min": null,
        "max": null
      },
      {
        "name": "stroke",
        "type": {
          "type": "color",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "color",
          "value": "none"
        },
        "title": "Stroke",
        "description": "Stroke color",
        "min": null,
        "max": null
      },
      {
        "name": "stroke_width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Stroke Width",
        "description": "Stroke width",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "svg_element",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "points",
      "fill",
      "stroke",
      "stroke_width"
    ]
  },
  {
    "title": "Path",
    "description": "Generate SVG path element.\n    svg, shape, vector, path",
    "namespace": "nodetool.image.svg",
    "node_type": "nodetool.image.svg.Path",
    "layout": "default",
    "properties": [
      {
        "name": "path_data",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Path Data",
        "description": "SVG path data (d attribute)",
        "min": null,
        "max": null
      },
      {
        "name": "fill",
        "type": {
          "type": "color",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "color",
          "value": "#000000"
        },
        "title": "Fill",
        "description": "Fill color",
        "min": null,
        "max": null
      },
      {
        "name": "stroke",
        "type": {
          "type": "color",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "color",
          "value": "none"
        },
        "title": "Stroke",
        "description": "Stroke color",
        "min": null,
        "max": null
      },
      {
        "name": "stroke_width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Stroke Width",
        "description": "Stroke width",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "svg_element",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "path_data",
      "fill",
      "stroke",
      "stroke_width"
    ]
  },
  {
    "title": "Text",
    "description": "Add text elements to SVG.\n    svg, text, typography\n\n    Use cases:\n    - Add labels to vector graphics\n    - Create text-based logos\n    - Generate dynamic text content in SVGs",
    "namespace": "nodetool.image.svg",
    "node_type": "nodetool.image.svg.Text",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "Text content",
        "min": null,
        "max": null
      },
      {
        "name": "x",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "X",
        "description": "X coordinate",
        "min": null,
        "max": null
      },
      {
        "name": "y",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Y",
        "description": "Y coordinate",
        "min": null,
        "max": null
      },
      {
        "name": "font_family",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Arial",
        "title": "Font Family",
        "description": "Font family",
        "min": null,
        "max": null
      },
      {
        "name": "font_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 16,
        "title": "Font Size",
        "description": "Font size",
        "min": null,
        "max": null
      },
      {
        "name": "fill",
        "type": {
          "type": "color",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "color",
          "value": "#000000"
        },
        "title": "Fill",
        "description": "Text color",
        "min": null,
        "max": null
      },
      {
        "name": "text_anchor",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "start",
            "middle",
            "end"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.image.svg.SVGTextAnchor"
        },
        "default": "start",
        "title": "Text Anchor",
        "description": "Text anchor position",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "svg_element",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "x",
      "y",
      "font_family",
      "font_size",
      "fill",
      "text_anchor"
    ]
  },
  {
    "title": "Gaussian Blur",
    "description": "Apply Gaussian blur filter to SVG elements.\n    svg, filter, blur, effects",
    "namespace": "nodetool.image.svg",
    "node_type": "nodetool.image.svg.GaussianBlur",
    "layout": "default",
    "properties": [
      {
        "name": "std_deviation",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.0,
        "title": "Std Deviation",
        "description": "Standard deviation for blur",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "svg_element",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "std_deviation"
    ]
  },
  {
    "title": "Drop Shadow",
    "description": "Apply drop shadow filter to SVG elements.\n    svg, filter, shadow, effects",
    "namespace": "nodetool.image.svg",
    "node_type": "nodetool.image.svg.DropShadow",
    "layout": "default",
    "properties": [
      {
        "name": "std_deviation",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.0,
        "title": "Std Deviation",
        "description": "Standard deviation for blur",
        "min": null,
        "max": null
      },
      {
        "name": "dx",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Dx",
        "description": "X offset for shadow",
        "min": null,
        "max": null
      },
      {
        "name": "dy",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Dy",
        "description": "Y offset for shadow",
        "min": null,
        "max": null
      },
      {
        "name": "color",
        "type": {
          "type": "color",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "color",
          "value": "#000000"
        },
        "title": "Color",
        "description": "Color for shadow",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "svg_element",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "std_deviation",
      "dx",
      "dy",
      "color"
    ]
  },
  {
    "title": "SVG Document",
    "description": "Combine SVG elements into a complete SVG document.\n    svg, document, combine\n\n    Use cases:\n    - Combine multiple SVG elements into a single document\n    - Set document-level properties like viewBox and dimensions\n    - Export complete SVG documents",
    "namespace": "nodetool.image.svg",
    "node_type": "nodetool.image.svg.Document",
    "layout": "default",
    "properties": [
      {
        "name": "content",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "svg_element",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "list",
              "optional": false,
              "values": null,
              "type_args": [
                {
                  "type": "svg_element",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                }
              ],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Content",
        "description": "SVG content",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 800,
        "title": "Width",
        "description": "Document width",
        "min": 1.0,
        "max": 4096.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 600,
        "title": "Height",
        "description": "Document height",
        "min": 1.0,
        "max": 4096.0
      },
      {
        "name": "viewBox",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "0 0 800 600",
        "title": "Viewbox",
        "description": "SVG viewBox attribute",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "svg",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "content",
      "width",
      "height",
      "viewBox"
    ]
  },
  {
    "title": "Combine",
    "description": "Combine multiple SVG elements into a list.\n    svg, combine, list\n\n    Use cases:\n    - Merge multiple SVG elements into a single list\n    - Prepare elements for SVGDocument\n    - Group related SVG elements together",
    "namespace": "nodetool.image.svg",
    "node_type": "nodetool.image.svg.Combine",
    "layout": "default",
    "properties": [
      {
        "name": "element1",
        "type": {
          "type": "svg_element",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Element1",
        "description": "First SVG element to combine",
        "min": null,
        "max": null
      },
      {
        "name": "element2",
        "type": {
          "type": "svg_element",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Element2",
        "description": "Second SVG element to combine",
        "min": null,
        "max": null
      },
      {
        "name": "element3",
        "type": {
          "type": "svg_element",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Element3",
        "description": "Third SVG element to combine",
        "min": null,
        "max": null
      },
      {
        "name": "element4",
        "type": {
          "type": "svg_element",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Element4",
        "description": "Fourth SVG element to combine",
        "min": null,
        "max": null
      },
      {
        "name": "element5",
        "type": {
          "type": "svg_element",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Element5",
        "description": "Fifth SVG element to combine",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "svg_element",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "element1",
      "element2",
      "element3",
      "element4",
      "element5"
    ]
  },
  {
    "title": "SVG to Image",
    "description": "Create an SVG document and convert it to a raster image in one step.\n    svg, document, raster, convert\n\n    Use cases:\n    - Create and rasterize SVG documents in a single operation\n    - Generate image files from SVG elements\n    - Convert vector graphics to bitmap format with custom dimensions",
    "namespace": "nodetool.image.svg",
    "node_type": "nodetool.image.svg.SVGToImage",
    "layout": "default",
    "properties": [
      {
        "name": "content",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "svg_element",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "list",
              "optional": false,
              "values": null,
              "type_args": [
                {
                  "type": "svg_element",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                }
              ],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Content",
        "description": "SVG content",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 800,
        "title": "Width",
        "description": "Document width",
        "min": 1.0,
        "max": 4096.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 600,
        "title": "Height",
        "description": "Document height",
        "min": 1.0,
        "max": 4096.0
      },
      {
        "name": "viewBox",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "0 0 800 600",
        "title": "Viewbox",
        "description": "SVG viewBox attribute",
        "min": null,
        "max": null
      },
      {
        "name": "scale",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Scale",
        "description": "Scale factor for rasterization",
        "min": 1.0,
        "max": 10.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "content",
      "width",
      "height",
      "viewBox",
      "scale"
    ]
  },
  {
    "title": "Gradient",
    "description": "Create linear or radial gradients for SVG elements.\n    svg, gradient, color\n\n    Use cases:\n    - Add smooth color transitions\n    - Create complex color effects\n    - Define reusable gradient definitions",
    "namespace": "nodetool.image.svg",
    "node_type": "nodetool.image.svg.Gradient",
    "layout": "default",
    "properties": [
      {
        "name": "gradient_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "linearGradient",
            "radialGradient"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.image.svg.GradientType"
        },
        "default": "linearGradient",
        "title": "Gradient Type",
        "description": "Type of gradient",
        "min": null,
        "max": null
      },
      {
        "name": "x1",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "X1",
        "description": "Start X position (linear) or center X (radial)",
        "min": null,
        "max": null
      },
      {
        "name": "y1",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Y1",
        "description": "Start Y position (linear) or center Y (radial)",
        "min": null,
        "max": null
      },
      {
        "name": "x2",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "X2",
        "description": "End X position (linear) or radius X (radial)",
        "min": null,
        "max": null
      },
      {
        "name": "y2",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Y2",
        "description": "End Y position (linear) or radius Y (radial)",
        "min": null,
        "max": null
      },
      {
        "name": "color1",
        "type": {
          "type": "color",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "color",
          "value": "#000000"
        },
        "title": "Color1",
        "description": "Start color of gradient",
        "min": null,
        "max": null
      },
      {
        "name": "color2",
        "type": {
          "type": "color",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "color",
          "value": "#FFFFFF"
        },
        "title": "Color2",
        "description": "End color of gradient",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "svg_element",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "gradient_type",
      "x1",
      "y1",
      "x2",
      "y2",
      "color1",
      "color2"
    ]
  },
  {
    "title": "Transform",
    "description": "Apply transformations to SVG elements.\n    svg, transform, animation\n\n    Use cases:\n    - Rotate, scale, or translate elements\n    - Create complex transformations\n    - Prepare elements for animation",
    "namespace": "nodetool.image.svg",
    "node_type": "nodetool.image.svg.Transform",
    "layout": "default",
    "properties": [
      {
        "name": "content",
        "type": {
          "type": "svg_element",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Content",
        "description": "SVG element to transform",
        "min": null,
        "max": null
      },
      {
        "name": "translate_x",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Translate X",
        "description": "X translation",
        "min": null,
        "max": null
      },
      {
        "name": "translate_y",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Translate Y",
        "description": "Y translation",
        "min": null,
        "max": null
      },
      {
        "name": "rotate",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Rotate",
        "description": "Rotation angle in degrees",
        "min": null,
        "max": null
      },
      {
        "name": "scale_x",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Scale X",
        "description": "X scale factor",
        "min": null,
        "max": null
      },
      {
        "name": "scale_y",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Scale Y",
        "description": "Y scale factor",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "svg_element",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "content",
      "translate_x",
      "translate_y",
      "rotate",
      "scale_x",
      "scale_y"
    ]
  },
  {
    "title": "Clip Path",
    "description": "Create clipping paths for SVG elements.\n    svg, clip, mask\n\n    Use cases:\n    - Mask parts of elements\n    - Create complex shapes through clipping\n    - Apply visual effects using masks",
    "namespace": "nodetool.image.svg",
    "node_type": "nodetool.image.svg.ClipPath",
    "layout": "default",
    "properties": [
      {
        "name": "clip_content",
        "type": {
          "type": "svg_element",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Clip Content",
        "description": "SVG element to use as clip path",
        "min": null,
        "max": null
      },
      {
        "name": "content",
        "type": {
          "type": "svg_element",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Content",
        "description": "SVG element to clip",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "svg_element",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "clip_content",
      "content"
    ]
  },
  {
    "title": "Invert",
    "description": "Invert the colors of an image.\n    image, filter, invert\n\n    - Create negative versions of images for visual effects\n    - Analyze image data by bringing out hidden details\n    - Preprocess images for operations that work better on inverted colors",
    "namespace": "nodetool.image.transform",
    "node_type": "nodetool.image.transform.Invert",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to adjust the brightness for.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Solarize",
    "description": "Apply a solarize effect to partially invert image tones.\n    image, filter, solarize\n\n    - Create surreal artistic photo effects\n    - Enhance visual data by making certain elements more prominent\n    - Add a unique style to images for graphic design",
    "namespace": "nodetool.image.transform",
    "node_type": "nodetool.image.transform.Solarize",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to solarize.",
        "min": null,
        "max": null
      },
      {
        "name": "threshold",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 128,
        "title": "Threshold",
        "description": "Threshold for solarization.",
        "min": 0.0,
        "max": 255.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "threshold"
    ]
  },
  {
    "title": "Posterize",
    "description": "Reduce the number of colors in an image for a poster-like effect.\n    image, filter, posterize\n\n    - Create graphic art by simplifying image colors\n    - Apply artistic effects to photographs\n    - Generate visually compelling content for advertising",
    "namespace": "nodetool.image.transform",
    "node_type": "nodetool.image.transform.Posterize",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to posterize.",
        "min": null,
        "max": null
      },
      {
        "name": "bits",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Bits",
        "description": "Number of bits to posterize to.",
        "min": 1.0,
        "max": 8.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "bits"
    ]
  },
  {
    "title": "Fit",
    "description": "Resize an image to fit within specified dimensions while preserving aspect ratio.\n    image, resize, fit\n\n    - Resize images for online publishing requirements\n    - Preprocess images to uniform sizes for machine learning\n    - Control image display sizes for web development",
    "namespace": "nodetool.image.transform",
    "node_type": "nodetool.image.transform.Fit",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to fit.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Width",
        "description": "Width to fit to.",
        "min": 1.0,
        "max": 4096.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Height",
        "description": "Height to fit to.",
        "min": 1.0,
        "max": 4096.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "width",
      "height"
    ]
  },
  {
    "title": "Expand",
    "description": "Add a border around an image to increase its size.\n    image, border, expand\n\n    - Make images stand out by adding a colored border\n    - Create framed photo effects\n    - Separate image content from surroundings",
    "namespace": "nodetool.image.transform",
    "node_type": "nodetool.image.transform.Expand",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to expand.",
        "min": null,
        "max": null
      },
      {
        "name": "border",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Border",
        "description": "Border size.",
        "min": 0.0,
        "max": 512.0
      },
      {
        "name": "fill",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Fill",
        "description": "Fill color.",
        "min": 0.0,
        "max": 255.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "border",
      "fill"
    ]
  },
  {
    "title": "Blur",
    "description": "Apply a Gaussian blur effect to an image.\n    image, filter, blur\n\n    - Soften images or reduce noise and detail\n    - Make focal areas stand out by blurring surroundings\n    - Protect privacy by blurring sensitive information",
    "namespace": "nodetool.image.transform",
    "node_type": "nodetool.image.transform.Blur",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to blur.",
        "min": null,
        "max": null
      },
      {
        "name": "radius",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Radius",
        "description": "Blur radius.",
        "min": 0.0,
        "max": 128.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "radius"
    ]
  },
  {
    "title": "Contour",
    "description": "Apply a contour filter to highlight image edges.\n    image, filter, contour\n\n    - Extract key features from complex images\n    - Aid pattern recognition and object detection\n    - Create stylized contour sketch art effects",
    "namespace": "nodetool.image.transform",
    "node_type": "nodetool.image.transform.Contour",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to contour.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Emboss",
    "description": "Apply an emboss filter for a 3D raised effect.\n    image, filter, emboss\n\n    - Add texture and depth to photos\n    - Create visually interesting graphics\n    - Incorporate unique effects in digital artwork",
    "namespace": "nodetool.image.transform",
    "node_type": "nodetool.image.transform.Emboss",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to emboss.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Find Edges",
    "description": "Detect and highlight edges in an image.\n    image, filter, edges\n\n    - Analyze structural patterns in images\n    - Aid object detection in computer vision\n    - Detect important features like corners and ridges",
    "namespace": "nodetool.image.transform",
    "node_type": "nodetool.image.transform.FindEdges",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to find edges.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Smooth",
    "description": "Apply smoothing to reduce image noise and detail.\n    image, filter, smooth\n\n    - Enhance visual aesthetics of images\n    - Improve object detection by reducing irrelevant details\n    - Aid facial recognition by simplifying images",
    "namespace": "nodetool.image.transform",
    "node_type": "nodetool.image.transform.Smooth",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to smooth.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Canny",
    "description": "Apply Canny edge detection to an image.\n    image, filter, edges\n\n    - Highlight areas of rapid intensity change\n    - Outline object boundaries and structure\n    - Enhance inputs for object detection and image segmentation",
    "namespace": "nodetool.image.transform",
    "node_type": "nodetool.image.transform.Canny",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to canny.",
        "min": null,
        "max": null
      },
      {
        "name": "low_threshold",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Low Threshold",
        "description": "Low threshold.",
        "min": 0.0,
        "max": 255.0
      },
      {
        "name": "high_threshold",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 200,
        "title": "High Threshold",
        "description": "High threshold.",
        "min": 0.0,
        "max": 255.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "low_threshold",
      "high_threshold"
    ]
  },
  {
    "title": "Scale",
    "description": "Enlarge or shrink an image by a scale factor.\n    image, resize, scale\n\n    - Adjust image dimensions for display galleries\n    - Standardize image sizes for machine learning datasets\n    - Create thumbnail versions of images",
    "namespace": "nodetool.image.transform",
    "node_type": "nodetool.image.transform.Scale",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to scale.",
        "min": null,
        "max": null
      },
      {
        "name": "scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Scale",
        "description": "The scale factor.",
        "min": 0.0,
        "max": 10.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "scale"
    ]
  },
  {
    "title": "Resize",
    "description": "Change image dimensions to specified width and height.\n    image, resize\n\n    - Preprocess images for machine learning model inputs\n    - Optimize images for faster web page loading\n    - Create uniform image sizes for layouts",
    "namespace": "nodetool.image.transform",
    "node_type": "nodetool.image.transform.Resize",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to resize.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Width",
        "description": "The target width.",
        "min": 0.0,
        "max": 4096.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Height",
        "description": "The target height.",
        "min": 0.0,
        "max": 4096.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "width",
      "height"
    ]
  },
  {
    "title": "Crop",
    "description": "Crop an image to specified coordinates.\n    image, crop\n\n    - Remove unwanted borders from images\n    - Focus on particular subjects within an image\n    - Simplify images by removing distractions",
    "namespace": "nodetool.image.transform",
    "node_type": "nodetool.image.transform.Crop",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to crop.",
        "min": null,
        "max": null
      },
      {
        "name": "left",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Left",
        "description": "The left coordinate.",
        "min": 0.0,
        "max": 4096.0
      },
      {
        "name": "top",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Top",
        "description": "The top coordinate.",
        "min": 0.0,
        "max": 4096.0
      },
      {
        "name": "right",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Right",
        "description": "The right coordinate.",
        "min": 0.0,
        "max": 4096.0
      },
      {
        "name": "bottom",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Bottom",
        "description": "The bottom coordinate.",
        "min": 0.0,
        "max": 4096.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "left",
      "top",
      "right",
      "bottom"
    ]
  },
  {
    "title": "Convert To Grayscale",
    "description": "Convert an image to grayscale.\n    image, grayscale\n\n    - Simplify images for feature and edge detection\n    - Prepare images for shape-based machine learning\n    - Create vintage or monochrome aesthetic effects",
    "namespace": "nodetool.image.transform",
    "node_type": "nodetool.image.transform.ConvertToGrayscale",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to convert.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Get Channel",
    "description": "Extract a specific color channel from an image.\n    image, color, channel, isolate, extract\n\n    - Isolate color information for image analysis\n    - Manipulate specific color components in graphic design\n    - Enhance or reduce visibility of certain colors",
    "namespace": "nodetool.image.transform",
    "node_type": "nodetool.image.transform.GetChannel",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to get the channel from.",
        "min": null,
        "max": null
      },
      {
        "name": "channel",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "R",
            "G",
            "B"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.image.transform.ChannelEnum"
        },
        "default": "R",
        "title": "Channel",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "channel"
    ]
  },
  {
    "title": "Float Input",
    "description": "Float parameter input for workflows.\n    input, parameter, float, number\n\n    Use cases:\n    - Specify a numeric value within a defined range\n    - Set thresholds or scaling factors\n    - Configure continuous parameters like opacity or volume",
    "namespace": "nodetool.input",
    "node_type": "nodetool.input.FloatInput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this input node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "min",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Min",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "max",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Max",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Boolean Input",
    "description": "Boolean parameter input for workflows.\n    input, parameter, boolean, bool\n\n    Use cases:\n    - Toggle features on/off\n    - Set binary flags\n    - Control conditional logic",
    "namespace": "nodetool.input",
    "node_type": "nodetool.input.BooleanInput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this input node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Integer Input",
    "description": "Integer parameter input for workflows.\n    input, parameter, integer, number\n\n    Use cases:\n    - Specify counts or quantities\n    - Set index values\n    - Configure discrete numeric parameters",
    "namespace": "nodetool.input",
    "node_type": "nodetool.input.IntegerInput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this input node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "min",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Min",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "max",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Max",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "String Input",
    "description": "String parameter input for workflows.\n    input, parameter, string, text\n\n    Use cases:\n    - Provide text labels or names\n    - Enter search queries\n    - Specify file paths or URLs",
    "namespace": "nodetool.input",
    "node_type": "nodetool.input.StringInput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this input node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Chat Input",
    "description": "Chat message input for workflows.\n    input, parameter, chat, message\n\n    Use cases:\n    - Accept user prompts or queries\n    - Capture conversational input\n    - Provide instructions to language models",
    "namespace": "nodetool.input",
    "node_type": "nodetool.input.ChatInput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this input node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "message",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Value",
        "description": "The chat message to use as input.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "message",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "history",
        "stream": false
      },
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "text",
        "stream": false
      },
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      },
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "audio",
        "stream": false
      },
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "video",
        "stream": false
      },
      {
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "document",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Text Input",
    "description": "Text content input for workflows.\n    input, parameter, text\n\n    Use cases:\n    - Load text documents or articles\n    - Process multi-line text content\n    - Analyze large text bodies",
    "namespace": "nodetool.input",
    "node_type": "nodetool.input.TextInput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this input node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "text",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "text",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Value",
        "description": "The text to use as input.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "text",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Document Input",
    "description": "Document asset input for workflows.\n    input, parameter, document\n\n    Use cases:\n    - Load documents for processing\n    - Analyze document content\n    - Provide document input to models",
    "namespace": "nodetool.input",
    "node_type": "nodetool.input.DocumentInput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this input node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "document",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Value",
        "description": "The document to use as input.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Image Input",
    "description": "Image asset input for workflows.\n    input, parameter, image\n\n    Use cases:\n    - Load images for processing or analysis\n    - Provide visual input to models\n    - Select images for manipulation",
    "namespace": "nodetool.input",
    "node_type": "nodetool.input.ImageInput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this input node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Value",
        "description": "The image to use as input.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Video Input",
    "description": "Video asset input for workflows.\n    input, parameter, video\n\n    Use cases:\n    - Load video files for processing\n    - Analyze video content\n    - Extract frames or audio from videos",
    "namespace": "nodetool.input",
    "node_type": "nodetool.input.VideoInput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this input node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Value",
        "description": "The video to use as input.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Audio Input",
    "description": "Audio asset input for workflows.\n    input, parameter, audio\n\n    Use cases:\n    - Load audio files for processing\n    - Analyze sound or speech content\n    - Provide audio input to models",
    "namespace": "nodetool.input",
    "node_type": "nodetool.input.AudioInput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this input node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Value",
        "description": "The audio to use as input.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Path Input",
    "description": "Local path input for workflows.\n    input, parameter, path\n\n    Use cases:\n    - Provide a local path to a file or directory\n    - Specify a file or directory for processing\n    - Load local data for analysis",
    "namespace": "nodetool.input",
    "node_type": "nodetool.input.PathInput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this input node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "file_path",
          "path": ""
        },
        "title": "Value",
        "description": "The path to use as input.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Group Input",
    "description": "Generic group input for loops.\n    input, group, collection, loop\n\n    Use cases:\n    - provides input for a loop\n    - iterates over a group of items",
    "namespace": "nodetool.input",
    "node_type": "nodetool.input.GroupInput",
    "layout": "default",
    "properties": [],
    "outputs": [
      {
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": []
  },
  {
    "title": "Enum Input",
    "description": "Enumeration parameter input for workflows.\n    input, parameter, enum, options, select\n\n    Use cases:\n    - Select from predefined options\n    - Enforce choice from valid values\n    - Configure categorical parameters",
    "namespace": "nodetool.input",
    "node_type": "nodetool.input.EnumInput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this input node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "options",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Options",
        "description": "Comma-separated list of valid options",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Parse Dict",
    "description": "Parse a JSON string into a Python dictionary.\n    json, parse, decode, dictionary\n\n    Use cases:\n    - Convert JSON API responses to Python dictionaries\n    - Process JSON configuration files\n    - Parse object-like JSON data",
    "namespace": "nodetool.json",
    "node_type": "nodetool.json.ParseDict",
    "layout": "default",
    "properties": [
      {
        "name": "json_string",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Json String",
        "description": "JSON string to parse into a dictionary",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "json_string"
    ]
  },
  {
    "title": "Parse List",
    "description": "Parse a JSON string into a Python list.\n    json, parse, decode, array, list\n\n    Use cases:\n    - Convert JSON array responses to Python lists\n    - Process JSON data collections\n    - Parse array-like JSON data",
    "namespace": "nodetool.json",
    "node_type": "nodetool.json.ParseList",
    "layout": "default",
    "properties": [
      {
        "name": "json_string",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Json String",
        "description": "JSON string to parse into a list",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "json_string"
    ]
  },
  {
    "title": "Stringify JSON",
    "description": "Convert a Python object to a JSON string.\n    json, stringify, encode\n\n    Use cases:\n    - Prepare data for API requests\n    - Save data in JSON format",
    "namespace": "nodetool.json",
    "node_type": "nodetool.json.StringifyJSON",
    "layout": "default",
    "properties": [
      {
        "name": "data",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {},
        "title": "Data",
        "description": "Data to convert to JSON",
        "min": null,
        "max": null
      },
      {
        "name": "indent",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Indent",
        "description": "Number of spaces for indentation",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "data",
      "indent"
    ]
  },
  {
    "title": "Get JSONPath Str",
    "description": "Extract a string value from a JSON path\n    json, path, extract, string",
    "namespace": "nodetool.json",
    "node_type": "nodetool.json.GetJSONPathStr",
    "layout": "default",
    "properties": [
      {
        "name": "data",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Data",
        "description": "JSON object to extract from",
        "min": null,
        "max": null
      },
      {
        "name": "path",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Path",
        "description": "Path to the desired value (dot notation)",
        "min": null,
        "max": null
      },
      {
        "name": "default",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Default",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "data",
      "path",
      "default"
    ]
  },
  {
    "title": "Get JSONPath Int",
    "description": "Extract an integer value from a JSON path\n    json, path, extract, number",
    "namespace": "nodetool.json",
    "node_type": "nodetool.json.GetJSONPathInt",
    "layout": "default",
    "properties": [
      {
        "name": "data",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Data",
        "description": "JSON object to extract from",
        "min": null,
        "max": null
      },
      {
        "name": "path",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Path",
        "description": "Path to the desired value (dot notation)",
        "min": null,
        "max": null
      },
      {
        "name": "default",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Default",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "data",
      "path",
      "default"
    ]
  },
  {
    "title": "Get JSONPath Float",
    "description": "Extract a float value from a JSON path\n    json, path, extract, number",
    "namespace": "nodetool.json",
    "node_type": "nodetool.json.GetJSONPathFloat",
    "layout": "default",
    "properties": [
      {
        "name": "data",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Data",
        "description": "JSON object to extract from",
        "min": null,
        "max": null
      },
      {
        "name": "path",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Path",
        "description": "Path to the desired value (dot notation)",
        "min": null,
        "max": null
      },
      {
        "name": "default",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Default",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "data",
      "path",
      "default"
    ]
  },
  {
    "title": "Get JSONPath Bool",
    "description": "Extract a boolean value from a JSON path\n    json, path, extract, boolean",
    "namespace": "nodetool.json",
    "node_type": "nodetool.json.GetJSONPathBool",
    "layout": "default",
    "properties": [
      {
        "name": "data",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Data",
        "description": "JSON object to extract from",
        "min": null,
        "max": null
      },
      {
        "name": "path",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Path",
        "description": "Path to the desired value (dot notation)",
        "min": null,
        "max": null
      },
      {
        "name": "default",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Default",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "data",
      "path",
      "default"
    ]
  },
  {
    "title": "Get JSONPath List",
    "description": "Extract a list value from a JSON path\n    json, path, extract, array",
    "namespace": "nodetool.json",
    "node_type": "nodetool.json.GetJSONPathList",
    "layout": "default",
    "properties": [
      {
        "name": "data",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Data",
        "description": "JSON object to extract from",
        "min": null,
        "max": null
      },
      {
        "name": "path",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Path",
        "description": "Path to the desired value (dot notation)",
        "min": null,
        "max": null
      },
      {
        "name": "default",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Default",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "data",
      "path",
      "default"
    ]
  },
  {
    "title": "Get JSONPath Dict",
    "description": "Extract a dictionary value from a JSON path\n    json, path, extract, object",
    "namespace": "nodetool.json",
    "node_type": "nodetool.json.GetJSONPathDict",
    "layout": "default",
    "properties": [
      {
        "name": "data",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Data",
        "description": "JSON object to extract from",
        "min": null,
        "max": null
      },
      {
        "name": "path",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Path",
        "description": "Path to the desired value (dot notation)",
        "min": null,
        "max": null
      },
      {
        "name": "default",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Default",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "data",
      "path",
      "default"
    ]
  },
  {
    "title": "Validate JSON",
    "description": "Validate JSON data against a schema.\n    json, validate, schema\n\n    Use cases:\n    - Ensure API payloads match specifications\n    - Validate configuration files",
    "namespace": "nodetool.json",
    "node_type": "nodetool.json.ValidateJSON",
    "layout": "default",
    "properties": [
      {
        "name": "data",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Data",
        "description": "JSON data to validate",
        "min": null,
        "max": null
      },
      {
        "name": "schema",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Schema",
        "description": "JSON schema for validation",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "data",
      "schema"
    ]
  },
  {
    "title": "Filter JSON",
    "description": "Filter JSON array based on a key-value condition.\n    json, filter, array\n\n    Use cases:\n    - Filter arrays of objects\n    - Search JSON data",
    "namespace": "nodetool.json",
    "node_type": "nodetool.json.FilterJSON",
    "layout": "default",
    "properties": [
      {
        "name": "array",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Array",
        "description": "Array of JSON objects to filter",
        "min": null,
        "max": null
      },
      {
        "name": "key",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Key",
        "description": "Key to filter on",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Value",
        "description": "Value to match",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "array",
      "key",
      "value"
    ]
  },
  {
    "title": "JSON Template",
    "description": "Template JSON strings with variable substitution.\n    json, template, substitute, variables\n\n    Example:\n    template: '{\"name\": \"$user\", \"age\": $age}'\n    values: {\"user\": \"John\", \"age\": 30}\n    result: '{\"name\": \"John\", \"age\": 30}'\n\n    Use cases:\n    - Create dynamic JSON payloads\n    - Generate JSON with variable data\n    - Build API request templates",
    "namespace": "nodetool.json",
    "node_type": "nodetool.json.JSONTemplate",
    "layout": "default",
    "properties": [
      {
        "name": "template",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Template",
        "description": "JSON template string with $variable placeholders",
        "min": null,
        "max": null
      },
      {
        "name": "values",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": "Dictionary of values to substitute into the template",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "template",
      "values"
    ]
  },
  {
    "title": "Length",
    "description": "Calculates the length of a list.\n    list, count, size\n\n    Use cases:\n    - Determine the number of elements in a list\n    - Check if a list is empty\n    - Validate list size constraints",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.Length",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values"
    ]
  },
  {
    "title": "Generate Sequence",
    "description": "Generates a list of integers within a specified range.\n    list, range, sequence, numbers\n\n    Use cases:\n    - Create numbered lists\n    - Generate index sequences\n    - Produce arithmetic progressions",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.GenerateSequence",
    "layout": "default",
    "properties": [
      {
        "name": "start",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Start",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "stop",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Stop",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "step",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Step",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "start",
      "stop",
      "step"
    ]
  },
  {
    "title": "Slice",
    "description": "Extracts a subset from a list using start, stop, and step indices.\n    list, slice, subset, extract\n\n    Use cases:\n    - Get a portion of a list\n    - Implement pagination\n    - Extract every nth element",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.Slice",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "start",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Start",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "stop",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Stop",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "step",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Step",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "start",
      "stop",
      "step"
    ]
  },
  {
    "title": "Select Elements",
    "description": "Selects specific values from a list using index positions.\n    list, select, index, extract\n\n    Use cases:\n    - Pick specific elements by their positions\n    - Rearrange list elements\n    - Create a new list from selected indices",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.SelectElements",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "indices",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Indices",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "indices"
    ]
  },
  {
    "title": "Get Element",
    "description": "Retrieves a single value from a list at a specific index.\n    list, get, extract, value\n\n    Use cases:\n    - Access a specific element by position\n    - Implement array-like indexing\n    - Extract the first or last element",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.GetElement",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "index",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Index",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "index"
    ]
  },
  {
    "title": "Append",
    "description": "Adds a value to the end of a list.\n    list, add, insert, extend\n\n    Use cases:\n    - Grow a list dynamically\n    - Add new elements to an existing list\n    - Implement a stack-like structure",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.Append",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "value"
    ]
  },
  {
    "title": "Extend",
    "description": "Merges one list into another, extending the original list.\n    list, merge, concatenate, combine\n\n    Use cases:\n    - Combine multiple lists\n    - Add all elements from one list to another",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.Extend",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "other_values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Other Values",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "other_values"
    ]
  },
  {
    "title": "Dedupe",
    "description": "Removes duplicate elements from a list, ensuring uniqueness.\n    list, unique, distinct, deduplicate\n\n    Use cases:\n    - Remove redundant entries\n    - Create a set-like structure\n    - Ensure list elements are unique",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.Dedupe",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values"
    ]
  },
  {
    "title": "Reverse",
    "description": "Inverts the order of elements in a list.\n    list, reverse, invert, flip\n\n    Use cases:\n    - Reverse the order of a sequence",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.Reverse",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values"
    ]
  },
  {
    "title": "Save List",
    "description": "Saves a list to a text file, placing each element on a new line.\n    list, save, file, serialize\n\n    Use cases:\n    - Export list data to a file\n    - Create a simple text-based database\n    - Generate line-separated output",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.SaveList",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": "The list to save.",
        "min": null,
        "max": null
      },
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "text.txt",
        "title": "Name",
        "description": "\n        Name of the output file.\n        You can use time and date variables to create unique names:\n        %Y - Year\n        %m - Month\n        %d - Day\n        %H - Hour\n        %M - Minute\n        %S - Second\n        ",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "text",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "name"
    ]
  },
  {
    "title": "Randomize",
    "description": "Randomly shuffles the elements of a list.\n    list, shuffle, random, order\n\n    Use cases:\n    - Randomize the order of items in a playlist\n    - Implement random sampling without replacement\n    - Create randomized data sets for testing",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.Randomize",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values"
    ]
  },
  {
    "title": "Sort",
    "description": "Sorts the elements of a list in ascending or descending order.\n    list, sort, order, arrange\n\n    Use cases:\n    - Organize data in a specific order\n    - Prepare data for binary search or other algorithms\n    - Rank items based on their values",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.Sort",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "order",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "ascending",
            "descending"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.list.SortOrder"
        },
        "default": "ascending",
        "title": "Order",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "order"
    ]
  },
  {
    "title": "Filter Dicts",
    "description": "Filter a list of dictionaries based on a condition.\n    list, filter, query, condition\n\n    Basic Operators:\n    - Comparison: >, <, >=, <=, ==, !=\n    - Logical: and, or, not\n    - Membership: in, not in\n\n    Example Conditions:\n    # Basic comparisons\n    age > 30\n    price <= 100\n    status == 'active'\n\n    # Multiple conditions\n    age > 30 and salary < 50000\n    (price >= 100) and (price <= 200)\n    department in ['Sales', 'Marketing']\n\n    # String operations\n    name.str.startswith('J')\n    email.str.contains('@company.com')\n\n    # Datetime conditions\n    date > '2024-01-01'\n    date.dt.year == 2024\n    date.dt.month >= 6\n    date.dt.day_name() == 'Monday'\n\n    # Date ranges\n    date.between('2024-01-01', '2024-12-31')\n    date >= '2024-01-01' and date < '2025-01-01'\n\n    # Complex datetime\n    date.dt.hour < 12\n    date.dt.dayofweek <= 4  # Weekdays only\n\n    # Numeric operations\n    price.between(100, 200)\n    quantity % 2 == 0  # Even numbers\n\n    # Special values\n    value.isna()  # Check for NULL/NaN\n    value.notna()  # Check for non-NULL/non-NaN\n\n    Note: Dates should be in ISO format (YYYY-MM-DD) or include time (YYYY-MM-DD HH:MM:SS)\n\n    Use cases:\n    - Filter list of dictionary objects based on criteria\n    - Extract subset of data meeting specific conditions\n    - Clean data by removing unwanted entries",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.FilterDicts",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": "The list of dictionaries to filter.",
        "min": null,
        "max": null
      },
      {
        "name": "condition",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Condition",
        "description": "\n        The filtering condition using pandas query syntax.\n\n        Basic Operators:\n        - Comparison: >, <, >=, <=, ==, !=\n        - Logical: and, or, not\n        - Membership: in, not in\n        \n        Example Conditions:\n        # Basic comparisons\n        age > 30\n        price <= 100\n        status == 'active'\n        \n        See node documentation for more examples.\n        ",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "condition"
    ]
  },
  {
    "title": "Filter Strings",
    "description": "Filters a list of strings based on various criteria.\n    list, filter, strings, text\n\n    Use cases:\n    - Filter strings by length\n    - Filter strings containing specific text\n    - Filter strings by prefix/suffix\n    - Filter strings using regex patterns",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.FilterStrings",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": "The list of strings to filter.",
        "min": null,
        "max": null
      },
      {
        "name": "filter_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "contains",
            "starts_with",
            "ends_with",
            "length_greater",
            "length_less",
            "exact_length"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.list.FilterType"
        },
        "default": "contains",
        "title": "Filter Type",
        "description": "The type of filter to apply",
        "min": null,
        "max": null
      },
      {
        "name": "criteria",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Criteria",
        "description": "The filtering criteria (text to match or length as string)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "filter_type",
      "criteria"
    ]
  },
  {
    "title": "Filter Numbers",
    "description": "Filters a list of numbers based on various numerical conditions.\n    list, filter, numbers, numeric\n\n    Use cases:\n    - Filter numbers by comparison (greater than, less than, equal to)\n    - Filter even/odd numbers\n    - Filter positive/negative numbers",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.FilterNumbers",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": "The list of numbers to filter.",
        "min": null,
        "max": null
      },
      {
        "name": "filter_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "greater_than",
            "less_than",
            "equal_to",
            "even",
            "odd",
            "positive",
            "negative"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.list.FilterType"
        },
        "default": "greater_than",
        "title": "Filter Type",
        "description": "The type of filter to apply",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Value",
        "description": "The comparison value (for greater_than, less_than, equal_to)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "filter_type",
      "value"
    ]
  },
  {
    "title": "Filter Number Range",
    "description": "Filters a list of numbers to find values within a specified range.\n    list, filter, numbers, range, between\n\n    Use cases:\n    - Find numbers within a specific range\n    - Filter data points within bounds\n    - Implement range-based filtering",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.FilterNumberRange",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "min_value",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Min Value",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "max_value",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Max Value",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "inclusive",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Inclusive",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "min_value",
      "max_value",
      "inclusive"
    ]
  },
  {
    "title": "Filter Regex",
    "description": "Filters a list of strings using regular expressions.\n    list, filter, regex, pattern, text\n\n    Use cases:\n    - Filter strings using complex patterns\n    - Extract strings matching specific formats (emails, dates, etc.)\n    - Advanced text pattern matching",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.FilterRegex",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": "The list of strings to filter.",
        "min": null,
        "max": null
      },
      {
        "name": "pattern",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Pattern",
        "description": "The regular expression pattern to match against.",
        "min": null,
        "max": null
      },
      {
        "name": "full_match",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Full Match",
        "description": "Whether to match the entire string or find pattern anywhere in string",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "pattern",
      "full_match"
    ]
  },
  {
    "title": "Filter None",
    "description": "Filters out None values from a list.\n    list, filter, none, null\n\n    Use cases:\n    - Clean data by removing null values\n    - Get only valid entries\n    - Remove placeholder values",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.FilterNone",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": "The list to filter None values from.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values"
    ]
  },
  {
    "title": "Filter Dicts By Value",
    "description": "Filters a list of dictionaries based on their values using various criteria.\n    list, filter, dictionary, values\n\n    Use cases:\n    - Filter dictionaries by value content\n    - Filter dictionaries by value type\n    - Filter dictionaries by value patterns",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.FilterDictsByValue",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": "The list of dictionaries to filter.",
        "min": null,
        "max": null
      },
      {
        "name": "key",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Key",
        "description": "The dictionary key to check",
        "min": null,
        "max": null
      },
      {
        "name": "filter_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "contains",
            "starts_with",
            "ends_with",
            "equals",
            "type_is",
            "length_greater",
            "length_less",
            "exact_length"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.list.FilterType"
        },
        "default": "contains",
        "title": "Filter Type",
        "description": "The type of filter to apply",
        "min": null,
        "max": null
      },
      {
        "name": "criteria",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Criteria",
        "description": "The filtering criteria (text to match, type name, or length as string)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "key",
      "filter_type",
      "criteria"
    ]
  },
  {
    "title": "Filter Dicts By Range",
    "description": "Filters a list of dictionaries based on a numeric range for a specified key.\n    list, filter, dictionary, range, between\n\n    Use cases:\n    - Filter records based on numeric ranges (e.g., price range, age range)\n    - Find entries with values within specified bounds\n    - Filter data sets based on numeric criteria",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.FilterDictsByRange",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": "The list of dictionaries to filter.",
        "min": null,
        "max": null
      },
      {
        "name": "key",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Key",
        "description": "The dictionary key to check for the range",
        "min": null,
        "max": null
      },
      {
        "name": "min_value",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Min Value",
        "description": "The minimum value (inclusive) of the range",
        "min": null,
        "max": null
      },
      {
        "name": "max_value",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Max Value",
        "description": "The maximum value (inclusive) of the range",
        "min": null,
        "max": null
      },
      {
        "name": "inclusive",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Inclusive",
        "description": "If True, includes the min and max values in the results",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "key",
      "min_value",
      "max_value",
      "inclusive"
    ]
  },
  {
    "title": "Filter Dicts By Number",
    "description": "Filters a list of dictionaries based on numeric values for a specified key.\n    list, filter, dictionary, numbers, numeric\n\n    Use cases:\n    - Filter dictionaries by numeric comparisons (greater than, less than, equal to)\n    - Filter records with even/odd numeric values\n    - Filter entries with positive/negative numbers",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.FilterDictsByNumber",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "key",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Key",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "filter_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "greater_than",
            "less_than",
            "equal_to",
            "even",
            "odd",
            "positive",
            "negative"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.list.FilterType"
        },
        "default": "greater_than",
        "title": "Filter Type",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "key",
      "filter_type",
      "value"
    ]
  },
  {
    "title": "Filter Dicts Regex",
    "description": "Filters a list of dictionaries using regular expressions on specified keys.\n    list, filter, regex, dictionary, pattern\n\n    Use cases:\n    - Filter dictionaries with values matching complex patterns\n    - Search for dictionaries containing emails, dates, or specific formats\n    - Advanced text pattern matching across dictionary values",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.FilterDictsRegex",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "key",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Key",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "pattern",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Pattern",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "full_match",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Full Match",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "key",
      "pattern",
      "full_match"
    ]
  },
  {
    "title": "Intersection",
    "description": "Finds common elements between two lists.\n    list, set, intersection, common\n\n    Use cases:\n    - Find elements present in both lists\n    - Identify shared items between collections\n    - Filter for matching elements",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.Intersection",
    "layout": "default",
    "properties": [
      {
        "name": "list1",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "List1",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "list2",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "List2",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "list1",
      "list2"
    ]
  },
  {
    "title": "Union",
    "description": "Combines unique elements from two lists.\n    list, set, union, combine\n\n    Use cases:\n    - Merge lists while removing duplicates\n    - Combine collections uniquely\n    - Create comprehensive set of items",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.Union",
    "layout": "default",
    "properties": [
      {
        "name": "list1",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "List1",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "list2",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "List2",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "list1",
      "list2"
    ]
  },
  {
    "title": "Difference",
    "description": "Finds elements that exist in first list but not in second list.\n    list, set, difference, subtract\n\n    Use cases:\n    - Find unique elements in one list\n    - Remove items present in another list\n    - Identify distinct elements",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.Difference",
    "layout": "default",
    "properties": [
      {
        "name": "list1",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "List1",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "list2",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "List2",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "list1",
      "list2"
    ]
  },
  {
    "title": "Chunk",
    "description": "Splits a list into smaller chunks of specified size.\n    list, chunk, split, group\n\n    Use cases:\n    - Batch processing\n    - Pagination\n    - Creating sublists of fixed size",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.Chunk",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "chunk_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Chunk Size",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "list",
              "optional": false,
              "values": null,
              "type_args": [
                {
                  "type": "any",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                }
              ],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "chunk_size"
    ]
  },
  {
    "title": "Transform",
    "description": "Applies a transformation to each element in a list.\n    list, transform, map, convert\n\n    Use cases:\n    - Convert types (str to int, etc.)\n    - Apply formatting\n    - Mathematical operations",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.Transform",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": "The list of values to transform",
        "min": null,
        "max": null
      },
      {
        "name": "transform_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "to_int",
            "to_float",
            "to_string",
            "uppercase",
            "lowercase",
            "strip"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.list.TransformType"
        },
        "default": "to_string",
        "title": "Transform Type",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "transform_type"
    ]
  },
  {
    "title": "Sum",
    "description": "Calculates the sum of a list of numbers.\n    list, sum, aggregate, math\n\n    Use cases:\n    - Calculate total of numeric values\n    - Add up all elements in a list",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.Sum",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values"
    ]
  },
  {
    "title": "Average",
    "description": "Calculates the arithmetic mean of a list of numbers.\n    list, average, mean, aggregate, math\n\n    Use cases:\n    - Find average value\n    - Calculate mean of numeric data",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.Average",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values"
    ]
  },
  {
    "title": "Minimum",
    "description": "Finds the smallest value in a list of numbers.\n    list, min, minimum, aggregate, math\n\n    Use cases:\n    - Find lowest value\n    - Get smallest number in dataset",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.Minimum",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values"
    ]
  },
  {
    "title": "Maximum",
    "description": "Finds the largest value in a list of numbers.\n    list, max, maximum, aggregate, math\n\n    Use cases:\n    - Find highest value\n    - Get largest number in dataset",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.Maximum",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values"
    ]
  },
  {
    "title": "Product",
    "description": "Calculates the product of all numbers in a list.\n    list, product, multiply, aggregate, math\n\n    Use cases:\n    - Multiply all numbers together\n    - Calculate compound values",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.Product",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values"
    ]
  },
  {
    "title": "Map Field",
    "description": "Extracts a specific field from a list of dictionaries or objects.\n    list, map, field, extract, pluck\n\n    Use cases:\n    - Extract specific fields from a list of objects\n    - Transform complex data structures into simple lists\n    - Collect values for a particular key across multiple dictionaries",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.MapField",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "union",
              "optional": false,
              "values": null,
              "type_args": [
                {
                  "type": "dict",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                },
                {
                  "type": "object",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                }
              ],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": "The list of dictionaries or objects to extract from",
        "min": null,
        "max": null
      },
      {
        "name": "field",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Field",
        "description": "The dictionary key or object field to extract",
        "min": null,
        "max": null
      },
      {
        "name": "default",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Default",
        "description": "Default value if field is missing (None if not specified)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "field",
      "default"
    ]
  },
  {
    "title": "Join Strings",
    "description": "Joins a list of strings using a specified delimiter.\n    list, join, concatenate, strings\n\n    Use cases:\n    - Combine strings with a separator\n    - Create CSV-like strings\n    - Format text for display or output",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.JoinStrings",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": "The list of strings to join",
        "min": null,
        "max": null
      },
      {
        "name": "delimiter",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Delimiter",
        "description": "The string to use as a separator between elements",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "delimiter"
    ]
  },
  {
    "title": "Map Template",
    "description": "Maps a template string over a list of dictionaries or objects.\n    list, template, map, formatting\n\n    Use cases:\n    - Formatting multiple records into strings\n    - Generating text from structured data\n    - Creating text representations of data collections\n\n    Examples:\n    - template: \"Name: {name}, Age: {age}\"\n      values: [{\"name\": \"Alice\", \"age\": 30}, {\"name\": \"Bob\", \"age\": 25}]\n      -> [\"Name: Alice, Age: 30\", \"Name: Bob, Age: 25\"]\n\n    - template: \"Hello, {0} {1}!\"\n      values: [[\"Alice\", \"Smith\"], [\"Bob\", \"Jones\"]]\n      -> [\"Hello, Alice Smith!\", \"Hello, Bob Jones!\"]",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.MapTemplate",
    "layout": "default",
    "properties": [
      {
        "name": "template",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Template",
        "description": "\n        Template string with placeholders for formatting\n        - Placeholders can be indexed (e.g., {0}, {1}, etc.) for lists\n        - Placeholders can be named (e.g., {name}, {age}, etc.) for dictionaries\n        - Placeholders can be named (e.g., {name}, {age}, etc.) for objects\n        ",
        "min": null,
        "max": null
      },
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "union",
              "optional": false,
              "values": null,
              "type_args": [
                {
                  "type": "dict",
                  "optional": false,
                  "values": null,
                  "type_args": [
                    {
                      "type": "str",
                      "optional": false,
                      "values": null,
                      "type_args": [],
                      "type_name": null
                    },
                    {
                      "type": "any",
                      "optional": false,
                      "values": null,
                      "type_args": [],
                      "type_name": null
                    }
                  ],
                  "type_name": null
                },
                {
                  "type": "list",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                },
                {
                  "type": "object",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                }
              ],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": "List of values to format the template with",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "template",
      "values"
    ]
  },
  {
    "title": "Flatten",
    "description": "Flattens a nested list structure into a single flat list.\n    list, flatten, nested, structure\n\n    Use cases:\n    - Convert nested lists into a single flat list\n    - Simplify complex list structures\n    - Process hierarchical data as a sequence\n\n    Examples:\n    [[1, 2], [3, 4]] -> [1, 2, 3, 4]\n    [[1, [2, 3]], [4, [5, 6]]] -> [1, 2, 3, 4, 5, 6]",
    "namespace": "nodetool.list",
    "node_type": "nodetool.list.Flatten",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Values",
        "description": "The nested list structure to flatten",
        "min": null,
        "max": null
      },
      {
        "name": "max_depth",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Max Depth",
        "description": "Maximum depth to flatten (-1 for unlimited)",
        "min": -1.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values",
      "max_depth"
    ]
  },
  {
    "title": "Binary Operation",
    "description": "",
    "namespace": "nodetool.math",
    "node_type": "nodetool.math.BinaryOperation",
    "layout": "small",
    "properties": [
      {
        "name": "a",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 0.0,
        "title": "A",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "b",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 0.0,
        "title": "B",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "a",
      "b"
    ]
  },
  {
    "title": "Add",
    "description": "Performs addition on two inputs.\n    math, plus, add, addition, sum, +",
    "namespace": "nodetool.math",
    "node_type": "nodetool.math.Add",
    "layout": "small",
    "properties": [
      {
        "name": "a",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 0.0,
        "title": "A",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "b",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 0.0,
        "title": "B",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "a",
      "b"
    ]
  },
  {
    "title": "Subtract",
    "description": "Subtracts the second input from the first.\n    math, minus, difference, -",
    "namespace": "nodetool.math",
    "node_type": "nodetool.math.Subtract",
    "layout": "small",
    "properties": [
      {
        "name": "a",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 0.0,
        "title": "A",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "b",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 0.0,
        "title": "B",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "a",
      "b"
    ]
  },
  {
    "title": "Multiply",
    "description": "Multiplies two inputs.\n    math, product, times, *",
    "namespace": "nodetool.math",
    "node_type": "nodetool.math.Multiply",
    "layout": "small",
    "properties": [
      {
        "name": "a",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 0.0,
        "title": "A",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "b",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 0.0,
        "title": "B",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "a",
      "b"
    ]
  },
  {
    "title": "Divide",
    "description": "Divides the first input by the second.\n    math, division, arithmetic, quotient",
    "namespace": "nodetool.math",
    "node_type": "nodetool.math.Divide",
    "layout": "small",
    "properties": [
      {
        "name": "a",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 0.0,
        "title": "A",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "b",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 0.0,
        "title": "B",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "a",
      "b"
    ]
  },
  {
    "title": "Modulus",
    "description": "Calculates the element-wise remainder of division.\n    math, modulo, remainder, mod, %\n\n    Use cases:\n    - Implementing cyclic behaviors\n    - Checking for even/odd numbers\n    - Limiting values to a specific range",
    "namespace": "nodetool.math",
    "node_type": "nodetool.math.Modulus",
    "layout": "small",
    "properties": [
      {
        "name": "a",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 0.0,
        "title": "A",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "b",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 0.0,
        "title": "B",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "a",
      "b"
    ]
  },
  {
    "title": "Sine",
    "description": "Computes the sine of input angles in radians.\n    math, trigonometry, sine, sin\n\n    Use cases:\n    - Calculating vertical components in physics\n    - Generating smooth periodic functions\n    - Audio signal processing",
    "namespace": "nodetool.math",
    "node_type": "nodetool.math.Sine",
    "layout": "small",
    "properties": [
      {
        "name": "angle_rad",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 0.0,
        "title": "Angle (Radians)",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "angle_rad"
    ]
  },
  {
    "title": "Cosine",
    "description": "Computes the cosine of input angles in radians.\n    math, trigonometry, cosine, cos\n\n    Use cases:\n    - Calculating horizontal components in physics\n    - Creating circular motions\n    - Phase calculations in signal processing",
    "namespace": "nodetool.math",
    "node_type": "nodetool.math.Cosine",
    "layout": "small",
    "properties": [
      {
        "name": "angle_rad",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 0.0,
        "title": "Angle (Radians)",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "angle_rad"
    ]
  },
  {
    "title": "Power",
    "description": "Raises the base to the power of the exponent element-wise.\n    math, exponentiation, power, pow, **\n\n    Use cases:\n    - Calculating compound interest\n    - Implementing polynomial functions\n    - Applying non-linear transformations to data",
    "namespace": "nodetool.math",
    "node_type": "nodetool.math.Power",
    "layout": "small",
    "properties": [
      {
        "name": "base",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 1.0,
        "title": "Base",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "exponent",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 2.0,
        "title": "Exponent",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "base",
      "exponent"
    ]
  },
  {
    "title": "Sqrt",
    "description": "Calculates the square root of the input element-wise.\n    math, square root, sqrt, \u221a\n\n    Use cases:\n    - Normalizing data\n    - Calculating distances in Euclidean space\n    - Finding intermediate values in binary search",
    "namespace": "nodetool.math",
    "node_type": "nodetool.math.Sqrt",
    "layout": "small",
    "properties": [
      {
        "name": "x",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 1.0,
        "title": "Input",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "x"
    ]
  },
  {
    "title": "GET Request",
    "description": "Perform an HTTP GET request to retrieve data from a specified URL.\n    http, get, request, url\n\n    Use cases:\n    - Fetch web page content\n    - Retrieve API data\n    - Download files\n    - Check website availability",
    "namespace": "nodetool.network.http",
    "node_type": "nodetool.network.http.GetRequest",
    "layout": "default",
    "properties": [
      {
        "name": "url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Url",
        "description": "The URL to make the request to.",
        "min": null,
        "max": null
      },
      {
        "name": "headers",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Headers",
        "description": "Optional headers to include in the request.",
        "min": null,
        "max": null
      },
      {
        "name": "auth",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Auth",
        "description": "Authentication credentials.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "url",
      "headers",
      "auth"
    ]
  },
  {
    "title": "POST Request",
    "description": "Send data to a server using an HTTP POST request.\n    http, post, request, url, data\n\n    Use cases:\n    - Submit form data\n    - Create new resources on an API\n    - Upload files\n    - Authenticate users",
    "namespace": "nodetool.network.http",
    "node_type": "nodetool.network.http.PostRequest",
    "layout": "default",
    "properties": [
      {
        "name": "url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Url",
        "description": "The URL to make the request to.",
        "min": null,
        "max": null
      },
      {
        "name": "headers",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Headers",
        "description": "Optional headers to include in the request.",
        "min": null,
        "max": null
      },
      {
        "name": "auth",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Auth",
        "description": "Authentication credentials.",
        "min": null,
        "max": null
      },
      {
        "name": "data",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Data",
        "description": "The data to send in the POST request.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "url",
      "headers",
      "auth",
      "data"
    ]
  },
  {
    "title": "PUT Request",
    "description": "Update existing resources on a server using an HTTP PUT request.\n    http, put, request, url, data\n\n    Use cases:\n    - Update user profiles\n    - Modify existing API resources\n    - Replace file contents\n    - Set configuration values",
    "namespace": "nodetool.network.http",
    "node_type": "nodetool.network.http.PutRequest",
    "layout": "default",
    "properties": [
      {
        "name": "url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Url",
        "description": "The URL to make the request to.",
        "min": null,
        "max": null
      },
      {
        "name": "headers",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Headers",
        "description": "Optional headers to include in the request.",
        "min": null,
        "max": null
      },
      {
        "name": "auth",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Auth",
        "description": "Authentication credentials.",
        "min": null,
        "max": null
      },
      {
        "name": "data",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Data",
        "description": "The data to send in the PUT request.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "url",
      "headers",
      "auth",
      "data"
    ]
  },
  {
    "title": "DELETE Request",
    "description": "Remove a resource from a server using an HTTP DELETE request.\n    http, delete, request, url\n\n    Use cases:\n    - Delete user accounts\n    - Remove API resources\n    - Cancel subscriptions\n    - Clear cache entries",
    "namespace": "nodetool.network.http",
    "node_type": "nodetool.network.http.DeleteRequest",
    "layout": "default",
    "properties": [
      {
        "name": "url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Url",
        "description": "The URL to make the request to.",
        "min": null,
        "max": null
      },
      {
        "name": "headers",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Headers",
        "description": "Optional headers to include in the request.",
        "min": null,
        "max": null
      },
      {
        "name": "auth",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Auth",
        "description": "Authentication credentials.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "url",
      "headers",
      "auth"
    ]
  },
  {
    "title": "HEAD Request",
    "description": "Retrieve headers from a resource using an HTTP HEAD request.\n    http, head, request, url\n\n    Use cases:\n    - Check resource existence\n    - Get metadata without downloading content\n    - Verify authentication or permissions",
    "namespace": "nodetool.network.http",
    "node_type": "nodetool.network.http.HeadRequest",
    "layout": "default",
    "properties": [
      {
        "name": "url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Url",
        "description": "The URL to make the request to.",
        "min": null,
        "max": null
      },
      {
        "name": "headers",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Headers",
        "description": "Optional headers to include in the request.",
        "min": null,
        "max": null
      },
      {
        "name": "auth",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Auth",
        "description": "Authentication credentials.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "url",
      "headers",
      "auth"
    ]
  },
  {
    "title": "Fetch Page",
    "description": "Fetch a web page using Selenium and return its content.\n    selenium, fetch, webpage, http\n\n    Use cases:\n    - Retrieve content from dynamic websites\n    - Capture JavaScript-rendered content\n    - Interact with web applications",
    "namespace": "nodetool.network.http",
    "node_type": "nodetool.network.http.FetchPage",
    "layout": "default",
    "properties": [
      {
        "name": "url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Url",
        "description": "The URL to fetch the page from.",
        "min": null,
        "max": null
      },
      {
        "name": "wait_time",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10,
        "title": "Wait Time",
        "description": "Maximum time to wait for page load (in seconds).",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "html",
        "stream": false
      },
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "success",
        "stream": false
      },
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "error_message",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "url",
      "wait_time"
    ]
  },
  {
    "title": "Image Downloader",
    "description": "Download images from URLs in a dataframe and return a list of ImageRefs.\n    image download, web scraping, data processing\n\n    Use cases:\n    - Prepare image datasets for machine learning tasks\n    - Archive images from web pages\n    - Process and analyze images extracted from websites",
    "namespace": "nodetool.network.http",
    "node_type": "nodetool.network.http.ImageDownloader",
    "layout": "default",
    "properties": [
      {
        "name": "images",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Images",
        "description": "Dataframe containing image URLs and alt text.",
        "min": null,
        "max": null
      },
      {
        "name": "base_url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Base Url",
        "description": "Base URL to prepend to relative image URLs.",
        "min": null,
        "max": null
      },
      {
        "name": "max_concurrent_downloads",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10,
        "title": "Max Concurrent Downloads",
        "description": "Maximum number of concurrent image downloads.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "images",
      "base_url",
      "max_concurrent_downloads"
    ]
  },
  {
    "title": "GET Binary",
    "description": "Perform an HTTP GET request and return raw binary data.\n    http, get, request, url, binary, download\n\n    Use cases:\n    - Download binary files\n    - Fetch images or media\n    - Retrieve PDF documents\n    - Download any non-text content",
    "namespace": "nodetool.network.http",
    "node_type": "nodetool.network.http.GetRequestBinary",
    "layout": "default",
    "properties": [
      {
        "name": "url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Url",
        "description": "The URL to make the request to.",
        "min": null,
        "max": null
      },
      {
        "name": "headers",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Headers",
        "description": "Optional headers to include in the request.",
        "min": null,
        "max": null
      },
      {
        "name": "auth",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Auth",
        "description": "Authentication credentials.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bytes",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "url",
      "headers",
      "auth"
    ]
  },
  {
    "title": "GET Document",
    "description": "Perform an HTTP GET request and return a document\n    http, get, request, url, document\n\n    Use cases:\n    - Download PDF documents\n    - Retrieve Word documents\n    - Fetch Excel files\n    - Download any document format",
    "namespace": "nodetool.network.http",
    "node_type": "nodetool.network.http.GetRequestDocument",
    "layout": "default",
    "properties": [
      {
        "name": "url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Url",
        "description": "The URL to make the request to.",
        "min": null,
        "max": null
      },
      {
        "name": "headers",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Headers",
        "description": "Optional headers to include in the request.",
        "min": null,
        "max": null
      },
      {
        "name": "auth",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Auth",
        "description": "Authentication credentials.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "url",
      "headers",
      "auth"
    ]
  },
  {
    "title": "POST Binary",
    "description": "Send data using an HTTP POST request and return raw binary data.\n    http, post, request, url, data, binary\n\n    Use cases:\n    - Upload and receive binary files\n    - Interact with binary APIs\n    - Process image or media uploads\n    - Handle binary file transformations",
    "namespace": "nodetool.network.http",
    "node_type": "nodetool.network.http.PostRequestBinary",
    "layout": "default",
    "properties": [
      {
        "name": "url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Url",
        "description": "The URL to make the request to.",
        "min": null,
        "max": null
      },
      {
        "name": "headers",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Headers",
        "description": "Optional headers to include in the request.",
        "min": null,
        "max": null
      },
      {
        "name": "auth",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Auth",
        "description": "Authentication credentials.",
        "min": null,
        "max": null
      },
      {
        "name": "data",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "bytes",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": "",
        "title": "Data",
        "description": "The data to send in the POST request. Can be string or binary.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bytes",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "url",
      "headers",
      "auth",
      "data"
    ]
  },
  {
    "title": "Filter Valid URLs",
    "description": "Filter a list of URLs by checking their validity using HEAD requests.\n    url validation, http, head request\n\n    Use cases:\n    - Clean URL lists by removing broken links\n    - Verify resource availability\n    - Validate website URLs before processing",
    "namespace": "nodetool.network.http",
    "node_type": "nodetool.network.http.FilterValidURLs",
    "layout": "default",
    "properties": [
      {
        "name": "url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Url",
        "description": "The URL to make the request to.",
        "min": null,
        "max": null
      },
      {
        "name": "headers",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Headers",
        "description": "Optional headers to include in the request.",
        "min": null,
        "max": null
      },
      {
        "name": "auth",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Auth",
        "description": "Authentication credentials.",
        "min": null,
        "max": null
      },
      {
        "name": "urls",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Urls",
        "description": "List of URLs to validate.",
        "min": null,
        "max": null
      },
      {
        "name": "max_concurrent_requests",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10,
        "title": "Max Concurrent Requests",
        "description": "Maximum number of concurrent HEAD requests.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "url",
      "headers",
      "auth",
      "urls",
      "max_concurrent_requests"
    ]
  },
  {
    "title": "Download Files",
    "description": "Download files from a list of URLs into a local folder.\n    download, files, urls, batch\n\n    Use cases:\n    - Batch download files from multiple URLs\n    - Create local copies of remote resources\n    - Archive web content\n    - Download datasets",
    "namespace": "nodetool.network.http",
    "node_type": "nodetool.network.http.DownloadFiles",
    "layout": "default",
    "properties": [
      {
        "name": "urls",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Urls",
        "description": "List of URLs to download.",
        "min": null,
        "max": null
      },
      {
        "name": "output_folder",
        "type": {
          "type": "file_path",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "downloads",
        "title": "Output Folder",
        "description": "Local folder path where files will be saved.",
        "min": null,
        "max": null
      },
      {
        "name": "headers",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Headers",
        "description": "Optional headers to include in the request.",
        "min": null,
        "max": null
      },
      {
        "name": "auth",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Auth",
        "description": "Authentication credentials.",
        "min": null,
        "max": null
      },
      {
        "name": "max_concurrent_downloads",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5,
        "title": "Max Concurrent Downloads",
        "description": "Maximum number of concurrent downloads.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "success",
        "stream": false
      },
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "failed",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "urls",
      "output_folder",
      "headers",
      "auth",
      "max_concurrent_downloads"
    ]
  },
  {
    "title": "POST JSON",
    "description": "Send JSON data to a server using an HTTP POST request.\n    http, post, request, url, json, api\n\n    Use cases:\n    - Send structured data to REST APIs\n    - Create resources with JSON payloads\n    - Interface with modern web services",
    "namespace": "nodetool.network.http",
    "node_type": "nodetool.network.http.JSONPostRequest",
    "layout": "default",
    "properties": [
      {
        "name": "url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Url",
        "description": "The URL to make the request to.",
        "min": null,
        "max": null
      },
      {
        "name": "headers",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Headers",
        "description": "Optional headers to include in the request.",
        "min": null,
        "max": null
      },
      {
        "name": "auth",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Auth",
        "description": "Authentication credentials.",
        "min": null,
        "max": null
      },
      {
        "name": "data",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Data",
        "description": "The JSON data to send in the POST request.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "url",
      "headers",
      "auth",
      "data"
    ]
  },
  {
    "title": "PUT JSON",
    "description": "Update resources with JSON data using an HTTP PUT request.\n    http, put, request, url, json, api\n\n    Use cases:\n    - Update existing API resources\n    - Replace complete objects in REST APIs\n    - Set configuration with JSON data",
    "namespace": "nodetool.network.http",
    "node_type": "nodetool.network.http.JSONPutRequest",
    "layout": "default",
    "properties": [
      {
        "name": "url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Url",
        "description": "The URL to make the request to.",
        "min": null,
        "max": null
      },
      {
        "name": "headers",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Headers",
        "description": "Optional headers to include in the request.",
        "min": null,
        "max": null
      },
      {
        "name": "auth",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Auth",
        "description": "Authentication credentials.",
        "min": null,
        "max": null
      },
      {
        "name": "data",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Data",
        "description": "The JSON data to send in the PUT request.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "url",
      "headers",
      "auth",
      "data"
    ]
  },
  {
    "title": "PATCH JSON",
    "description": "Partially update resources with JSON data using an HTTP PATCH request.\n    http, patch, request, url, json, api\n\n    Use cases:\n    - Partial updates to API resources\n    - Modify specific fields without full replacement\n    - Efficient updates for large objects",
    "namespace": "nodetool.network.http",
    "node_type": "nodetool.network.http.JSONPatchRequest",
    "layout": "default",
    "properties": [
      {
        "name": "url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Url",
        "description": "The URL to make the request to.",
        "min": null,
        "max": null
      },
      {
        "name": "headers",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Headers",
        "description": "Optional headers to include in the request.",
        "min": null,
        "max": null
      },
      {
        "name": "auth",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Auth",
        "description": "Authentication credentials.",
        "min": null,
        "max": null
      },
      {
        "name": "data",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Data",
        "description": "The JSON data to send in the PATCH request.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "url",
      "headers",
      "auth",
      "data"
    ]
  },
  {
    "title": "GET JSON",
    "description": "Perform an HTTP GET request and parse the response as JSON.\n    http, get, request, url, json, api\n\n    Use cases:\n    - Fetch data from REST APIs\n    - Retrieve JSON-formatted responses\n    - Interface with JSON web services",
    "namespace": "nodetool.network.http",
    "node_type": "nodetool.network.http.JSONGetRequest",
    "layout": "default",
    "properties": [
      {
        "name": "url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Url",
        "description": "The URL to make the request to.",
        "min": null,
        "max": null
      },
      {
        "name": "headers",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Headers",
        "description": "Optional headers to include in the request.",
        "min": null,
        "max": null
      },
      {
        "name": "auth",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Auth",
        "description": "Authentication credentials.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "url",
      "headers",
      "auth"
    ]
  },
  {
    "title": "Get Text ID",
    "description": "Returns the asset id.\n    index, asset, identifier",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.TextID",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text"
    ]
  },
  {
    "title": "Concatenate Text",
    "description": "Concatenates two text inputs into a single output.\n    text, concatenation, combine\n\n    Use cases:\n    - Joining outputs from multiple text processing nodes\n    - Combining parts of sentences or paragraphs\n    - Merging text data from different sources",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.Concat",
    "layout": "default",
    "properties": [
      {
        "name": "a",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "A",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "b",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "B",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "a",
      "b"
    ]
  },
  {
    "title": "Join Text",
    "description": "Joins a list of strings into a single string using a specified separator.\n    text, join, combine\n\n    Use cases:\n    - Combining multiple text elements with a consistent delimiter\n    - Creating comma-separated lists from individual items\n    - Assembling formatted text from array elements",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.Join",
    "layout": "default",
    "properties": [
      {
        "name": "strings",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Strings",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "separator",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Separator",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "strings",
      "separator"
    ]
  },
  {
    "title": "Format Text",
    "description": "Replaces placeholders in a string with provided values.\n    text, template, formatting\n\n    Use cases:\n    - Generating personalized messages with dynamic content\n    - Creating parameterized queries or commands\n    - Formatting text output based on variable inputs\n\n    Examples:\n    - text: \"Hello, {name}!\" values: {\"name\": \"Alice\"} -> \"Hello, Alice!\"\n    - text: \"Hello, {0} {1}!\" values: [\"Alice\", \"Meyer\"] -> \"Hello, Alice Meyer!\"\n    - text: \"Hello, {0}!\" values: \"Alice\" -> \"Hello, Alice!\"",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.Template",
    "layout": "default",
    "properties": [
      {
        "name": "string",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "String",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "values",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "list",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [
                {
                  "type": "str",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                },
                {
                  "type": "any",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                }
              ],
              "type_name": null
            },
            {
              "type": "object",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": {},
        "title": "Values",
        "description": "\n        The values to replace in the string.\n        - If a string, it will be used as the format string.\n        - If a list, it will be used as the format arguments.\n        - If a dictionary, it will be used as the format keyword arguments.\n        - If an object, it will be converted to a dictionary using the object's __dict__ method.\n        ",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "string",
      "values"
    ]
  },
  {
    "title": "Replace Text",
    "description": "Replaces a substring in a text with another substring.\n    text, replace, substitute\n\n    Use cases:\n    - Correcting or updating specific text patterns\n    - Sanitizing or normalizing text data\n    - Implementing simple text transformations",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.Replace",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "old",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Old",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "new",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "New",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "old",
      "new"
    ]
  },
  {
    "title": "Convert JSON to DataFrame",
    "description": "Transforms a JSON string into a pandas DataFrame.\n    json, dataframe, conversion\n\n    Use cases:\n    - Converting API responses to tabular format\n    - Preparing JSON data for analysis or visualization\n    - Structuring unstructured JSON data for further processing",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.JSONToDataframe",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "JSON",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text"
    ]
  },
  {
    "title": "Save Text",
    "description": "Saves input text to a file in the assets folder.\n    text, save, file\n\n    Use cases:\n    - Persisting processed text results\n    - Creating text files for downstream nodes or external use\n    - Archiving text data within the workflow",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.SaveText",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "folder",
        "type": {
          "type": "folder",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "folder",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Folder",
        "description": "Name of the output folder.",
        "min": null,
        "max": null
      },
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "%Y-%m-%d-%H-%M-%S.txt",
        "title": "Name",
        "description": "\n        Name of the output file.\n        You can use time and date variables to create unique names:\n        %Y - Year\n        %m - Month\n        %d - Day\n        %H - Hour\n        %M - Minute\n        %S - Second\n        ",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "text",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "folder",
      "name"
    ]
  },
  {
    "title": "Split Text",
    "description": "Separates text into a list of strings based on a specified delimiter.\n    text, split, tokenize\n\n    Use cases:\n    - Parsing CSV or similar delimited data\n    - Breaking down sentences into words or phrases\n    - Extracting specific elements from structured text",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.Split",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "delimiter",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": ",",
        "title": "Delimiter",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "delimiter"
    ]
  },
  {
    "title": "Extract Text",
    "description": "Extracts a substring from input text.\n    text, extract, substring\n\n    Use cases:\n    - Extracting specific portions of text for analysis\n    - Trimming unwanted parts from text data\n    - Focusing on relevant sections of longer documents",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.Extract",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "start",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Start",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "end",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "End",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "start",
      "end"
    ]
  },
  {
    "title": "Split Text into Chunks",
    "description": "Splits text into chunks of specified word length.\n    text, chunk, split\n\n    Use cases:\n    - Preparing text for processing by models with input length limits\n    - Creating manageable text segments for parallel processing\n    - Generating summaries of text sections",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.Chunk",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Length",
        "description": null,
        "min": 1.0,
        "max": 1000.0
      },
      {
        "name": "overlap",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Overlap",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "separator",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Separator",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "length",
      "overlap",
      "separator"
    ]
  },
  {
    "title": "Extract Regex Groups",
    "description": "Extracts substrings matching regex groups from text.\n    text, regex, extract\n\n    Use cases:\n    - Extracting structured data (e.g., dates, emails) from unstructured text\n    - Parsing specific patterns in log files or documents\n    - Isolating relevant information from complex text formats",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.ExtractRegex",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "regex",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Regex",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "dotall",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Dotall",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "ignorecase",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Ignorecase",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "multiline",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Multiline",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "regex",
      "dotall",
      "ignorecase",
      "multiline"
    ]
  },
  {
    "title": "Find All Regex Matches",
    "description": "Finds all regex matches in text as separate substrings.\n    text, regex, find\n\n    Use cases:\n    - Identifying all occurrences of a pattern in text\n    - Extracting multiple instances of structured data\n    - Analyzing frequency and distribution of specific text patterns",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.FindAllRegex",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "regex",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Regex",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "dotall",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Dotall",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "ignorecase",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Ignorecase",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "multiline",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Multiline",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "regex",
      "dotall",
      "ignorecase",
      "multiline"
    ]
  },
  {
    "title": "Parse JSON String",
    "description": "Parses a JSON string into a Python object.\n    json, parse, convert\n\n    Use cases:\n    - Converting JSON API responses for further processing\n    - Preparing structured data for analysis or storage\n    - Extracting configuration or settings from JSON files",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.ParseJSON",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "JSON string",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text"
    ]
  },
  {
    "title": "Extract JSON",
    "description": "Extracts data from JSON using JSONPath expressions.\n    json, extract, jsonpath\n\n    Use cases:\n    - Retrieving specific fields from complex JSON structures\n    - Filtering and transforming JSON data for analysis\n    - Extracting nested data from API responses or configurations",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.ExtractJSON",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "JSON Text",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "json_path",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "$.*",
        "title": "JSONPath Expression",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "find_all",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Find All",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "json_path",
      "find_all"
    ]
  },
  {
    "title": "Split Sentences",
    "description": "Splits text into chunks of a minimum length.\n    text, split, sentences\n\n    Use cases:\n    - Splitting text into manageable chunks for processing\n    - Creating traceable units for analysis or storage\n    - Preparing text for language model processing",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.SentenceSplitter",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "min_length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10,
        "title": "Minimum Length",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "source_id",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Source ID",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "chunk_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1000,
        "title": "Chunk Size",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "chunk_overlap",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 200,
        "title": "Chunk Overlap",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "text_chunk",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "min_length",
      "source_id",
      "chunk_size",
      "chunk_overlap"
    ]
  },
  {
    "title": "Find Regex Matches",
    "description": "Find all matches of a regex pattern in text.\n    regex, search, pattern, match\n\n    Use cases:\n    - Extract specific patterns from text\n    - Validate text against patterns\n    - Find all occurrences of a pattern",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.RegexMatch",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "Text to search in",
        "min": null,
        "max": null
      },
      {
        "name": "pattern",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Pattern",
        "description": "Regular expression pattern",
        "min": null,
        "max": null
      },
      {
        "name": "group",
        "type": {
          "type": "int",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Group",
        "description": "Capture group to extract (0 for full match)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "pattern",
      "group"
    ]
  },
  {
    "title": "Replace with Regex",
    "description": "Replace text matching a regex pattern.\n    regex, replace, substitute\n\n    Use cases:\n    - Clean or standardize text\n    - Remove unwanted patterns\n    - Transform text formats",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.RegexReplace",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "Text to perform replacements on",
        "min": null,
        "max": null
      },
      {
        "name": "pattern",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Pattern",
        "description": "Regular expression pattern",
        "min": null,
        "max": null
      },
      {
        "name": "replacement",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Replacement",
        "description": "Replacement text",
        "min": null,
        "max": null
      },
      {
        "name": "count",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Count",
        "description": "Maximum replacements (0 for unlimited)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "pattern",
      "replacement",
      "count"
    ]
  },
  {
    "title": "Split with Regex",
    "description": "Split text using a regex pattern as delimiter.\n    regex, split, tokenize\n\n    Use cases:\n    - Parse structured text\n    - Extract fields from formatted strings\n    - Tokenize text",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.RegexSplit",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "Text to split",
        "min": null,
        "max": null
      },
      {
        "name": "pattern",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Pattern",
        "description": "Regular expression pattern to split on",
        "min": null,
        "max": null
      },
      {
        "name": "maxsplit",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Maxsplit",
        "description": "Maximum number of splits (0 for unlimited)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "pattern",
      "maxsplit"
    ]
  },
  {
    "title": "Validate with Regex",
    "description": "Check if text matches a regex pattern.\n    regex, validate, check\n\n    Use cases:\n    - Validate input formats (email, phone, etc)\n    - Check text structure\n    - Filter text based on patterns",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.RegexValidate",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "Text to validate",
        "min": null,
        "max": null
      },
      {
        "name": "pattern",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Pattern",
        "description": "Regular expression pattern",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "pattern"
    ]
  },
  {
    "title": "Convert HTML to Text",
    "description": "Converts HTML to plain text by removing tags and decoding entities using BeautifulSoup.\n    html, text, convert\n\n    Use cases:\n    - Cleaning HTML content for text analysis\n    - Extracting readable content from web pages\n    - Preparing HTML data for natural language processing",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.HTMLToText",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "HTML",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "preserve_linebreaks",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Preserve Line Breaks",
        "description": "Convert block-level elements to newlines",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "preserve_linebreaks"
    ]
  },
  {
    "title": "Slice Text",
    "description": "Slices text using Python's slice notation (start:stop:step).\n    text, slice, substring\n\n    Use cases:\n    - Extracting specific portions of text with flexible indexing\n    - Reversing text using negative step\n    - Taking every nth character with step parameter\n\n    Examples:\n    - start=0, stop=5: first 5 characters\n    - start=-5: last 5 characters\n    - step=2: every second character\n    - step=-1: reverse the text",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.Slice",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "start",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Start Index",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "stop",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Stop Index",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "step",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Step",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "start",
      "stop",
      "step"
    ]
  },
  {
    "title": "Split Recursively",
    "description": "Splits text recursively using LangChain's RecursiveCharacterTextSplitter.\n    text, split, chunks\n\n    Use cases:\n    - Splitting documents while preserving semantic relationships\n    - Creating chunks for language model processing\n    - Handling text in languages with/without word boundaries",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.RecursiveTextSplitter",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "source_id",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Document ID",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "chunk_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1000,
        "title": "Chunk Size",
        "description": "Maximum size of each chunk in characters",
        "min": null,
        "max": null
      },
      {
        "name": "chunk_overlap",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 200,
        "title": "Chunk Overlap",
        "description": "Number of characters to overlap between chunks",
        "min": null,
        "max": null
      },
      {
        "name": "separators",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [
          "\n\n",
          "\n",
          "."
        ],
        "title": "Separators",
        "description": "List of separators to use for splitting, in order of preference",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "text_chunk",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "source_id",
      "chunk_size",
      "chunk_overlap",
      "separators"
    ]
  },
  {
    "title": "Split Markdown",
    "description": "Splits markdown text by headers while preserving header hierarchy in metadata.\n    markdown, split, headers\n\n    Use cases:\n    - Splitting markdown documentation while preserving structure\n    - Processing markdown files for semantic search\n    - Creating context-aware chunks from markdown content",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.MarkdownSplitter",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Markdown Text",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "source_id",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Document ID",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "headers_to_split_on",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "tuple",
              "optional": false,
              "values": null,
              "type_args": [
                {
                  "type": "str",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                },
                {
                  "type": "str",
                  "optional": false,
                  "values": null,
                  "type_args": [],
                  "type_name": null
                }
              ],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [
          [
            "#",
            "Header 1"
          ],
          [
            "##",
            "Header 2"
          ],
          [
            "###",
            "Header 3"
          ]
        ],
        "title": "Headers To Split On",
        "description": "List of tuples containing (header_symbol, header_name)",
        "min": null,
        "max": null
      },
      {
        "name": "strip_headers",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Strip Headers",
        "description": "Whether to remove headers from the output content",
        "min": null,
        "max": null
      },
      {
        "name": "return_each_line",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Return Each Line",
        "description": "Whether to split into individual lines instead of header sections",
        "min": null,
        "max": null
      },
      {
        "name": "chunk_size",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Chunk Size",
        "description": "Optional maximum chunk size for further splitting",
        "min": null,
        "max": null
      },
      {
        "name": "chunk_overlap",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Chunk Overlap",
        "description": "Overlap size when using chunk_size",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "text_chunk",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "source_id",
      "headers_to_split_on",
      "strip_headers",
      "return_each_line",
      "chunk_size",
      "chunk_overlap"
    ]
  },
  {
    "title": "Starts With",
    "description": "Checks if text starts with a specified prefix.\n    text, check, prefix, compare, validate, substring, string\n\n    Use cases:\n    - Validating string prefixes\n    - Filtering text based on starting content\n    - Checking file name patterns",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.StartsWith",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "prefix",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prefix",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "prefix"
    ]
  },
  {
    "title": "Ends With",
    "description": "Checks if text ends with a specified suffix.\n    text, check, suffix, compare, validate, substring, string\n\n    Use cases:\n    - Validating file extensions\n    - Checking string endings\n    - Filtering text based on ending content",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.EndsWith",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "suffix",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Suffix",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "suffix"
    ]
  },
  {
    "title": "Contains Text",
    "description": "Checks if text contains a specified substring.\n    text, check, contains, compare, validate, substring, string\n\n    Use cases:\n    - Searching for keywords in text\n    - Filtering content based on presence of terms\n    - Validating text content",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.Contains",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "substring",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Substring",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "case_sensitive",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Case Sensitive",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "substring",
      "case_sensitive"
    ]
  },
  {
    "title": "Is Empty",
    "description": "Checks if text is empty or contains only whitespace.\n    text, check, empty, compare, validate, whitespace, string\n\n    Use cases:\n    - Validating required text fields\n    - Filtering out empty content\n    - Checking for meaningful input",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.IsEmpty",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "trim_whitespace",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Trim Whitespace",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "trim_whitespace"
    ]
  },
  {
    "title": "Check Length",
    "description": "Checks if text length meets specified conditions.\n    text, check, length, compare, validate, whitespace, string\n\n    Use cases:\n    - Validating input length requirements\n    - Filtering text by length\n    - Checking content size constraints",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.HasLength",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "min_length",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Minimum Length",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "max_length",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Maximum Length",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "exact_length",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Exact Length",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "min_length",
      "max_length",
      "exact_length"
    ]
  },
  {
    "title": "Count Tokens",
    "description": "Counts the number of tokens in text using tiktoken.\n    text, tokens, count, encoding\n\n    Use cases:\n    - Checking text length for LLM input limits\n    - Estimating API costs\n    - Managing token budgets in text processing",
    "namespace": "nodetool.text",
    "node_type": "nodetool.text.CountTokens",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "encoding",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "cl100k_base",
            "p50k_base",
            "r50k_base"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.text.TiktokenEncoding"
        },
        "default": "cl100k_base",
        "title": "Encoding",
        "description": "The tiktoken encoding to use for token counting",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "encoding"
    ]
  },
  {
    "title": "Email Fields",
    "description": "Decomposes an email into its individual components.\n    email, decompose, extract\n\n    Takes an Email object and returns its individual fields:\n    - id: Message ID\n    - subject: Email subject\n    - sender: Sender address\n    - date: Datetime of email\n    - body: Email body content",
    "namespace": "nodetool.network.imap",
    "node_type": "nodetool.network.imap.EmailFields",
    "layout": "default",
    "properties": [
      {
        "name": "email",
        "type": {
          "type": "email",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Email",
        "description": "Email object to decompose",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "id",
        "stream": false
      },
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "subject",
        "stream": false
      },
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "sender",
        "stream": false
      },
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "date",
        "stream": false
      },
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "body",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "email"
    ]
  },
  {
    "title": "Configure IMAP",
    "description": "Creates an IMAP configuration for email operations.\n    email, imap, config\n\n    Use cases:\n    - Set up email access credentials\n    - Enable programmatic email access",
    "namespace": "nodetool.network.imap",
    "node_type": "nodetool.network.imap.ConfigureIMAP",
    "layout": "default",
    "properties": [
      {
        "name": "host",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Host",
        "description": "IMAP server hostname (e.g. imap.gmail.com)",
        "min": null,
        "max": null
      },
      {
        "name": "port",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 993,
        "title": "Port",
        "description": "IMAP server port",
        "min": null,
        "max": null
      },
      {
        "name": "username",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Username",
        "description": "Email account username",
        "min": null,
        "max": null
      },
      {
        "name": "password",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Password",
        "description": "Email account password",
        "min": null,
        "max": null
      },
      {
        "name": "use_ssl",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Use Ssl",
        "description": "Whether to use SSL/TLS connection",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "imap_connection",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "host",
      "port",
      "username",
      "password",
      "use_ssl"
    ]
  },
  {
    "title": "IMAPSearch",
    "description": "Searches IMAP using IMAP-specific search operators.\n    email, imap, search\n\n    Returns emails with following fields:\n    - id: Message ID\n    - subject: Email subject\n    - from: Sender address\n    - date: Datetime of email\n    - body: Email body content\n\n    Use cases:\n    - Search for emails based on specific criteria\n    - Retrieve emails from a specific sender\n    - Filter emails by subject, sender, or date",
    "namespace": "nodetool.network.imap",
    "node_type": "nodetool.network.imap.IMAPSearch",
    "layout": "default",
    "properties": [
      {
        "name": "connection",
        "type": {
          "type": "imap_connection",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "imap_connection",
          "host": "",
          "port": 993,
          "username": "",
          "password": "",
          "use_ssl": true
        },
        "title": "Connection",
        "description": "IMAP connection details",
        "min": null,
        "max": null
      },
      {
        "name": "search_criteria",
        "type": {
          "type": "email_search_criteria",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "email_search_criteria",
          "from_address": null,
          "to_address": null,
          "subject": null,
          "body": null,
          "cc": null,
          "bcc": null,
          "date_condition": null,
          "flags": [],
          "keywords": [],
          "folder": null,
          "text": null
        },
        "title": "Search Criteria",
        "description": "Search criteria",
        "min": null,
        "max": null
      },
      {
        "name": "max_results",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Max Results",
        "description": "Maximum number of emails to return",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "email",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "connection",
      "search_criteria",
      "max_results"
    ]
  },
  {
    "title": "Fetch RSS Feed",
    "description": "Fetches and parses an RSS feed from a URL.\n    rss, feed, network\n    \n    Use cases:\n    - Monitor news feeds\n    - Aggregate content from multiple sources\n    - Process blog updates",
    "namespace": "nodetool.network.rss",
    "node_type": "nodetool.network.rss.FetchRSSFeed",
    "layout": "default",
    "properties": [
      {
        "name": "url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Url",
        "description": "URL of the RSS feed to fetch",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "rss_entry",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "url"
    ]
  },
  {
    "title": "Extract RSS Entry Fields",
    "description": "Extracts fields from an RSS entry.\n    rss, entry, fields",
    "namespace": "nodetool.network.rss",
    "node_type": "nodetool.network.rss.RSSEntryFields",
    "layout": "default",
    "properties": [
      {
        "name": "entry",
        "type": {
          "type": "rss_entry",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "rss_entry",
          "title": "",
          "link": "",
          "published": {
            "type": "datetime",
            "year": 0,
            "month": 0,
            "day": 0,
            "hour": 0,
            "minute": 0,
            "second": 0,
            "microsecond": 0,
            "tzinfo": "UTC",
            "utc_offset": 0
          },
          "summary": "",
          "author": ""
        },
        "title": "Entry",
        "description": "The RSS entry to extract fields from.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "title",
        "stream": false
      },
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "link",
        "stream": false
      },
      {
        "type": {
          "type": "datetime",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "published",
        "stream": false
      },
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "summary",
        "stream": false
      },
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "author",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "entry"
    ]
  },
  {
    "title": "Extract Feed Metadata",
    "description": "Extracts metadata from an RSS feed.\n    rss, metadata, feed\n    \n    Use cases:\n    - Get feed information\n    - Validate feed details\n    - Extract feed metadata",
    "namespace": "nodetool.network.rss",
    "node_type": "nodetool.network.rss.ExtractFeedMetadata",
    "layout": "default",
    "properties": [
      {
        "name": "url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Url",
        "description": "URL of the RSS feed",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "url"
    ]
  },
  {
    "title": "Get Environment Variable",
    "description": "Gets an environment variable value.\n    environment, variable, system\n\n    Use cases:\n    - Access configuration\n    - Get system settings",
    "namespace": "nodetool.os",
    "node_type": "nodetool.os.GetEnvironmentVariable",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "Environment variable name",
        "min": null,
        "max": null
      },
      {
        "name": "default",
        "type": {
          "type": "str",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Default",
        "description": "Default value if not found",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name",
      "default"
    ]
  },
  {
    "title": "Set Environment Variable",
    "description": "Sets an environment variable.\n    environment, variable, system\n\n    Use cases:\n    - Configure runtime settings\n    - Set up process environment",
    "namespace": "nodetool.os",
    "node_type": "nodetool.os.SetEnvironmentVariable",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "Environment variable name",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Value",
        "description": "Environment variable value",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name",
      "value"
    ]
  },
  {
    "title": "Get System Info",
    "description": "Gets system information.\n    system, info, platform\n\n    Use cases:\n    - Check system compatibility\n    - Platform-specific logic",
    "namespace": "nodetool.os",
    "node_type": "nodetool.os.GetSystemInfo",
    "layout": "default",
    "properties": [],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": []
  },
  {
    "title": "Copy Text To Clipboard",
    "description": "Copies text to system clipboard.\n    clipboard, system, copy\n\n    Use cases:\n    - Copy text to clipboard\n    - Save output for external use",
    "namespace": "nodetool.os",
    "node_type": "nodetool.os.CopyTextToClipboard",
    "layout": "default",
    "properties": [
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "Text to copy to clipboard",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text"
    ]
  },
  {
    "title": "Paste Text From Clipboard",
    "description": "Pastes text from system clipboard.\n    clipboard, system, paste\n\n    Use cases:\n    - Read clipboard content\n    - Import external data",
    "namespace": "nodetool.os",
    "node_type": "nodetool.os.PasteTextFromClipboard",
    "layout": "default",
    "properties": [],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": []
  },
  {
    "title": "Copy Image To Clipboard",
    "description": "Copies an image to system clipboard.\n    clipboard, system, copy, image\n\n    Use cases:\n    - Copy images to clipboard\n    - Share screenshots or processed images",
    "namespace": "nodetool.os",
    "node_type": "nodetool.os.CopyImageToClipboard",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Image",
        "description": "Image to copy to clipboard",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "List Output",
    "description": "Output node for a list of arbitrary values.\n    list, output, any\n\n    Use cases:\n    - Returning multiple results from a workflow\n    - Aggregating outputs from multiple nodes",
    "namespace": "nodetool.output",
    "node_type": "nodetool.output.ListOutput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this output node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Image List Output",
    "description": "Output node for a list of image references.\n    images, list, gallery\n\n    Use cases:\n    - Displaying multiple images in a grid\n    - Returning image search results",
    "namespace": "nodetool.output",
    "node_type": "nodetool.output.ImageListOutput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this output node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Value",
        "description": "The images to display.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Integer Output",
    "description": "Output node for a single integer value.\n    integer, number, count\n\n    Use cases:\n    - Returning numeric results (e.g. counts, indices)\n    - Passing integer parameters between nodes\n    - Displaying numeric metrics",
    "namespace": "nodetool.output",
    "node_type": "nodetool.output.IntegerOutput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this output node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Float Output",
    "description": "Output node for a single float value.\n    float, decimal, number\n\n    Use cases:\n    - Returning decimal results (e.g. percentages, ratios)\n    - Passing floating-point parameters between nodes\n    - Displaying numeric metrics with decimal precision",
    "namespace": "nodetool.output",
    "node_type": "nodetool.output.FloatOutput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this output node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Boolean Output",
    "description": "Output node for a single boolean value.\n    boolean, true/false, flag\n\n    Use cases:\n    - Returning binary results (yes/no, true/false)\n    - Controlling conditional logic in workflows\n    - Indicating success/failure of operations",
    "namespace": "nodetool.output",
    "node_type": "nodetool.output.BooleanOutput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this output node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "String Output",
    "description": "Output node for a single string value.\n    string, text, output\n\n    Use cases:\n    - Returning text results or messages\n    - Passing string parameters between nodes\n    - Displaying short text outputs",
    "namespace": "nodetool.output",
    "node_type": "nodetool.output.StringOutput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this output node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Text Output",
    "description": "Output node for structured text content.\n    text, content, document\n\n    Use cases:\n    - Returning longer text content or documents\n    - Passing formatted text between processing steps\n    - Displaying rich text output",
    "namespace": "nodetool.output",
    "node_type": "nodetool.output.TextOutput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this output node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "text",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "text",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "text",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Image Output",
    "description": "Output node for a single image reference.\n    image, picture, visual\n\n    Use cases:\n    - Displaying a single processed or generated image\n    - Passing image data between workflow nodes\n    - Returning image analysis results",
    "namespace": "nodetool.output",
    "node_type": "nodetool.output.ImageOutput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this output node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Video Output",
    "description": "Output node for video content references.\n    video, media, clip\n\n    Use cases:\n    - Displaying processed or generated video content\n    - Passing video data between workflow steps\n    - Returning results of video analysis",
    "namespace": "nodetool.output",
    "node_type": "nodetool.output.VideoOutput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this output node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Tensor Output",
    "description": "Output node for generic tensor data.\n    tensor, array, numerical\n\n    Use cases:\n    - Passing multi-dimensional data between nodes\n    - Outputting results from machine learning models\n    - Representing complex numerical data structures",
    "namespace": "nodetool.output",
    "node_type": "nodetool.output.TensorOutput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this output node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Model Output",
    "description": "Output node for machine learning model references.\n    model, ml, ai\n\n    Use cases:\n    - Passing trained models between workflow steps\n    - Outputting newly created or fine-tuned models\n    - Referencing models for later use in the workflow",
    "namespace": "nodetool.output",
    "node_type": "nodetool.output.ModelOutput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this output node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "model_ref",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "model_ref",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "model_ref",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Audio Output",
    "description": "Output node for audio content references.\n    audio, sound, media\n\n    Use cases:\n    - Displaying processed or generated audio\n    - Passing audio data between workflow nodes\n    - Returning results of audio analysis",
    "namespace": "nodetool.output",
    "node_type": "nodetool.output.AudioOutput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this output node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Dataframe Output",
    "description": "Output node for structured data references.\n    dataframe, table, structured\n\n    Use cases:\n    - Outputting tabular data results\n    - Passing structured data between analysis steps\n    - Displaying data in table format",
    "namespace": "nodetool.output",
    "node_type": "nodetool.output.DataframeOutput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this output node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Dictionary Output",
    "description": "Output node for key-value pair data.\n    dictionary, key-value, mapping\n\n    Use cases:\n    - Returning multiple named values\n    - Passing complex data structures between nodes\n    - Organizing heterogeneous output data",
    "namespace": "nodetool.output",
    "node_type": "nodetool.output.DictionaryOutput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this output node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": {},
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Group Output",
    "description": "Generic output node for grouped data from any node.\n    group, composite, multi-output\n\n    Use cases:\n    - Aggregating multiple outputs from a single node\n    - Passing varied data types as a single unit\n    - Organizing related outputs in workflows",
    "namespace": "nodetool.output",
    "node_type": "nodetool.output.GroupOutput",
    "layout": "default",
    "properties": [
      {
        "name": "input",
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Input",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input"
    ]
  },
  {
    "title": "Document Output",
    "description": "Output node for document content references.\n    document, pdf, file\n\n    Use cases:\n    - Displaying processed or generated documents\n    - Passing document data between workflow nodes\n    - Returning results of document analysis",
    "namespace": "nodetool.output",
    "node_type": "nodetool.output.DocumentOutput",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Name",
        "description": "The parameter name for the workflow.",
        "min": null,
        "max": null
      },
      {
        "name": "description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Description",
        "description": "The description for this output node.",
        "min": null,
        "max": null
      },
      {
        "name": "value",
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "document",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "document",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "name"
    ]
  },
  {
    "title": "Save Tensor",
    "description": "Save a tensor to a file in the specified folder.\n    tensor, save, file, storage\n\n    Use cases:\n    - Persist tensor data for later use\n    - Export tensor results from a workflow\n    - Save intermediate tensor outputs for debugging",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.SaveTensor",
    "layout": "default",
    "properties": [
      {
        "name": "tensor",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Tensor",
        "description": "The tensor to save.",
        "min": null,
        "max": null
      },
      {
        "name": "folder",
        "type": {
          "type": "folder",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "folder",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Folder",
        "description": "The folder to save the tensor in.",
        "min": null,
        "max": null
      },
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "%Y-%m-%d_%H-%M-%S.npy",
        "title": "Name",
        "description": "\n        The name of the asset to save.\n        You can use time and date variables to create unique names:\n        %Y - Year\n        %m - Month\n        %d - Day\n        %H - Hour\n        %M - Minute\n        %S - Second\n        ",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensor",
      "folder",
      "name"
    ]
  },
  {
    "title": "Convert To Image",
    "description": "Convert tensor data to PIL Image format.\n    tensor, image, conversion, denormalization\n\n    Use cases:\n    - Visualize tensor data as images\n    - Save processed tensor results as images\n    - Convert model outputs back to viewable format",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.ConvertToImage",
    "layout": "default",
    "properties": [
      {
        "name": "tensor",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Tensor",
        "description": "The input tensor to convert to an image. Should have either 1, 3, or 4 channels.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensor"
    ]
  },
  {
    "title": "Convert To Audio",
    "description": "Converts a tensor object back to an audio file.\n    audio, conversion, tensor\n\n    Use cases:\n    - Save processed audio data as a playable file\n    - Convert generated or modified audio tensors to audio format\n    - Output results of audio processing pipelinesr",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.ConvertToAudio",
    "layout": "default",
    "properties": [
      {
        "name": "tensor",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Tensor",
        "description": "The tensor to convert to an audio file.",
        "min": null,
        "max": null
      },
      {
        "name": "sample_rate",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 44100,
        "title": "Sample Rate",
        "description": "The sample rate of the audio file.",
        "min": 0.0,
        "max": 44100.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensor",
      "sample_rate"
    ]
  },
  {
    "title": "Stack",
    "description": "Stack multiple tensors along a specified axis.\n    tensor, stack, concatenate, join, merge, axis\n\n    Use cases:\n    - Combine multiple 2D tensors into a 3D tensor\n    - Stack time series data from multiple sources\n    - Merge feature vectors for machine learning models",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.Stack",
    "layout": "default",
    "properties": [
      {
        "name": "tensors",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Tensors",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "axis",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Axis",
        "description": "The axis to stack along.",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensors",
      "axis"
    ]
  },
  {
    "title": "Mat Mul",
    "description": "Perform matrix multiplication on two input tensors.\n    tensor, matrix, multiplication, linear algebra\n\n    Use cases:\n    - Implement linear transformations\n    - Calculate dot products of vectors\n    - Perform matrix operations in neural networks",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.MatMul",
    "layout": "small",
    "properties": [
      {
        "name": "a",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "A",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "b",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "B",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "a",
      "b"
    ]
  },
  {
    "title": "Transpose",
    "description": "Transpose the dimensions of the input tensor.\n    tensor, transpose, reshape, dimensions\n\n    Use cases:\n    - Convert row vectors to column vectors\n    - Rearrange data for compatibility with other operations\n    - Implement certain linear algebra operations",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.Transpose",
    "layout": "small",
    "properties": [
      {
        "name": "tensor",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Tensor",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensor"
    ]
  },
  {
    "title": "Max",
    "description": "Compute the maximum value along a specified axis of a tensor.\n    tensor, maximum, reduction, statistics\n\n    Use cases:\n    - Find peak values in time series data\n    - Implement max pooling in neural networks\n    - Determine highest scores across multiple categories",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.Max",
    "layout": "default",
    "properties": [
      {
        "name": "tensor",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Tensor",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "axis",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Axis",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensor",
      "axis"
    ]
  },
  {
    "title": "Min",
    "description": "Calculate the minimum value along a specified axis of a tensor.\n    tensor, minimum, reduction, statistics\n\n    Use cases:\n    - Find lowest values in datasets\n    - Implement min pooling in neural networks\n    - Determine minimum thresholds across categories",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.Min",
    "layout": "default",
    "properties": [
      {
        "name": "tensor",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Tensor",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "axis",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Axis",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensor",
      "axis"
    ]
  },
  {
    "title": "Mean",
    "description": "Compute the mean value along a specified axis of a tensor.\n    tensor, average, reduction, statistics\n\n    Use cases:\n    - Calculate average values in datasets\n    - Implement mean pooling in neural networks\n    - Compute centroids in clustering algorithms",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.Mean",
    "layout": "default",
    "properties": [
      {
        "name": "tensor",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Tensor",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "axis",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Axis",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensor",
      "axis"
    ]
  },
  {
    "title": "Sum",
    "description": "Calculate the sum of values along a specified axis of a tensor.\n    tensor, summation, reduction, statistics\n\n    Use cases:\n    - Compute total values across categories\n    - Implement sum pooling in neural networks\n    - Calculate cumulative metrics in time series data",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.Sum",
    "layout": "default",
    "properties": [
      {
        "name": "tensor",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Tensor",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "axis",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Axis",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensor",
      "axis"
    ]
  },
  {
    "title": "Arg Max",
    "description": "Find indices of maximum values along a specified axis of a tensor.\n    tensor, argmax, index, maximum\n\n    Use cases:\n    - Determine winning classes in classification tasks\n    - Find peaks in signal processing\n    - Locate best-performing items in datasets",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.ArgMax",
    "layout": "default",
    "properties": [
      {
        "name": "a",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "A",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "axis",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Axis",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "a",
      "axis"
    ]
  },
  {
    "title": "Arg Min",
    "description": "Find indices of minimum values along a specified axis of a tensor.\n    tensor, argmin, index, minimum\n\n    Use cases:\n    - Locate lowest-performing items in datasets\n    - Find troughs in signal processing\n    - Determine least likely classes in classification tasks",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.ArgMin",
    "layout": "default",
    "properties": [
      {
        "name": "tensor",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Tensor",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "axis",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Axis",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensor",
      "axis"
    ]
  },
  {
    "title": "Abs",
    "description": "Compute the absolute value of each element in a tensor.\n    tensor, absolute, magnitude\n\n    Use cases:\n    - Calculate magnitudes of complex numbers\n    - Preprocess data for certain algorithms\n    - Implement activation functions in neural networks",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.Abs",
    "layout": "default",
    "properties": [
      {
        "name": "input_tensor",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Input Tensor",
        "description": "The input tensor to compute the absolute values from.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input_tensor"
    ]
  },
  {
    "title": "Tensor To Scalar",
    "description": "Convert a single-element tensor to a scalar value.\n    tensor, scalar, conversion, type\n\n    Use cases:\n    - Extract final results from tensor computations\n    - Prepare values for non-tensor operations\n    - Simplify output for human-readable results",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.TensorToScalar",
    "layout": "default",
    "properties": [
      {
        "name": "tensor",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Tensor",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensor"
    ]
  },
  {
    "title": "Scalar To Tensor",
    "description": "Convert a scalar value to a single-element tensor.\n    scalar, tensor, conversion, type\n\n    Use cases:\n    - Prepare scalar inputs for tensor operations\n    - Create constant tensors for computations\n    - Initialize tensor values in workflows",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.ScalarToTensor",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 0,
        "title": "Value",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value"
    ]
  },
  {
    "title": "List To Tensor",
    "description": "Convert a list of values to a tensor.\n    list, tensor, conversion, type\n\n    Use cases:\n    - Prepare list data for tensor operations\n    - Create tensors from Python data structures\n    - Convert sequence data to tensor format",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.ListToTensor",
    "layout": "default",
    "properties": [
      {
        "name": "values",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Values",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "values"
    ]
  },
  {
    "title": "Plot Tensor",
    "description": "Create a plot visualization of tensor data.\n    tensor, plot, visualization, graph\n\n    Use cases:\n    - Visualize trends in tensor data\n    - Create charts for reports or dashboards\n    - Debug tensor outputs in workflows",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.PlotTensor",
    "layout": "default",
    "properties": [
      {
        "name": "tensor",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Tensor",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "plot_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "line",
            "bar",
            "scatter"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.tensor.PlotType"
        },
        "default": "line",
        "title": "Plot Type",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensor",
      "plot_type"
    ]
  },
  {
    "title": "Plot TSNE",
    "description": "Create a t-SNE plot for high-dimensional tensor data.\n    tensor, tsne, visualization, dimensionality reduction\n\n    Use cases:\n    - Visualize clusters in high-dimensional data\n    - Explore relationships in complex datasets\n    - Reduce dimensionality for data analysis",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.PlotTSNE",
    "layout": "default",
    "properties": [
      {
        "name": "tensor",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Tensor",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "color_indices",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Color Indices",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "perplexity",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Perplexity",
        "description": null,
        "min": 1.0,
        "max": 50.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensor",
      "color_indices",
      "perplexity"
    ]
  },
  {
    "title": "Tensor To List",
    "description": "Convert a tensor to a nested list structure.\n    tensor, list, conversion, type\n\n    Use cases:\n    - Prepare tensor data for JSON serialization\n    - Convert tensor outputs to Python data structures\n    - Interface tensor data with non-tensor operations",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.TensorToList",
    "layout": "default",
    "properties": [
      {
        "name": "tensor",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Tensor",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tensor"
    ]
  },
  {
    "title": "Exp",
    "description": "Calculate the exponential of each element in a tensor.\n    tensor, exponential, math, activation\n\n    Use cases:\n    - Implement exponential activation functions\n    - Calculate growth rates in scientific models\n    - Transform data for certain statistical analyses",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.Exp",
    "layout": "default",
    "properties": [
      {
        "name": "x",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 1.0,
        "title": "Input",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "x"
    ]
  },
  {
    "title": "Log",
    "description": "Calculate the natural logarithm of each element in a tensor.\n    tensor, logarithm, math, transformation\n\n    Use cases:\n    - Implement log transformations on data\n    - Calculate entropy in information theory\n    - Normalize data with large ranges",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.Log",
    "layout": "default",
    "properties": [
      {
        "name": "x",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": 1.0,
        "title": "Input",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "x"
    ]
  },
  {
    "title": "Nearest Neighbors",
    "description": "Stores input embeddings in a database and retrieves the nearest neighbors for a query embedding.\n    tensor, embeddings, nearest neighbors, search, similarity",
    "namespace": "nodetool.tensor",
    "node_type": "nodetool.tensor.NearestNeighbors",
    "layout": "default",
    "properties": [
      {
        "name": "documents",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "tensor",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Documents",
        "description": "The list of documents to search",
        "min": null,
        "max": null
      },
      {
        "name": "query",
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "tensor",
          "value": [],
          "dtype": null
        },
        "title": "Query",
        "description": "The query to search for",
        "min": null,
        "max": null
      },
      {
        "name": "n_neighbors",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "N Neighbors",
        "description": "The number of neighbors to return",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "distances",
        "stream": false
      },
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "indices",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "documents",
      "query",
      "n_neighbors"
    ]
  },
  {
    "title": "Display Text",
    "description": "Display text in a scrollable window.\n    gui, text, display\n\n    Use cases:\n    - Show processing results\n    - Display log messages\n    - Preview text content",
    "namespace": "nodetool.ui.tk",
    "node_type": "nodetool.ui.tk.DisplayText",
    "layout": "default",
    "properties": [
      {
        "name": "title",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Display Window",
        "title": "Title",
        "description": "Window title",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 400,
        "title": "Width",
        "description": "Window width",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 300,
        "title": "Height",
        "description": "Window height",
        "min": null,
        "max": null
      },
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "Text content to display",
        "min": null,
        "max": null
      },
      {
        "name": "font",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Arial 12",
        "title": "Font",
        "description": "Text font and size",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "title",
      "width",
      "height",
      "text",
      "font"
    ]
  },
  {
    "title": "Display Image",
    "description": "Display an image in a window.\n    gui, image, display\n\n    Use cases:\n    - Preview image processing results\n    - Show generated images\n    - Display image transformations",
    "namespace": "nodetool.ui.tk",
    "node_type": "nodetool.ui.tk.DisplayImage",
    "layout": "default",
    "properties": [
      {
        "name": "title",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Display Window",
        "title": "Title",
        "description": "Window title",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 400,
        "title": "Width",
        "description": "Window width",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 300,
        "title": "Height",
        "description": "Window height",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Image",
        "description": "Image to display",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "title",
      "width",
      "height",
      "image"
    ]
  },
  {
    "title": "Save Video",
    "description": "Save a video to a file.\n    video, save, file, output\n\n    Use cases:\n    1. Export processed video to a specific folder\n    2. Save video with a custom name\n    3. Create a copy of a video in a different location",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.SaveVideo",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "The video to save.",
        "min": null,
        "max": null
      },
      {
        "name": "folder",
        "type": {
          "type": "folder",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "folder",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Folder",
        "description": "Name of the output folder.",
        "min": null,
        "max": null
      },
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "%Y-%m-%d-%H-%M-%S.mp4",
        "title": "Name",
        "description": "\n        Name of the output video.\n        You can use time and date variables to create unique names:\n        %Y - Year\n        %m - Month\n        %d - Day\n        %H - Hour\n        %M - Minute\n        %S - Second\n        ",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video",
      "folder",
      "name"
    ]
  },
  {
    "title": "Extract Frames",
    "description": "Extract frames from a video file using OpenCV.\n    video, frames, extract, sequence\n\n    Use cases:\n    1. Generate image sequences for further processing\n    2. Extract specific frame ranges from a video\n    3. Create thumbnails or previews from video content",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.ExtractFrames",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "The input video to extract frames from.",
        "min": null,
        "max": null
      },
      {
        "name": "start",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Start",
        "description": "The frame to start extracting from.",
        "min": null,
        "max": null
      },
      {
        "name": "end",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "End",
        "description": "The frame to stop extracting from.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video",
      "start",
      "end"
    ]
  },
  {
    "title": "Fps",
    "description": "Get the frames per second (FPS) of a video file.\n    video, analysis, frames, fps\n\n    Use cases:\n    1. Analyze video properties for quality assessment\n    2. Determine appropriate playback speed for video editing\n    3. Ensure compatibility with target display systems",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.Fps",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "The input video to adjust the brightness for.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video"
    ]
  },
  {
    "title": "Create Video",
    "description": "Combine a sequence of frames into a single video file.\n    video, frames, combine, sequence\n\n    Use cases:\n    1. Create time-lapse videos from image sequences\n    2. Compile processed frames back into a video\n    3. Generate animations from individual images",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.CreateVideo",
    "layout": "default",
    "properties": [
      {
        "name": "frames",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Frames",
        "description": "The frames to combine into a video.",
        "min": null,
        "max": null
      },
      {
        "name": "fps",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Fps",
        "description": "The FPS of the output video.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "frames",
      "fps"
    ]
  },
  {
    "title": "Concat",
    "description": "Concatenate multiple video files into a single video, including audio when available.\n    video, concat, merge, combine, audio",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.Concat",
    "layout": "default",
    "properties": [
      {
        "name": "video_a",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video A",
        "description": "The first video to concatenate.",
        "min": null,
        "max": null
      },
      {
        "name": "video_b",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video B",
        "description": "The second video to concatenate.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video_a",
      "video_b"
    ]
  },
  {
    "title": "Trim",
    "description": "Trim a video to a specific start and end time.\n    video, trim, cut, segment\n\n    Use cases:\n    1. Extract specific segments from a longer video\n    2. Remove unwanted parts from the beginning or end of a video\n    3. Create shorter clips from a full-length video",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.Trim",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "The input video to trim.",
        "min": null,
        "max": null
      },
      {
        "name": "start_time",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Start Time",
        "description": "The start time in seconds for the trimmed video.",
        "min": null,
        "max": null
      },
      {
        "name": "end_time",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1.0,
        "title": "End Time",
        "description": "The end time in seconds for the trimmed video. Use -1 for the end of the video.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video",
      "start_time",
      "end_time"
    ]
  },
  {
    "title": "Resize",
    "description": "Resize a video to a specific width and height.\n    video, resize, scale, dimensions\n\n    Use cases:\n    1. Adjust video resolution for different display requirements\n    2. Reduce file size by downscaling video\n    3. Prepare videos for specific platforms with size constraints",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.Resize",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "The input video to resize.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Width",
        "description": "The target width. Use -1 to maintain aspect ratio.",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Height",
        "description": "The target height. Use -1 to maintain aspect ratio.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video",
      "width",
      "height"
    ]
  },
  {
    "title": "Rotate",
    "description": "Rotate a video by a specified angle.\n    video, rotate, orientation, transform\n\n    Use cases:\n    1. Correct orientation of videos taken with a rotated camera\n    2. Create artistic effects by rotating video content\n    3. Adjust video for different display orientations",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.Rotate",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "The input video to rotate.",
        "min": null,
        "max": null
      },
      {
        "name": "angle",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Angle",
        "description": "The angle of rotation in degrees.",
        "min": -360.0,
        "max": 360.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video",
      "angle"
    ]
  },
  {
    "title": "Set Speed",
    "description": "Adjust the playback speed of a video.\n    video, speed, tempo, time\n\n    Use cases:\n    1. Create slow-motion effects by decreasing video speed\n    2. Generate time-lapse videos by increasing playback speed\n    3. Synchronize video duration with audio or other timing requirements",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.SetSpeed",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "The input video to adjust speed.",
        "min": null,
        "max": null
      },
      {
        "name": "speed_factor",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Speed Factor",
        "description": "The speed adjustment factor. Values > 1 speed up, < 1 slow down.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video",
      "speed_factor"
    ]
  },
  {
    "title": "Overlay",
    "description": "Overlay one video on top of another, including audio overlay when available.\n    video, overlay, composite, picture-in-picture, audio",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.Overlay",
    "layout": "default",
    "properties": [
      {
        "name": "main_video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Main Video",
        "description": "The main (background) video.",
        "min": null,
        "max": null
      },
      {
        "name": "overlay_video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Overlay Video",
        "description": "The video to overlay on top.",
        "min": null,
        "max": null
      },
      {
        "name": "x",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "X",
        "description": "X-coordinate for overlay placement.",
        "min": null,
        "max": null
      },
      {
        "name": "y",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Y",
        "description": "Y-coordinate for overlay placement.",
        "min": null,
        "max": null
      },
      {
        "name": "scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Scale",
        "description": "Scale factor for the overlay video.",
        "min": null,
        "max": null
      },
      {
        "name": "overlay_audio_volume",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Overlay Audio Volume",
        "description": "Volume of the overlay audio relative to the main audio.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "main_video",
      "overlay_video",
      "x",
      "y",
      "scale",
      "overlay_audio_volume"
    ]
  },
  {
    "title": "Color Balance",
    "description": "Adjust the color balance of a video.\n    video, color, balance, adjustment\n\n    Use cases:\n    1. Correct color casts in video footage\n    2. Enhance specific color tones for artistic effect\n    3. Normalize color balance across multiple video clips",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.ColorBalance",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "The input video to adjust color balance.",
        "min": null,
        "max": null
      },
      {
        "name": "red_adjust",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Red Adjust",
        "description": "Red channel adjustment factor.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "green_adjust",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Green Adjust",
        "description": "Green channel adjustment factor.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "blue_adjust",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Blue Adjust",
        "description": "Blue channel adjustment factor.",
        "min": 0.0,
        "max": 2.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video",
      "red_adjust",
      "green_adjust",
      "blue_adjust"
    ]
  },
  {
    "title": "Denoise",
    "description": "Apply noise reduction to a video.\n    video, denoise, clean, enhance\n\n    Use cases:\n    1. Improve video quality by reducing unwanted noise\n    2. Enhance low-light footage\n    3. Prepare video for further processing or compression",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.Denoise",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "The input video to denoise.",
        "min": null,
        "max": null
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5.0,
        "title": "Strength",
        "description": "Strength of the denoising effect. Higher values mean more denoising.",
        "min": 0.0,
        "max": 20.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video",
      "strength"
    ]
  },
  {
    "title": "Stabilize",
    "description": "Apply video stabilization to reduce camera shake and jitter.\n    video, stabilize, smooth, shake-reduction\n\n    Use cases:\n    1. Improve quality of handheld or action camera footage\n    2. Smooth out panning and tracking shots\n    3. Enhance viewer experience by reducing motion sickness",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.Stabilize",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "The input video to stabilize.",
        "min": null,
        "max": null
      },
      {
        "name": "smoothing",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10.0,
        "title": "Smoothing",
        "description": "Smoothing strength. Higher values result in smoother but potentially more cropped video.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "crop_black",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Crop Black",
        "description": "Whether to crop black borders that may appear after stabilization.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video",
      "smoothing",
      "crop_black"
    ]
  },
  {
    "title": "Sharpness",
    "description": "Adjust the sharpness of a video.\n    video, sharpen, enhance, detail\n\n    Use cases:\n    1. Enhance detail in slightly out-of-focus footage\n    2. Correct softness introduced by video compression\n    3. Create stylistic effects by over-sharpening",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.Sharpness",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "The input video to sharpen.",
        "min": null,
        "max": null
      },
      {
        "name": "luma_amount",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Luma Amount",
        "description": "Amount of sharpening to apply to luma (brightness) channel.",
        "min": 0.0,
        "max": 3.0
      },
      {
        "name": "chroma_amount",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Chroma Amount",
        "description": "Amount of sharpening to apply to chroma (color) channels.",
        "min": 0.0,
        "max": 3.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video",
      "luma_amount",
      "chroma_amount"
    ]
  },
  {
    "title": "Blur",
    "description": "Apply a blur effect to a video.\n    video, blur, smooth, soften\n\n    Use cases:\n    1. Create a dreamy or soft focus effect\n    2. Obscure or censor specific areas of the video\n    3. Reduce noise or grain in low-quality footage",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.Blur",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "The input video to apply blur effect.",
        "min": null,
        "max": null
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5.0,
        "title": "Strength",
        "description": "The strength of the blur effect. Higher values create a stronger blur.",
        "min": 0.0,
        "max": 20.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video",
      "strength"
    ]
  },
  {
    "title": "Saturation",
    "description": "Adjust the color saturation of a video.\n    video, saturation, color, enhance\n\n    Use cases:\n    1. Enhance color vibrancy in dull or flat-looking footage\n    2. Create stylistic effects by over-saturating or desaturating video\n    3. Correct oversaturated footage from certain cameras",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.Saturation",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "The input video to adjust saturation.",
        "min": null,
        "max": null
      },
      {
        "name": "saturation",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Saturation",
        "description": "Saturation level. 1.0 is original, <1 decreases saturation, >1 increases saturation.",
        "min": 0.0,
        "max": 3.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video",
      "saturation"
    ]
  },
  {
    "title": "Add Subtitles",
    "description": "Add subtitles to a video.\n    video, subtitles, text, caption\n\n    Use cases:\n    1. Add translations or closed captions to videos\n    2. Include explanatory text or commentary in educational videos\n    3. Create lyric videos for music content",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.AddSubtitles",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "The input video to add subtitles to.",
        "min": null,
        "max": null
      },
      {
        "name": "chunks",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "audio_chunk",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Chunks",
        "description": "Audio chunks to add as subtitles.",
        "min": null,
        "max": null
      },
      {
        "name": "font",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DejaVuSans-Bold.ttf",
            "DejaVuSans.ttf",
            "FreeSans.ttf"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.video.SubtitleTextFont"
        },
        "default": "DejaVuSans.ttf",
        "title": "Font",
        "description": "The font to use.",
        "min": null,
        "max": null
      },
      {
        "name": "align",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "top",
            "center",
            "bottom"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.video.SubtitleTextAlignment"
        },
        "default": "bottom",
        "title": "Align",
        "description": "Vertical alignment of subtitles.",
        "min": null,
        "max": null
      },
      {
        "name": "font_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 24,
        "title": "Font Size",
        "description": "The font size.",
        "min": 1.0,
        "max": 72.0
      },
      {
        "name": "font_color",
        "type": {
          "type": "color",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "color",
          "value": "#FFFFFF"
        },
        "title": "Font Color",
        "description": "The font color.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video",
      "chunks",
      "font",
      "align",
      "font_size",
      "font_color"
    ]
  },
  {
    "title": "Reverse",
    "description": "Reverse the playback of a video.\n    video, reverse, backwards, effect\n\n    Use cases:\n    1. Create artistic effects by playing video in reverse\n    2. Analyze motion or events in reverse order\n    3. Generate unique transitions or intros for video projects",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.Reverse",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "The input video to reverse.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video"
    ]
  },
  {
    "title": "Transition",
    "description": "Create a transition effect between two videos, including audio transition when available.\n    video, transition, effect, merge, audio\n\n    Use cases:\n    1. Create smooth transitions between video clips in a montage\n    2. Add professional-looking effects to video projects\n    3. Blend scenes together for creative storytelling\n    4. Smoothly transition between audio tracks of different video clips",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.Transition",
    "layout": "default",
    "properties": [
      {
        "name": "video_a",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video A",
        "description": "The first video in the transition.",
        "min": null,
        "max": null
      },
      {
        "name": "video_b",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video B",
        "description": "The second video in the transition.",
        "min": null,
        "max": null
      },
      {
        "name": "transition_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "fade",
            "wipeleft",
            "wiperight",
            "wipeup",
            "wipedown",
            "slideleft",
            "slideright",
            "slideup",
            "slidedown",
            "circlecrop",
            "rectcrop",
            "distance",
            "fadeblack",
            "fadewhite",
            "radial",
            "smoothleft",
            "smoothright",
            "smoothup",
            "smoothdown",
            "circleopen",
            "circleclose",
            "vertopen",
            "vertclose",
            "horzopen",
            "horzclose",
            "dissolve",
            "pixelize",
            "diagtl",
            "diagtr",
            "diagbl",
            "diagbr",
            "hlslice",
            "hrslice",
            "vuslice",
            "vdslice",
            "hblur",
            "fadegrays",
            "wipetl",
            "wipetr",
            "wipebl",
            "wipebr",
            "squeezeh",
            "squeezev",
            "zoomin",
            "fadefast",
            "fadeslow",
            "hlwind",
            "hrwind",
            "vuwind",
            "vdwind",
            "coverleft",
            "coverright",
            "coverup",
            "coverdown",
            "revealleft",
            "revealright",
            "revealup",
            "revealdown"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.nodetool.video.TransitionType"
        },
        "default": "fade",
        "title": "Transition Type",
        "description": "Type of transition effect",
        "min": null,
        "max": null
      },
      {
        "name": "duration",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Duration",
        "description": "Duration of the transition effect in seconds.",
        "min": 0.1,
        "max": 5.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video_a",
      "video_b",
      "transition_type",
      "duration"
    ]
  },
  {
    "title": "Add Audio",
    "description": "Add an audio track to a video, replacing or mixing with existing audio.\n    video, audio, soundtrack, merge\n\n    Use cases:\n    1. Add background music or narration to a silent video\n    2. Replace original audio with a new soundtrack\n    3. Mix new audio with existing video sound",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.AddAudio",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "The input video to add audio to.",
        "min": null,
        "max": null
      },
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to add to the video.",
        "min": null,
        "max": null
      },
      {
        "name": "volume",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Volume",
        "description": "Volume adjustment for the added audio. 1.0 is original volume.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "mix",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Mix",
        "description": "If True, mix new audio with existing. If False, replace existing audio.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video",
      "audio",
      "volume",
      "mix"
    ]
  },
  {
    "title": "Chroma Key",
    "description": "Apply chroma key (green screen) effect to a video.\n    video, chroma key, green screen, compositing\n\n    Use cases:\n    1. Remove green or blue background from video footage\n    2. Create special effects by compositing video onto new backgrounds\n    3. Produce professional-looking videos for presentations or marketing",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.ChromaKey",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "The input video to apply chroma key effect.",
        "min": null,
        "max": null
      },
      {
        "name": "key_color",
        "type": {
          "type": "color",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "color",
          "value": "#00FF00"
        },
        "title": "Key Color",
        "description": "The color to key out (e.g., '#00FF00' for green).",
        "min": null,
        "max": null
      },
      {
        "name": "similarity",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.3,
        "title": "Similarity",
        "description": "Similarity threshold for the key color.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "blend",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.1,
        "title": "Blend",
        "description": "Blending of the keyed area edges.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video",
      "key_color",
      "similarity",
      "blend"
    ]
  },
  {
    "title": "Extract Audio",
    "description": "Separate audio from a video file.\n    video, audio, extract, separate",
    "namespace": "nodetool.video",
    "node_type": "nodetool.video.ExtractAudio",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "The input video to separate.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video"
    ]
  },
  {
    "title": "Image Composite Masked",
    "description": "The Image Composite Masked node can be used to composite an image onto another image using a mask.",
    "namespace": "comfy.image",
    "node_type": "comfy.image.ImageCompositeMasked",
    "layout": "default",
    "properties": [
      {
        "name": "destination",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Destination",
        "description": "The destination image.",
        "min": null,
        "max": null
      },
      {
        "name": "source",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Source",
        "description": "The source image.",
        "min": null,
        "max": null
      },
      {
        "name": "x",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "X",
        "description": "The x position.",
        "min": null,
        "max": null
      },
      {
        "name": "y",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Y",
        "description": "The y position.",
        "min": null,
        "max": null
      },
      {
        "name": "resize_source",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Resize Source",
        "description": "Whether to resize the source.",
        "min": null,
        "max": null
      },
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Mask",
        "description": "The mask to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "destination",
      "source",
      "x",
      "y",
      "resize_source",
      "mask"
    ]
  },
  {
    "title": "Load Image",
    "description": "The Load Image node can be used to to load an image. Images can be uploaded in the asset manager or by dropping an image onto the node. Once the image has been uploaded they can be selected inside the node.",
    "namespace": "comfy.image",
    "node_type": "comfy.image.LoadImage",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Load Image Mask",
    "description": "Load an Image and extract a mask from it.",
    "namespace": "comfy.image",
    "node_type": "comfy.image.LoadImageMask",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to load.",
        "min": null,
        "max": null
      },
      {
        "name": "channel",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "alpha",
            "red",
            "green",
            "blue"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.image.ColorChannel"
        },
        "default": "alpha",
        "title": "Channel",
        "description": "The color channel to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "channel"
    ]
  },
  {
    "title": "Save Image",
    "description": "The Save Image node can be used to save images. To simply preview an image inside the node graph use the Preview Image node. It can be hard to keep track of all the images that you generate. To help with organizing your images you can pass specially formatted strings to an output node with a file_prefix widget.",
    "namespace": "comfy.image",
    "node_type": "comfy.image.SaveImage",
    "layout": "default",
    "properties": [
      {
        "name": "images",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Images",
        "description": "The image to save.",
        "min": null,
        "max": null
      },
      {
        "name": "filename_prefix",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Filename Prefix",
        "description": "The prefix for the filename where the image will be saved.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "images",
      "filename_prefix"
    ]
  },
  {
    "title": "Pad Image for Outpainting",
    "description": "The Pad Image for Outpainting node can be used to to add padding to an image for outpainting. This image can then be given to an inpaint diffusion model via the VAE Encode for Inpainting.",
    "namespace": "comfy.image",
    "node_type": "comfy.image.ImagePadForOutpaint",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to pad.",
        "min": null,
        "max": null
      },
      {
        "name": "left",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Left",
        "description": "The padding size on the left side.",
        "min": null,
        "max": null
      },
      {
        "name": "top",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Top",
        "description": "The padding size on the top side.",
        "min": null,
        "max": null
      },
      {
        "name": "right",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Right",
        "description": "The padding size on the right side.",
        "min": null,
        "max": null
      },
      {
        "name": "bottom",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Bottom",
        "description": "The padding size on the bottom side.",
        "min": null,
        "max": null
      },
      {
        "name": "feathering",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 40,
        "title": "Feathering",
        "description": "The feathering value for softening the edges of the padding.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "left",
      "top",
      "right",
      "bottom",
      "feathering"
    ]
  },
  {
    "title": "Save Animated WEBP",
    "description": "Save a list of images as an animated WEBP.",
    "namespace": "comfy.image.animation",
    "node_type": "comfy.image.animation.SaveAnimatedWEBP",
    "layout": "default",
    "properties": [
      {
        "name": "images",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Images",
        "description": "list of images to save as animated WEBP.",
        "min": null,
        "max": null
      },
      {
        "name": "filename_prefix",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "ComfyUI",
        "title": "Filename Prefix",
        "description": "Prefix for the filename.",
        "min": null,
        "max": null
      },
      {
        "name": "fps",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 6.0,
        "title": "Fps",
        "description": "Frames per second.",
        "min": null,
        "max": null
      },
      {
        "name": "lossless",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Lossless",
        "description": "Whether to use lossless compression.",
        "min": null,
        "max": null
      },
      {
        "name": "quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Quality",
        "description": "Quality of the WEBP.",
        "min": null,
        "max": null
      },
      {
        "name": "method",
        "type": {
          "type": "enum",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "default",
        "title": "Method",
        "description": "Compression method to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "images",
      "filename_prefix",
      "fps",
      "lossless",
      "quality",
      "method"
    ]
  },
  {
    "title": "Save Animated PNG",
    "description": "Save a list of images as an animated PNG.",
    "namespace": "comfy.image.animation",
    "node_type": "comfy.image.animation.SaveAnimatedPNG",
    "layout": "default",
    "properties": [
      {
        "name": "images",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Images",
        "description": "list of images to save as animated PNG.",
        "min": null,
        "max": null
      },
      {
        "name": "filename_prefix",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "ComfyUI",
        "title": "Filename Prefix",
        "description": "Prefix for the filename.",
        "min": null,
        "max": null
      },
      {
        "name": "fps",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 6.0,
        "title": "Fps",
        "description": "Frames per second.",
        "min": null,
        "max": null
      },
      {
        "name": "compress_level",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Compress Level",
        "description": "PNG compression level.",
        "min": null,
        "max": null
      },
      {
        "name": "hidden_fields",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Hidden Fields",
        "description": "Hidden fields like prompt and extra PNG information.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "images",
      "filename_prefix",
      "fps",
      "compress_level",
      "hidden_fields"
    ]
  },
  {
    "title": "Repeat Image Batch",
    "description": "Repeat an image a given number of times.",
    "namespace": "comfy.image.batch",
    "node_type": "comfy.image.batch.RepeatImageBatch",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to repeat.",
        "min": null,
        "max": null
      },
      {
        "name": "amount",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Amount",
        "description": "The number of times to repeat the image.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "amount"
    ]
  },
  {
    "title": "Image Crop",
    "description": "Crop an image to a given size.",
    "namespace": "comfy.image.transform",
    "node_type": "comfy.image.transform.ImageCrop",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to crop.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Width",
        "description": "Width of the crop.",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Height",
        "description": "Height of the crop.",
        "min": null,
        "max": null
      },
      {
        "name": "x",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "X",
        "description": "X position where the crop starts.",
        "min": null,
        "max": null
      },
      {
        "name": "y",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Y",
        "description": "Y position where the crop starts.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "width",
      "height",
      "x",
      "y"
    ]
  },
  {
    "title": "Image Scale",
    "description": "Scale an image to a given size.",
    "namespace": "comfy.image.upscaling",
    "node_type": "comfy.image.upscaling.ImageScale",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to scale.",
        "min": null,
        "max": null
      },
      {
        "name": "upscale_method",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "nearest_exact",
            "bilinear",
            "area",
            "bicubic",
            "lanczos"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.image.upscaling.UpscaleMethod"
        },
        "default": "nearest_exact",
        "title": "Upscale Method",
        "description": "The method to use for upscaling the image.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Width",
        "description": "The target width for scaling.",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Height",
        "description": "The target height for scaling.",
        "min": null,
        "max": null
      },
      {
        "name": "crop",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "disabled",
            "center"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.image.upscaling.CropMethod"
        },
        "default": "disabled",
        "title": "Crop",
        "description": "The method to use if cropping is required.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "upscale_method",
      "width",
      "height",
      "crop"
    ]
  },
  {
    "title": "Image Scale By",
    "description": "Scale an image by a given factor.",
    "namespace": "comfy.image.upscaling",
    "node_type": "comfy.image.upscaling.ImageScaleBy",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to scale.",
        "min": null,
        "max": null
      },
      {
        "name": "upscale_method",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "nearest_exact",
            "bilinear",
            "area",
            "bicubic",
            "lanczos"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.image.upscaling.UpscaleMethod"
        },
        "default": "nearest_exact",
        "title": "Upscale Method",
        "description": "The method to use for upscaling the image.",
        "min": null,
        "max": null
      },
      {
        "name": "scale_by",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Scale By",
        "description": "The scaling factor by which to scale the image.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "upscale_method",
      "scale_by"
    ]
  },
  {
    "title": "Image Upscale With Model",
    "description": "Upscale an image using a given model.",
    "namespace": "comfy.image.upscaling",
    "node_type": "comfy.image.upscaling.ImageUpscaleWithModel",
    "layout": "default",
    "properties": [
      {
        "name": "upscale_model",
        "type": {
          "type": "comfy.upscale_model",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Upscale Model",
        "description": "The model to use for upscaling the image.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to upscale.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "upscale_model",
      "image"
    ]
  },
  {
    "title": "Audio Classifier",
    "description": "Classifies audio into predefined categories.\n    audio, classification, labeling, categorization\n\n    Use cases:\n    - Classify music genres\n    - Detect speech vs. non-speech audio\n    - Identify environmental sounds\n    - Emotion recognition in speech\n\n    Recommended models\n    - MIT/ast-finetuned-audioset-10-10-0.4593\n    - ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
    "namespace": "huggingface.audio_classification",
    "node_type": "huggingface.audio_classification.AudioClassifier",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.audio_classification",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.audio_classification",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for audio classification",
        "min": null,
        "max": null
      },
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The input audio to classify",
        "min": null,
        "max": null
      },
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10,
        "title": "Top K",
        "description": "The number of top results to return",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.audio_classification",
        "repo_id": "MIT/ast-finetuned-audioset-10-10-0.4593",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.audio_classification",
        "repo_id": "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
        "path": null,
        "allow_patterns": [
          "pytorch_model.bin",
          "*.json"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "audio",
      "top_k"
    ]
  },
  {
    "title": "Zero Shot Audio Classifier",
    "description": "Classifies audio into categories without the need for training data.\n    audio, classification, labeling, categorization, zero-shot\n\n    Use cases:\n    - Quickly categorize audio without training data\n    - Identify sounds or music genres without predefined labels\n    - Automate audio tagging for large datasets",
    "namespace": "huggingface.audio_classification",
    "node_type": "huggingface.audio_classification.ZeroShotAudioClassifier",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.zero_shot_audio_classification",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.zero_shot_audio_classification",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for the classification",
        "min": null,
        "max": null
      },
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The input audio to classify",
        "min": null,
        "max": null
      },
      {
        "name": "candidate_labels",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Candidate Labels",
        "description": "The candidate labels to classify the audio against, separated by commas",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.zero_shot_audio_classification",
        "repo_id": "laion/clap-htsat-unfused",
        "path": null,
        "allow_patterns": [
          "model.safetensors",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "audio",
      "candidate_labels"
    ]
  },
  {
    "title": "Whisper",
    "description": "Convert speech to text\n    asr, automatic-speech-recognition, speech-to-text, translate, transcribe, audio, huggingface\n\n    **Use Cases:**\n    - Voice input for a chatbot\n    - Transcribe or translate audio files\n    - Create subtitles for videos\n\n    **Features:**\n    - Multilingual speech recognition\n    - Speech translation\n    - Language identification\n\n    **Note**\n    - Language selection is sorted by word error rate in the FLEURS benchmark\n    - There are many variants of Whisper that are optimized for different use cases.\n\n    **Links:**\n    - https://github.com/openai/whisper\n    - https://platform.openai.com/docs/guides/speech-to-text/supported-languages",
    "namespace": "huggingface.automatic_speech_recognition",
    "node_type": "huggingface.automatic_speech_recognition.Whisper",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.automatic_speech_recognition",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.automatic_speech_recognition",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for the speech recognition.",
        "min": null,
        "max": null
      },
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio Input",
        "description": "The input audio to transcribe.",
        "min": null,
        "max": null
      },
      {
        "name": "task",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "transcribe",
            "translate"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.automatic_speech_recognition.Task"
        },
        "default": "transcribe",
        "title": "Task",
        "description": "The task to perform: 'transcribe' for speech-to-text or 'translate' for speech translation.",
        "min": null,
        "max": null
      },
      {
        "name": "language",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "auto_detect",
            "spanish",
            "italian",
            "korean",
            "portuguese",
            "english",
            "japanese",
            "german",
            "russian",
            "dutch",
            "polish",
            "catalan",
            "french",
            "indonesian",
            "ukrainian",
            "turkish",
            "malay",
            "swedish",
            "mandarin",
            "finnish",
            "norwegian",
            "romanian",
            "thai",
            "vietnamese",
            "slovak",
            "arabic",
            "czech",
            "croatian",
            "greek",
            "serbian",
            "danish",
            "bulgarian",
            "hungarian",
            "filipino",
            "bosnian",
            "galician",
            "macedonian",
            "hindi",
            "estonian",
            "slovenian",
            "tamil",
            "latvian",
            "azerbaijani",
            "urdu",
            "lithuanian",
            "hebrew",
            "welsh",
            "persian",
            "icelandic",
            "kazakh",
            "afrikaans",
            "kannada",
            "marathi",
            "swahili",
            "telugu",
            "maori",
            "nepali",
            "armenian",
            "belarusian",
            "gujarati",
            "punjabi",
            "bengali"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.automatic_speech_recognition.WhisperLanguage"
        },
        "default": "auto_detect",
        "title": "Language",
        "description": "The language of the input audio. If not specified, the model will attempt to detect it automatically.",
        "min": null,
        "max": null
      },
      {
        "name": "timestamps",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "none",
            "word",
            "sentence"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.automatic_speech_recognition.Timestamps"
        },
        "default": "none",
        "title": "Timestamps",
        "description": "The type of timestamps to return for the generated text.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "text",
        "stream": false
      },
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "audio_chunk",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "chunks",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.automatic_speech_recognition",
        "repo_id": "openai/whisper-large-v3",
        "path": null,
        "allow_patterns": [
          "model.safetensors",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.automatic_speech_recognition",
        "repo_id": "openai/whisper-large-v2",
        "path": null,
        "allow_patterns": [
          "model.safetensors",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.automatic_speech_recognition",
        "repo_id": "openai/whisper-small",
        "path": null,
        "allow_patterns": [
          "model.safetensors",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.automatic_speech_recognition",
        "repo_id": "Systran/faster-whisper-large-v3",
        "path": null,
        "allow_patterns": [
          "model.bin",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "audio",
      "task"
    ]
  },
  {
    "title": "Chunks To SRT",
    "description": "Convert audio chunks to SRT (SubRip Subtitle) format\n    subtitle, srt, whisper, transcription\n\n    **Use Cases:**\n    - Generate subtitles for videos\n    - Create closed captions from audio transcriptions\n    - Convert speech-to-text output to a standardized subtitle format\n\n    **Features:**\n    - Converts Whisper audio chunks to SRT format\n    - Supports customizable time offset\n    - Generates properly formatted SRT file content",
    "namespace": "huggingface.automatic_speech_recognition",
    "node_type": "huggingface.automatic_speech_recognition.ChunksToSRT",
    "layout": "default",
    "properties": [
      {
        "name": "chunks",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "audio_chunk",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Audio Chunks",
        "description": "List of audio chunks from Whisper transcription",
        "min": null,
        "max": null
      },
      {
        "name": "time_offset",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Time Offset",
        "description": "Time offset in seconds to apply to all timestamps",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "chunks",
      "time_offset"
    ]
  },
  {
    "title": "Depth Estimation",
    "description": "Estimates depth from a single image.\n    image, depth estimation, 3D, huggingface\n\n    Use cases:\n    - Generate depth maps for 3D modeling\n    - Assist in augmented reality applications\n    - Enhance computer vision systems for robotics\n    - Improve scene understanding in autonomous vehicles\n\n    Recommended models:\n    - LiheYoung/depth-anything-base-hf\n    - Intel/dpt-large",
    "namespace": "huggingface.depth_estimation",
    "node_type": "huggingface.depth_estimation.DepthEstimation",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.depth_estimation",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.depth_estimation",
          "repo_id": "LiheYoung/depth-anything-base-hf",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for depth estimation",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image for depth estimation",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.depth_estimation",
        "repo_id": "depth-anything/Depth-Anything-V2-Small-hf",
        "path": null,
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.depth_estimation",
        "repo_id": "depth-anything/Depth-Anything-V2-Base-hf",
        "path": null,
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.depth_estimation",
        "repo_id": "depth-anything/Depth-Anything-V2-Large-hf",
        "path": null,
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.depth_estimation",
        "repo_id": "Intel/dpt-large",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.safetensors",
          "*.json",
          "**/*.json",
          "txt"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "image"
    ]
  },
  {
    "title": "Feature Extraction",
    "description": "Extracts features from text using pre-trained models.\n    text, feature extraction, embeddings, natural language processing\n\n    Use cases:\n    - Text similarity comparison\n    - Clustering text documents\n    - Input for machine learning models\n    - Semantic search applications",
    "namespace": "huggingface.feature_extraction",
    "node_type": "huggingface.feature_extraction.FeatureExtraction",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.feature_extraction",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.feature_extraction",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for feature extraction",
        "min": null,
        "max": null
      },
      {
        "name": "inputs",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Input Text",
        "description": "The text to extract features from",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.feature_extraction",
        "repo_id": "mixedbread-ai/mxbai-embed-large-v1",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.txt",
          "*,json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.feature_extraction",
        "repo_id": "BAAI/bge-base-en-v1.5",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.txt",
          "*,json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.feature_extraction",
        "repo_id": "BAAI/bge-large-en-v1.5",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.txt",
          "*,json"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "inputs"
    ]
  },
  {
    "title": "Fill Mask",
    "description": "Fills in a masked token in a given text.\n    text, fill-mask, natural language processing\n\n    Use cases:\n    - Text completion\n    - Sentence prediction\n    - Language understanding tasks\n    - Generating text options",
    "namespace": "huggingface.fill_mask",
    "node_type": "huggingface.fill_mask.FillMask",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.fill_mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.fill_mask",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID",
        "description": "The model ID to use for fill-mask task",
        "min": null,
        "max": null
      },
      {
        "name": "inputs",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "The capital of France is [MASK].",
        "title": "Inputs",
        "description": "The input text with [MASK] token to be filled",
        "min": null,
        "max": null
      },
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5,
        "title": "Top K",
        "description": "Number of top predictions to return",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.fill_mask",
        "repo_id": "bert-base-uncased",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.fill_mask",
        "repo_id": "roberta-base",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.fill_mask",
        "repo_id": "distilbert-base-uncased",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.fill_mask",
        "repo_id": "albert-base-v2",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "inputs",
      "top_k"
    ]
  },
  {
    "title": "Image Classifier",
    "description": "Classifies images into predefined categories.\n    image, classification, labeling, categorization\n\n    Use cases:\n    - Content moderation by detecting inappropriate images\n    - Organizing photo libraries by automatically tagging images",
    "namespace": "huggingface.image_classification",
    "node_type": "huggingface.image_classification.ImageClassifier",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.image_classification",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.image_classification",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for the classification",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image to classify",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.image_classification",
        "repo_id": "google/vit-base-patch16-224",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.safetensors",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.image_classification",
        "repo_id": "microsoft/resnet-50",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.safetensors",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.image_classification",
        "repo_id": "microsoft/resnet-18",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.safetensors",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.image_classification",
        "repo_id": "apple/mobilevit-small",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.bin",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.image_classification",
        "repo_id": "apple/mobilevit-xx-small",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.bin",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.image_classification",
        "repo_id": "nateraw/vit-age-classifier",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.safetensors",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.image_classification",
        "repo_id": "Falconsai/nsfw_image_detection",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.safetensors",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.image_classification",
        "repo_id": "rizvandwiki/gender-classification-2",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.safetensors",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "image"
    ]
  },
  {
    "title": "Zero-Shot Image Classifier",
    "description": "Classifies images into categories without the need for training data.\n    image, classification, labeling, categorization\n\n    Use cases:\n    - Quickly categorize images without training data\n    - Identify objects in images without predefined labels\n    - Automate image tagging for large datasets\n\n    Recommended models:\n    - openai/clip-vit-large-patch14\n    - openai/clip-vit-base-patch16\n    - openai/clip-vit-base-patch32\n    - patrickjohncyh/fashion-clip\n    - laion/CLIP-ViT-H-14-laion2B-s32B-b79K",
    "namespace": "huggingface.image_classification",
    "node_type": "huggingface.image_classification.ZeroShotImageClassifier",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.zero_shot_image_classification",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.zero_shot_image_classification",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for the classification",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image to classify",
        "min": null,
        "max": null
      },
      {
        "name": "candidate_labels",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Candidate Labels",
        "description": "The candidate labels to classify the image against, separated by commas",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.zero_shot_image_classification",
        "repo_id": "openai/clip-vit-base-patch16",
        "path": null,
        "allow_patterns": [
          "README.md",
          "pytorch_model.bin",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.zero_shot_image_classification",
        "repo_id": "openai/clip-vit-base-patch32",
        "path": null,
        "allow_patterns": [
          "README.md",
          "pytorch_model.bin",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.zero_shot_image_classification",
        "repo_id": "openai/clip-vit-base-patch14",
        "path": null,
        "allow_patterns": [
          "README.md",
          "pytorch_model.bin",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.zero_shot_image_classification",
        "repo_id": "patricjohncyh/fashion-clip",
        "path": null,
        "allow_patterns": [
          "README.md",
          "pytorch_model.bin",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.zero_shot_image_classification",
        "repo_id": "laion/CLIP-ViT-H-14-laion2B-s32B-b79K",
        "path": null,
        "allow_patterns": [
          "README.md",
          "pytorch_model.bin",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.zero_shot_image_classification",
        "repo_id": "laion/CLIP-ViT-g-14-laion2B-s12B-b42K",
        "path": null,
        "allow_patterns": [
          "README.md",
          "pytorch_model.bin",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "image",
      "candidate_labels"
    ]
  },
  {
    "title": "Image Segmentation",
    "description": "Performs semantic segmentation on images, identifying and labeling different regions.\n    image, segmentation, object detection, scene parsing\n\n    Use cases:\n    - Segmenting objects in images\n    - Segmenting facial features in images\n\n    Recommended models:\n    - nvidia/segformer-b3-finetuned-ade-512-512\n    - mattmdjaga/segformer_b2_clothes",
    "namespace": "huggingface.image_segmentation",
    "node_type": "huggingface.image_segmentation.Segmentation",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.image_segmentation",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.image_segmentation",
          "repo_id": "nvidia/segformer-b3-finetuned-ade-512-512",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for the segmentation",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image to segment",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image_segmentation_result",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.image_segmentation",
        "repo_id": "nvidia/segformer-b3-finetuned-ade-512-512",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.bin",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.image_segmentation",
        "repo_id": "mattmdjaga/segformer_b2_clothes",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.bin",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "image"
    ]
  },
  {
    "title": "SAM2 Segmentation",
    "description": "Performs semantic segmentation on images using SAM2 (Segment Anything Model 2).\n    image, segmentation, object detection, scene parsing, mask\n\n    Use cases:\n    - Automatic segmentation of objects in images\n    - Instance segmentation for computer vision tasks\n    - Interactive segmentation with point prompts\n    - Scene understanding and object detection",
    "namespace": "huggingface.image_segmentation",
    "node_type": "huggingface.image_segmentation.SAM2Segmentation",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Input Image",
        "description": "The input image to segment",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.model",
        "repo_id": "facebook/sam2-hiera-large",
        "path": null,
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Find Segment",
    "description": "Extracts a specific segment from a list of segmentation masks.\n    image, segmentation, object detection, mask",
    "namespace": "huggingface.image_segmentation",
    "node_type": "huggingface.image_segmentation.FindSegment",
    "layout": "default",
    "properties": [
      {
        "name": "segments",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image_segmentation_result",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": {},
        "title": "Segmentation Masks",
        "description": "The segmentation masks to search",
        "min": null,
        "max": null
      },
      {
        "name": "segment_label",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Label",
        "description": "The label of the segment to extract",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "segments",
      "segment_label"
    ]
  },
  {
    "title": "Visualize Segmentation",
    "description": "Visualizes segmentation masks on images with labels.\n    image, segmentation, visualization, mask\n\n    Use cases:\n    - Visualize results of image segmentation models\n    - Analyze and compare different segmentation techniques\n    - Create labeled images for presentations or reports",
    "namespace": "huggingface.image_segmentation",
    "node_type": "huggingface.image_segmentation.VisualizeSegmentation",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image to visualize",
        "min": null,
        "max": null
      },
      {
        "name": "segments",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image_segmentation_result",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Segmentation Masks",
        "description": "The segmentation masks to visualize",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "segments"
    ]
  },
  {
    "title": "Real ESRGAN",
    "description": "Performs image super-resolution using the RealESRGAN model.\n    image, super-resolution, enhancement, huggingface\n\n    Use cases:\n    - Enhance low-resolution images\n    - Improve image quality for printing or display\n    - Upscale images for better detail",
    "namespace": "huggingface.image_to_image",
    "node_type": "huggingface.image_to_image.RealESRGAN",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Input Image",
        "description": "The input image to transform",
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "hf.real_esrgan",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.real_esrgan",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "RealESRGAN Model",
        "description": "The RealESRGAN model to use for image super-resolution",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.real_esrgan",
        "repo_id": "ai-forever/Real-ESRGAN",
        "path": "RealESRGAN_x2.pth",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.real_esrgan",
        "repo_id": "ai-forever/Real-ESRGAN",
        "path": "RealESRGAN_x4.pth",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.real_esrgan",
        "repo_id": "ai-forever/Real-ESRGAN",
        "path": "RealESRGAN_x8.pth",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.real_esrgan",
        "repo_id": "ximso/RealESRGAN_x4plus_anime_6B",
        "path": "RealESRGAN_x4plus_anime_6B.pth",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "image",
      "model"
    ]
  },
  {
    "title": "Swin2SR",
    "description": "Performs image super-resolution using the Swin2SR model.\n    image, super-resolution, enhancement, huggingface\n\n    Use cases:\n    - Enhance low-resolution images\n    - Improve image quality for printing or display\n    - Upscale images for better detail",
    "namespace": "huggingface.image_to_image",
    "node_type": "huggingface.image_to_image.Swin2SR",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Input Image",
        "description": "The input image to transform",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The text prompt to guide the image transformation (if applicable)",
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "hf.image_to_image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.image_to_image",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for image super-resolution",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.image_to_image",
        "repo_id": "caidas/swin2SR-classical-sr-x2-64",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.safetensors",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.image_to_image",
        "repo_id": "caidas/swin2SR-classical-sr-x4-48",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.safetensors",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.image_to_image",
        "repo_id": "caidas/swin2SR-lightweight-sr-x2-64",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.bin",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.image_to_image",
        "repo_id": "caidas/swin2SR-realworld-sr-x4-64-bsrgan-psnr",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.bin",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "image",
      "prompt",
      "model"
    ]
  },
  {
    "title": "Kandinsky 3 Image-to-Image",
    "description": "Transforms existing images using the Kandinsky-3 model based on text prompts.\n    image, generation, image-to-image\n\n    Use cases:\n    - Modify existing images based on text descriptions\n    - Apply specific styles or concepts to photographs or artwork\n    - Create variations of existing visual content\n    - Blend AI-generated elements with existing images",
    "namespace": "huggingface.image_to_image",
    "node_type": "huggingface.image_to_image.Kandinsky3Img2Img",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "A photograph of the inside of a subway train. There are raccoons sitting on the seats. One of them is reading a newspaper. The window shows the city in the background.",
        "title": "Prompt",
        "description": "A text prompt describing the desired image transformation.",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Inference Steps",
        "description": "The number of denoising steps.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Strength",
        "description": "The strength of the transformation. Use a value between 0.0 and 1.0.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Input Image",
        "description": "The input image to transform",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Seed",
        "description": "Seed for the random number generator. Use -1 for a random seed.",
        "min": -1.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.model",
        "repo_id": "kandinsky-community/kandinsky-3",
        "path": null,
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "prompt",
      "num_inference_steps",
      "strength",
      "image",
      "seed",
      "image",
      "prompt",
      "num_inference_steps",
      "strength"
    ]
  },
  {
    "title": "Stable Diffusion ControlNet",
    "description": "Generates images using Stable Diffusion with ControlNet guidance.\n    image, generation, text-to-image, controlnet, SD\n\n    Use cases:\n    - Generate images with precise control over composition and structure\n    - Create variations of existing images while maintaining specific features\n    - Artistic image generation with guided outputs",
    "namespace": "huggingface.image_to_image",
    "node_type": "huggingface.image_to_image.StableDiffusionControlNet",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.stable_diffusion",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.stable_diffusion",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The model to use for image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt for image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "(blurry, low quality, deformed, mutated, bad anatomy, extra limbs, bad proportions, text, watermark, grainy, pixelated, disfigured face, missing fingers, cropped image, bad lighting",
        "title": "Negative Prompt",
        "description": "The negative prompt to guide what should not appear in the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "Seed for the random number generator. Use -1 for a random seed.",
        "min": -1.0,
        "max": 4294967295.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Guidance scale for generation.",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DPMSolverSDEScheduler",
            "EulerDiscreteScheduler",
            "LMSDiscreteScheduler",
            "DDIMScheduler",
            "DDPMScheduler",
            "HeunDiscreteScheduler",
            "DPMSolverMultistepScheduler",
            "DEISMultistepScheduler",
            "PNDMScheduler",
            "EulerAncestralDiscreteScheduler",
            "UniPCMultistepScheduler",
            "KDPM2DiscreteScheduler",
            "DPMSolverSinglestepScheduler",
            "KDPM2AncestralDiscreteScheduler"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionScheduler"
        },
        "default": "EulerDiscreteScheduler",
        "title": "Scheduler",
        "description": "The scheduler to use for the diffusion process.",
        "min": null,
        "max": null
      },
      {
        "name": "loras",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "hf.lora_sd_config",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Loras",
        "description": "The LoRA models to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_model",
        "type": {
          "type": "hf.ip_adapter",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.ip_adapter",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Ip Adapter Model",
        "description": "The IP adapter model to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Ip Adapter Image",
        "description": "When provided the image will be fed into the IP adapter",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Ip Adapter Scale",
        "description": "The strength of the IP adapter",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "detail_level",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Detail Level",
        "description": "Level of detail for the hi-res pass. 0.0 is low detail, 1.0 is high detail.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "enable_tiling",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Tiling",
        "description": "Enable tiling for the VAE. This can reduce VRAM usage.",
        "min": null,
        "max": null
      },
      {
        "name": "enable_cpu_offload",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Cpu Offload",
        "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage.",
        "min": null,
        "max": null
      },
      {
        "name": "upscaler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "None",
            "Latent",
            "Bicubic"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionUpscaler"
        },
        "default": "None",
        "title": "Upscaler",
        "description": "The upscaler to use for 2-pass generation.",
        "min": null,
        "max": null
      },
      {
        "name": "controlnet",
        "type": {
          "type": "hf.controlnet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.controlnet",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Controlnet",
        "description": "The ControlNet model to use for guidance.",
        "min": null,
        "max": null
      },
      {
        "name": "control_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Control Image",
        "description": "The control image to guide the generation process.",
        "min": null,
        "max": null
      },
      {
        "name": "controlnet_conditioning_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Controlnet Conditioning Scale",
        "description": "The scale for ControlNet conditioning.",
        "min": 0.0,
        "max": 2.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_canny",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_inpaint",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_mlsd",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_tile",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_shuffle",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_ip2p",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_lineart",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_lineart_anime",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_scribble",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_openpose",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_scribble",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_seg",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_hed",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_normalbae",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_light.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_vit-G.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "SG161222/Realistic_Vision_V5.1_noVAE",
        "path": "Realistic_Vision_V5.1_fp16-no-ema.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "digiplay/majicMIX_realistic_v7",
        "path": "majicmixRealistic_v7.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "philz1337x/epicrealism",
        "path": "epicrealism_naturalSinRC1VAE.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/DreamShaper",
        "path": "DreamShaper_5_beta2_noVae_half_pruned.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/DreamShaper",
        "path": "DreamShaper_4BakedVae_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "XpucT/Deliberate",
        "path": "Deliberate_v6.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "XpucT/Deliberate",
        "path": "Deliberate_v6-inpainting.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/AbsoluteReality",
        "path": "AbsoluteReality_1.8.1_pruned.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/AbsoluteReality",
        "path": "AbsoluteReality_1.8.1_INPAINTING.inpainting.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "gsdf/Counterfeit-V2.5",
        "path": "Counterfeit-V2.5_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_light.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_vit-G.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "stabilityai/sd-x2-latent-upscaler",
        "path": null,
        "allow_patterns": [
          "README.md",
          "**/*.safetensors",
          "**/*.json",
          "**/*.txt",
          "*.json"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt",
      "controlnet",
      "control_image",
      "controlnet_conditioning_scale"
    ]
  },
  {
    "title": "Stable Diffusion (Img2Img)",
    "description": "Transforms existing images based on text prompts using Stable Diffusion.\n    image, generation, image-to-image, SD, img2img\n\n    Use cases:\n    - Modifying existing images to fit a specific style or theme\n    - Enhancing or altering photographs\n    - Creating variations of existing artwork\n    - Applying text-guided edits to images",
    "namespace": "huggingface.image_to_image",
    "node_type": "huggingface.image_to_image.StableDiffusionImg2Img",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.stable_diffusion",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.stable_diffusion",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The model to use for image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt for image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "(blurry, low quality, deformed, mutated, bad anatomy, extra limbs, bad proportions, text, watermark, grainy, pixelated, disfigured face, missing fingers, cropped image, bad lighting",
        "title": "Negative Prompt",
        "description": "The negative prompt to guide what should not appear in the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "Seed for the random number generator. Use -1 for a random seed.",
        "min": -1.0,
        "max": 4294967295.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Guidance scale for generation.",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DPMSolverSDEScheduler",
            "EulerDiscreteScheduler",
            "LMSDiscreteScheduler",
            "DDIMScheduler",
            "DDPMScheduler",
            "HeunDiscreteScheduler",
            "DPMSolverMultistepScheduler",
            "DEISMultistepScheduler",
            "PNDMScheduler",
            "EulerAncestralDiscreteScheduler",
            "UniPCMultistepScheduler",
            "KDPM2DiscreteScheduler",
            "DPMSolverSinglestepScheduler",
            "KDPM2AncestralDiscreteScheduler"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionScheduler"
        },
        "default": "EulerDiscreteScheduler",
        "title": "Scheduler",
        "description": "The scheduler to use for the diffusion process.",
        "min": null,
        "max": null
      },
      {
        "name": "loras",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "hf.lora_sd_config",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Loras",
        "description": "The LoRA models to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_model",
        "type": {
          "type": "hf.ip_adapter",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.ip_adapter",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Ip Adapter Model",
        "description": "The IP adapter model to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Ip Adapter Image",
        "description": "When provided the image will be fed into the IP adapter",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Ip Adapter Scale",
        "description": "The strength of the IP adapter",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "detail_level",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Detail Level",
        "description": "Level of detail for the hi-res pass. 0.0 is low detail, 1.0 is high detail.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "enable_tiling",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Tiling",
        "description": "Enable tiling for the VAE. This can reduce VRAM usage.",
        "min": null,
        "max": null
      },
      {
        "name": "enable_cpu_offload",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Cpu Offload",
        "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage.",
        "min": null,
        "max": null
      },
      {
        "name": "upscaler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "None",
            "Latent",
            "Bicubic"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionUpscaler"
        },
        "default": "None",
        "title": "Upscaler",
        "description": "The upscaler to use for 2-pass generation.",
        "min": null,
        "max": null
      },
      {
        "name": "init_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Init Image",
        "description": "The initial image for Image-to-Image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Strength",
        "description": "Strength for Image-to-Image generation. Higher values allow for more deviation from the original image.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_light.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_vit-G.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "SG161222/Realistic_Vision_V5.1_noVAE",
        "path": "Realistic_Vision_V5.1_fp16-no-ema.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "digiplay/majicMIX_realistic_v7",
        "path": "majicmixRealistic_v7.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "philz1337x/epicrealism",
        "path": "epicrealism_naturalSinRC1VAE.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/DreamShaper",
        "path": "DreamShaper_5_beta2_noVae_half_pruned.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/DreamShaper",
        "path": "DreamShaper_4BakedVae_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "XpucT/Deliberate",
        "path": "Deliberate_v6.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "XpucT/Deliberate",
        "path": "Deliberate_v6-inpainting.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/AbsoluteReality",
        "path": "AbsoluteReality_1.8.1_pruned.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/AbsoluteReality",
        "path": "AbsoluteReality_1.8.1_INPAINTING.inpainting.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "gsdf/Counterfeit-V2.5",
        "path": "Counterfeit-V2.5_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_light.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_vit-G.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "stabilityai/sd-x2-latent-upscaler",
        "path": null,
        "allow_patterns": [
          "README.md",
          "**/*.safetensors",
          "**/*.json",
          "**/*.txt",
          "*.json"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt",
      "init_image",
      "strength"
    ]
  },
  {
    "title": "Stable Diffusion ControlNet Inpaint",
    "description": "Performs inpainting on images using Stable Diffusion with ControlNet guidance.\n    image, inpainting, controlnet, SD\n\n    Use cases:\n    - Remove unwanted objects from images with precise control\n    - Fill in missing parts of images guided by control images\n    - Modify specific areas of images while preserving the rest and maintaining structure",
    "namespace": "huggingface.image_to_image",
    "node_type": "huggingface.image_to_image.StableDiffusionControlNetInpaint",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.stable_diffusion",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.stable_diffusion",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The model to use for image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt for image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "(blurry, low quality, deformed, mutated, bad anatomy, extra limbs, bad proportions, text, watermark, grainy, pixelated, disfigured face, missing fingers, cropped image, bad lighting",
        "title": "Negative Prompt",
        "description": "The negative prompt to guide what should not appear in the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "Seed for the random number generator. Use -1 for a random seed.",
        "min": -1.0,
        "max": 4294967295.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Guidance scale for generation.",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DPMSolverSDEScheduler",
            "EulerDiscreteScheduler",
            "LMSDiscreteScheduler",
            "DDIMScheduler",
            "DDPMScheduler",
            "HeunDiscreteScheduler",
            "DPMSolverMultistepScheduler",
            "DEISMultistepScheduler",
            "PNDMScheduler",
            "EulerAncestralDiscreteScheduler",
            "UniPCMultistepScheduler",
            "KDPM2DiscreteScheduler",
            "DPMSolverSinglestepScheduler",
            "KDPM2AncestralDiscreteScheduler"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionScheduler"
        },
        "default": "EulerDiscreteScheduler",
        "title": "Scheduler",
        "description": "The scheduler to use for the diffusion process.",
        "min": null,
        "max": null
      },
      {
        "name": "loras",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "hf.lora_sd_config",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Loras",
        "description": "The LoRA models to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_model",
        "type": {
          "type": "hf.ip_adapter",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.ip_adapter",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Ip Adapter Model",
        "description": "The IP adapter model to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Ip Adapter Image",
        "description": "When provided the image will be fed into the IP adapter",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Ip Adapter Scale",
        "description": "The strength of the IP adapter",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "detail_level",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Detail Level",
        "description": "Level of detail for the hi-res pass. 0.0 is low detail, 1.0 is high detail.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "enable_tiling",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Tiling",
        "description": "Enable tiling for the VAE. This can reduce VRAM usage.",
        "min": null,
        "max": null
      },
      {
        "name": "enable_cpu_offload",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Cpu Offload",
        "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage.",
        "min": null,
        "max": null
      },
      {
        "name": "upscaler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "None",
            "Latent",
            "Bicubic"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionUpscaler"
        },
        "default": "None",
        "title": "Upscaler",
        "description": "The upscaler to use for 2-pass generation.",
        "min": null,
        "max": null
      },
      {
        "name": "controlnet",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "lllyasviel/control_v11p_sd15_inpaint"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.image_to_image.StableDiffusionControlNetModel"
        },
        "default": "lllyasviel/control_v11p_sd15_inpaint",
        "title": "Controlnet",
        "description": "The ControlNet model to use for guidance.",
        "min": null,
        "max": null
      },
      {
        "name": "init_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Init Image",
        "description": "The initial image to be inpainted.",
        "min": null,
        "max": null
      },
      {
        "name": "mask_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask Image",
        "description": "The mask image indicating areas to be inpainted.",
        "min": null,
        "max": null
      },
      {
        "name": "control_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Control Image",
        "description": "The control image to guide the inpainting process.",
        "min": null,
        "max": null
      },
      {
        "name": "controlnet_conditioning_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Controlnet Conditioning Scale",
        "description": "The scale for ControlNet conditioning.",
        "min": 0.0,
        "max": 2.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_light.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_vit-G.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "SG161222/Realistic_Vision_V5.1_noVAE",
        "path": "Realistic_Vision_V5.1_fp16-no-ema.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "digiplay/majicMIX_realistic_v7",
        "path": "majicmixRealistic_v7.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "philz1337x/epicrealism",
        "path": "epicrealism_naturalSinRC1VAE.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/DreamShaper",
        "path": "DreamShaper_5_beta2_noVae_half_pruned.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/DreamShaper",
        "path": "DreamShaper_4BakedVae_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "XpucT/Deliberate",
        "path": "Deliberate_v6.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "XpucT/Deliberate",
        "path": "Deliberate_v6-inpainting.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/AbsoluteReality",
        "path": "AbsoluteReality_1.8.1_pruned.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/AbsoluteReality",
        "path": "AbsoluteReality_1.8.1_INPAINTING.inpainting.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "gsdf/Counterfeit-V2.5",
        "path": "Counterfeit-V2.5_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_light.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_vit-G.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "stabilityai/sd-x2-latent-upscaler",
        "path": null,
        "allow_patterns": [
          "README.md",
          "**/*.safetensors",
          "**/*.json",
          "**/*.txt",
          "*.json"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt",
      "init_image",
      "mask_image",
      "control_image",
      "controlnet_conditioning_scale"
    ]
  },
  {
    "title": "Stable Diffusion (Inpaint)",
    "description": "Performs inpainting on images using Stable Diffusion.\n    image, inpainting, AI, SD\n\n    Use cases:\n    - Remove unwanted objects from images\n    - Fill in missing parts of images\n    - Modify specific areas of images while preserving the rest",
    "namespace": "huggingface.image_to_image",
    "node_type": "huggingface.image_to_image.StableDiffusionInpaint",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.stable_diffusion",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.stable_diffusion",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The model to use for image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt for image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "(blurry, low quality, deformed, mutated, bad anatomy, extra limbs, bad proportions, text, watermark, grainy, pixelated, disfigured face, missing fingers, cropped image, bad lighting",
        "title": "Negative Prompt",
        "description": "The negative prompt to guide what should not appear in the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "Seed for the random number generator. Use -1 for a random seed.",
        "min": -1.0,
        "max": 4294967295.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Guidance scale for generation.",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DPMSolverSDEScheduler",
            "EulerDiscreteScheduler",
            "LMSDiscreteScheduler",
            "DDIMScheduler",
            "DDPMScheduler",
            "HeunDiscreteScheduler",
            "DPMSolverMultistepScheduler",
            "DEISMultistepScheduler",
            "PNDMScheduler",
            "EulerAncestralDiscreteScheduler",
            "UniPCMultistepScheduler",
            "KDPM2DiscreteScheduler",
            "DPMSolverSinglestepScheduler",
            "KDPM2AncestralDiscreteScheduler"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionScheduler"
        },
        "default": "EulerDiscreteScheduler",
        "title": "Scheduler",
        "description": "The scheduler to use for the diffusion process.",
        "min": null,
        "max": null
      },
      {
        "name": "loras",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "hf.lora_sd_config",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Loras",
        "description": "The LoRA models to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_model",
        "type": {
          "type": "hf.ip_adapter",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.ip_adapter",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Ip Adapter Model",
        "description": "The IP adapter model to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Ip Adapter Image",
        "description": "When provided the image will be fed into the IP adapter",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Ip Adapter Scale",
        "description": "The strength of the IP adapter",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "detail_level",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Detail Level",
        "description": "Level of detail for the hi-res pass. 0.0 is low detail, 1.0 is high detail.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "enable_tiling",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Tiling",
        "description": "Enable tiling for the VAE. This can reduce VRAM usage.",
        "min": null,
        "max": null
      },
      {
        "name": "enable_cpu_offload",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Cpu Offload",
        "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage.",
        "min": null,
        "max": null
      },
      {
        "name": "upscaler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "None",
            "Latent",
            "Bicubic"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionUpscaler"
        },
        "default": "None",
        "title": "Upscaler",
        "description": "The upscaler to use for 2-pass generation.",
        "min": null,
        "max": null
      },
      {
        "name": "init_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Init Image",
        "description": "The initial image to be inpainted.",
        "min": null,
        "max": null
      },
      {
        "name": "mask_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask Image",
        "description": "The mask image indicating areas to be inpainted.",
        "min": null,
        "max": null
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Strength",
        "description": "Strength for inpainting. Higher values allow for more deviation from the original image.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_light.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_vit-G.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "SG161222/Realistic_Vision_V5.1_noVAE",
        "path": "Realistic_Vision_V5.1_fp16-no-ema.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "digiplay/majicMIX_realistic_v7",
        "path": "majicmixRealistic_v7.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "philz1337x/epicrealism",
        "path": "epicrealism_naturalSinRC1VAE.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/DreamShaper",
        "path": "DreamShaper_5_beta2_noVae_half_pruned.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/DreamShaper",
        "path": "DreamShaper_4BakedVae_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "XpucT/Deliberate",
        "path": "Deliberate_v6.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "XpucT/Deliberate",
        "path": "Deliberate_v6-inpainting.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/AbsoluteReality",
        "path": "AbsoluteReality_1.8.1_pruned.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/AbsoluteReality",
        "path": "AbsoluteReality_1.8.1_INPAINTING.inpainting.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "gsdf/Counterfeit-V2.5",
        "path": "Counterfeit-V2.5_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_light.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_vit-G.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "stabilityai/sd-x2-latent-upscaler",
        "path": null,
        "allow_patterns": [
          "README.md",
          "**/*.safetensors",
          "**/*.json",
          "**/*.txt",
          "*.json"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt",
      "init_image",
      "mask_image",
      "strength"
    ]
  },
  {
    "title": "Stable Diffusion ControlNet (Img2Img)",
    "description": "Transforms existing images using Stable Diffusion with ControlNet guidance.\n    image, generation, image-to-image, controlnet, SD\n\n    Use cases:\n    - Modify existing images with precise control over composition and structure\n    - Apply specific styles or concepts to photographs or artwork with guided transformations\n    - Create variations of existing visual content while maintaining certain features\n    - Enhance image editing capabilities with AI-guided transformations",
    "namespace": "huggingface.image_to_image",
    "node_type": "huggingface.image_to_image.StableDiffusionControlNetImg2Img",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.stable_diffusion",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.stable_diffusion",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The model to use for image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt for image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "(blurry, low quality, deformed, mutated, bad anatomy, extra limbs, bad proportions, text, watermark, grainy, pixelated, disfigured face, missing fingers, cropped image, bad lighting",
        "title": "Negative Prompt",
        "description": "The negative prompt to guide what should not appear in the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "Seed for the random number generator. Use -1 for a random seed.",
        "min": -1.0,
        "max": 4294967295.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Guidance scale for generation.",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DPMSolverSDEScheduler",
            "EulerDiscreteScheduler",
            "LMSDiscreteScheduler",
            "DDIMScheduler",
            "DDPMScheduler",
            "HeunDiscreteScheduler",
            "DPMSolverMultistepScheduler",
            "DEISMultistepScheduler",
            "PNDMScheduler",
            "EulerAncestralDiscreteScheduler",
            "UniPCMultistepScheduler",
            "KDPM2DiscreteScheduler",
            "DPMSolverSinglestepScheduler",
            "KDPM2AncestralDiscreteScheduler"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionScheduler"
        },
        "default": "EulerDiscreteScheduler",
        "title": "Scheduler",
        "description": "The scheduler to use for the diffusion process.",
        "min": null,
        "max": null
      },
      {
        "name": "loras",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "hf.lora_sd_config",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Loras",
        "description": "The LoRA models to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_model",
        "type": {
          "type": "hf.ip_adapter",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.ip_adapter",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Ip Adapter Model",
        "description": "The IP adapter model to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Ip Adapter Image",
        "description": "When provided the image will be fed into the IP adapter",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Ip Adapter Scale",
        "description": "The strength of the IP adapter",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "detail_level",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Detail Level",
        "description": "Level of detail for the hi-res pass. 0.0 is low detail, 1.0 is high detail.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "enable_tiling",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Tiling",
        "description": "Enable tiling for the VAE. This can reduce VRAM usage.",
        "min": null,
        "max": null
      },
      {
        "name": "enable_cpu_offload",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Cpu Offload",
        "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage.",
        "min": null,
        "max": null
      },
      {
        "name": "upscaler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "None",
            "Latent",
            "Bicubic"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionUpscaler"
        },
        "default": "None",
        "title": "Upscaler",
        "description": "The upscaler to use for 2-pass generation.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image to be transformed.",
        "min": null,
        "max": null
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Strength",
        "description": "Similarity to the input image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "controlnet",
        "type": {
          "type": "hf.controlnet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.controlnet",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Controlnet",
        "description": "The ControlNet model to use for guidance.",
        "min": null,
        "max": null
      },
      {
        "name": "control_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Control Image",
        "description": "The control image to guide the transformation.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_canny",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_inpaint",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_mlsd",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_tile",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_shuffle",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_ip2p",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_lineart",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_lineart_anime",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_scribble",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_openpose",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_scribble",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_seg",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_hed",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_normalbae",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_light.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_vit-G.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "SG161222/Realistic_Vision_V5.1_noVAE",
        "path": "Realistic_Vision_V5.1_fp16-no-ema.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "digiplay/majicMIX_realistic_v7",
        "path": "majicmixRealistic_v7.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "philz1337x/epicrealism",
        "path": "epicrealism_naturalSinRC1VAE.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/DreamShaper",
        "path": "DreamShaper_5_beta2_noVae_half_pruned.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/DreamShaper",
        "path": "DreamShaper_4BakedVae_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "XpucT/Deliberate",
        "path": "Deliberate_v6.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "XpucT/Deliberate",
        "path": "Deliberate_v6-inpainting.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/AbsoluteReality",
        "path": "AbsoluteReality_1.8.1_pruned.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/AbsoluteReality",
        "path": "AbsoluteReality_1.8.1_INPAINTING.inpainting.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "gsdf/Counterfeit-V2.5",
        "path": "Counterfeit-V2.5_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_light.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_vit-G.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "stabilityai/sd-x2-latent-upscaler",
        "path": null,
        "allow_patterns": [
          "README.md",
          "**/*.safetensors",
          "**/*.json",
          "**/*.txt",
          "*.json"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt",
      "image",
      "controlnet",
      "control_image"
    ]
  },
  {
    "title": "Stable Diffusion 4x Upscale",
    "description": "Upscales an image using Stable Diffusion 4x upscaler.\n    image, upscaling, stable-diffusion, SD\n\n    Use cases:\n    - Enhance low-resolution images\n    - Improve image quality for printing or display\n    - Create high-resolution versions of small images",
    "namespace": "huggingface.image_to_image",
    "node_type": "huggingface.image_to_image.StableDiffusionUpscale",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt for image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "The negative prompt to guide what should not appear in the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Inference Steps",
        "description": "Number of upscaling steps.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Guidance scale for generation.",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The initial image for Image-to-Image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DPMSolverSDEScheduler",
            "EulerDiscreteScheduler",
            "LMSDiscreteScheduler",
            "DDIMScheduler",
            "DDPMScheduler",
            "HeunDiscreteScheduler",
            "DPMSolverMultistepScheduler",
            "DEISMultistepScheduler",
            "PNDMScheduler",
            "EulerAncestralDiscreteScheduler",
            "UniPCMultistepScheduler",
            "KDPM2DiscreteScheduler",
            "DPMSolverSinglestepScheduler",
            "KDPM2AncestralDiscreteScheduler"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionScheduler"
        },
        "default": "HeunDiscreteScheduler",
        "title": "Scheduler",
        "description": "The scheduler to use for the diffusion process.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "Seed for the random number generator. Use -1 for a random seed.",
        "min": -1.0,
        "max": 4294967295.0
      },
      {
        "name": "enable_tiling",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Tiling",
        "description": "Enable tiling to save VRAM",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.stable_diffusion_upscale",
        "repo_id": "stabilityai/stable-diffusion-x4-upscaler",
        "path": null,
        "allow_patterns": [
          "README.md",
          "**/*.fp16.safetensors",
          "**/*.json",
          "**/*.txt",
          "*.json"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "prompt",
      "negative_prompt",
      "image"
    ]
  },
  {
    "title": "Stable Diffusion XL (Img2Img)",
    "description": "Transforms existing images based on text prompts using Stable Diffusion XL.\n    image, generation, image-to-image, SDXL\n\n    Use cases:\n    - Modifying existing images to fit a specific style or theme\n    - Enhancing or altering photographs\n    - Creating variations of existing artwork\n    - Applying text-guided edits to images",
    "namespace": "huggingface.image_to_image",
    "node_type": "huggingface.image_to_image.StableDiffusionXLImg2Img",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.stable_diffusion_xl",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The Stable Diffusion XL model to use for generation.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt for image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "The negative prompt to guide what should not appear in the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "Seed for the random number generator.",
        "min": -1.0,
        "max": 1000000.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Inference Steps",
        "description": "Number of inference steps.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.0,
        "title": "Guidance Scale",
        "description": "Guidance scale for generation.",
        "min": 0.0,
        "max": 20.0
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "Width of the generated image.",
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "Height of the generated image",
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DPMSolverSDEScheduler",
            "EulerDiscreteScheduler",
            "LMSDiscreteScheduler",
            "DDIMScheduler",
            "DDPMScheduler",
            "HeunDiscreteScheduler",
            "DPMSolverMultistepScheduler",
            "DEISMultistepScheduler",
            "PNDMScheduler",
            "EulerAncestralDiscreteScheduler",
            "UniPCMultistepScheduler",
            "KDPM2DiscreteScheduler",
            "DPMSolverSinglestepScheduler",
            "KDPM2AncestralDiscreteScheduler"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionScheduler"
        },
        "default": "EulerDiscreteScheduler",
        "title": "Scheduler",
        "description": "The scheduler to use for the diffusion process.",
        "min": null,
        "max": null
      },
      {
        "name": "loras",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "hf.lora_sdxl_config",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Loras",
        "description": "The LoRA models to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Lora Scale",
        "description": "Strength of the LoRAs",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "ip_adapter_model",
        "type": {
          "type": "hf.ip_adapter",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.ip_adapter",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Ip Adapter Model",
        "description": "The IP adapter model to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Ip Adapter Image",
        "description": "When provided the image will be fed into the IP adapter",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Ip Adapter Scale",
        "description": "Strength of the IP adapter image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "enable_tiling",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Tiling",
        "description": "Enable tiling for the VAE. This can reduce VRAM usage.",
        "min": null,
        "max": null
      },
      {
        "name": "enable_cpu_offload",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Cpu Offload",
        "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage.",
        "min": null,
        "max": null
      },
      {
        "name": "init_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Init Image",
        "description": "The initial image for Image-to-Image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Strength",
        "description": "Strength for Image-to-Image generation. Higher values allow for more deviation from the original image.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "sdxl_models/ip-adapter_sdxl.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "sdxl_models/ip-adapter_sdxl_vit-h.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "sdxl_models/ip-adapter-plus_sdxl_vit-h.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "stabilityai/stable-diffusion-xl-base-1.0",
        "path": "sd_xl_base_1.0.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "stabilityai/stable-diffusion-xl-refiner-1.0",
        "path": "sd_xl_refiner_1.0.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "playgroundai/playground-v2.5-1024px-aesthetic",
        "path": "playground-v2.5-1024px-aesthetic.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "RunDiffusion/Juggernaut-XL-v9",
        "path": "Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "dataautogpt3/ProteusV0.5",
        "path": "proteusV0.5.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "Lykon/dreamshaper-xl-lightning",
        "path": "DreamShaperXL_Lightning.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "Lykon/AAM_XL_AnimeMix",
        "path": "AAM_XL_Anime_Mix.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "stabilityai/sdxl-turbo",
        "path": "sd_xl_turbo_1.0_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "Lykon/dreamshaper-xl-v2-turbo",
        "path": "DreamShaperXL_Turbo_v2_1.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt",
      "width",
      "height",
      "init_image",
      "strength"
    ]
  },
  {
    "title": "Stable Diffusion XL (Inpaint)",
    "description": "Performs inpainting on images using Stable Diffusion XL.\n    image, inpainting, SDXL\n\n    Use cases:\n    - Remove unwanted objects from images\n    - Fill in missing parts of images\n    - Modify specific areas of images while preserving the rest",
    "namespace": "huggingface.image_to_image",
    "node_type": "huggingface.image_to_image.StableDiffusionXLInpainting",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.stable_diffusion_xl",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The Stable Diffusion XL model to use for generation.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt for image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "The negative prompt to guide what should not appear in the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "Seed for the random number generator.",
        "min": -1.0,
        "max": 1000000.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Inference Steps",
        "description": "Number of inference steps.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.0,
        "title": "Guidance Scale",
        "description": "Guidance scale for generation.",
        "min": 0.0,
        "max": 20.0
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "Width of the generated image.",
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "Height of the generated image",
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DPMSolverSDEScheduler",
            "EulerDiscreteScheduler",
            "LMSDiscreteScheduler",
            "DDIMScheduler",
            "DDPMScheduler",
            "HeunDiscreteScheduler",
            "DPMSolverMultistepScheduler",
            "DEISMultistepScheduler",
            "PNDMScheduler",
            "EulerAncestralDiscreteScheduler",
            "UniPCMultistepScheduler",
            "KDPM2DiscreteScheduler",
            "DPMSolverSinglestepScheduler",
            "KDPM2AncestralDiscreteScheduler"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionScheduler"
        },
        "default": "EulerDiscreteScheduler",
        "title": "Scheduler",
        "description": "The scheduler to use for the diffusion process.",
        "min": null,
        "max": null
      },
      {
        "name": "loras",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "hf.lora_sdxl_config",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Loras",
        "description": "The LoRA models to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Lora Scale",
        "description": "Strength of the LoRAs",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "ip_adapter_model",
        "type": {
          "type": "hf.ip_adapter",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.ip_adapter",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Ip Adapter Model",
        "description": "The IP adapter model to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Ip Adapter Image",
        "description": "When provided the image will be fed into the IP adapter",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Ip Adapter Scale",
        "description": "Strength of the IP adapter image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "enable_tiling",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Tiling",
        "description": "Enable tiling for the VAE. This can reduce VRAM usage.",
        "min": null,
        "max": null
      },
      {
        "name": "enable_cpu_offload",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Cpu Offload",
        "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The initial image to be inpainted.",
        "min": null,
        "max": null
      },
      {
        "name": "mask_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask Image",
        "description": "The mask image indicating areas to be inpainted.",
        "min": null,
        "max": null
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Strength",
        "description": "Strength for inpainting. Higher values allow for more deviation from the original image.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "sdxl_models/ip-adapter_sdxl.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "sdxl_models/ip-adapter_sdxl_vit-h.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "sdxl_models/ip-adapter-plus_sdxl_vit-h.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "stabilityai/stable-diffusion-xl-base-1.0",
        "path": "sd_xl_base_1.0.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "stabilityai/stable-diffusion-xl-refiner-1.0",
        "path": "sd_xl_refiner_1.0.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "playgroundai/playground-v2.5-1024px-aesthetic",
        "path": "playground-v2.5-1024px-aesthetic.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "RunDiffusion/Juggernaut-XL-v9",
        "path": "Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "dataautogpt3/ProteusV0.5",
        "path": "proteusV0.5.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "Lykon/dreamshaper-xl-lightning",
        "path": "DreamShaperXL_Lightning.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "Lykon/AAM_XL_AnimeMix",
        "path": "AAM_XL_Anime_Mix.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "stabilityai/sdxl-turbo",
        "path": "sd_xl_turbo_1.0_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "Lykon/dreamshaper-xl-v2-turbo",
        "path": "DreamShaperXL_Turbo_v2_1.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt",
      "width",
      "height",
      "image",
      "mask_image",
      "strength"
    ]
  },
  {
    "title": "Stable Diffusion XL ControlNet",
    "description": "Transforms existing images using Stable Diffusion XL with ControlNet guidance.\n    image, generation, image-to-image, controlnet, SDXL\n\n    Use cases:\n    - Modify existing images with precise control over composition and structure\n    - Apply specific styles or concepts to photographs or artwork with guided transformations\n    - Create variations of existing visual content while maintaining certain features\n    - Enhance image editing capabilities with AI-guided transformations",
    "namespace": "huggingface.image_to_image",
    "node_type": "huggingface.image_to_image.StableDiffusionXLControlNet",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.stable_diffusion_xl",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The Stable Diffusion XL model to use for generation.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt for image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "The negative prompt to guide what should not appear in the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "Seed for the random number generator.",
        "min": -1.0,
        "max": 1000000.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Inference Steps",
        "description": "Number of inference steps.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.0,
        "title": "Guidance Scale",
        "description": "Guidance scale for generation.",
        "min": 0.0,
        "max": 20.0
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "Width of the generated image.",
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "Height of the generated image",
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DPMSolverSDEScheduler",
            "EulerDiscreteScheduler",
            "LMSDiscreteScheduler",
            "DDIMScheduler",
            "DDPMScheduler",
            "HeunDiscreteScheduler",
            "DPMSolverMultistepScheduler",
            "DEISMultistepScheduler",
            "PNDMScheduler",
            "EulerAncestralDiscreteScheduler",
            "UniPCMultistepScheduler",
            "KDPM2DiscreteScheduler",
            "DPMSolverSinglestepScheduler",
            "KDPM2AncestralDiscreteScheduler"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionScheduler"
        },
        "default": "EulerDiscreteScheduler",
        "title": "Scheduler",
        "description": "The scheduler to use for the diffusion process.",
        "min": null,
        "max": null
      },
      {
        "name": "loras",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "hf.lora_sdxl_config",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Loras",
        "description": "The LoRA models to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Lora Scale",
        "description": "Strength of the LoRAs",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "ip_adapter_model",
        "type": {
          "type": "hf.ip_adapter",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.ip_adapter",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Ip Adapter Model",
        "description": "The IP adapter model to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Ip Adapter Image",
        "description": "When provided the image will be fed into the IP adapter",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Ip Adapter Scale",
        "description": "Strength of the IP adapter image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "enable_tiling",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Tiling",
        "description": "Enable tiling for the VAE. This can reduce VRAM usage.",
        "min": null,
        "max": null
      },
      {
        "name": "enable_cpu_offload",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Cpu Offload",
        "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage.",
        "min": null,
        "max": null
      },
      {
        "name": "init_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Init Image",
        "description": "The initial image for Image-to-Image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Strength",
        "description": "Strength for Image-to-Image generation. Higher values allow for more deviation from the original image.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "controlnet",
        "type": {
          "type": "hf.controlnet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.controlnet",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Controlnet",
        "description": "The ControlNet model to use for guidance.",
        "min": null,
        "max": null
      },
      {
        "name": "control_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Control Image",
        "description": "The control image to guide the transformation.",
        "min": null,
        "max": null
      },
      {
        "name": "controlnet_conditioning_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Controlnet Conditioning Scale",
        "description": "The scale for ControlNet conditioning.",
        "min": 0.0,
        "max": 2.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "sdxl_models/ip-adapter_sdxl.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "sdxl_models/ip-adapter_sdxl_vit-h.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "sdxl_models/ip-adapter-plus_sdxl_vit-h.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "stabilityai/stable-diffusion-xl-base-1.0",
        "path": "sd_xl_base_1.0.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "stabilityai/stable-diffusion-xl-refiner-1.0",
        "path": "sd_xl_refiner_1.0.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "playgroundai/playground-v2.5-1024px-aesthetic",
        "path": "playground-v2.5-1024px-aesthetic.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "RunDiffusion/Juggernaut-XL-v9",
        "path": "Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "dataautogpt3/ProteusV0.5",
        "path": "proteusV0.5.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "Lykon/dreamshaper-xl-lightning",
        "path": "DreamShaperXL_Lightning.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "Lykon/AAM_XL_AnimeMix",
        "path": "AAM_XL_Anime_Mix.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "stabilityai/sdxl-turbo",
        "path": "sd_xl_turbo_1.0_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "Lykon/dreamshaper-xl-v2-turbo",
        "path": "DreamShaperXL_Turbo_v2_1.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt",
      "width",
      "height",
      "init_image",
      "strength",
      "controlnet",
      "control_image",
      "controlnet_conditioning_scale"
    ]
  },
  {
    "title": "LoRA Selector",
    "description": "Selects up to 5 LoRA models to apply to a Stable Diffusion model.\n    lora, model customization, fine-tuning, SD\n\n    Use cases:\n    - Combining multiple LoRA models for unique image styles\n    - Fine-tuning Stable Diffusion models with specific attributes\n    - Experimenting with different LoRA combinations",
    "namespace": "huggingface.lora",
    "node_type": "huggingface.lora.LoRASelector",
    "layout": "default",
    "properties": [
      {
        "name": "lora1",
        "type": {
          "type": "hf.lora_sd",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.lora_sd",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Lora1",
        "description": "First LoRA model",
        "min": null,
        "max": null
      },
      {
        "name": "strength1",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength1",
        "description": "Strength for first LoRA",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "lora2",
        "type": {
          "type": "hf.lora_sd",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.lora_sd",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Lora2",
        "description": "Second LoRA model",
        "min": null,
        "max": null
      },
      {
        "name": "strength2",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength2",
        "description": "Strength for second LoRA",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "lora3",
        "type": {
          "type": "hf.lora_sd",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.lora_sd",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Lora3",
        "description": "Third LoRA model",
        "min": null,
        "max": null
      },
      {
        "name": "strength3",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength3",
        "description": "Strength for third LoRA",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "lora4",
        "type": {
          "type": "hf.lora_sd",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.lora_sd",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Lora4",
        "description": "Fourth LoRA model",
        "min": null,
        "max": null
      },
      {
        "name": "strength4",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength4",
        "description": "Strength for fourth LoRA",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "lora5",
        "type": {
          "type": "hf.lora_sd",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.lora_sd",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Lora5",
        "description": "Fifth LoRA model",
        "min": null,
        "max": null
      },
      {
        "name": "strength5",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength5",
        "description": "Strength for fifth LoRA",
        "min": 0.0,
        "max": 2.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "hf.lora_sd_config",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "2d_sprite.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "ghibli_scenery.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "add_detail.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "colorwater.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "sxz_game_assets.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "3Danaglyph.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "akiratoriyama_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "animeoutlineV4.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "aqua_konosuba.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "arakihirohiko_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "arcane_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "canetaazul.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "cyberpunk_tarot.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "discoelysium_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "esdeath_akamegakill.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "fire_vfx.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "flamingeye.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "funnycreatures.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "gacha_splash.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "gigachad.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "gyokai_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "harold.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "hiderohoribes_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "ilyakuvshinov_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "jacksparrow.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "jimlee_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "komowataharuka_chibiart.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "lightning_vfx.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "lucy_cyberpunk.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "luisap_pixelart.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "mumei_kabaneri.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "myheroacademia_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "neoartcore.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "ochakouraraka.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "onepiece_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "paimon_genshinimpact.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "peanutscomics_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "pepefrog.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "persona5_portraits.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "persona5_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "pixhell.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "princesszelda.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "satoshiuruchihara_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "shinobu_demonslayer.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "sokolov_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "standingbackgroundv1.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "sun_shadow_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "thickeranimelines.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "threesidedview.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "twitch_emotes.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "water_vfx.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "wlop_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "zerotwo_darling.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "lora1",
      "strength1",
      "lora2",
      "strength2",
      "lora3",
      "strength3",
      "lora4",
      "strength4",
      "lora5",
      "strength5"
    ]
  },
  {
    "title": "LoRA XL Selector",
    "description": "Selects up to 5 LoRA models to apply to a Stable Diffusion XL model.\n    lora, model customization, fine-tuning, SDXL\n\n    Use cases:\n    - Combining multiple LoRA models for unique image styles\n    - Fine-tuning Stable Diffusion XL models with specific attributes\n    - Experimenting with different LoRA combinations",
    "namespace": "huggingface.lora",
    "node_type": "huggingface.lora.LoRASelectorXL",
    "layout": "default",
    "properties": [
      {
        "name": "lora1",
        "type": {
          "type": "hf.lora_sdxl",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.lora_sdxl",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Lora1",
        "description": "First LoRA model",
        "min": null,
        "max": null
      },
      {
        "name": "strength1",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength1",
        "description": "Strength for first LoRA",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "lora2",
        "type": {
          "type": "hf.lora_sdxl",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.lora_sdxl",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Lora2",
        "description": "Second LoRA model",
        "min": null,
        "max": null
      },
      {
        "name": "strength2",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength2",
        "description": "Strength for second LoRA",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "lora3",
        "type": {
          "type": "hf.lora_sdxl",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.lora_sdxl",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Lora3",
        "description": "Third LoRA model",
        "min": null,
        "max": null
      },
      {
        "name": "strength3",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength3",
        "description": "Strength for third LoRA",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "lora4",
        "type": {
          "type": "hf.lora_sdxl",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.lora_sdxl",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Lora4",
        "description": "Fourth LoRA model",
        "min": null,
        "max": null
      },
      {
        "name": "strength4",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength4",
        "description": "Strength for fourth LoRA",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "lora5",
        "type": {
          "type": "hf.lora_sdxl",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.lora_sdxl",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Lora5",
        "description": "Fifth LoRA model",
        "min": null,
        "max": null
      },
      {
        "name": "strength5",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength5",
        "description": "Strength for fifth LoRA",
        "min": 0.0,
        "max": 2.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "hf.lora_sdxl_config",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.lora_sdxl",
        "repo_id": "CiroN2022/toy-face",
        "path": "toy_face_sdxl.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sdxl",
        "repo_id": "nerijs/pixel-art-xl",
        "path": "pixel-art-xl.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sdxl",
        "repo_id": "goofyai/3d_render_style_xl",
        "path": "3d_render_style_xl.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sdxl",
        "repo_id": "artificialguybr/CuteCartoonRedmond-V2",
        "path": "CuteCartoonRedmond-CuteCartoon-CuteCartoonAF.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sdxl",
        "repo_id": "blink7630/graphic-novel-illustration",
        "path": "Graphic_Novel_Illustration-000007.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sdxl",
        "repo_id": "robert123231/coloringbookgenerator",
        "path": "ColoringBookRedmond-ColoringBook-ColoringBookAF.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sdxl",
        "repo_id": "Linaqruf/anime-detailer-xl-lora",
        "path": "anime-detailer-xl-lora.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "lora1",
      "strength1",
      "lora2",
      "strength2",
      "lora3",
      "strength3",
      "lora4",
      "strength4",
      "lora5",
      "strength5"
    ]
  },
  {
    "title": "Image To Text",
    "description": "Generates text descriptions from images.\n    image, text, captioning, vision-language\n\n    Use cases:\n    - Automatic image captioning\n    - Assisting visually impaired users\n    - Enhancing image search capabilities\n    - Generating alt text for web images",
    "namespace": "huggingface.multimodal",
    "node_type": "huggingface.multimodal.ImageToText",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.image_to_text",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.image_to_text",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for image-to-text generation",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Input Image",
        "description": "The image to generate text from",
        "min": null,
        "max": null
      },
      {
        "name": "max_new_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Max New Tokens",
        "description": "The maximum number of tokens to generate",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.image_to_text",
        "repo_id": "Salesforce/blip-image-captioning-base",
        "path": null,
        "allow_patterns": [
          "*.bin",
          "*.json",
          "*.txt    "
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.image_to_text",
        "repo_id": "Salesforce/blip-image-captioning-large",
        "path": null,
        "allow_patterns": [
          "*.bin",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.image_to_text",
        "repo_id": "nlpconnect/vit-gpt2-image-captioning",
        "path": null,
        "allow_patterns": [
          "*.bin",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.image_to_text",
        "repo_id": "microsoft/git-base-coco",
        "path": null,
        "allow_patterns": [
          "*.bin",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "image",
      "max_new_tokens"
    ]
  },
  {
    "title": "Visual Question Answering",
    "description": "Answers questions about images.\n    image, text, question answering, multimodal\n\n    Use cases:\n    - Image content analysis\n    - Automated image captioning\n    - Visual information retrieval\n    - Accessibility tools for visually impaired users",
    "namespace": "huggingface.multimodal",
    "node_type": "huggingface.multimodal.VisualQuestionAnswering",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.visual_question_answering",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.visual_question_answering",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for visual question answering",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to analyze",
        "min": null,
        "max": null
      },
      {
        "name": "question",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Question",
        "description": "The question to be answered about the image",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.visual_question_answering",
        "repo_id": "Salesforce/blip-vqa-base",
        "path": null,
        "allow_patterns": [
          "*.bin",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "image",
      "question"
    ]
  },
  {
    "title": "GOTOCR",
    "description": "Performs OCR on images using the GOT-OCR model.\n    image, text, OCR, multimodal\n\n    Use cases:\n    - Text extraction from images\n    - Document digitization\n    - Image-based information retrieval\n    - Accessibility tools for visually impaired users",
    "namespace": "huggingface.multimodal",
    "node_type": "huggingface.multimodal.GOTOCR",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.gotocr",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.gotocr",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for GOT-OCR",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to perform OCR on",
        "min": null,
        "max": null
      },
      {
        "name": "ocr_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "ocr",
            "format"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.multimodal.OCRType"
        },
        "default": "ocr",
        "title": "OCR Type",
        "description": "The type of OCR to perform",
        "min": null,
        "max": null
      },
      {
        "name": "ocr_box",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "OCR Box",
        "description": "Bounding box for fine-grained OCR (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "ocr_color",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "OCR Color",
        "description": "Color for fine-grained OCR (optional)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.gotocr",
        "repo_id": "ucaslcl/GOT-OCR2_0",
        "path": null,
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "image"
    ]
  },
  {
    "title": "Object Detection",
    "description": "Detects and localizes objects in images.\n    image, object detection, bounding boxes, huggingface\n\n    Use cases:\n    - Identify and count objects in images\n    - Locate specific items in complex scenes\n    - Assist in autonomous vehicle vision systems\n    - Enhance security camera footage analysis\n\n    Recommended models:\n    - facebook/detr-resnet-50",
    "namespace": "huggingface.object_detection",
    "node_type": "huggingface.object_detection.ObjectDetection",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.object_detection",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.object_detection",
          "repo_id": "facebook/detr-resnet-50",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for object detection",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Inputs",
        "description": "The input image for object detection",
        "min": null,
        "max": null
      },
      {
        "name": "threshold",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.9,
        "title": "Confidence Threshold",
        "description": "Minimum confidence score for detected objects",
        "min": null,
        "max": null
      },
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5,
        "title": "Top K",
        "description": "The number of top predictions to return",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "object_detection_result",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.object_detection",
        "repo_id": "facebook/detr-resnet-50",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.bin",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.object_detection",
        "repo_id": "facebook/detr-resnet-101",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.safetensors",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.object_detection",
        "repo_id": "hustvl/yolos-tiny",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.safetensors",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.object_detection",
        "repo_id": "hustvl/yolos-small",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.safetensors",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.object_detection",
        "repo_id": "microsoft/table-transformer-detection",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.bin",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.object_detection",
        "repo_id": "microsoft/table-transformer-structure-recognition-v1.1-all",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.bin",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.object_detection",
        "repo_id": "valentinafeve/yolos-fashionpedia",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.bin",
          "*.json",
          "**/*.json"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "image"
    ]
  },
  {
    "title": "Visualize Object Detection",
    "description": "Visualizes object detection results on images.\n    image, object detection, bounding boxes, visualization, mask",
    "namespace": "huggingface.object_detection",
    "node_type": "huggingface.object_detection.VisualizeObjectDetection",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image to visualize",
        "min": null,
        "max": null
      },
      {
        "name": "objects",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "object_detection_result",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": {},
        "title": "Detected Objects",
        "description": "The detected objects to visualize",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "objects"
    ]
  },
  {
    "title": "Zero-Shot Object Detection",
    "description": "Detects objects in images without the need for training data.\n    image, object detection, bounding boxes, zero-shot, mask\n\n    Use cases:\n    - Quickly detect objects in images without training data\n    - Identify objects in images without predefined labels\n    - Automate object detection for large datasets\n\n    Recommended models:\n    - google/owlvit-base-patch32\n    - google/owlvit-large-patch14\n    - google/owlvit-base-patch16\n    - google/owlv2-base-patch16\n    - google/owlv2-base-patch16-ensemble\n    - IDEA-Research/grounding-dino-tiny",
    "namespace": "huggingface.object_detection",
    "node_type": "huggingface.object_detection.ZeroShotObjectDetection",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.zero_shot_object_detection",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.zero_shot_object_detection",
          "repo_id": "google/owlv2-base-patch16",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for object detection",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Inputs",
        "description": "The input image for object detection",
        "min": null,
        "max": null
      },
      {
        "name": "threshold",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.1,
        "title": "Confidence Threshold",
        "description": "Minimum confidence score for detected objects",
        "min": null,
        "max": null
      },
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5,
        "title": "Top K",
        "description": "The number of top predictions to return",
        "min": null,
        "max": null
      },
      {
        "name": "candidate_labels",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Candidate Labels",
        "description": "The candidate labels to detect in the image, separated by commas",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "object_detection_result",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.zero_shot_object_detection",
        "repo_id": "google/owlvit-base-patch32",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.bin",
          "*.json",
          "**/*.json",
          "txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.zero_shot_object_detection",
        "repo_id": "google/owlvit-large-patch14",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.bin",
          "*.json",
          "**/*.json",
          "txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.zero_shot_object_detection",
        "repo_id": "google/owlvit-base-patch16",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.bin",
          "*.json",
          "**/*.json",
          "txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.zero_shot_object_detection",
        "repo_id": "google/owlv2-base-patch16",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.bin",
          "*.json",
          "**/*.json",
          "txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.zero_shot_object_detection",
        "repo_id": "google/owlv2-base-patch16-ensemble",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.bin",
          "*.json",
          "**/*.json",
          "txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.zero_shot_object_detection",
        "repo_id": "IDEA-Research/grounding-dino-tiny",
        "path": null,
        "allow_patterns": [
          "README.md",
          "*.bin",
          "*.json",
          "**/*.json",
          "txt"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "image",
      "threshold",
      "top_k",
      "candidate_labels"
    ]
  },
  {
    "title": "Reranker",
    "description": "Reranks pairs of text based on their semantic similarity.\n    text, ranking, reranking, natural language processing\n\n    Use cases:\n    - Improve search results ranking\n    - Question-answer pair scoring\n    - Document relevance ranking",
    "namespace": "huggingface.ranking",
    "node_type": "huggingface.ranking.Reranker",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.reranker",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.reranker",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for reranking",
        "min": null,
        "max": null
      },
      {
        "name": "query",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Query Text",
        "description": "The query text to compare against candidates",
        "min": null,
        "max": null
      },
      {
        "name": "candidates",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Candidate Texts",
        "description": "List of candidate texts to rank",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.reranker",
        "repo_id": "BAAI/bge-reranker-v2-m3",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.txt",
          "*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.reranker",
        "repo_id": "BAAI/bge-reranker-base",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.txt",
          "*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.reranker",
        "repo_id": "BAAI/bge-reranker-large",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.txt",
          "*.json"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "query",
      "candidates"
    ]
  },
  {
    "title": "Sentence Similarity",
    "description": "Compares the similarity between two sentences.\n    text, sentence similarity, embeddings, natural language processing\n\n    Use cases:\n    - Duplicate detection in text data\n    - Semantic search\n    - Sentiment analysis",
    "namespace": "huggingface.sentence_similarity",
    "node_type": "huggingface.sentence_similarity.SentenceSimilarity",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.sentence_similarity",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.sentence_similarity",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for sentence similarity",
        "min": null,
        "max": null
      },
      {
        "name": "inputs",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Input Text",
        "description": "The text to compare",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.sentence_similarity",
        "repo_id": "sentence-transformers/all-mpnet-base-v2",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.txt",
          "*,json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.sentence_similarity",
        "repo_id": "sentence-transformers/all-MiniLM-L6-v2",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.txt",
          "*,json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.sentence_similarity",
        "repo_id": "BAAI/bge-m3",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.txt",
          "*,json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.sentence_similarity",
        "repo_id": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.txt",
          "*,json"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "inputs"
    ]
  },
  {
    "title": "Summarize",
    "description": "Summarizes text using a Hugging Face model.\n    text, summarization, AI, LLM",
    "namespace": "huggingface.summarization",
    "node_type": "huggingface.summarization.Summarize",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.text_generation",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.text_generation",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for the text generation",
        "min": null,
        "max": null
      },
      {
        "name": "inputs",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Inputs",
        "description": "The input text to summarize",
        "min": null,
        "max": null
      },
      {
        "name": "max_length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Max Length",
        "description": "The maximum length of the generated text",
        "min": null,
        "max": null
      },
      {
        "name": "do_sample",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Do Sample",
        "description": "Whether to sample from the model",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.text_generation",
        "repo_id": "Falconsai/text_summarization",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.text_generation",
        "repo_id": "Falconsai/medical_summarization",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.text_generation",
        "repo_id": "imvladikon/het5_summarization",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "inputs"
    ]
  },
  {
    "title": "Music Gen",
    "description": "Generates audio (music or sound effects) from text descriptions.\n    audio, music, generation, huggingface\n\n    Use cases:\n    - Create custom background music for videos or games\n    - Generate sound effects based on textual descriptions\n    - Prototype musical ideas quickly",
    "namespace": "huggingface.text_to_audio",
    "node_type": "huggingface.text_to_audio.MusicGen",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.text_to_audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.text_to_audio",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for the audio generation",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Inputs",
        "description": "The input text to the model",
        "min": null,
        "max": null
      },
      {
        "name": "max_new_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Max New Tokens",
        "description": "The maximum number of tokens to generate",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.text_to_audio",
        "repo_id": "facebook/musicgen-small",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.json",
          "*.model"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.text_to_audio",
        "repo_id": "facebook/musicgen-medium",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.json",
          "*.model"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.text_to_audio",
        "repo_id": "facebook/musicgen-large",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.json",
          "*.model"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.text_to_audio",
        "repo_id": "facebook/musicgen-melody",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.json",
          "*.model"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.text_to_audio",
        "repo_id": "facebook/musicgen-stereo-small",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.json",
          "*.model"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.text_to_audio",
        "repo_id": "facebook/musicgen-stereo-large",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.json",
          "*.model"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt"
    ]
  },
  {
    "title": "Music LDM",
    "description": "Generates audio (music or sound effects) from text descriptions.\n    audio, music, generation, huggingface\n\n    Use cases:\n    - Create custom background music for videos or games\n    - Generate sound effects based on textual descriptions\n    - Prototype musical ideas quickly",
    "namespace": "huggingface.text_to_audio",
    "node_type": "huggingface.text_to_audio.MusicLDM",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.text_to_audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.text_to_audio",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for the audio generation",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Inputs",
        "description": "The input text to the model",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10,
        "title": "Number of Inference Steps",
        "description": "The number of inference steps to use for the generation",
        "min": null,
        "max": null
      },
      {
        "name": "audio_length_in_s",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5.0,
        "title": "Audio Length",
        "description": "The length of the generated audio in seconds",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.text_to_audio",
        "repo_id": "ucsd-reach/musicldm",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt"
    ]
  },
  {
    "title": "Audio LDM",
    "description": "Generates audio using the AudioLDM model based on text prompts.\n    audio, generation, AI, text-to-audio\n\n    Use cases:\n    - Create custom music or sound effects from text descriptions\n    - Generate background audio for videos, games, or other media\n    - Produce audio content for creative projects\n    - Explore AI-generated audio for music production or sound design",
    "namespace": "huggingface.text_to_audio",
    "node_type": "huggingface.text_to_audio.AudioLDM",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Techno music with a strong, upbeat tempo and high melodic riffs",
        "title": "Prompt",
        "description": "A text prompt describing the desired audio.",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. More steps generally improve quality but increase generation time.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "audio_length_in_s",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5.0,
        "title": "Audio Length In S",
        "description": "The desired duration of the generated audio in seconds.",
        "min": 1.0,
        "max": 30.0
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Seed",
        "description": "Seed for the random number generator. Use -1 for a random seed.",
        "min": -1.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.text_to_audio",
        "repo_id": "cvssp/audioldm-s-full-v2",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt"
    ]
  },
  {
    "title": "Audio LDM 2",
    "description": "Generates audio using the AudioLDM2 model based on text prompts.\n    audio, generation, AI, text-to-audio\n\n    Use cases:\n    - Create custom sound effects based on textual descriptions\n    - Generate background audio for videos or games\n    - Produce audio content for multimedia projects\n    - Explore AI-generated audio for creative sound design",
    "namespace": "huggingface.text_to_audio",
    "node_type": "huggingface.text_to_audio.AudioLDM2",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "The sound of a hammer hitting a wooden surface.",
        "title": "Prompt",
        "description": "A text prompt describing the desired audio.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Low quality.",
        "title": "Negative Prompt",
        "description": "A text prompt describing what you don't want in the audio.",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 200,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. More steps generally improve quality but increase generation time.",
        "min": 50.0,
        "max": 500.0
      },
      {
        "name": "audio_length_in_s",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10.0,
        "title": "Audio Length In S",
        "description": "The desired duration of the generated audio in seconds.",
        "min": 1.0,
        "max": 30.0
      },
      {
        "name": "num_waveforms_per_prompt",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Num Waveforms Per Prompt",
        "description": "Number of audio samples to generate per prompt.",
        "min": 1.0,
        "max": 5.0
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Seed",
        "description": "Seed for the random number generator. Use -1 for a random seed.",
        "min": -1.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.text_to_audio",
        "repo_id": "cvssp/audioldm2",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt"
    ]
  },
  {
    "title": "Dance Diffusion",
    "description": "Generates audio using the DanceDiffusion model.\n    audio, generation, AI, music\n\n    Use cases:\n    - Create AI-generated music samples\n    - Produce background music for videos or games\n    - Generate audio content for creative projects\n    - Explore AI-composed musical ideas",
    "namespace": "huggingface.text_to_audio",
    "node_type": "huggingface.text_to_audio.DanceDiffusion",
    "layout": "default",
    "properties": [
      {
        "name": "audio_length_in_s",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4.0,
        "title": "Audio Length In S",
        "description": "The desired duration of the generated audio in seconds.",
        "min": 1.0,
        "max": 30.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. More steps generally improve quality but increase generation time.",
        "min": 1.0,
        "max": 1000.0
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Seed",
        "description": "Seed for the random number generator. Use -1 for a random seed.",
        "min": -1.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.text_to_audio",
        "repo_id": "harmonai/maestro-150k",
        "path": null,
        "allow_patterns": [
          "*.bin",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt"
    ]
  },
  {
    "title": "Stable Audio",
    "description": "Generates audio using the Stable Audio Pipeline based on a text prompt.\n    audio, generation, AI, text-to-audio\n\n    Use cases:\n    - Creating custom sound effects based on textual descriptions\n    - Generating background audio for videos or games\n    - Exploring AI-generated audio for creative projects",
    "namespace": "huggingface.text_to_audio",
    "node_type": "huggingface.text_to_audio.StableAudio",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "A peaceful piano melody.",
        "title": "Prompt",
        "description": "A text prompt describing the desired audio.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Low quality.",
        "title": "Negative Prompt",
        "description": "A text prompt describing what you don't want in the audio.",
        "min": null,
        "max": null
      },
      {
        "name": "duration",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10.0,
        "title": "Duration",
        "description": "The desired duration of the generated audio in seconds.",
        "min": 1.0,
        "max": 300.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 200,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. More steps generally improve quality but increase generation time.",
        "min": 50.0,
        "max": 500.0
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Seed",
        "description": "Seed for the random number generator. Use -1 for a random seed.",
        "min": -1.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.text_to_audio",
        "repo_id": "stabilityai/stable-audio-open-1.0",
        "path": null,
        "allow_patterns": [
          "*.safetensors",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt"
    ]
  },
  {
    "title": "Text Classifier",
    "description": "Classifies text into predefined categories using a Hugging Face model.\n    text, classification, zero-shot, natural language processing",
    "namespace": "huggingface.text_classification",
    "node_type": "huggingface.text_classification.TextClassifier",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.text_classification",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.text_classification",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for the classification",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Inputs",
        "description": "The input text to the model",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.text_classification",
        "repo_id": "cardiffnlp/twitter-roberta-base-sentiment-latest",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.bin"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.text_classification",
        "repo_id": "michellejieli/emotion_text_classifier",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.bin"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt"
    ]
  },
  {
    "title": "Zero Shot Text Classifier",
    "description": "Performs zero-shot classification on text.\n    text, classification, zero-shot, natural language processing\n\n    Use cases:\n    - Classify text into custom categories without training\n    - Topic detection in documents\n    - Sentiment analysis with custom sentiment labels\n    - Intent classification in conversational AI",
    "namespace": "huggingface.text_classification",
    "node_type": "huggingface.text_classification.ZeroShotTextClassifier",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.zero_shot_classification",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.zero_shot_classification",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for zero-shot classification",
        "min": null,
        "max": null
      },
      {
        "name": "inputs",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Input Text",
        "description": "The text to classify",
        "min": null,
        "max": null
      },
      {
        "name": "candidate_labels",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Candidate Labels",
        "description": "Comma-separated list of candidate labels for classification",
        "min": null,
        "max": null
      },
      {
        "name": "multi_label",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Multi-label Classification",
        "description": "Whether to perform multi-label classification",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "float",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.zero_shot_classification",
        "repo_id": "facebook/bart-large-mnli",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.zero_shot_classification",
        "repo_id": "MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.zero_shot_classification",
        "repo_id": "MoritzLaurer/mDeBERTa-v3-base-mnli-xnli",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.zero_shot_classification",
        "repo_id": "tasksource/ModernBERT-base-nli",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.zero_shot_classification",
        "repo_id": "cross-encoder/nli-deberta-v3-base",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.zero_shot_classification",
        "repo_id": "microsoft/deberta-v2-xlarge-mnli",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.zero_shot_classification",
        "repo_id": "roberta-large-mnli",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "inputs",
      "candidate_labels",
      "multi_label"
    ]
  },
  {
    "title": "Stable Diffusion",
    "description": "Generates images from text prompts using Stable Diffusion.\n    image, generation, AI, text-to-image, SD\n\n    Use cases:\n    - Creating custom illustrations for various projects\n    - Generating concept art for creative endeavors\n    - Producing unique visual content for marketing materials\n    - Exploring AI-generated art for personal or professional use",
    "namespace": "huggingface.text_to_image",
    "node_type": "huggingface.text_to_image.StableDiffusion",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.stable_diffusion",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.stable_diffusion",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The model to use for image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt for image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "(blurry, low quality, deformed, mutated, bad anatomy, extra limbs, bad proportions, text, watermark, grainy, pixelated, disfigured face, missing fingers, cropped image, bad lighting",
        "title": "Negative Prompt",
        "description": "The negative prompt to guide what should not appear in the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "Seed for the random number generator. Use -1 for a random seed.",
        "min": -1.0,
        "max": 4294967295.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Guidance scale for generation.",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DPMSolverSDEScheduler",
            "EulerDiscreteScheduler",
            "LMSDiscreteScheduler",
            "DDIMScheduler",
            "DDPMScheduler",
            "HeunDiscreteScheduler",
            "DPMSolverMultistepScheduler",
            "DEISMultistepScheduler",
            "PNDMScheduler",
            "EulerAncestralDiscreteScheduler",
            "UniPCMultistepScheduler",
            "KDPM2DiscreteScheduler",
            "DPMSolverSinglestepScheduler",
            "KDPM2AncestralDiscreteScheduler"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionScheduler"
        },
        "default": "EulerDiscreteScheduler",
        "title": "Scheduler",
        "description": "The scheduler to use for the diffusion process.",
        "min": null,
        "max": null
      },
      {
        "name": "loras",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "hf.lora_sd_config",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Loras",
        "description": "The LoRA models to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_model",
        "type": {
          "type": "hf.ip_adapter",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.ip_adapter",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Ip Adapter Model",
        "description": "The IP adapter model to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Ip Adapter Image",
        "description": "When provided the image will be fed into the IP adapter",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Ip Adapter Scale",
        "description": "The strength of the IP adapter",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "detail_level",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Detail Level",
        "description": "Level of detail for the hi-res pass. 0.0 is low detail, 1.0 is high detail.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "enable_tiling",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Tiling",
        "description": "Enable tiling for the VAE. This can reduce VRAM usage.",
        "min": null,
        "max": null
      },
      {
        "name": "enable_cpu_offload",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Cpu Offload",
        "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage.",
        "min": null,
        "max": null
      },
      {
        "name": "upscaler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "None",
            "Latent",
            "Bicubic"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionUpscaler"
        },
        "default": "None",
        "title": "Upscaler",
        "description": "The upscaler to use for 2-pass generation.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Width",
        "description": "Width of the generated image.",
        "min": 256.0,
        "max": 1024.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Height",
        "description": "Height of the generated image",
        "min": 256.0,
        "max": 1024.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_light.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_vit-G.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "SG161222/Realistic_Vision_V5.1_noVAE",
        "path": "Realistic_Vision_V5.1_fp16-no-ema.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "digiplay/majicMIX_realistic_v7",
        "path": "majicmixRealistic_v7.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "philz1337x/epicrealism",
        "path": "epicrealism_naturalSinRC1VAE.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/DreamShaper",
        "path": "DreamShaper_5_beta2_noVae_half_pruned.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/DreamShaper",
        "path": "DreamShaper_4BakedVae_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "XpucT/Deliberate",
        "path": "Deliberate_v6.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "XpucT/Deliberate",
        "path": "Deliberate_v6-inpainting.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/AbsoluteReality",
        "path": "AbsoluteReality_1.8.1_pruned.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/AbsoluteReality",
        "path": "AbsoluteReality_1.8.1_INPAINTING.inpainting.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "gsdf/Counterfeit-V2.5",
        "path": "Counterfeit-V2.5_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_light.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_vit-G.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "stabilityai/sd-x2-latent-upscaler",
        "path": null,
        "allow_patterns": [
          "README.md",
          "**/*.safetensors",
          "**/*.json",
          "**/*.txt",
          "*.json"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt",
      "width",
      "height"
    ]
  },
  {
    "title": "Stable Diffusion XL",
    "description": "Generates images from text prompts using Stable Diffusion XL.\n    image, generation, AI, text-to-image, SDXL\n\n    Use cases:\n    - Creating custom illustrations for marketing materials\n    - Generating concept art for game and film development\n    - Producing unique stock imagery for websites and publications\n    - Visualizing interior design concepts for clients",
    "namespace": "huggingface.text_to_image",
    "node_type": "huggingface.text_to_image.StableDiffusionXL",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.stable_diffusion_xl",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The Stable Diffusion XL model to use for generation.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt for image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "The negative prompt to guide what should not appear in the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "Seed for the random number generator.",
        "min": -1.0,
        "max": 1000000.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Inference Steps",
        "description": "Number of inference steps.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.0,
        "title": "Guidance Scale",
        "description": "Guidance scale for generation.",
        "min": 0.0,
        "max": 20.0
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "Width of the generated image.",
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "Height of the generated image",
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DPMSolverSDEScheduler",
            "EulerDiscreteScheduler",
            "LMSDiscreteScheduler",
            "DDIMScheduler",
            "DDPMScheduler",
            "HeunDiscreteScheduler",
            "DPMSolverMultistepScheduler",
            "DEISMultistepScheduler",
            "PNDMScheduler",
            "EulerAncestralDiscreteScheduler",
            "UniPCMultistepScheduler",
            "KDPM2DiscreteScheduler",
            "DPMSolverSinglestepScheduler",
            "KDPM2AncestralDiscreteScheduler"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.stable_diffusion_base.StableDiffusionScheduler"
        },
        "default": "EulerDiscreteScheduler",
        "title": "Scheduler",
        "description": "The scheduler to use for the diffusion process.",
        "min": null,
        "max": null
      },
      {
        "name": "loras",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "hf.lora_sdxl_config",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Loras",
        "description": "The LoRA models to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Lora Scale",
        "description": "Strength of the LoRAs",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "ip_adapter_model",
        "type": {
          "type": "hf.ip_adapter",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.ip_adapter",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Ip Adapter Model",
        "description": "The IP adapter model to use for image processing",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Ip Adapter Image",
        "description": "When provided the image will be fed into the IP adapter",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Ip Adapter Scale",
        "description": "Strength of the IP adapter image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "enable_tiling",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Tiling",
        "description": "Enable tiling for the VAE. This can reduce VRAM usage.",
        "min": null,
        "max": null
      },
      {
        "name": "enable_cpu_offload",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Cpu Offload",
        "description": "Enable CPU offload for the pipeline. This can reduce VRAM usage.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "sdxl_models/ip-adapter_sdxl.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "sdxl_models/ip-adapter_sdxl_vit-h.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "sdxl_models/ip-adapter-plus_sdxl_vit-h.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "stabilityai/stable-diffusion-xl-base-1.0",
        "path": "sd_xl_base_1.0.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "stabilityai/stable-diffusion-xl-refiner-1.0",
        "path": "sd_xl_refiner_1.0.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "playgroundai/playground-v2.5-1024px-aesthetic",
        "path": "playground-v2.5-1024px-aesthetic.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "RunDiffusion/Juggernaut-XL-v9",
        "path": "Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "dataautogpt3/ProteusV0.5",
        "path": "proteusV0.5.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "Lykon/dreamshaper-xl-lightning",
        "path": "DreamShaperXL_Lightning.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "Lykon/AAM_XL_AnimeMix",
        "path": "AAM_XL_Anime_Mix.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "stabilityai/sdxl-turbo",
        "path": "sd_xl_turbo_1.0_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "Lykon/dreamshaper-xl-v2-turbo",
        "path": "DreamShaperXL_Turbo_v2_1.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt",
      "width",
      "height",
      "width",
      "height"
    ]
  },
  {
    "title": "Text Generation",
    "description": "Generates text based on a given prompt.\n    text, generation, natural language processing\n\n    Use cases:\n    - Creative writing assistance\n    - Automated content generation\n    - Chatbots and conversational AI\n    - Code generation and completion",
    "namespace": "huggingface.text_generation",
    "node_type": "huggingface.text_generation.TextGeneration",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.text_generation",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.text_generation",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for the text generation",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The input text prompt for generation",
        "min": null,
        "max": null
      },
      {
        "name": "max_new_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Max New Tokens",
        "description": "The maximum number of new tokens to generate",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Temperature",
        "description": "Controls randomness in generation. Lower values make it more deterministic.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Top P",
        "description": "Controls diversity of generated text. Lower values make it more focused.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "do_sample",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Do Sample",
        "description": "Whether to use sampling or greedy decoding",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.text_generation",
        "repo_id": "gpt2",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.text_generation",
        "repo_id": "distilgpt2",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.text_generation",
        "repo_id": "Qwen/Qwen2-0.5B-Instruct",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.text_generation",
        "repo_id": "bigcode/starcoder",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt"
    ]
  },
  {
    "title": "Bark",
    "description": "Bark is a text-to-audio model created by Suno. Bark can generate highly realistic, multilingual speech as well as other audio - including music, background noise and simple sound effects. The model can also produce nonverbal communications like laughing, sighing and crying.\n    tts, audio, speech, huggingface\n\n    Use cases:\n    - Create voice content for apps and websites\n    - Develop voice assistants with natural-sounding speech\n    - Generate automated announcements for public spaces",
    "namespace": "huggingface.text_to_speech",
    "node_type": "huggingface.text_to_speech.Bark",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.text_to_speech",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.text_to_speech",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for the image generation",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Inputs",
        "description": "The input text to the model",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.text_to_speech",
        "repo_id": "suno/bark",
        "path": null,
        "allow_patterns": [
          "*.bin",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.text_to_speech",
        "repo_id": "suno/bark-small",
        "path": null,
        "allow_patterns": [
          "*.bin",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt"
    ]
  },
  {
    "title": "Text To Speech",
    "description": "A generic Text-to-Speech node that can work with various Hugging Face TTS models.\n    tts, audio, speech, huggingface\n\n    Use cases:\n    - Generate speech from text for various applications\n    - Create voice content for apps, websites, or virtual assistants\n    - Produce audio narrations for videos, presentations, or e-learning content",
    "namespace": "huggingface.text_to_speech",
    "node_type": "huggingface.text_to_speech.TextToSpeech",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.text_to_speech",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.text_to_speech",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for text-to-speech generation",
        "min": null,
        "max": null
      },
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Hello, this is a test of the text-to-speech system.",
        "title": "Input Text",
        "description": "The text to convert to speech",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.text_to_speech",
        "repo_id": "facebook/mms-tts-eng",
        "path": null,
        "allow_patterns": [
          "*.bin",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.text_to_speech",
        "repo_id": "facebook/mms-tts-kor",
        "path": null,
        "allow_patterns": [
          "*.bin",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.text_to_speech",
        "repo_id": "facebook/mms-tts-fra",
        "path": null,
        "allow_patterns": [
          "*.bin",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.text_to_speech",
        "repo_id": "facebook/mms-tts-deu",
        "path": null,
        "allow_patterns": [
          "*.bin",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "text"
    ]
  },
  {
    "title": "Text To Text",
    "description": "Performs text-to-text generation tasks.\n    text, generation, translation, question-answering, summarization, nlp, natural-language-processing\n\n    Use cases:\n    - Text translation\n    - Text summarization\n    - Paraphrasing\n    - Text style transfer\n\n    Usage:\n    Start with a command like Translate, Summarize, or Q (for question)\n    Follow with the text you want to translate, summarize, or answer a question about.\n    Examples:\n    - Translate to German: Hello\n    - Summarize: The quick brown fox jumps over the lazy dog.\n    - Q: Who ate the cookie? followed by the text of the cookie monster.",
    "namespace": "huggingface.text_to_text",
    "node_type": "huggingface.text_to_text.TextToText",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.text2text_generation",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.text2text_generation",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for the text-to-text generation",
        "min": null,
        "max": null
      },
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Input Text",
        "description": "The input text for the text-to-text task",
        "min": null,
        "max": null
      },
      {
        "name": "max_length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Max Length",
        "description": "The maximum length of the generated text",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.text2text_generation",
        "repo_id": "google/flan-t5-small",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.text2text_generation",
        "repo_id": "google/flan-t5-base",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.text2text_generation",
        "repo_id": "google/flan-t5-large",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.text2text_generation",
        "repo_id": "gokaygokay/Flux-Prompt-Enhance",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "text"
    ]
  },
  {
    "title": "Token Classification",
    "description": "Performs token classification tasks such as Named Entity Recognition (NER).\n    text, token classification, named entity recognition, natural language processing\n\n    Use cases:\n    - Named Entity Recognition in text\n    - Part-of-speech tagging\n    - Chunking and shallow parsing\n    - Information extraction from unstructured text",
    "namespace": "huggingface.token_classification",
    "node_type": "huggingface.token_classification.TokenClassification",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.token_classification",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.token_classification",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on Huggingface",
        "description": "The model ID to use for token classification",
        "min": null,
        "max": null
      },
      {
        "name": "inputs",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Input Text",
        "description": "The input text for token classification",
        "min": null,
        "max": null
      },
      {
        "name": "aggregation_strategy",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "simple",
            "first",
            "average",
            "max"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.token_classification.AggregationStrategy"
        },
        "default": "simple",
        "title": "Aggregation Strategy",
        "description": "Strategy to aggregate tokens into entities",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "inputs",
      "aggregation_strategy"
    ]
  },
  {
    "title": "Translation",
    "description": "Translates text from one language to another.\n    text, translation, natural language processing\n\n    Use cases:\n    - Multilingual content creation\n    - Cross-language communication\n    - Localization of applications and websites\n\n    Note: some models support more languages than others.",
    "namespace": "huggingface.translation",
    "node_type": "huggingface.translation.Translation",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.translation",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.translation",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model ID on HuggingFace",
        "description": "The model ID to use for translation",
        "min": null,
        "max": null
      },
      {
        "name": "inputs",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Input Text",
        "description": "The text to translate",
        "min": null,
        "max": null
      },
      {
        "name": "source_lang",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "ar",
            "bn",
            "bs",
            "zh",
            "hr",
            "cs",
            "da",
            "nl",
            "en",
            "fil",
            "fi",
            "fr",
            "de",
            "el",
            "he",
            "hi",
            "id",
            "it",
            "ja",
            "ko",
            "ms",
            "me",
            "no",
            "pl",
            "pt",
            "pa",
            "ru",
            "ro",
            "sr",
            "sk",
            "sl",
            "es",
            "sv",
            "th",
            "tr",
            "vi"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.translation.LanguageCode"
        },
        "default": "en",
        "title": "Source Language",
        "description": "The source language code (e.g., 'en' for English)",
        "min": null,
        "max": null
      },
      {
        "name": "target_lang",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "ar",
            "bn",
            "bs",
            "zh",
            "hr",
            "cs",
            "da",
            "nl",
            "en",
            "fil",
            "fi",
            "fr",
            "de",
            "el",
            "he",
            "hi",
            "id",
            "it",
            "ja",
            "ko",
            "ms",
            "me",
            "no",
            "pl",
            "pt",
            "pa",
            "ru",
            "ro",
            "sr",
            "sk",
            "sl",
            "es",
            "sv",
            "th",
            "tr",
            "vi"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.huggingface.translation.LanguageCode"
        },
        "default": "fr",
        "title": "Target Language",
        "description": "The target language code (e.g., 'fr' for French)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.translation",
        "repo_id": "google-t5/t5-base",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.translation",
        "repo_id": "google-t5/t5-large",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.translation",
        "repo_id": "google-t5/t5-small",
        "path": null,
        "allow_patterns": [
          "*.json",
          "*.txt",
          "*.safetensors"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "inputs",
      "source_lang",
      "target_lang"
    ]
  },
  {
    "title": "Animate Diff",
    "description": "Generates animated GIFs using the AnimateDiff pipeline.\n    image, animation, generation, AI\n\n    Use cases:\n    - Create animated visual content from text descriptions\n    - Generate dynamic visual effects for creative projects\n    - Produce animated illustrations for digital media",
    "namespace": "huggingface.video",
    "node_type": "huggingface.video.AnimateDiff",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.stable_diffusion",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.stable_diffusion",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The model to use for image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "masterpiece, bestquality, highlydetailed, ultradetailed, sunset, orange sky, warm lighting, fishing boats, ocean waves seagulls, rippling water, wharf, silhouette, serene atmosphere, dusk, evening glow, golden hour, coastal landscape, seaside scenery",
        "title": "Prompt",
        "description": "A text prompt describing the desired animation.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "bad quality, worse quality",
        "title": "Negative Prompt",
        "description": "A text prompt describing what you don't want in the animation.",
        "min": null,
        "max": null
      },
      {
        "name": "num_frames",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 16,
        "title": "Num Frames",
        "description": "The number of frames in the animation.",
        "min": 1.0,
        "max": 60.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Scale for classifier-free guidance.",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Inference Steps",
        "description": "The number of denoising steps.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 42,
        "title": "Seed",
        "description": "Seed for the random number generator.",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.text_to_video",
        "repo_id": "guoyww/animatediff-motion-adapter-v1-5-2",
        "path": null,
        "allow_patterns": [
          "*.fp16.safetensors",
          "*.json",
          "*.txt"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/dreamshaper-8",
        "path": null,
        "allow_patterns": [
          "**/*.fp16.safetensors",
          "**/*.json",
          "**/*.txt",
          "*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Yntec/Deliberate2",
        "path": null,
        "allow_patterns": [
          "**/*.fp16.safetensors",
          "**/*.json",
          "**/*.txt",
          "*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "imagepipeline/epiC-PhotoGasm",
        "path": null,
        "allow_patterns": [
          "**/*.fp16.safetensors",
          "**/*.json",
          "**/*.txt",
          "*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "526christian/526mix-v1.5",
        "path": null,
        "allow_patterns": [
          "**/*.fp16.safetensors",
          "**/*.json",
          "**/*.txt",
          "*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "stablediffusionapi/realistic-vision-v51",
        "path": null,
        "allow_patterns": [
          "**/*.fp16.safetensors",
          "**/*.json",
          "**/*.txt",
          "*.json"
        ],
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "stablediffusionapi/anything-v5",
        "path": null,
        "allow_patterns": [
          "**/*.fp16.safetensors",
          "**/*.json",
          "**/*.txt",
          "*.json"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt"
    ]
  },
  {
    "title": "Stable Video Diffusion",
    "description": "Generates a video from a single image using the Stable Video Diffusion model.\n    video, generation, AI, image-to-video, stable-diffusion, SD\n\n    Use cases:\n    - Create short animations from static images\n    - Generate dynamic content for presentations or social media\n    - Prototype video ideas from still concept art",
    "namespace": "huggingface.video",
    "node_type": "huggingface.video.StableVideoDiffusion",
    "layout": "default",
    "properties": [
      {
        "name": "input_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Input Image",
        "description": "The input image to generate the video from, resized to 1024x576.",
        "min": null,
        "max": null
      },
      {
        "name": "num_frames",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 14,
        "title": "Num Frames",
        "description": "Number of frames to generate.",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Inference Steps",
        "description": "Number of steps per generated frame",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "fps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7,
        "title": "Fps",
        "description": "Frames per second for the output video.",
        "min": 1.0,
        "max": 30.0
      },
      {
        "name": "decode_chunk_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8,
        "title": "Decode Chunk Size",
        "description": "Number of frames to decode at once.",
        "min": 1.0,
        "max": 16.0
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 42,
        "title": "Seed",
        "description": "Random seed for generation.",
        "min": 0.0,
        "max": 4294967295.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.stable_diffusion",
        "repo_id": "stabilityai/stable-video-diffusion-img2vid-xt",
        "path": null,
        "allow_patterns": [
          "**/*.fp16.safetensors",
          "**/*.json",
          "**/*.txt",
          "*.json"
        ],
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "input_image",
      "num_frames",
      "num_inference_steps",
      "fps",
      "decode_chunk_size",
      "seed"
    ]
  },
  {
    "title": "Prep Image For Clip Vision",
    "description": "The Prep Image For Clip Vision node can be used to prepare an image for use with a CLIPVision model.",
    "namespace": "comfy.ipadapter",
    "node_type": "comfy.ipadapter.PrepImageForClipVision",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to prepare.",
        "min": null,
        "max": null
      },
      {
        "name": "interpolation",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "LANCZOS",
            "BICUBIC",
            "HAMMING",
            "BILINEAR",
            "BOX",
            "NEAREST"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.ipadapter.InterpolationMethod"
        },
        "default": "LANCZOS",
        "title": "Interpolation",
        "description": "The interpolation method to use.",
        "min": null,
        "max": null
      },
      {
        "name": "crop_position",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "top",
            "bottom",
            "left",
            "right",
            "center",
            "pad"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.ipadapter.CropPosition"
        },
        "default": "center",
        "title": "Crop Position",
        "description": "The crop position to use.",
        "min": null,
        "max": null
      },
      {
        "name": "sharpening",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Sharpening",
        "description": "The amount of sharpening to apply.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "interpolation",
      "crop_position",
      "sharpening"
    ]
  },
  {
    "title": "IPAdapter Encoder",
    "description": "The IPAdapter Encoder node can be used to encode an image into an embedding that can be used to guide the diffusion model towards generating specific images.",
    "namespace": "comfy.ipadapter",
    "node_type": "comfy.ipadapter.IPAdapterEncoder",
    "layout": "default",
    "properties": [
      {
        "name": "clip_vision",
        "type": {
          "type": "comfy.clip_vision",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip_vision",
          "name": "",
          "model": null
        },
        "title": "Clip Vision",
        "description": "The CLIP vision to use.",
        "min": null,
        "max": null
      },
      {
        "name": "image_1",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image 1",
        "description": "The first image to encode.",
        "min": null,
        "max": null
      },
      {
        "name": "ipadapter_plus",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Ipadapter Plus",
        "description": "Whether to use IPAdapter+ enhancements.",
        "min": null,
        "max": null
      },
      {
        "name": "noise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Noise",
        "description": "The amount of noise to apply.",
        "min": null,
        "max": null
      },
      {
        "name": "weight_1",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Weight 1",
        "description": "The weight for the first image.",
        "min": null,
        "max": null
      },
      {
        "name": "image_2",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Image 2",
        "description": "The second image to encode (optional).",
        "min": null,
        "max": null
      },
      {
        "name": "image_3",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Image 3",
        "description": "The third image to encode (optional).",
        "min": null,
        "max": null
      },
      {
        "name": "image_4",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Image 4",
        "description": "The fourth image to encode (optional).",
        "min": null,
        "max": null
      },
      {
        "name": "weight_2",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Weight 2",
        "description": "The weight for the second image (optional).",
        "min": null,
        "max": null
      },
      {
        "name": "weight_3",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Weight 3",
        "description": "The weight for the third image (optional).",
        "min": null,
        "max": null
      },
      {
        "name": "weight_4",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Weight 4",
        "description": "The weight for the fourth image (optional).",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.embeds",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "embeds",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "clip_vision",
      "image_1",
      "ipadapter_plus",
      "noise",
      "weight_1",
      "image_2",
      "image_3",
      "image_4",
      "weight_2",
      "weight_3",
      "weight_4"
    ]
  },
  {
    "title": "IPAdapter Apply",
    "description": "The IPAdapter Apply node can be used to apply an IPAdapter to a model.",
    "namespace": "comfy.ipadapter",
    "node_type": "comfy.ipadapter.IPAdapterApply",
    "layout": "default",
    "properties": [
      {
        "name": "ipadapter",
        "type": {
          "type": "comfy.ip_adapter",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.ip_adapter",
          "name": "",
          "model": null
        },
        "title": "Ipadapter",
        "description": "The IPAdapter to apply.",
        "min": null,
        "max": null
      },
      {
        "name": "clip_vision",
        "type": {
          "type": "comfy.clip_vision",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip_vision",
          "name": "",
          "model": null
        },
        "title": "Clip Vision",
        "description": "The CLIP vision to use.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to use.",
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to apply the IPAdapter to.",
        "min": null,
        "max": null
      },
      {
        "name": "weight",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Weight",
        "description": "The weight of the application.",
        "min": null,
        "max": null
      },
      {
        "name": "noise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Noise",
        "description": "The amount of noise to apply.",
        "min": null,
        "max": null
      },
      {
        "name": "weight_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "original",
            "linear",
            "channel penalty"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.ipadapter.WeightTypeEnum"
        },
        "default": "original",
        "title": "Weight Type",
        "description": "The type of weight to apply.",
        "min": null,
        "max": null
      },
      {
        "name": "start_at",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Start At",
        "description": "The starting point for applying the IPAdapter.",
        "min": null,
        "max": null
      },
      {
        "name": "end_at",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "End At",
        "description": "The ending point for applying the IPAdapter.",
        "min": null,
        "max": null
      },
      {
        "name": "unfold_batch",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Unfold Batch",
        "description": "Whether to unfold the batch during the application.",
        "min": null,
        "max": null
      },
      {
        "name": "attn_mask",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "comfy.mask",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Attn Mask",
        "description": "The optional attention mask to use (if any).",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "unet",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "ipadapter",
      "clip_vision",
      "image",
      "model",
      "weight",
      "noise",
      "weight_type",
      "start_at",
      "end_at",
      "unfold_batch",
      "attn_mask"
    ]
  },
  {
    "title": "IPAdapter Apply Encoded",
    "description": "The IPAdapter Apply Encoded node can be used to apply an encoded IPAdapter to a model.",
    "namespace": "comfy.ipadapter",
    "node_type": "comfy.ipadapter.IPAdapterApplyEncoded",
    "layout": "default",
    "properties": [
      {
        "name": "ipadapter",
        "type": {
          "type": "comfy.ip_adapter",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.ip_adapter",
          "name": "",
          "model": null
        },
        "title": "Ipadapter",
        "description": "The IPAdapter to apply.",
        "min": null,
        "max": null
      },
      {
        "name": "clip_vision",
        "type": {
          "type": "comfy.clip_vision",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip_vision",
          "name": "",
          "model": null
        },
        "title": "Clip Vision",
        "description": "The CLIP vision to use.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to use.",
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to apply the IPAdapter to.",
        "min": null,
        "max": null
      },
      {
        "name": "weight",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Weight",
        "description": "The weight of the application.",
        "min": null,
        "max": null
      },
      {
        "name": "noise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Noise",
        "description": "The amount of noise to apply.",
        "min": null,
        "max": null
      },
      {
        "name": "weight_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "original",
            "linear",
            "channel penalty"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.ipadapter.WeightTypeEnum"
        },
        "default": "original",
        "title": "Weight Type",
        "description": "The type of weight to apply.",
        "min": null,
        "max": null
      },
      {
        "name": "start_at",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Start At",
        "description": "The starting point for applying the IPAdapter.",
        "min": null,
        "max": null
      },
      {
        "name": "end_at",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "End At",
        "description": "The ending point for applying the IPAdapter.",
        "min": null,
        "max": null
      },
      {
        "name": "unfold_batch",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Unfold Batch",
        "description": "Whether to unfold the batch during the application.",
        "min": null,
        "max": null
      },
      {
        "name": "attn_mask",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "comfy.mask",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Attn Mask",
        "description": "The optional attention mask to use (if any).",
        "min": null,
        "max": null
      },
      {
        "name": "embeds",
        "type": {
          "type": "comfy.embeds",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.embeds",
          "data": null
        },
        "title": "Embeds",
        "description": "The encoded embeddings to apply.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "unet",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "ipadapter",
      "clip_vision",
      "image",
      "model",
      "weight",
      "noise",
      "weight_type",
      "start_at",
      "end_at",
      "unfold_batch",
      "attn_mask",
      "embeds"
    ]
  },
  {
    "title": "IPAdapter Save Embeds",
    "description": "The IPAdapter Save Embeds node can be used to save an embedding to a file.",
    "namespace": "comfy.ipadapter",
    "node_type": "comfy.ipadapter.IPAdapterSaveEmbeds",
    "layout": "default",
    "properties": [
      {
        "name": "embeds",
        "type": {
          "type": "comfy.embeds",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.embeds",
          "data": null
        },
        "title": "Embeds",
        "description": "The embeddings to save.",
        "min": null,
        "max": null
      },
      {
        "name": "filename_prefix",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "embeds/IPAdapter",
        "title": "Filename Prefix",
        "description": "The prefix for the filename to save the embeddings.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "embeds",
      "filename_prefix"
    ]
  },
  {
    "title": "IPAdapter Batch Embeds",
    "description": "The IPAdapter Batch Embeds node can be used to batch two sets of embeddings.",
    "namespace": "comfy.ipadapter",
    "node_type": "comfy.ipadapter.IPAdapterBatchEmbeds",
    "layout": "default",
    "properties": [
      {
        "name": "embed1",
        "type": {
          "type": "comfy.embeds",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.embeds",
          "data": null
        },
        "title": "Embed1",
        "description": "The first set of embeddings.",
        "min": null,
        "max": null
      },
      {
        "name": "embed2",
        "type": {
          "type": "comfy.embeds",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.embeds",
          "data": null
        },
        "title": "Embed2",
        "description": "The second set of embeddings.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.embeds",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "embeds",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "embed1",
      "embed2"
    ]
  },
  {
    "title": "Latent Composite Masked",
    "description": "The Latent Composite Masked node can be used to paste a masked latent into another.",
    "namespace": "comfy.latent",
    "node_type": "comfy.latent.LatentCompositeMasked",
    "layout": "default",
    "properties": [
      {
        "name": "destination",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Destination",
        "description": "The destination latent.",
        "min": null,
        "max": null
      },
      {
        "name": "source",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Source",
        "description": "The source latent.",
        "min": null,
        "max": null
      },
      {
        "name": "x",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "X",
        "description": "The x position.",
        "min": null,
        "max": null
      },
      {
        "name": "y",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Y",
        "description": "The y position.",
        "min": null,
        "max": null
      },
      {
        "name": "resize_source",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Resize Source",
        "description": "Whether to resize the source.",
        "min": null,
        "max": null
      },
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask",
        "description": "The mask to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "destination",
      "source",
      "x",
      "y",
      "resize_source",
      "mask"
    ]
  },
  {
    "title": "Empty Latent Image",
    "description": "The Empty Latent Image node can be used to create a new set of empty latent images. These latents can then be used inside e.g. a text2image workflow by noising and denoising them with a sampler node.",
    "namespace": "comfy.latent",
    "node_type": "comfy.latent.EmptyLatentImage",
    "layout": "default",
    "properties": [
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Width",
        "description": "The width of the latent image to generate.",
        "min": 16.0,
        "max": 16384.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Height",
        "description": "The height of the latent image to generate.",
        "min": 16.0,
        "max": 16384.0
      },
      {
        "name": "batch_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Batch Size",
        "description": "The batch size of the latent image to generate.",
        "min": 1.0,
        "max": 16384.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "width",
      "height",
      "batch_size"
    ]
  },
  {
    "title": "Empty SD3 Latent Image",
    "description": "The Empty SD3 Latent Image node can be used to create a new set of empty latent images. These latents can then be used inside e.g. a text2image workflow by noising and denoising them with a sampler node.",
    "namespace": "comfy.latent",
    "node_type": "comfy.latent.EmptySD3LatentImage",
    "layout": "default",
    "properties": [
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "The width of the latent image.",
        "min": 16.0,
        "max": 16384.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "The height of the latent image.",
        "min": 16.0,
        "max": 16384.0
      },
      {
        "name": "batch_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Batch Size",
        "description": "The batch size.",
        "min": 1.0,
        "max": 4096.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "width",
      "height",
      "batch_size"
    ]
  },
  {
    "title": "VAE Encode",
    "description": "The VAE Encode node can be used to encode pixel space images into latent space images, using the provided VAE.",
    "namespace": "comfy.latent",
    "node_type": "comfy.latent.VAEEncode",
    "layout": "default",
    "properties": [
      {
        "name": "pixels",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Pixels",
        "description": "The image to encode.",
        "min": null,
        "max": null
      },
      {
        "name": "vae",
        "type": {
          "type": "comfy.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.vae",
          "name": "",
          "model": null
        },
        "title": "Vae",
        "description": "The VAE to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "pixels",
      "vae"
    ]
  },
  {
    "title": "VAEEncode Tiled",
    "description": "The VAE Encode Tiled node can be used to encode pixel space images into latent space images using a tiled approach. This is useful for encoding large images that might exceed memory limits when processed all at once.",
    "namespace": "comfy.latent",
    "node_type": "comfy.latent.VAEEncodeTiled",
    "layout": "default",
    "properties": [
      {
        "name": "pixels",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Pixels",
        "description": "The image pixels to encode.",
        "min": null,
        "max": null
      },
      {
        "name": "vae",
        "type": {
          "type": "comfy.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.vae",
          "name": "",
          "model": null
        },
        "title": "Vae",
        "description": "The VAE to use for encoding.",
        "min": null,
        "max": null
      },
      {
        "name": "tile_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Tile Size",
        "description": "The size of the tiles to encode.",
        "min": 320.0,
        "max": 4096.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "pixels",
      "vae",
      "tile_size"
    ]
  },
  {
    "title": "VAEEncode For Inpaint",
    "description": "The VAE Encode for Inpaint node can be used to encode pixel space images into latent space specifically for inpainting tasks. It takes into account a mask to focus the encoding on specific areas of the image.",
    "namespace": "comfy.latent",
    "node_type": "comfy.latent.VAEEncodeForInpaint",
    "layout": "default",
    "properties": [
      {
        "name": "pixels",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Pixels",
        "description": "The image pixels to encode for inpainting.",
        "min": null,
        "max": null
      },
      {
        "name": "vae",
        "type": {
          "type": "comfy.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.vae",
          "name": "",
          "model": null
        },
        "title": "Vae",
        "description": "The VAE to use for encoding.",
        "min": null,
        "max": null
      },
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask",
        "description": "The mask to apply for inpainting.",
        "min": null,
        "max": null
      },
      {
        "name": "grow_mask_by",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 6,
        "title": "Grow Mask By",
        "description": "Amount to grow the mask by.",
        "min": 0.0,
        "max": 64.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "pixels",
      "vae",
      "mask",
      "grow_mask_by"
    ]
  },
  {
    "title": "VAE Decode",
    "description": "The VAE Decode node can be used to decode latent space images back into pixel space images, using the provided VAE.",
    "namespace": "comfy.latent",
    "node_type": "comfy.latent.VAEDecode",
    "layout": "default",
    "properties": [
      {
        "name": "samples",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples",
        "description": "The latent samples to decode.",
        "min": null,
        "max": null
      },
      {
        "name": "vae",
        "type": {
          "type": "comfy.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.vae",
          "name": "",
          "model": null
        },
        "title": "Vae",
        "description": "The VAE to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples",
      "vae"
    ]
  },
  {
    "title": "VAEDecode Tiled",
    "description": "The VAE Decode node can be used to decode latent space images back into pixel space images, using the provided VAE.\n    The tiled version of the node is useful for decoding large images that would otherwise exceed the memory limits of the system.",
    "namespace": "comfy.latent",
    "node_type": "comfy.latent.VAEDecodeTiled",
    "layout": "default",
    "properties": [
      {
        "name": "samples",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples",
        "description": "The latent samples to decode.",
        "min": null,
        "max": null
      },
      {
        "name": "vae",
        "type": {
          "type": "comfy.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.vae",
          "name": "",
          "model": null
        },
        "title": "Vae",
        "description": "The VAE to use for decoding.",
        "min": null,
        "max": null
      },
      {
        "name": "tile_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Tile Size",
        "description": "The size of the tiles to decode.",
        "min": 320.0,
        "max": 4096.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples",
      "vae",
      "tile_size"
    ]
  },
  {
    "title": "Save Latent",
    "description": "Save a latent to a file in the specified folder.\n    latent, save, file, storage\n\n    Use cases:\n    - Persist latent data for later use\n    - Export latent results from a workflow\n    - Save intermediate latent outputs for debugging",
    "namespace": "comfy.latent",
    "node_type": "comfy.latent.SaveLatent",
    "layout": "default",
    "properties": [
      {
        "name": "samples",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples",
        "description": "The latent samples to save.",
        "min": null,
        "max": null
      },
      {
        "name": "folder",
        "type": {
          "type": "folder",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "folder",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Folder",
        "description": "The folder to save the latent in.",
        "min": null,
        "max": null
      },
      {
        "name": "name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "latent.latent",
        "title": "Name",
        "description": "The name of the asset to save.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples",
      "folder",
      "name"
    ]
  },
  {
    "title": "Upscale Latent",
    "description": "The Upscale Latent node can be used to resize latent images.",
    "namespace": "comfy.latent",
    "node_type": "comfy.latent.LatentUpscale",
    "layout": "default",
    "properties": [
      {
        "name": "samples",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples",
        "description": "The latent samples to upscale.",
        "min": null,
        "max": null
      },
      {
        "name": "upscale_method",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "nearest_exact",
            "bilinear",
            "area",
            "bicubic",
            "bislerp"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.latent.UpScaleMethod"
        },
        "default": "nearest_exact",
        "title": "Upscale Method",
        "description": "The method to use for upscaling.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Width",
        "description": "The target width after upscaling.",
        "min": 0.0,
        "max": 16384.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Height",
        "description": "The target height after upscaling.",
        "min": 0.0,
        "max": 16384.0
      },
      {
        "name": "crop",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "disabled",
            "center"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.latent.CropMethod"
        },
        "default": "disabled",
        "title": "Crop",
        "description": "The method to use for cropping.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples",
      "upscale_method",
      "width",
      "height",
      "crop"
    ]
  },
  {
    "title": "Upscale Latent By",
    "description": "The Upscale Latent node can be used to resize latent images.",
    "namespace": "comfy.latent",
    "node_type": "comfy.latent.LatentUpscaleBy",
    "layout": "default",
    "properties": [
      {
        "name": "samples",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples",
        "description": "The latent samples to upscale.",
        "min": null,
        "max": null
      },
      {
        "name": "upscale_method",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "nearest_exact",
            "bilinear",
            "area",
            "bicubic",
            "bislerp"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.latent.UpScaleMethod"
        },
        "default": "nearest_exact",
        "title": "Upscale Method",
        "description": "The method to use for upscaling.",
        "min": null,
        "max": null
      },
      {
        "name": "scale_by",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.5,
        "title": "Scale By",
        "description": "The factor by which to scale.",
        "min": 0.01,
        "max": 8.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples",
      "upscale_method",
      "scale_by"
    ]
  },
  {
    "title": "Latent Composite",
    "description": "The Latent Composite node can be used to paste one latent into another.",
    "namespace": "comfy.latent",
    "node_type": "comfy.latent.LatentComposite",
    "layout": "default",
    "properties": [
      {
        "name": "samples_to",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples To",
        "description": "The first latent sample.",
        "min": null,
        "max": null
      },
      {
        "name": "samples_from",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples From",
        "description": "The second latent sample.",
        "min": null,
        "max": null
      },
      {
        "name": "x",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "X",
        "description": "The x-coordinate for compositing.",
        "min": null,
        "max": null
      },
      {
        "name": "y",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Y",
        "description": "The y-coordinate for compositing.",
        "min": null,
        "max": null
      },
      {
        "name": "feather",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Feather",
        "description": "The feather amount for compositing edges.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples_to",
      "samples_from",
      "x",
      "y",
      "feather"
    ]
  },
  {
    "title": "Latent Blend",
    "description": "The Latent Blend node can be used to blend two sets of latent samples. This allows for smooth transitions or combinations of different latent representations.",
    "namespace": "comfy.latent",
    "node_type": "comfy.latent.LatentBlend",
    "layout": "default",
    "properties": [
      {
        "name": "samples1",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples1",
        "description": "The first set of latent samples.",
        "min": null,
        "max": null
      },
      {
        "name": "samples2",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples2",
        "description": "The second set of latent samples.",
        "min": null,
        "max": null
      },
      {
        "name": "blend_factor",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Blend Factor",
        "description": "The blend factor between samples.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples1",
      "samples2",
      "blend_factor"
    ]
  },
  {
    "title": "Flip Latent",
    "description": "The Flip Latent node can be used to flip latent images.",
    "namespace": "comfy.latent",
    "node_type": "comfy.latent.LatentFlip",
    "layout": "default",
    "properties": [
      {
        "name": "samples",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples",
        "description": "The latent samples to flip.",
        "min": null,
        "max": null
      },
      {
        "name": "horizontal",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Horizontal",
        "description": "Whether to flip horizontally.",
        "min": null,
        "max": null
      },
      {
        "name": "vertical",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Vertical",
        "description": "Whether to flip vertically.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples",
      "horizontal",
      "vertical"
    ]
  },
  {
    "title": "Rotate Latent",
    "description": "The Rotate Latent node can be used to rotate latent images.",
    "namespace": "comfy.latent",
    "node_type": "comfy.latent.LatentRotate",
    "layout": "default",
    "properties": [
      {
        "name": "samples",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples",
        "description": "The latent samples to rotate.",
        "min": null,
        "max": null
      },
      {
        "name": "angle",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Angle",
        "description": "The angle to rotate the latent by.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples",
      "angle"
    ]
  },
  {
    "title": "Crop Latent",
    "description": "The Crop Latent node can be used to crop latent images.",
    "namespace": "comfy.latent",
    "node_type": "comfy.latent.LatentCrop",
    "layout": "default",
    "properties": [
      {
        "name": "samples",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples",
        "description": "The latent samples to crop.",
        "min": null,
        "max": null
      },
      {
        "name": "x",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "X",
        "description": "The x-coordinate for cropping.",
        "min": null,
        "max": null
      },
      {
        "name": "y",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Y",
        "description": "The y-coordinate for cropping.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Width",
        "description": "The width of the crop.",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Height",
        "description": "The height of the crop.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples",
      "x",
      "y",
      "width",
      "height"
    ]
  },
  {
    "title": "Latent Add",
    "description": "The Latent Add node can be used to add two sets of latent samples together. This operation allows for combining different latent representations, potentially creating interesting hybrid results.",
    "namespace": "comfy.latent.advanced",
    "node_type": "comfy.latent.advanced.LatentAdd",
    "layout": "default",
    "properties": [
      {
        "name": "samples1",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples1",
        "description": "The first set of latent samples to add.",
        "min": null,
        "max": null
      },
      {
        "name": "samples2",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples2",
        "description": "The second set of latent samples to add.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples1",
      "samples2"
    ]
  },
  {
    "title": "Latent Subtract",
    "description": "The Latent Subtract node can be used to subtract one set of latent samples from another. This operation can be useful for removing certain features or characteristics represented in the latent space.",
    "namespace": "comfy.latent.advanced",
    "node_type": "comfy.latent.advanced.LatentSubtract",
    "layout": "default",
    "properties": [
      {
        "name": "samples1",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples1",
        "description": "The first set of latent samples to subtract from.",
        "min": null,
        "max": null
      },
      {
        "name": "samples2",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples2",
        "description": "The second set of latent samples to subtract.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples1",
      "samples2"
    ]
  },
  {
    "title": "Latent Multiply",
    "description": "The Latent Multiply node can be used to scale the values of latent samples by a specified multiplier. This operation can amplify or diminish certain features in the latent representation.",
    "namespace": "comfy.latent.advanced",
    "node_type": "comfy.latent.advanced.LatentMultiply",
    "layout": "default",
    "properties": [
      {
        "name": "samples",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples",
        "description": "The latent samples to multiply.",
        "min": null,
        "max": null
      },
      {
        "name": "multiplier",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Multiplier",
        "description": "The multiplier for the latent samples.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples",
      "multiplier"
    ]
  },
  {
    "title": "Latent Interpolate",
    "description": "The Latent Interpolate node can be used to create a smooth transition between two sets of latent samples. This allows for blending different latent representations, potentially creating intermediate results.",
    "namespace": "comfy.latent.advanced",
    "node_type": "comfy.latent.advanced.LatentInterpolate",
    "layout": "default",
    "properties": [
      {
        "name": "samples1",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples1",
        "description": "The first set of latent samples for interpolation.",
        "min": null,
        "max": null
      },
      {
        "name": "samples2",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples2",
        "description": "The second set of latent samples for interpolation.",
        "min": null,
        "max": null
      },
      {
        "name": "ratio",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Ratio",
        "description": "The ratio for interpolation, controlling the blend between samples1 and samples2.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples1",
      "samples2",
      "ratio"
    ]
  },
  {
    "title": "Latent From Batch",
    "description": "The Latent From Batch node can be used to pick a slice from a batch of latents. This is useful when a specific latent image or images inside the batch need to be isolated in the workflow.",
    "namespace": "comfy.latent.batch",
    "node_type": "comfy.latent.batch.LatentFromBatch",
    "layout": "default",
    "properties": [
      {
        "name": "samples",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples",
        "description": "The batch of latent samples.",
        "min": null,
        "max": null
      },
      {
        "name": "batch_index",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Batch Index",
        "description": "The index of the sample in the batch.",
        "min": 0.0,
        "max": 63.0
      },
      {
        "name": "length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Length",
        "description": "The length of latent samples to extract.",
        "min": 1.0,
        "max": 64.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples",
      "batch_index",
      "length"
    ]
  },
  {
    "title": "Repeat Latent Batch",
    "description": "The Repeat Latent Batch node can be used to repeat a batch of latent images. This can e.g. be used to create multiple variations of an image in an image to image workflow.",
    "namespace": "comfy.latent.batch",
    "node_type": "comfy.latent.batch.RepeatLatentBatch",
    "layout": "default",
    "properties": [
      {
        "name": "samples",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples",
        "description": "The latent samples to repeat.",
        "min": null,
        "max": null
      },
      {
        "name": "amount",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Amount",
        "description": "The amount of times to repeat each sample.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples",
      "amount"
    ]
  },
  {
    "title": "Latent Batch",
    "description": "The Latent Batch node can be used to batch latent images.",
    "namespace": "comfy.latent.batch",
    "node_type": "comfy.latent.batch.LatentBatch",
    "layout": "default",
    "properties": [
      {
        "name": "samples1",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples1",
        "description": "The first set of latent samples for the batch process.",
        "min": null,
        "max": null
      },
      {
        "name": "samples2",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples2",
        "description": "The second set of latent samples for the batch process.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples1",
      "samples2"
    ]
  },
  {
    "title": "Set Latent Noise Mask",
    "description": "The Set Latent Noise Mask node can be used to add a mask to the latent images for inpainting. When the noise mask is set a sampler node will only operate on the masked area. If a single mask is provided, all the latents in the batch will use this mask.",
    "namespace": "comfy.latent.inpaint",
    "node_type": "comfy.latent.inpaint.SetLatentNoiseMask",
    "layout": "default",
    "properties": [
      {
        "name": "samples",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples",
        "description": "The latent samples to set the noise mask for.",
        "min": null,
        "max": null
      },
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask",
        "description": "The mask to use for the noise.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples",
      "mask"
    ]
  },
  {
    "title": "Stable Cascade Empty Latent Image",
    "description": "The Stable Cascade Empty Latent Image node can be used to create an empty latent image.",
    "namespace": "comfy.latent.stable_cascade",
    "node_type": "comfy.latent.stable_cascade.StableCascade_EmptyLatentImage",
    "layout": "default",
    "properties": [
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "The width of the latent image.",
        "min": 256.0,
        "max": 16384.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "The height of the latent image.",
        "min": 256.0,
        "max": 16384.0
      },
      {
        "name": "compression",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 42,
        "title": "Compression",
        "description": "The compression factor for the latent image.",
        "min": 4.0,
        "max": 128.0
      },
      {
        "name": "batch_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Batch Size",
        "description": "The batch size for the latent images.",
        "min": 1.0,
        "max": 4096.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "stage_c",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "stage_b",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "width",
      "height",
      "compression",
      "batch_size"
    ]
  },
  {
    "title": "Stable Cascade Stage C VAE Encode",
    "description": "The Stable Cascade Stage C VAE Encode node can be used to encode an image into a latent image.",
    "namespace": "comfy.latent.stable_cascade",
    "node_type": "comfy.latent.stable_cascade.StableCascade_StageC_VAEEncode",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image to encode.",
        "min": null,
        "max": null
      },
      {
        "name": "vae",
        "type": {
          "type": "comfy.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.vae",
          "name": "",
          "model": null
        },
        "title": "Vae",
        "description": "The VAE model to use for encoding.",
        "min": null,
        "max": null
      },
      {
        "name": "compression",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 42,
        "title": "Compression",
        "description": "The compression factor for the latent image.",
        "min": 4.0,
        "max": 128.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "stage_c",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "stage_b",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "vae",
      "compression"
    ]
  },
  {
    "title": "Stable Cascade Stage B Conditioning",
    "description": "The Stable Cascade Stage B Conditioning node can be used to condition the stage B latent image.",
    "namespace": "comfy.latent.stable_cascade",
    "node_type": "comfy.latent.stable_cascade.StableCascade_StageB_Conditioning",
    "layout": "default",
    "properties": [
      {
        "name": "conditioning",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning",
        "description": "The input conditioning.",
        "min": null,
        "max": null
      },
      {
        "name": "stage_c",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Stage C",
        "description": "The stage C latent.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "conditioning",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "conditioning",
      "stage_c"
    ]
  },
  {
    "title": "Stable Cascade Super Resolution Controlnet",
    "description": "The Stable Cascade Super Resolution Controlnet node can be used to encode an image into a latent image.",
    "namespace": "comfy.latent.stable_cascade",
    "node_type": "comfy.latent.stable_cascade.StableCascade_SuperResolutionControlnet",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image for super-resolution.",
        "min": null,
        "max": null
      },
      {
        "name": "vae",
        "type": {
          "type": "comfy.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.vae",
          "name": "",
          "model": null
        },
        "title": "Vae",
        "description": "The VAE model to use for encoding.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "controlnet_input",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "stage_c",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "stage_b",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "vae"
    ]
  },
  {
    "title": "Latent Rotate",
    "description": "The Latent Rotate node can be used to rotate latent samples by a specified degree. This allows for orientation adjustments in the latent space, which can be useful for aligning or reorienting generated images.",
    "namespace": "comfy.latent.transform",
    "node_type": "comfy.latent.transform.LatentRotate",
    "layout": "default",
    "properties": [
      {
        "name": "samples",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples",
        "description": "The latent samples to rotate.",
        "min": null,
        "max": null
      },
      {
        "name": "rotation",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "none",
            "90 degrees",
            "180 degrees",
            "270 degrees"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.latent.transform.Rotation"
        },
        "default": "none",
        "title": "Rotation",
        "description": "The degree of rotation to apply.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples",
      "rotation"
    ]
  },
  {
    "title": "Latent Flip",
    "description": "The Latent Flip node can be used to flip latent samples either horizontally or vertically. This operation allows for mirror transformations in the latent space, which can create interesting variations of the generated images.",
    "namespace": "comfy.latent.transform",
    "node_type": "comfy.latent.transform.LatentFlip",
    "layout": "default",
    "properties": [
      {
        "name": "samples",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples",
        "description": "The latent samples to flip.",
        "min": null,
        "max": null
      },
      {
        "name": "flip_method",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "y-axis: horizontally",
            "x-axis: vertically"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.latent.transform.FlipMethod"
        },
        "default": "y-axis: horizontally",
        "title": "Flip Method",
        "description": "The method to use for flipping.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples",
      "flip_method"
    ]
  },
  {
    "title": "Latent Crop",
    "description": "The Latent Crop node can be used to crop a specific area from latent samples. This operation allows for focusing on particular regions in the latent space, which can be useful for generating or manipulating specific parts of an image.",
    "namespace": "comfy.latent.transform",
    "node_type": "comfy.latent.transform.LatentCrop",
    "layout": "default",
    "properties": [
      {
        "name": "samples",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Samples",
        "description": "The latent samples to crop.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Width",
        "description": "The width of the crop.",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Height",
        "description": "The height of the crop.",
        "min": null,
        "max": null
      },
      {
        "name": "x",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "X",
        "description": "The x-coordinate for the top-left corner of the crop area.",
        "min": null,
        "max": null
      },
      {
        "name": "y",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Y",
        "description": "The y-coordinate for the top-left corner of the crop area.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "samples",
      "width",
      "height",
      "x",
      "y"
    ]
  },
  {
    "title": "Empty Mochi Latent Video",
    "description": "The Empty Mochi Latent Video node creates a new set of empty latent\n    images specifically formatted for video processing.",
    "namespace": "comfy.latent.video",
    "node_type": "comfy.latent.video.EmptyMochiLatentVideo",
    "layout": "default",
    "properties": [
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 848,
        "title": "Width",
        "description": "The width of the latent video to generate.",
        "min": 16.0,
        "max": 16384.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 480,
        "title": "Height",
        "description": "The height of the latent video to generate.",
        "min": 16.0,
        "max": 16384.0
      },
      {
        "name": "length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Length",
        "description": "The number of frames in the video.",
        "min": 7.0,
        "max": 16384.0
      },
      {
        "name": "batch_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Batch Size",
        "description": "The batch size of the latent video to generate.",
        "min": 1.0,
        "max": 4096.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "width",
      "height",
      "length",
      "batch_size"
    ]
  },
  {
    "title": "Empty LTXV Latent Video",
    "description": "Generates an empty latent video tensor.\n    latent, video, ltxv\n\n    Use cases:\n    - Initialize a latent tensor for video generation\n    - Prepare inputs for LTXV-based models",
    "namespace": "comfy.latent.video",
    "node_type": "comfy.latent.video.EmptyLTXVLatentVideo",
    "layout": "default",
    "properties": [
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 768,
        "title": "Width",
        "description": "Width of the latent video.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Height",
        "description": "Height of the latent video.",
        "min": 64.0,
        "max": 16384.0
      },
      {
        "name": "length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 97,
        "title": "Length",
        "description": "Length (frames) of the latent video.",
        "min": 1.0,
        "max": 16384.0
      },
      {
        "name": "batch_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Batch Size",
        "description": "Batch size.",
        "min": 1.0,
        "max": 4096.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "width",
      "height",
      "length",
      "batch_size"
    ]
  },
  {
    "title": "Load Checkpoint",
    "description": "Loads a checkpoint.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.CheckpointLoaderSimple",
    "layout": "default",
    "properties": [
      {
        "name": "ckpt_name",
        "type": {
          "type": "comfy.checkpoint_file",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.checkpoint_file",
          "name": ""
        },
        "title": "Ckpt Name",
        "description": "The checkpoint to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "clip",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "vae",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "ckpt_name"
    ]
  },
  {
    "title": "Load Checkpoint (Advanced)",
    "description": "Loads a checkpoint.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.CheckpointLoader",
    "layout": "default",
    "properties": [
      {
        "name": "ckpt_name",
        "type": {
          "type": "comfy.checkpoint_file",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.checkpoint_file",
          "name": ""
        },
        "title": "Ckpt Name",
        "description": "The checkpoint to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "clip",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "vae",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "ckpt_name"
    ]
  },
  {
    "title": "Load Checkpoint from Huggingface",
    "description": "Loads a checkpoint from Huggingface.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.HuggingFaceCheckpointLoader",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.checkpoint_model",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.checkpoint_model",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The Stable Diffusion model to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "clip",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "vae",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.stable_diffusion",
        "repo_id": "SG161222/Realistic_Vision_V5.1_noVAE",
        "path": "Realistic_Vision_V5.1_fp16-no-ema.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "digiplay/majicMIX_realistic_v7",
        "path": "majicmixRealistic_v7.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "philz1337x/epicrealism",
        "path": "epicrealism_naturalSinRC1VAE.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/DreamShaper",
        "path": "DreamShaper_5_beta2_noVae_half_pruned.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/DreamShaper",
        "path": "DreamShaper_4BakedVae_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "XpucT/Deliberate",
        "path": "Deliberate_v6.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "XpucT/Deliberate",
        "path": "Deliberate_v6-inpainting.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/AbsoluteReality",
        "path": "AbsoluteReality_1.8.1_pruned.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/AbsoluteReality",
        "path": "AbsoluteReality_1.8.1_INPAINTING.inpainting.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "gsdf/Counterfeit-V2.5",
        "path": "Counterfeit-V2.5_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "stabilityai/stable-diffusion-xl-base-1.0",
        "path": "sd_xl_base_1.0.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "stabilityai/stable-diffusion-xl-refiner-1.0",
        "path": "sd_xl_refiner_1.0.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "playgroundai/playground-v2.5-1024px-aesthetic",
        "path": "playground-v2.5-1024px-aesthetic.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "RunDiffusion/Juggernaut-XL-v9",
        "path": "Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "dataautogpt3/ProteusV0.5",
        "path": "proteusV0.5.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "Lykon/dreamshaper-xl-lightning",
        "path": "DreamShaperXL_Lightning.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "Lykon/AAM_XL_AnimeMix",
        "path": "AAM_XL_Anime_Mix.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "stabilityai/sdxl-turbo",
        "path": "sd_xl_turbo_1.0_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "Lykon/dreamshaper-xl-v2-turbo",
        "path": "DreamShaperXL_Turbo_v2_1.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_3",
        "repo_id": "Comfy-Org/stable-diffusion-3.5-fp8",
        "path": "sd3.5_large_fp8_scaled.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_3",
        "repo_id": "Comfy-Org/stable-diffusion-3.5-fp8",
        "path": "sd3.5_medium_incl_clips_t5xxlfp8scaled.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.flux",
        "repo_id": "Comfy-Org/flux1-dev",
        "path": "flux1-dev-fp8.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.flux",
        "repo_id": "Comfy-Org/flux1-schnell",
        "path": "flux1-schnell-fp8.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.flux",
        "repo_id": "black-forest-labs/FLUX.1-Fill-dev",
        "path": "flux1-fill-dev.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ltxv",
        "repo_id": "Lightricks/LTX-Video",
        "path": "ltx-video-2b-v0.9.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model"
    ]
  },
  {
    "title": "un CLIPCheckpoint Loader",
    "description": "Loads a unCLIP checkpoint.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.unCLIPCheckpointLoader",
    "layout": "default",
    "properties": [
      {
        "name": "ckpt_name",
        "type": {
          "type": "comfy.unclip_file",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unclip_file",
          "name": ""
        },
        "title": "Ckpt Name",
        "description": "The checkpoint to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "clip",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "vae",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.clip_vision",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "clip_vision",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "ckpt_name"
    ]
  },
  {
    "title": "CLIPVision Loader",
    "description": "Loads a CLIPVision model.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.CLIPVisionLoader",
    "layout": "default",
    "properties": [
      {
        "name": "clip_name",
        "type": {
          "type": "comfy.clip_vision_file",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip_vision_file",
          "name": ""
        },
        "title": "Clip Name",
        "description": "The name of the CLIP vision model to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.clip_vision",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "clip_vision",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "clip_name"
    ]
  },
  {
    "title": "Load CLIP Vision from Huggingface",
    "description": "Loads a CLIPVision model from Huggingface.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.HuggingFaceCLIPVisionLoader",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.clip_vision",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.clip_vision",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The CLIP vision model to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.clip_vision",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "clip_vision",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.clip_vision",
        "repo_id": "Comfy-Org/sigclip_vision_384",
        "path": "sigclip_vision_patch14_384.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.clip_vision",
        "repo_id": "h94/IP-Adapter",
        "path": "models/image_encoder/model.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.clip_vision",
        "repo_id": "h94/IP-Adapter",
        "path": "sdxl_models/image_encoder/model.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model"
    ]
  },
  {
    "title": "Load ControlNet Model",
    "description": "Loads a ControlNet model.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.ControlNetLoader",
    "layout": "default",
    "properties": [
      {
        "name": "control_net_name",
        "type": {
          "type": "comfy.control_net_file",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.control_net_file",
          "name": ""
        },
        "title": "Control Net Name",
        "description": "The filename of the control net to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.control_net",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "control_net",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "control_net_name"
    ]
  },
  {
    "title": "Load ControlNet from Huggingface",
    "description": "Loads a ControlNet model from Huggingface.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.HuggingFaceControlNetLoader",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.controlnet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.controlnet",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The ControlNet model to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.control_net",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "control_net",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_canny",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_inpaint",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_mlsd",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_tile",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_shuffle",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_ip2p",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_lineart",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_lineart_anime",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_scribble",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_openpose",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_scribble",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_seg",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_hed",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_normalbae",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model"
    ]
  },
  {
    "title": "Load Upscale Model",
    "description": "Loads an upscale model.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.UpscaleModelLoader",
    "layout": "default",
    "properties": [
      {
        "name": "model_name",
        "type": {
          "type": "comfy.upscale_model_file",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.upscale_model_file",
          "name": ""
        },
        "title": "Model Name",
        "description": "The filename of the upscale model to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.upscale_model",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "upscale_model",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model_name"
    ]
  },
  {
    "title": "Load GLIGEN Model",
    "description": "Loads a GLIGEN model.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.GLIGENLoader",
    "layout": "default",
    "properties": [
      {
        "name": "gligen_name",
        "type": {
          "type": "comfy.gligen_file",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.gligen_file",
          "name": ""
        },
        "title": "Gligen Name",
        "description": "The GLIGEN checkpoint to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.gligen",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "gligen",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "gligen_name"
    ]
  },
  {
    "title": "Lora Loader",
    "description": "Loads a LoRA model.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.LoraLoader",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to apply Lora to.",
        "min": null,
        "max": null
      },
      {
        "name": "clip",
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip",
          "name": "",
          "model": null
        },
        "title": "Clip",
        "description": "The CLIP model to apply Lora to.",
        "min": null,
        "max": null
      },
      {
        "name": "lora_name",
        "type": {
          "type": "comfy.lora_file",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.lora_file",
          "name": ""
        },
        "title": "Lora Name",
        "description": "The name of the LoRA to load.",
        "min": null,
        "max": null
      },
      {
        "name": "strength_model",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength Model",
        "description": "The strength of the LoRA to apply to the model.",
        "min": -20.0,
        "max": 20.0
      },
      {
        "name": "strength_clip",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength Clip",
        "description": "The strength of the LoRA to apply to the CLIP.",
        "min": -20.0,
        "max": 20.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "clip",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "clip",
      "lora_name",
      "strength_model",
      "strength_clip"
    ]
  },
  {
    "title": "Load LoRA from Huggingface",
    "description": "Loads a LoRA model from Huggingface.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.HuggingFaceLoraLoader",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to apply LoRA to.",
        "min": null,
        "max": null
      },
      {
        "name": "clip",
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip",
          "name": "",
          "model": null
        },
        "title": "Clip",
        "description": "The CLIP model to apply LoRA to.",
        "min": null,
        "max": null
      },
      {
        "name": "lora",
        "type": {
          "type": "hf.lora_sd",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.lora_sd",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Lora",
        "description": "The LoRA to load.",
        "min": null,
        "max": null
      },
      {
        "name": "strength_model",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength Model",
        "description": "The strength of the LoRA to apply to the model.",
        "min": -20.0,
        "max": 20.0
      },
      {
        "name": "strength_clip",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength Clip",
        "description": "The strength of the LoRA to apply to the CLIP.",
        "min": -20.0,
        "max": 20.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "clip",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "2d_sprite.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "ghibli_scenery.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "add_detail.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "colorwater.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "sxz_game_assets.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "3Danaglyph.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "akiratoriyama_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "animeoutlineV4.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "aqua_konosuba.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "arakihirohiko_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "arcane_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "canetaazul.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "cyberpunk_tarot.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "discoelysium_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "esdeath_akamegakill.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "fire_vfx.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "flamingeye.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "funnycreatures.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "gacha_splash.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "gigachad.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "gyokai_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "harold.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "hiderohoribes_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "ilyakuvshinov_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "jacksparrow.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "jimlee_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "komowataharuka_chibiart.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "lightning_vfx.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "lucy_cyberpunk.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "luisap_pixelart.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "mumei_kabaneri.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "myheroacademia_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "neoartcore.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "ochakouraraka.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "onepiece_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "paimon_genshinimpact.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "peanutscomics_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "pepefrog.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "persona5_portraits.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "persona5_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "pixhell.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "princesszelda.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "satoshiuruchihara_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "shinobu_demonslayer.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "sokolov_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "standingbackgroundv1.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "sun_shadow_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "thickeranimelines.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "threesidedview.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "twitch_emotes.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "water_vfx.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "wlop_style.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sd",
        "repo_id": "danbrown/loras",
        "path": "zerotwo_darling.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sdxl",
        "repo_id": "CiroN2022/toy-face",
        "path": "toy_face_sdxl.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sdxl",
        "repo_id": "nerijs/pixel-art-xl",
        "path": "pixel-art-xl.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sdxl",
        "repo_id": "goofyai/3d_render_style_xl",
        "path": "3d_render_style_xl.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sdxl",
        "repo_id": "artificialguybr/CuteCartoonRedmond-V2",
        "path": "CuteCartoonRedmond-CuteCartoon-CuteCartoonAF.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sdxl",
        "repo_id": "blink7630/graphic-novel-illustration",
        "path": "Graphic_Novel_Illustration-000007.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sdxl",
        "repo_id": "robert123231/coloringbookgenerator",
        "path": "ColoringBookRedmond-ColoringBook-ColoringBookAF.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.lora_sdxl",
        "repo_id": "Linaqruf/anime-detailer-xl-lora",
        "path": "anime-detailer-xl-lora.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "clip",
      "lora",
      "strength_model",
      "strength_clip"
    ]
  },
  {
    "title": "Lora Loader Model Only",
    "description": "Loads a LoRA model (model only).",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.LoraLoaderModelOnly",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to apply Lora to.",
        "min": null,
        "max": null
      },
      {
        "name": "lora_name",
        "type": {
          "type": "comfy.lora_file",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.lora_file",
          "name": ""
        },
        "title": "Lora Name",
        "description": "The name of the LoRA to load.",
        "min": null,
        "max": null
      },
      {
        "name": "strength_model",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength Model",
        "description": "The strength of the LoRA to apply to the model.",
        "min": -20.0,
        "max": 20.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "lora_name",
      "strength_model"
    ]
  },
  {
    "title": "Load VAE",
    "description": "Loads a VAE model.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.VAELoader",
    "layout": "default",
    "properties": [
      {
        "name": "vae_name",
        "type": {
          "type": "comfy.vae_file",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.vae_file",
          "name": ""
        },
        "title": "Vae Name",
        "description": "The name of the VAE to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "vae",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "vae_name"
    ]
  },
  {
    "title": "Load VAE from Huggingface",
    "description": "Loads a VAE model from Huggingface.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.HuggingFaceVAELoader",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.vae",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The VAE model to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "vae",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.vae",
        "repo_id": "Comfy-Org/mochi_preview_repackaged",
        "path": "split_files/vae/mochi_vae.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.vae",
        "repo_id": "black-forest-labs/FLUX.1-schnell",
        "path": "ae.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model"
    ]
  },
  {
    "title": "Load CLIP",
    "description": "Loads a CLIP model.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.CLIPLoader",
    "layout": "default",
    "properties": [
      {
        "name": "clip_name",
        "type": {
          "type": "comfy.clip_file",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip_file",
          "name": ""
        },
        "title": "Clip Name",
        "description": "The name of the CLIP to load.",
        "min": null,
        "max": null
      },
      {
        "name": "type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "stable_diffusion",
            "stable_cascade",
            "sd3",
            "stable_audio",
            "mochi",
            "ltxv"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.loaders.CLIPTypeEnum"
        },
        "default": "stable_diffusion",
        "title": "Type",
        "description": "The type of the CLIP model to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "clip",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "clip_name",
      "type"
    ]
  },
  {
    "title": "Load CLIP from Huggingface",
    "description": "Loads a CLIP model from Huggingface.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.HuggingFaceCLIPLoader",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.clip",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The CLIP model to load.",
        "min": null,
        "max": null
      },
      {
        "name": "type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "stable_diffusion",
            "stable_cascade",
            "sd3",
            "stable_audio",
            "mochi",
            "ltxv"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.loaders.CLIPTypeEnum"
        },
        "default": "stable_diffusion",
        "title": "Type",
        "description": "The type of the CLIP model to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "clip",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.clip",
        "repo_id": "Comfy-Org/mochi_preview_repackaged",
        "path": "split_files/text_encoders/t5xxl_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.clip",
        "repo_id": "Comfy-Org/mochi_preview_repackaged",
        "path": "split_files/text_encoders/t5xxl_fp8_e4m3fn_scaled.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.clip",
        "repo_id": "comfyanonymous/flux_text_encoders",
        "path": "clip_l.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.clip",
        "repo_id": "comfyanonymous/flux_text_encoders",
        "path": "t5xxl_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "type"
    ]
  },
  {
    "title": "Load Dual CLIP",
    "description": "Loads a dual CLIP model.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.DualCLIPLoader",
    "layout": "default",
    "properties": [
      {
        "name": "clip_name1",
        "type": {
          "type": "comfy.clip_file",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip_file",
          "name": ""
        },
        "title": "Clip Name1",
        "description": "The name of the CLIP to load.",
        "min": null,
        "max": null
      },
      {
        "name": "clip_name2",
        "type": {
          "type": "comfy.clip_file",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.clip_file",
          "name": ""
        },
        "title": "Clip Name2",
        "description": "The name of the CLIP to load.",
        "min": null,
        "max": null
      },
      {
        "name": "type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "sdxl",
            "sd3",
            "flux"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.loaders.DualCLIPEnum"
        },
        "default": "sdxl",
        "title": "Type",
        "description": "The type of the dual CLIP model to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "clip",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "clip_name1",
      "clip_name2",
      "type"
    ]
  },
  {
    "title": "Load Dual CLIP from Huggingface",
    "description": "Loads a dual CLIP model from Huggingface.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.HuggingFaceDualCLIPLoader",
    "layout": "default",
    "properties": [
      {
        "name": "type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "sdxl",
            "sd3",
            "flux"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.loaders.DualCLIPEnum"
        },
        "default": "sdxl",
        "title": "Type",
        "description": "The type of the dual CLIP model to load.",
        "min": null,
        "max": null
      },
      {
        "name": "clip_model_1",
        "type": {
          "type": "hf.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.clip",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Clip Model 1",
        "description": "The first CLIP model to load.",
        "min": null,
        "max": null
      },
      {
        "name": "clip_model_2",
        "type": {
          "type": "hf.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.clip",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Clip Model 2",
        "description": "The second CLIP model to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.clip",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "clip",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.clip",
        "repo_id": "Comfy-Org/mochi_preview_repackaged",
        "path": "split_files/text_encoders/t5xxl_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.clip",
        "repo_id": "Comfy-Org/mochi_preview_repackaged",
        "path": "split_files/text_encoders/t5xxl_fp8_e4m3fn_scaled.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.clip",
        "repo_id": "comfyanonymous/flux_text_encoders",
        "path": "clip_l.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.clip",
        "repo_id": "comfyanonymous/flux_text_encoders",
        "path": "t5xxl_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "type",
      "clip_model_1",
      "clip_model_2"
    ]
  },
  {
    "title": "Load Diffusion Model",
    "description": "Loads a UNet model.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.UNETLoader",
    "layout": "default",
    "properties": [
      {
        "name": "unet_name",
        "type": {
          "type": "comfy.unet_file",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet_file",
          "name": ""
        },
        "title": "Unet Name",
        "description": "The name of the UNet model to load.",
        "min": null,
        "max": null
      },
      {
        "name": "weight_dtype",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "default",
            "fp8_e4m3fn",
            "fp8_e4m3fn_fast",
            "fp8_e5m2"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.loaders.WeightDataTypeEnum"
        },
        "default": "default",
        "title": "Weight Dtype",
        "description": "The weight data type to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "unet",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "unet_name",
      "weight_dtype"
    ]
  },
  {
    "title": "Load Diffusion Model from Huggingface",
    "description": "Loads a UNet model from Huggingface.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.HuggingFaceUNetLoader",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.unet",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The UNet model to load.",
        "min": null,
        "max": null
      },
      {
        "name": "weight_dtype",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "default",
            "fp8_e4m3fn",
            "fp8_e4m3fn_fast",
            "fp8_e5m2"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.loaders.WeightDataTypeEnum"
        },
        "default": "default",
        "title": "Weight Dtype",
        "description": "The weight data type to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "unet",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.unet",
        "repo_id": "Comfy-Org/mochi_preview_repackaged",
        "path": "split_files/diffusion_models/mochi_preview_bf16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.unet",
        "repo_id": "Comfy-Org/mochi_preview_repackaged",
        "path": "split_files/diffusion_models/mochi_preview_fp8_scaled.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.unet",
        "repo_id": "black-forest-labs/FLUX.1-dev",
        "path": "flux1-dev.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.unet",
        "repo_id": "black-forest-labs/FLUX.1-schnell",
        "path": "flux1-schnell.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "weight_dtype"
    ]
  },
  {
    "title": "Image Only Checkpoint Loader (img2vid model)",
    "description": "Loads a checkpoint for img2vid.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.ImageOnlyCheckpointLoader",
    "layout": "default",
    "properties": [
      {
        "name": "ckpt_name",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Ckpt Name",
        "description": "The name of the checkpoint to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.clip_vision",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "clip_vision",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.vae",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "vae",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "ckpt_name"
    ]
  },
  {
    "title": "Load IPAdapter",
    "description": "Loads an IPAdapter model.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.IPAdapterModelLoader",
    "layout": "default",
    "properties": [
      {
        "name": "ipadapter_file",
        "type": {
          "type": "comfy.ip_adapter_file",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.ip_adapter_file",
          "name": ""
        },
        "title": "Ipadapter File",
        "description": "List of available IPAdapter model names.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.ip_adapter",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "ipadapter",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "ipadapter_file"
    ]
  },
  {
    "title": "Load IPAdapter from Huggingface",
    "description": "Loads an IPAdapter model from Huggingface.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.HuggingFaceIPAdapterLoader",
    "layout": "default",
    "properties": [
      {
        "name": "ipadapter",
        "type": {
          "type": "hf.ip_adapter",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.ip_adapter",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Ipadapter",
        "description": "The IPAdapter to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.ip_adapter",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "ipadapter",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_light.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "models/ip-adapter_sd15_vit-G.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "sdxl_models/ip-adapter_sdxl.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "sdxl_models/ip-adapter_sdxl_vit-h.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.ip_adapter",
        "repo_id": "h94/IP-Adapter",
        "path": "sdxl_models/ip-adapter-plus_sdxl_vit-h.bin",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "ipadapter"
    ]
  },
  {
    "title": "Load Style Model",
    "description": "Loads a style model.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.StyleModelLoader",
    "layout": "default",
    "properties": [
      {
        "name": "style_model_name",
        "type": {
          "type": "comfy.style_model_file",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.style_model_file",
          "name": ""
        },
        "title": "Style Model Name",
        "description": "The name of the style model to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.style_model",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "style_model",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "style_model_name"
    ]
  },
  {
    "title": "Load Style Model from Huggingface",
    "description": "Loads a style model from HuggingFace.",
    "namespace": "comfy.loaders",
    "node_type": "comfy.loaders.HuggingFaceStyleModelLoader",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.style_model",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.style_model",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The style model to load.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.style_model",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "style_model",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.style_model",
        "repo_id": "black-forest-labs/FLUX.1-Redux-dev",
        "path": "flux1-redux-dev.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model"
    ]
  },
  {
    "title": "Convert Mask to Image",
    "description": "The Convert Mask to Image node can be used to convert a mask to a grey scale image.",
    "namespace": "comfy.mask",
    "node_type": "comfy.mask.MaskToImage",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask",
        "description": "The mask to convert.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "mask"
    ]
  },
  {
    "title": "Convert Image to Mask",
    "description": "The Convert Image yo Mask node can be used to convert a specific channel of an image into a mask.",
    "namespace": "comfy.mask",
    "node_type": "comfy.mask.ImageToMask",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to extract the mask.",
        "min": null,
        "max": null
      },
      {
        "name": "channel",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "red",
            "green",
            "blue",
            "alpha"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.mask.ChannelEnum"
        },
        "default": "red",
        "title": "Channel",
        "description": "The channel to use for the mask.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "channel"
    ]
  },
  {
    "title": "Image Color To Mask",
    "description": "The Image Color to Mask node can be used to extract a mask from an image based on a specific color.",
    "namespace": "comfy.mask",
    "node_type": "comfy.mask.ImageColorToMask",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to extract the color mask.",
        "min": null,
        "max": null
      },
      {
        "name": "color",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Color",
        "description": "The color to use for the mask.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "color"
    ]
  },
  {
    "title": "Solid Mask",
    "description": "The Solid Mask node can be used to create a solid masking containing a single value.",
    "namespace": "comfy.mask",
    "node_type": "comfy.mask.SolidMask",
    "layout": "default",
    "properties": [
      {
        "name": "value",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Value",
        "description": "The value for the solid mask.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Width",
        "description": "Width of the solid mask.",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Height",
        "description": "Height of the solid mask.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "value",
      "width",
      "height"
    ]
  },
  {
    "title": "Invert Mask",
    "description": "The Invert Mask node can be used to invert a mask.",
    "namespace": "comfy.mask",
    "node_type": "comfy.mask.InvertMask",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask",
        "description": "The mask to invert.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "mask"
    ]
  },
  {
    "title": "Crop Mask",
    "description": "The Crop Mask node can be used to crop a mask to a new shape.",
    "namespace": "comfy.mask",
    "node_type": "comfy.mask.CropMask",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask",
        "description": "The mask to crop.",
        "min": null,
        "max": null
      },
      {
        "name": "x",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "X",
        "description": "The x position for cropping.",
        "min": null,
        "max": null
      },
      {
        "name": "y",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Y",
        "description": "The y position for cropping.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Width",
        "description": "Width of the crop.",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Height",
        "description": "Height of the crop.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "x",
      "y",
      "width",
      "height"
    ]
  },
  {
    "title": "Mask Composite",
    "description": "The Mask Composite node can be used to paste one mask into another.",
    "namespace": "comfy.mask",
    "node_type": "comfy.mask.MaskComposite",
    "layout": "default",
    "properties": [
      {
        "name": "destination",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Destination",
        "description": "The destination mask.",
        "min": null,
        "max": null
      },
      {
        "name": "source",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Source",
        "description": "The source mask.",
        "min": null,
        "max": null
      },
      {
        "name": "x",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "X",
        "description": "The x position.",
        "min": null,
        "max": null
      },
      {
        "name": "y",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Y",
        "description": "The y position.",
        "min": null,
        "max": null
      },
      {
        "name": "operation",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "multiply",
            "add",
            "subtract",
            "and",
            "or",
            "xor"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.mask.OperationEnum"
        },
        "default": "multiply",
        "title": "Operation",
        "description": "The operation to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "destination",
      "source",
      "x",
      "y",
      "operation"
    ]
  },
  {
    "title": "Feather Mask",
    "description": "The Feather Mask node can be used to feather a mask.",
    "namespace": "comfy.mask",
    "node_type": "comfy.mask.FeatherMask",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask",
        "description": "The mask to feather.",
        "min": null,
        "max": null
      },
      {
        "name": "left",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Left",
        "description": "Feather amount on the left.",
        "min": null,
        "max": null
      },
      {
        "name": "top",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Top",
        "description": "Feather amount on the top.",
        "min": null,
        "max": null
      },
      {
        "name": "right",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Right",
        "description": "Feather amount on the right.",
        "min": null,
        "max": null
      },
      {
        "name": "bottom",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Bottom",
        "description": "Feather amount on the bottom.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "left",
      "top",
      "right",
      "bottom"
    ]
  },
  {
    "title": "Grow Mask",
    "description": "The Grow Mask node can be used to grow a mask.",
    "namespace": "comfy.mask",
    "node_type": "comfy.mask.GrowMask",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Mask",
        "description": "The mask to grow.",
        "min": null,
        "max": null
      },
      {
        "name": "expand",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Expand",
        "description": "The amount to expand the mask.",
        "min": null,
        "max": null
      },
      {
        "name": "tapered_corners",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Tapered Corners",
        "description": "Whether to taper the corners.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "expand",
      "tapered_corners"
    ]
  },
  {
    "title": "Porter Duff Image Composite",
    "description": "The Porter-Duff Image Composite node can be used to combine two images using various compositing modes. This allows for complex image blending operations, useful for creating layered effects or combining multiple image elements.",
    "namespace": "comfy.mask.compositing",
    "node_type": "comfy.mask.compositing.PorterDuffImageComposite",
    "layout": "default",
    "properties": [
      {
        "name": "source",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Source",
        "description": "The source image.",
        "min": null,
        "max": null
      },
      {
        "name": "source_alpha",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Source Alpha",
        "description": "The source alpha (mask).",
        "min": null,
        "max": null
      },
      {
        "name": "destination",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Destination",
        "description": "The destination image.",
        "min": null,
        "max": null
      },
      {
        "name": "destination_alpha",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Destination Alpha",
        "description": "The destination alpha (mask).",
        "min": null,
        "max": null
      },
      {
        "name": "mode",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "ADD",
            "CLEAR",
            "DARKEN",
            "DST",
            "DST_ATOP",
            "DST_IN",
            "DST_OUT",
            "DST_OVER",
            "LIGHTEN",
            "MULTIPLY",
            "OVERLAY",
            "SCREEN",
            "SRC",
            "SRC_ATOP",
            "SRC_IN",
            "SRC_OUT",
            "SRC_OVER",
            "XOR"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.mask.compositing.PorterDuffModeEnum"
        },
        "default": "DST",
        "title": "Mode",
        "description": "The Porter-Duff compositing mode to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "source",
      "source_alpha",
      "destination",
      "destination_alpha",
      "mode"
    ]
  },
  {
    "title": "Split Image With Alpha",
    "description": "The Split Image with Alpha node can be used to separate an image with an alpha channel into its color components and alpha mask. This is useful when you need to manipulate the image and its transparency separately.",
    "namespace": "comfy.mask.compositing",
    "node_type": "comfy.mask.compositing.SplitImageWithAlpha",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image with an alpha channel to split.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "mask",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Join Image With Alpha",
    "description": "The Join Image with Alpha node can be used to combine an image and an alpha mask into a single image with transparency. This is useful for creating images with varying levels of opacity or for preparing images for compositing operations.",
    "namespace": "comfy.mask.compositing",
    "node_type": "comfy.mask.compositing.JoinImageWithAlpha",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to join with an alpha channel.",
        "min": null,
        "max": null
      },
      {
        "name": "alpha",
        "type": {
          "type": "comfy.mask",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.mask",
          "data": null
        },
        "title": "Alpha",
        "description": "The alpha channel (mask) to join with the image.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "image",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "alpha"
    ]
  },
  {
    "title": "KSampler",
    "description": "The KSampler uses the provided model and positive and negative conditioning to generate a new version of the given latent. First the latent is noised up according to the given seed and denoise strength, erasing some of the latent image. then this noise is removed using the given Model and the positive and negative conditioning as guidance, \"dreaming\" up new details in places where the image was erased by noise.",
    "namespace": "comfy.sampling",
    "node_type": "comfy.sampling.KSampler",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Seed",
        "description": "The seed to use.",
        "min": null,
        "max": null
      },
      {
        "name": "seed_control_mode",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "fixed",
            "randomize",
            "increment",
            "decrement"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.sampling.SeedControlMode"
        },
        "default": "fixed",
        "title": "Seed Control Mode",
        "description": "The seed control mode to use.",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Steps",
        "description": "The number of steps to use.",
        "min": null,
        "max": null
      },
      {
        "name": "cfg",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8.0,
        "title": "Cfg",
        "description": "The cfg to use.",
        "min": null,
        "max": null
      },
      {
        "name": "sampler_name",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "ddim",
            "uni_pc",
            "uni_pc_bh2",
            "euler",
            "euler_ancestral",
            "heun",
            "heunpp2",
            "dpm_2",
            "dpm_2_ancestral",
            "lms",
            "dpm_fast",
            "dpm_adaptive",
            "dpmpp_2s_ancestral",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "dpmpp_2m",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "ddpm",
            "lcm"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.sampling.SamplerEnum"
        },
        "default": "ddim",
        "title": "Sampler Name",
        "description": "The sampler to use.",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "normal",
            "karras",
            "exponential",
            "sgm_uniform",
            "simple",
            "ddim_uniform"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.sampling.SchedulerEnum"
        },
        "default": "normal",
        "title": "Scheduler",
        "description": "The scheduler to use.",
        "min": null,
        "max": null
      },
      {
        "name": "positive",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Positive",
        "description": "The positive conditioning to use.",
        "min": null,
        "max": null
      },
      {
        "name": "negative",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Negative",
        "description": "The negative conditioning to use.",
        "min": null,
        "max": null
      },
      {
        "name": "latent_image",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Latent Image",
        "description": "The latent image to use.",
        "min": null,
        "max": null
      },
      {
        "name": "denoise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Denoise",
        "description": "The denoise to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "seed",
      "seed_control_mode",
      "steps",
      "cfg",
      "sampler_name",
      "scheduler",
      "positive",
      "negative",
      "latent_image",
      "denoise"
    ]
  },
  {
    "title": "KSampler (Advanced)",
    "description": "The KSampler Advanced node is the more advanced version of the KSampler node. While the KSampler node always adds noise to the latent followed by completely denoising the noised up latent, the KSampler Advanced node provides extra settings to control this behavior. The KSampler Advanced node can be told not to add noise into the latent with the add_noise setting. It can also be made to return partially denoised images via the return_with_leftover_noise setting. Unlike the KSampler node, this node does not have a denoise setting but this process is instead controlled by the start_at_step and end_at_step settings. This makes it possible to e.g. hand over a partially denoised latent to a separate KSampler Advanced node to finish the process.",
    "namespace": "comfy.sampling",
    "node_type": "comfy.sampling.KSamplerAdvanced",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "add_noise",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "enable",
            "disable"
          ],
          "type_args": [],
          "type_name": "nodetool.common.comfy_node.EnableDisable"
        },
        "default": "enable",
        "title": "Add Noise",
        "description": "Enable or disable noise addition.",
        "min": null,
        "max": null
      },
      {
        "name": "noise_seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Noise Seed",
        "description": "The seed for noise generation.",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Steps",
        "description": "The number of steps to use during sampling.",
        "min": null,
        "max": null
      },
      {
        "name": "cfg",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8.0,
        "title": "Cfg",
        "description": "The configuration value for the sampler.",
        "min": null,
        "max": null
      },
      {
        "name": "sampler_name",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "ddim",
            "uni_pc",
            "uni_pc_bh2",
            "euler",
            "euler_ancestral",
            "heun",
            "heunpp2",
            "dpm_2",
            "dpm_2_ancestral",
            "lms",
            "dpm_fast",
            "dpm_adaptive",
            "dpmpp_2s_ancestral",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "dpmpp_2m",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "ddpm",
            "lcm"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.sampling.SamplerEnum"
        },
        "default": "ddim",
        "title": "Sampler Name",
        "description": "The name of the sampler to use.",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "normal",
            "karras",
            "exponential",
            "sgm_uniform",
            "simple",
            "ddim_uniform"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.sampling.SchedulerEnum"
        },
        "default": "normal",
        "title": "Scheduler",
        "description": "The scheduler to use.",
        "min": null,
        "max": null
      },
      {
        "name": "positive",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Positive",
        "description": "The positive conditioning influence.",
        "min": null,
        "max": null
      },
      {
        "name": "negative",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Negative",
        "description": "The negative conditioning influence.",
        "min": null,
        "max": null
      },
      {
        "name": "latent_image",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Latent Image",
        "description": "The starting latent image.",
        "min": null,
        "max": null
      },
      {
        "name": "start_at_step",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Start At Step",
        "description": "The step at which to start the sampling process.",
        "min": null,
        "max": null
      },
      {
        "name": "end_at_step",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10000,
        "title": "End At Step",
        "description": "The step at which to end the sampling process.",
        "min": null,
        "max": null
      },
      {
        "name": "return_with_leftover_noise",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "enable",
            "disable"
          ],
          "type_args": [],
          "type_name": "nodetool.common.comfy_node.EnableDisable"
        },
        "default": "disable",
        "title": "Return With Leftover Noise",
        "description": "Whether to return with leftover noise or not.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "add_noise",
      "noise_seed",
      "steps",
      "cfg",
      "sampler_name",
      "scheduler",
      "positive",
      "negative",
      "latent_image",
      "start_at_step",
      "end_at_step",
      "return_with_leftover_noise"
    ]
  },
  {
    "title": "Differential Diffusion",
    "description": "Implements differential diffusion by modifying the model's denoise mask function.\n    Adapted from https://github.com/exx8/differential-diffusion",
    "namespace": "comfy.sampling",
    "node_type": "comfy.sampling.DifferentialDiffusion",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to modify.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model"
    ]
  },
  {
    "title": "KSampler Select",
    "description": "Select a specific sampler for the diffusion process with different performance characteristics and output qualities.\n    sampling, diffusion\n    Use cases:\n    - Experimenting with different sampling methods for optimal image quality\n    - Balancing speed vs quality in image generation\n    - Testing model behavior with different sampling algorithms",
    "namespace": "comfy.sampling.samplers",
    "node_type": "comfy.sampling.samplers.KSamplerSelect",
    "layout": "default",
    "properties": [
      {
        "name": "sampler_name",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "ddim",
            "uni_pc",
            "uni_pc_bh2",
            "euler",
            "euler_ancestral",
            "heun",
            "heunpp2",
            "dpm_2",
            "dpm_2_ancestral",
            "lms",
            "dpm_fast",
            "dpm_adaptive",
            "dpmpp_2s_ancestral",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "dpmpp_2m",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "ddpm",
            "lcm"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.sampling.SamplerEnum"
        },
        "default": "ddim",
        "title": "Sampler Name",
        "description": "The name of the sampler.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.sampler",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "sampler",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "sampler_name"
    ]
  },
  {
    "title": "Sampler DPMPP 2 M SDE",
    "description": "Advanced DPMPP (2M) SDE sampler implementation offering high-quality results with fewer steps.\n    sampling, diffusion, sde, dpmpp\n    Use cases:\n    - High-quality image generation with reduced step count\n    - Performance-optimized sampling for production workflows\n    - Advanced noise control with GPU/CPU options",
    "namespace": "comfy.sampling.samplers",
    "node_type": "comfy.sampling.samplers.SamplerDPMPP_2M_SDE",
    "layout": "default",
    "properties": [
      {
        "name": "solver_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "midpoint",
            "heun"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.sampling.samplers.SolverTypeEnum"
        },
        "default": "midpoint",
        "title": "Solver Type",
        "description": "The type of solver.",
        "min": null,
        "max": null
      },
      {
        "name": "eta",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Eta",
        "description": "The eta parameter.",
        "min": null,
        "max": null
      },
      {
        "name": "s_noise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "S Noise",
        "description": "The scale noise factor.",
        "min": null,
        "max": null
      },
      {
        "name": "noise_device",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "gpu",
            "cpu"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.sampling.samplers.DeviceEnum"
        },
        "default": "gpu",
        "title": "Noise Device",
        "description": "The device for noise generation, either 'gpu' or 'cpu'.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.sampler",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "sampler",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "solver_type",
      "eta",
      "s_noise",
      "noise_device"
    ]
  },
  {
    "title": "Sampler DPMPP SDE",
    "description": "Implementation of DPMPP SDE sampler with configurable noise and performance parameters.\n    sampling, diffusion, sde, dpmpp\n    Use cases:\n    - Efficient image generation with controllable noise levels\n    - Fine-tuning sampling parameters for specific image styles\n    - Balancing quality and speed with custom parameters",
    "namespace": "comfy.sampling.samplers",
    "node_type": "comfy.sampling.samplers.SamplerDPMPP_SDE",
    "layout": "default",
    "properties": [
      {
        "name": "eta",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Eta",
        "description": "The eta parameter.",
        "min": null,
        "max": null
      },
      {
        "name": "s_noise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "S Noise",
        "description": "The scale noise factor.",
        "min": null,
        "max": null
      },
      {
        "name": "r",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "R",
        "description": "The r parameter.",
        "min": null,
        "max": null
      },
      {
        "name": "noise_device",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "gpu",
            "cpu"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.sampling.samplers.DeviceEnum"
        },
        "default": "gpu",
        "title": "Noise Device",
        "description": "The device for noise generation, either 'gpu' or 'cpu'.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.sampler",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "sampler",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "eta",
      "s_noise",
      "r",
      "noise_device"
    ]
  },
  {
    "title": "Sampler Custom",
    "description": "Customizable sampling process with fine-grained control over noise, CFG, and conditioning parameters.\n    sampling, cfg, noise, conditioning\n    Use cases:\n    - Advanced sampling control for complex image generation tasks\n    - Customizing sampling parameters for specific models or tasks\n    - Fine-tuning sampling for specific effects or styles",
    "namespace": "comfy.sampling.samplers",
    "node_type": "comfy.sampling.samplers.SamplerCustom",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model used by the sampler.",
        "min": null,
        "max": null
      },
      {
        "name": "add_noise",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Add Noise",
        "description": "Whether to add noise or not.",
        "min": null,
        "max": null
      },
      {
        "name": "noise_seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Noise Seed",
        "description": "The seed for the noise generation.",
        "min": null,
        "max": null
      },
      {
        "name": "cfg",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8.0,
        "title": "Cfg",
        "description": "The cfg (classifier-free guidance) parameter.",
        "min": null,
        "max": null
      },
      {
        "name": "positive",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Positive",
        "description": "The positive conditioning.",
        "min": null,
        "max": null
      },
      {
        "name": "negative",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Negative",
        "description": "The negative conditioning.",
        "min": null,
        "max": null
      },
      {
        "name": "sampler",
        "type": {
          "type": "comfy.sampler",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.sampler",
          "data": null
        },
        "title": "Sampler",
        "description": "The sampler to use.",
        "min": null,
        "max": null
      },
      {
        "name": "sigmas",
        "type": {
          "type": "comfy.sigmas",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.sigmas",
          "data": null
        },
        "title": "Sigmas",
        "description": "The sigmas used in sampling.",
        "min": null,
        "max": null
      },
      {
        "name": "latent_image",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Latent Image",
        "description": "The latent image to sample from.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "latent",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "add_noise",
      "noise_seed",
      "cfg",
      "positive",
      "negative",
      "sampler",
      "sigmas",
      "latent_image"
    ]
  },
  {
    "title": "Sampler Custom Advanced",
    "description": "Advanced sampling implementation with separate control over noise, guidance, and multiple output options.\n    sampling, noise, guidance, cfg\n    Use cases:\n    - Complex image generation requiring precise noise control\n    - Workflows needing access to intermediate denoised results\n    - Advanced guidance-based sampling applications",
    "namespace": "comfy.sampling.samplers",
    "node_type": "comfy.sampling.samplers.SamplerCustomAdvanced",
    "layout": "default",
    "properties": [
      {
        "name": "noise",
        "type": {
          "type": "comfy.noise",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.noise",
          "data": null
        },
        "title": "Noise",
        "description": "The noise to apply.",
        "min": null,
        "max": null
      },
      {
        "name": "guider",
        "type": {
          "type": "comfy.guider",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.guider",
          "data": null
        },
        "title": "Guider",
        "description": "The guider to apply.",
        "min": null,
        "max": null
      },
      {
        "name": "sampler",
        "type": {
          "type": "comfy.sampler",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.sampler",
          "data": null
        },
        "title": "Sampler",
        "description": "The sampler to use.",
        "min": null,
        "max": null
      },
      {
        "name": "sigmas",
        "type": {
          "type": "comfy.sigmas",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.sigmas",
          "data": null
        },
        "title": "Sigmas",
        "description": "The sigmas used in sampling.",
        "min": null,
        "max": null
      },
      {
        "name": "latent_image",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.latent",
          "data": null
        },
        "title": "Latent Image",
        "description": "The latent image to sample from.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      },
      {
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "denoised_output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "noise",
      "guider",
      "sampler",
      "sigmas",
      "latent_image"
    ]
  },
  {
    "title": "Basic Scheduler",
    "description": "The Basic Scheduler node provides a simple scheduling mechanism for the sampling process.\n    It allows selection of different scheduler types and control over steps and denoising.",
    "namespace": "comfy.sampling.schedulers",
    "node_type": "comfy.sampling.schedulers.BasicScheduler",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "normal",
            "karras",
            "exponential",
            "sgm_uniform",
            "simple",
            "ddim_uniform"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.sampling.SchedulerEnum"
        },
        "default": "normal",
        "title": "Scheduler",
        "description": "The scheduler name.",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Steps",
        "description": "The number of steps.",
        "min": null,
        "max": null
      },
      {
        "name": "denoise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Denoise",
        "description": "The denoising factor.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.sigmas",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "sigmas",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "scheduler",
      "steps",
      "denoise"
    ]
  },
  {
    "title": "Karras Scheduler",
    "description": "The Karras Scheduler node implements the Karras et al. noise schedule, which can provide\n    improved sampling quality, especially for fewer sampling steps.",
    "namespace": "comfy.sampling.schedulers",
    "node_type": "comfy.sampling.schedulers.KarrasScheduler",
    "layout": "default",
    "properties": [
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Steps",
        "description": "The number of steps.",
        "min": null,
        "max": null
      },
      {
        "name": "sigma_max",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 14.614642,
        "title": "Sigma Max",
        "description": "The maximum sigma value.",
        "min": null,
        "max": null
      },
      {
        "name": "sigma_min",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0291675,
        "title": "Sigma Min",
        "description": "The minimum sigma value.",
        "min": null,
        "max": null
      },
      {
        "name": "rho",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.0,
        "title": "Rho",
        "description": "The rho value.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.sigmas",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "sigmas",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "steps",
      "sigma_max",
      "sigma_min",
      "rho"
    ]
  },
  {
    "title": "Exponential Scheduler",
    "description": "The Exponential Scheduler node provides an exponential decay schedule for the sampling process,\n    which can offer a balance between speed and quality.",
    "namespace": "comfy.sampling.schedulers",
    "node_type": "comfy.sampling.schedulers.ExponentialScheduler",
    "layout": "default",
    "properties": [
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Steps",
        "description": "The number of steps.",
        "min": null,
        "max": null
      },
      {
        "name": "sigma_max",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 14.614642,
        "title": "Sigma Max",
        "description": "The maximum sigma value.",
        "min": null,
        "max": null
      },
      {
        "name": "sigma_min",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0291675,
        "title": "Sigma Min",
        "description": "The minimum sigma value.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.sigmas",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "sigmas",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "steps",
      "sigma_max",
      "sigma_min"
    ]
  },
  {
    "title": "Polyexponential Scheduler",
    "description": "The Polyexponential Scheduler node implements a more flexible scheduling mechanism,\n    allowing for fine-tuned control over the noise schedule through the rho parameter.",
    "namespace": "comfy.sampling.schedulers",
    "node_type": "comfy.sampling.schedulers.PolyexponentialScheduler",
    "layout": "default",
    "properties": [
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Steps",
        "description": "The number of steps to compute the sigmas.",
        "min": null,
        "max": null
      },
      {
        "name": "sigma_max",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 14.614642,
        "title": "Sigma Max",
        "description": "The maximum sigma value.",
        "min": null,
        "max": null
      },
      {
        "name": "sigma_min",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0291675,
        "title": "Sigma Min",
        "description": "The minimum sigma value.",
        "min": null,
        "max": null
      },
      {
        "name": "rho",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Rho",
        "description": "The rho parameter for the scheduler.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.sigmas",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "sigmas",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "steps",
      "sigma_max",
      "sigma_min",
      "rho"
    ]
  },
  {
    "title": "SDTurbo Scheduler",
    "description": "The SDTurbo Scheduler node is designed for very fast inference, often used with\n    specific models trained for few-step generation. It's particularly useful for\n    real-time or near-real-time applications.",
    "namespace": "comfy.sampling.schedulers",
    "node_type": "comfy.sampling.schedulers.SDTurboScheduler",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model for which to use the scheduler.",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Steps",
        "description": "The number of steps for the scheduler.",
        "min": null,
        "max": null
      },
      {
        "name": "denoise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Denoise",
        "description": "The denoising factor to apply in the scheduler.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.sigmas",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "sigmas",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "steps",
      "denoise"
    ]
  },
  {
    "title": "VPScheduler",
    "description": "The VP (Variance Preserving) Scheduler node implements a variance preserving stochastic differential equation (SDE) based scheduler, which can provide high-quality results for certain types of models and generation tasks.\n    sampling, custom, scheduler\n\n    Use cases:\n    - Generate custom sigma schedules for sampling\n    - Fine-tune sampling parameters for specific models\n    - Experiment with variance preserving noise schedules",
    "namespace": "comfy.sampling.schedulers",
    "node_type": "comfy.sampling.schedulers.VPScheduler",
    "layout": "default",
    "properties": [
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Steps",
        "description": "The number of steps to compute the sigmas.",
        "min": null,
        "max": null
      },
      {
        "name": "beta_d",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 19.9,
        "title": "Beta D",
        "description": "beta_d parameter for the VP scheduler.",
        "min": null,
        "max": null
      },
      {
        "name": "beta_min",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.1,
        "title": "Beta Min",
        "description": "beta_min parameter for the VP scheduler.",
        "min": null,
        "max": null
      },
      {
        "name": "eps_s",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.001,
        "title": "Eps S",
        "description": "eps_s parameter for the VP scheduler.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.sigmas",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "sigmas",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "steps",
      "beta_d",
      "beta_min",
      "eps_s"
    ]
  },
  {
    "title": "LTXV Scheduler",
    "description": "Custom scheduler for LTXV models.\n    sampling, custom, scheduler, ltxv\n\n    Use cases:\n    - Generate custom sigma schedules for sampling\n    - Adjust sigmas based on latent tokens\n    - Fine-tune sampling parameters for video models",
    "namespace": "comfy.sampling.schedulers",
    "node_type": "comfy.sampling.schedulers.LTXVScheduler",
    "layout": "default",
    "properties": [
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Steps",
        "description": "Number of steps.",
        "min": 1.0,
        "max": 10000.0
      },
      {
        "name": "max_shift",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2.05,
        "title": "Max Shift",
        "description": "Maximum shift parameter.",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "base_shift",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.95,
        "title": "Base Shift",
        "description": "Base shift parameter.",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "stretch",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Stretch",
        "description": "Stretch sigmas to fit terminal value.",
        "min": null,
        "max": null
      },
      {
        "name": "terminal",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.1,
        "title": "Terminal",
        "description": "Terminal value for sigmas.",
        "min": 0.0,
        "max": 0.99
      },
      {
        "name": "latent",
        "type": {
          "type": "comfy.latent",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Latent",
        "description": "Optional latent input.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.sigmas",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "sigmas",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "steps",
      "max_shift",
      "base_shift",
      "stretch",
      "terminal",
      "latent"
    ]
  },
  {
    "title": "Split Sigmas",
    "description": "Split an array of sigmas into two arrays.",
    "namespace": "comfy.sampling.sigmas",
    "node_type": "comfy.sampling.sigmas.SplitSigmas",
    "layout": "default",
    "properties": [
      {
        "name": "sigmas",
        "type": {
          "type": "comfy.sigmas",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.sigmas",
          "data": null
        },
        "title": "Sigmas",
        "description": "The array of sigmas to split.",
        "min": null,
        "max": null
      },
      {
        "name": "step",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Step",
        "description": "The specific step at which to split the sigmas array.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "sigmas",
      "step"
    ]
  },
  {
    "title": "Flip Sigmas",
    "description": "Flip an array of sigmas.",
    "namespace": "comfy.sampling.sigmas",
    "node_type": "comfy.sampling.sigmas.FlipSigmas",
    "layout": "default",
    "properties": [
      {
        "name": "sigmas",
        "type": {
          "type": "comfy.sigmas",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.sigmas",
          "data": null
        },
        "title": "Sigmas",
        "description": "The array of sigmas to flip.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.sigmas",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "sigmas",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "sigmas"
    ]
  },
  {
    "title": "Basic Guider",
    "description": "The Basic Guider node provides a simple guidance mechanism for the sampling process. It uses a single conditioning input to guide the model's generation.\n    sampling, guidance, basic\n    Use cases:\n    - Simple guidance for image generation\n    - Single conditioning input scenarios\n    - Basic control over the sampling process",
    "namespace": "comfy.sampling.guiders",
    "node_type": "comfy.sampling.guiders.BasicGuider",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model used by the sampler.",
        "min": null,
        "max": null
      },
      {
        "name": "conditioning",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Conditioning",
        "description": "The conditioning.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.guider",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "guider",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "conditioning"
    ]
  },
  {
    "title": "CFGGuider",
    "description": "The CFG (Classifier-Free Guidance) Guider node implements the classifier-free guidance method for controlling the generation process. It allows for separate positive and negative conditioning, along with a CFG scale parameter.\n    sampling, guidance, cfg\n    Use cases:\n    - Advanced control over the sampling process\n    - Combining multiple conditioning inputs\n    - Creating diverse image variations",
    "namespace": "comfy.sampling.guiders",
    "node_type": "comfy.sampling.guiders.CFGGuider",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model used by the sampler.",
        "min": null,
        "max": null
      },
      {
        "name": "positive",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Positive",
        "description": "The positive conditioning.",
        "min": null,
        "max": null
      },
      {
        "name": "negative",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative",
        "description": "The negative conditioning.",
        "min": null,
        "max": null
      },
      {
        "name": "cfg",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8.0,
        "title": "Cfg",
        "description": "The cfg (classifier-free guidance) parameter.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.guider",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "guider",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "positive",
      "negative",
      "cfg"
    ]
  },
  {
    "title": "Dual CFGGuider",
    "description": "The Dual CFG Guider node extends the CFG guidance method by allowing two separate conditioning inputs, each with its own CFG scale. This can be useful for more complex guidance scenarios or when combining multiple concepts.\n    sampling, guidance, cfg, dual\n    Use cases:\n    - Advanced control over the sampling process\n    - Combining multiple conditioning inputs\n    - Creating diverse image variations",
    "namespace": "comfy.sampling.guiders",
    "node_type": "comfy.sampling.guiders.DualCFGGuider",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model used by the sampler.",
        "min": null,
        "max": null
      },
      {
        "name": "cond1",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Cond1",
        "description": "The first conditioning.",
        "min": null,
        "max": null
      },
      {
        "name": "cond2",
        "type": {
          "type": "comfy.conditioning",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.conditioning",
          "data": null
        },
        "title": "Cond2",
        "description": "The second conditioning.",
        "min": null,
        "max": null
      },
      {
        "name": "negative",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative",
        "description": "The negative conditioning.",
        "min": null,
        "max": null
      },
      {
        "name": "cfg_conds",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8.0,
        "title": "Cfg Conds",
        "description": "The cfg (classifier-free guidance) parameter.",
        "min": null,
        "max": null
      },
      {
        "name": "cfg_conds2_negative",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8.0,
        "title": "Cfg Conds2 Negative",
        "description": "The cfg (classifier-free guidance) parameter for the second conditioning.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.guider",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "guider",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "cond1",
      "cond2",
      "negative",
      "cfg_conds",
      "cfg_conds2_negative"
    ]
  },
  {
    "title": "Video Linear CFGGuidance",
    "description": "The Video Linear CFG Guidance node applies a linear CFG guidance scheme specifically designed for video generation tasks. It allows setting a minimum CFG value to control the strength of the guidance throughout the video frames.\n    sampling, guidance, cfg, video\n    Use cases:\n    - Creating consistent video outputs\n    - Controlling the strength of guidance across frames\n    - Enhancing video generation with CFG",
    "namespace": "comfy.sampling.guiders",
    "node_type": "comfy.sampling.guiders.VideoLinearCFGGuidance",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to apply guidance to.",
        "min": null,
        "max": null
      },
      {
        "name": "min_cfg",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Min Cfg",
        "description": "The minimum CFG value.",
        "min": 0.0,
        "max": 100.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "min_cfg"
    ]
  },
  {
    "title": "Video Triangle CFGGuidance",
    "description": "The Video Triangle CFG Guidance node applies a triangular CFG guidance scheme for video generation. This can create a varying strength of guidance across video frames, potentially leading to more dynamic or consistent video outputs.\n    sampling, guidance, cfg, video\n    Use cases:\n    - Creating dynamic video outputs\n    - Controlling the strength of guidance across frames\n    - Enhancing video generation with CFG",
    "namespace": "comfy.sampling.guiders",
    "node_type": "comfy.sampling.guiders.VideoTriangleCFGGuidance",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model to apply guidance to.",
        "min": null,
        "max": null
      },
      {
        "name": "min_cfg",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Min Cfg",
        "description": "The minimum CFG value.",
        "min": 0.0,
        "max": 100.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "model",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "min_cfg"
    ]
  },
  {
    "title": "Random Noise",
    "description": "Generate random noise.",
    "namespace": "comfy.sampling.noise",
    "node_type": "comfy.sampling.noise.RandomNoise",
    "layout": "default",
    "properties": [
      {
        "name": "noise_seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Noise Seed",
        "description": "The seed for the noise generation.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "comfy.noise",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "noise",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "noise_seed"
    ]
  },
  {
    "title": "Disable Noise",
    "description": "Disable noise generation.",
    "namespace": "comfy.sampling.noise",
    "node_type": "comfy.sampling.noise.DisableNoise",
    "layout": "default",
    "properties": [],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": []
  },
  {
    "title": "Add Noise",
    "description": "Add noise to an image.",
    "namespace": "comfy.sampling.noise",
    "node_type": "comfy.sampling.noise.AddNoise",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "comfy.unet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.unet",
          "name": "",
          "model": null
        },
        "title": "Model",
        "description": "The model used by the sampler.",
        "min": null,
        "max": null
      },
      {
        "name": "noise",
        "type": {
          "type": "comfy.noise",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.noise",
          "data": null
        },
        "title": "Noise",
        "description": "The noise to add.",
        "min": null,
        "max": null
      },
      {
        "name": "sigmas",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8.0,
        "title": "Sigmas",
        "description": "The sigmas used in sampling.",
        "min": null,
        "max": null
      },
      {
        "name": "latent_image",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Latent Image",
        "description": "The latent image to sample from.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "noise",
      "sigmas",
      "latent_image"
    ]
  },
  {
    "title": "Lo RASelector",
    "description": "Selects up to 5 LoRA models to apply to a Stable Diffusion model.\n    lora, model customization, fine-tuning\n\n    Use cases:\n    - Combining multiple LoRA models for unique image styles\n    - Fine-tuning Stable Diffusion models with specific attributes\n    - Experimenting with different LoRA combinations",
    "namespace": "comfy.basic",
    "node_type": "comfy.basic.LoRASelector",
    "layout": "default",
    "properties": [
      {
        "name": "lora1",
        "type": {
          "type": "comfy.lora_file",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.lora_file",
          "name": ""
        },
        "title": "Lora1",
        "description": "First LoRA model",
        "min": null,
        "max": null
      },
      {
        "name": "strength1",
        "type": {
          "type": "float",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength1",
        "description": "Strength for first LoRA",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "lora2",
        "type": {
          "type": "comfy.lora_file",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.lora_file",
          "name": ""
        },
        "title": "Lora2",
        "description": "Second LoRA model",
        "min": null,
        "max": null
      },
      {
        "name": "strength2",
        "type": {
          "type": "float",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength2",
        "description": "Strength for second LoRA",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "lora3",
        "type": {
          "type": "comfy.lora_file",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.lora_file",
          "name": ""
        },
        "title": "Lora3",
        "description": "Third LoRA model",
        "min": null,
        "max": null
      },
      {
        "name": "strength3",
        "type": {
          "type": "float",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength3",
        "description": "Strength for third LoRA",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "lora4",
        "type": {
          "type": "comfy.lora_file",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.lora_file",
          "name": ""
        },
        "title": "Lora4",
        "description": "Fourth LoRA model",
        "min": null,
        "max": null
      },
      {
        "name": "strength4",
        "type": {
          "type": "float",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength4",
        "description": "Strength for fourth LoRA",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "lora5",
        "type": {
          "type": "comfy.lora_file",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "comfy.lora_file",
          "name": ""
        },
        "title": "Lora5",
        "description": "Fifth LoRA model",
        "min": null,
        "max": null
      },
      {
        "name": "strength5",
        "type": {
          "type": "float",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength5",
        "description": "Strength for fifth LoRA",
        "min": 0.0,
        "max": 2.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "comfy.lora_config",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "lora1",
      "strength1",
      "lora2",
      "strength2",
      "lora3",
      "strength3",
      "lora4",
      "strength4",
      "lora5",
      "strength5"
    ]
  },
  {
    "title": "Stable Diffusion",
    "description": "Generates images based on an input image and text prompts using Stable Diffusion. Works with 1.5 and XL models. Supports optional high-resolution upscaling.\n    image, image-to-image, generative AI, stable diffusion, high-resolution, SD1.5\n\n    Use cases:\n    - Modifying existing images based on text descriptions\n    - Applying artistic styles to photographs\n    - Generating variations of existing artwork or designs\n    - Enhancing or altering stock images for specific needs\n    - Creating high-resolution images from lower resolution inputs",
    "namespace": "comfy.basic",
    "node_type": "comfy.basic.StableDiffusion",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.stable_diffusion",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.stable_diffusion",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to use.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "The negative prompt to use.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Seed",
        "description": null,
        "min": 0.0,
        "max": 1000000.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.0,
        "title": "Guidance Scale",
        "description": null,
        "min": 1.0,
        "max": 30.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Num Inference Steps",
        "description": null,
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 768,
        "title": "Width",
        "description": null,
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 768,
        "title": "Height",
        "description": null,
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "normal",
            "karras",
            "exponential",
            "sgm_uniform",
            "simple",
            "ddim_uniform",
            "beta",
            "linear_quadratic"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.enums.Scheduler"
        },
        "default": "exponential",
        "title": "Scheduler",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "sampler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "ddim",
            "ddpm",
            "dpm_2",
            "dpm_2_ancestral",
            "dpm_adaptive",
            "dpm_fast",
            "dpmpp_2m",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_2s_ancestral",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "euler",
            "euler_ancestral",
            "heun",
            "heunpp2",
            "lcm",
            "lms",
            "uni_pc",
            "uni_pc_bh2"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.enums.Sampler"
        },
        "default": "euler_ancestral",
        "title": "Sampler",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "input_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Input Image",
        "description": "Input image for img2img (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "mask_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask Image",
        "description": "Mask image for img2img (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "grow_mask_by",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 6,
        "title": "Grow Mask By",
        "description": null,
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "denoise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Denoise",
        "description": null,
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "loras",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "comfy.lora_config",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Loras",
        "description": "List of LoRA models to apply",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.stable_diffusion",
        "repo_id": "SG161222/Realistic_Vision_V5.1_noVAE",
        "path": "Realistic_Vision_V5.1_fp16-no-ema.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "digiplay/majicMIX_realistic_v7",
        "path": "majicmixRealistic_v7.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "philz1337x/epicrealism",
        "path": "epicrealism_naturalSinRC1VAE.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/DreamShaper",
        "path": "DreamShaper_5_beta2_noVae_half_pruned.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/DreamShaper",
        "path": "DreamShaper_4BakedVae_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "XpucT/Deliberate",
        "path": "Deliberate_v6.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "XpucT/Deliberate",
        "path": "Deliberate_v6-inpainting.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/AbsoluteReality",
        "path": "AbsoluteReality_1.8.1_pruned.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "Lykon/AbsoluteReality",
        "path": "AbsoluteReality_1.8.1_INPAINTING.inpainting.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion",
        "repo_id": "gsdf/Counterfeit-V2.5",
        "path": "Counterfeit-V2.5_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt",
      "negative_prompt",
      "seed",
      "guidance_scale",
      "num_inference_steps",
      "width",
      "height",
      "scheduler",
      "sampler",
      "input_image",
      "mask_image",
      "grow_mask_by",
      "denoise",
      "loras"
    ]
  },
  {
    "title": "Stable Diffusion XL",
    "description": "Generates images using Stable Diffusion XL model.\n    image, text-to-image, generative AI, SDXL\n\n    Use cases:\n    - Creating high-quality images with the latest SDXL models\n    - Generating detailed and coherent images from text descriptions\n    - Producing images with improved composition and understanding",
    "namespace": "comfy.basic",
    "node_type": "comfy.basic.StableDiffusionXL",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.stable_diffusion_xl",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.stable_diffusion_xl",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to use.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "The negative prompt to use.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Seed",
        "description": null,
        "min": 0.0,
        "max": 1000000.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.0,
        "title": "Guidance Scale",
        "description": null,
        "min": 1.0,
        "max": 30.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Num Inference Steps",
        "description": null,
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 768,
        "title": "Width",
        "description": null,
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 768,
        "title": "Height",
        "description": null,
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "normal",
            "karras",
            "exponential",
            "sgm_uniform",
            "simple",
            "ddim_uniform",
            "beta",
            "linear_quadratic"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.enums.Scheduler"
        },
        "default": "exponential",
        "title": "Scheduler",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "sampler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "ddim",
            "ddpm",
            "dpm_2",
            "dpm_2_ancestral",
            "dpm_adaptive",
            "dpm_fast",
            "dpmpp_2m",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_2s_ancestral",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "euler",
            "euler_ancestral",
            "heun",
            "heunpp2",
            "lcm",
            "lms",
            "uni_pc",
            "uni_pc_bh2"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.enums.Sampler"
        },
        "default": "euler_ancestral",
        "title": "Sampler",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "input_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Input Image",
        "description": "Input image for img2img (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "mask_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask Image",
        "description": "Mask image for img2img (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "grow_mask_by",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 6,
        "title": "Grow Mask By",
        "description": null,
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "denoise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Denoise",
        "description": null,
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "loras",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "comfy.lora_config",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Loras",
        "description": "List of LoRA models to apply",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "stabilityai/stable-diffusion-xl-base-1.0",
        "path": "sd_xl_base_1.0.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "stabilityai/stable-diffusion-xl-refiner-1.0",
        "path": "sd_xl_refiner_1.0.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "playgroundai/playground-v2.5-1024px-aesthetic",
        "path": "playground-v2.5-1024px-aesthetic.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "RunDiffusion/Juggernaut-XL-v9",
        "path": "Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "dataautogpt3/ProteusV0.5",
        "path": "proteusV0.5.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "Lykon/dreamshaper-xl-lightning",
        "path": "DreamShaperXL_Lightning.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "Lykon/AAM_XL_AnimeMix",
        "path": "AAM_XL_Anime_Mix.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "stabilityai/sdxl-turbo",
        "path": "sd_xl_turbo_1.0_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.stable_diffusion_xl",
        "repo_id": "Lykon/dreamshaper-xl-v2-turbo",
        "path": "DreamShaperXL_Turbo_v2_1.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt",
      "negative_prompt",
      "seed",
      "guidance_scale",
      "num_inference_steps",
      "width",
      "height",
      "scheduler",
      "sampler",
      "input_image",
      "mask_image",
      "grow_mask_by",
      "denoise",
      "loras"
    ]
  },
  {
    "title": "Stable Diffusion 3.5",
    "description": "Generates images using Stable Diffusion 3.5 model.\n    image, text-to-image, generative, SD3.5\n    Generates images using Stable Diffusion 3 model.\n    image, text-to-image, generative, SD3\n\n    Use cases:\n    - Creating high-quality images with the latest SD3 model\n    - Generating detailed and coherent images from text descriptions\n    - Producing images with improved composition and understanding",
    "namespace": "comfy.basic",
    "node_type": "comfy.basic.StableDiffusion3",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.stable_diffusion_3",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.stable_diffusion_3",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to use.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "The negative prompt to use.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Seed",
        "description": null,
        "min": 0.0,
        "max": 1000000.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4.0,
        "title": "Guidance Scale",
        "description": null,
        "min": 1.0,
        "max": 30.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Num Inference Steps",
        "description": null,
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 768,
        "title": "Width",
        "description": null,
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 768,
        "title": "Height",
        "description": null,
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "normal",
            "karras",
            "exponential",
            "sgm_uniform",
            "simple",
            "ddim_uniform",
            "beta",
            "linear_quadratic"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.enums.Scheduler"
        },
        "default": "exponential",
        "title": "Scheduler",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "sampler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "ddim",
            "ddpm",
            "dpm_2",
            "dpm_2_ancestral",
            "dpm_adaptive",
            "dpm_fast",
            "dpmpp_2m",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_2s_ancestral",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "euler",
            "euler_ancestral",
            "heun",
            "heunpp2",
            "lcm",
            "lms",
            "uni_pc",
            "uni_pc_bh2"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.enums.Sampler"
        },
        "default": "euler_ancestral",
        "title": "Sampler",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "input_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Input Image",
        "description": "Input image for img2img (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "mask_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask Image",
        "description": "Mask image for img2img (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "grow_mask_by",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 6,
        "title": "Grow Mask By",
        "description": null,
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "denoise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Denoise",
        "description": null,
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "loras",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "comfy.lora_config",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Loras",
        "description": "List of LoRA models to apply",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.stable_diffusion_3",
        "repo_id": "Comfy-Org/stable-diffusion-3.5-fp8",
        "path": "sd3.5_large_fp8_scaled.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt",
      "negative_prompt",
      "seed",
      "guidance_scale",
      "num_inference_steps",
      "width",
      "height",
      "scheduler",
      "sampler",
      "input_image",
      "mask_image",
      "grow_mask_by",
      "denoise",
      "loras"
    ]
  },
  {
    "title": "Control Net",
    "description": "Generates images using Stable Diffusion with ControlNet for additional image control. Supports optional high-resolution upscaling while maintaining the same ControlNet strength.\n    image, controlnet, generative, stable diffusion, high-resolution, SD\n    \n    Use cases:\n    - Generating images with specific structural guidance\n    - Creating images that follow edge maps or depth information\n    - Producing variations of images while maintaining certain features\n    - Enhancing image generation with additional control signals\n    - Creating high-resolution images with consistent controlled features",
    "namespace": "comfy.basic",
    "node_type": "comfy.basic.ControlNet",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.stable_diffusion",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.stable_diffusion",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to use.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "The negative prompt to use.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Seed",
        "description": null,
        "min": 0.0,
        "max": 1000000.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.0,
        "title": "Guidance Scale",
        "description": null,
        "min": 1.0,
        "max": 30.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Num Inference Steps",
        "description": null,
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 768,
        "title": "Width",
        "description": null,
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 768,
        "title": "Height",
        "description": null,
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "normal",
            "karras",
            "exponential",
            "sgm_uniform",
            "simple",
            "ddim_uniform",
            "beta",
            "linear_quadratic"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.enums.Scheduler"
        },
        "default": "exponential",
        "title": "Scheduler",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "sampler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "ddim",
            "ddpm",
            "dpm_2",
            "dpm_2_ancestral",
            "dpm_adaptive",
            "dpm_fast",
            "dpmpp_2m",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_2s_ancestral",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "euler",
            "euler_ancestral",
            "heun",
            "heunpp2",
            "lcm",
            "lms",
            "uni_pc",
            "uni_pc_bh2"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.enums.Sampler"
        },
        "default": "euler_ancestral",
        "title": "Sampler",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "input_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Input Image",
        "description": "Input image for img2img (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "mask_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask Image",
        "description": "Mask image for img2img (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "grow_mask_by",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 6,
        "title": "Grow Mask By",
        "description": null,
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "denoise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Denoise",
        "description": null,
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "loras",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "comfy.lora_config",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Loras",
        "description": "List of LoRA models to apply",
        "min": null,
        "max": null
      },
      {
        "name": "controlnet",
        "type": {
          "type": "hf.controlnet",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.controlnet",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Controlnet",
        "description": "The ControlNet model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Canny edge detection image for ControlNet",
        "min": null,
        "max": null
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Strength",
        "description": "Strength of ControlNet (used for both low and high resolution)",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_canny",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_inpaint",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_mlsd",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_tile",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_shuffle",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_ip2p",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_lineart",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_lineart_anime",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_scribble",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_openpose",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_scribble",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_seg",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_hed",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.controlnet",
        "repo_id": "lllyasviel/control_v11p_sd15_normalbae",
        "path": "diffusion_pytorch_model.fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt",
      "negative_prompt",
      "seed",
      "guidance_scale",
      "num_inference_steps",
      "width",
      "height",
      "scheduler",
      "sampler",
      "input_image",
      "mask_image",
      "grow_mask_by",
      "denoise",
      "loras",
      "controlnet",
      "image",
      "strength"
    ]
  },
  {
    "title": "Flux",
    "description": "Generates images from text prompts using the Flux model.\n    image, text-to-image, generative AI, flux\n\n    Use cases:\n    - Creating high-quality anime-style illustrations\n    - Generating detailed character artwork\n    - Producing images with specific artistic styles",
    "namespace": "comfy.basic",
    "node_type": "comfy.basic.Flux",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.flux",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.flux",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to use.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "The negative prompt to use.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": null,
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": null,
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "batch_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Batch Size",
        "description": null,
        "min": 1.0,
        "max": 16.0
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Steps",
        "description": null,
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Guidance Scale",
        "description": null,
        "min": 1.0,
        "max": 30.0
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Seed",
        "description": null,
        "min": 0.0,
        "max": 1000000000.0
      },
      {
        "name": "denoise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Denoise",
        "description": null,
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "normal",
            "karras",
            "exponential",
            "sgm_uniform",
            "simple",
            "ddim_uniform",
            "beta",
            "linear_quadratic"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.enums.Scheduler"
        },
        "default": "simple",
        "title": "Scheduler",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "sampler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "ddim",
            "ddpm",
            "dpm_2",
            "dpm_2_ancestral",
            "dpm_adaptive",
            "dpm_fast",
            "dpmpp_2m",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_2s_ancestral",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "euler",
            "euler_ancestral",
            "heun",
            "heunpp2",
            "lcm",
            "lms",
            "uni_pc",
            "uni_pc_bh2"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.enums.Sampler"
        },
        "default": "euler",
        "title": "Sampler",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.unet",
        "repo_id": "black-forest-labs/FLUX.1-dev",
        "path": "flux1-dev.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.unet",
        "repo_id": "black-forest-labs/FLUX.1-schnell",
        "path": "flux1-schnell.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.vae",
        "repo_id": "black-forest-labs/FLUX.1-schnell",
        "path": "ae.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.clip",
        "repo_id": "comfyanonymous/flux_text_encoders",
        "path": "clip_l.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.clip",
        "repo_id": "comfyanonymous/flux_text_encoders",
        "path": "t5xxl_fp16.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt",
      "negative_prompt",
      "width",
      "height",
      "batch_size",
      "steps",
      "guidance_scale",
      "seed",
      "denoise",
      "scheduler",
      "sampler"
    ]
  },
  {
    "title": "Flux FP8",
    "description": "Generates images from text prompts using the Flux model.\n    image, text-to-image, generative AI, flux\n\n    Use cases:\n    - Creating high-quality anime-style illustrations\n    - Generating detailed character artwork\n    - Producing images with specific artistic styles",
    "namespace": "comfy.basic",
    "node_type": "comfy.basic.FluxFP8",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "hf.flux",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "hf.flux",
          "repo_id": "",
          "path": null,
          "allow_patterns": null,
          "ignore_patterns": null
        },
        "title": "Model",
        "description": "The model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to use.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "The negative prompt to use.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": null,
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": null,
        "min": 64.0,
        "max": 2048.0
      },
      {
        "name": "batch_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Batch Size",
        "description": null,
        "min": 1.0,
        "max": 16.0
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Steps",
        "description": null,
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Guidance Scale",
        "description": null,
        "min": 1.0,
        "max": 30.0
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Seed",
        "description": null,
        "min": 0.0,
        "max": 1000000000.0
      },
      {
        "name": "denoise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Denoise",
        "description": null,
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "normal",
            "karras",
            "exponential",
            "sgm_uniform",
            "simple",
            "ddim_uniform",
            "beta",
            "linear_quadratic"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.enums.Scheduler"
        },
        "default": "simple",
        "title": "Scheduler",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "sampler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "ddim",
            "ddpm",
            "dpm_2",
            "dpm_2_ancestral",
            "dpm_adaptive",
            "dpm_fast",
            "dpmpp_2m",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_2s_ancestral",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "euler",
            "euler_ancestral",
            "heun",
            "heunpp2",
            "lcm",
            "lms",
            "uni_pc",
            "uni_pc_bh2"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.comfy.enums.Sampler"
        },
        "default": "euler",
        "title": "Sampler",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [
      {
        "type": "hf.flux",
        "repo_id": "Comfy-Org/flux1-dev",
        "path": "flux1-dev-fp8.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      },
      {
        "type": "hf.flux",
        "repo_id": "Comfy-Org/flux1-schnell",
        "path": "flux1-schnell-fp8.safetensors",
        "allow_patterns": null,
        "ignore_patterns": null
      }
    ],
    "basic_fields": [
      "model",
      "prompt",
      "negative_prompt",
      "width",
      "height",
      "batch_size",
      "steps",
      "guidance_scale",
      "seed",
      "denoise",
      "scheduler",
      "sampler"
    ]
  },
  {
    "title": "Primitive",
    "description": "",
    "namespace": "comfy",
    "node_type": "comfy.Primitive",
    "layout": "default",
    "properties": [],
    "outputs": [
      {
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": []
  },
  {
    "title": "Reroute",
    "description": "",
    "namespace": "comfy",
    "node_type": "comfy.Reroute",
    "layout": "default",
    "properties": [],
    "outputs": [
      {
        "type": {
          "type": "any",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": []
  },
  {
    "title": "Any LLM",
    "description": "Use any large language model from a selected catalogue (powered by OpenRouter).\n    Supports various models including Claude 3, Gemini, Llama, and GPT-4.",
    "namespace": "fal.llm",
    "node_type": "fal.llm.AnyLLM",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to send to the language model",
        "min": null,
        "max": null
      },
      {
        "name": "system_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "System Prompt",
        "description": "Optional system prompt to provide context or instructions",
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "anthropic/claude-3.5-sonnet",
            "anthropic/claude-3-5-haiku",
            "anthropic/claude-3-haiku",
            "google/gemini-pro-1.5",
            "google/gemini-flash-1.5",
            "google/gemini-flash-1.5-8b",
            "meta-llama/llama-3.2-1b-instruct",
            "meta-llama/llama-3.2-3b-instruct",
            "meta-llama/llama-3.1-8b-instruct",
            "meta-llama/llama-3.1-70b-instruct",
            "openai/gpt-4o-mini",
            "openai/gpt-4o"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.llm.ModelEnum"
        },
        "default": "google/gemini-flash-1.5",
        "title": "Model",
        "description": "The language model to use for the completion",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "model",
      "system_prompt"
    ]
  },
  {
    "title": "Ideogram V 2",
    "description": "Ideogram V2 is a state-of-the-art image generation model optimized for commercial and creative use,\n    featuring exceptional typography handling and realistic outputs.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.IdeogramV2",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "10:16",
            "16:10",
            "9:16",
            "16:9",
            "4:3",
            "3:4",
            "1:1",
            "1:3",
            "3:1",
            "3:2",
            "2:3",
            "4:5",
            "5:4"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "The aspect ratio of the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "expand_prompt",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Expand Prompt",
        "description": "Whether to expand the prompt with MagicPrompt functionality.",
        "min": null,
        "max": null
      },
      {
        "name": "style",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "auto",
            "general",
            "realistic",
            "design",
            "render_3D",
            "anime"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.IdeogramStyle"
        },
        "default": "auto",
        "title": "Style",
        "description": "The style of the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "A negative prompt to avoid in the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "Seed for the random number generator.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "aspect_ratio",
      "style"
    ]
  },
  {
    "title": "Ideogram V 2 Turbo",
    "description": "Accelerated image generation with Ideogram V2 Turbo. Create high-quality visuals, posters,\n    and logos with enhanced speed while maintaining Ideogram's signature quality.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.IdeogramV2Turbo",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "10:16",
            "16:10",
            "9:16",
            "16:9",
            "4:3",
            "3:4",
            "1:1",
            "1:3",
            "3:1",
            "3:2",
            "2:3",
            "4:5",
            "5:4"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "The aspect ratio of the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "expand_prompt",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Expand Prompt",
        "description": "Whether to expand the prompt with MagicPrompt functionality.",
        "min": null,
        "max": null
      },
      {
        "name": "style",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "auto",
            "general",
            "realistic",
            "design",
            "render_3D",
            "anime"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.IdeogramStyle"
        },
        "default": "auto",
        "title": "Style",
        "description": "The style of the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "A negative prompt to avoid in the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "Seed for the random number generator.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "aspect_ratio",
      "style"
    ]
  },
  {
    "title": "Flux V 1 Pro",
    "description": "FLUX1.1 [pro] is an enhanced version of FLUX.1 [pro], improved image generation capabilities, delivering superior composition, detail, and artistic fidelity compared to its predecessor.\n    fal, text, image",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.FluxV1Pro",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square_hd",
        "title": "Image Size",
        "description": "Either a preset size or a custom {width, height} dictionary. Max dimension 14142",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform.",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": true,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image_size",
      "guidance_scale"
    ]
  },
  {
    "title": "Flux V 1 Pro Ultra",
    "description": "FLUX1.1 [ultra] is the latest and most advanced version of FLUX.1 [pro],\n    featuring cutting-edge improvements in image generation, delivering unparalleled\n    composition, detail, and artistic fidelity.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.FluxV1ProUltra",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square_hd",
        "title": "Image Size",
        "description": "Either a preset size or a custom {width, height} dictionary. Max dimension 14142",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform.",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and the same prompt given to the same version of the model will output the same image every time.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image_size",
      "guidance_scale"
    ]
  },
  {
    "title": "Recraft V 3",
    "description": "Recraft V3 is a text-to-image model with the ability to generate long texts, vector art, images in brand style, and much more.\n    image, text",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.RecraftV3",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square_hd",
        "title": "Image Size",
        "description": "Either a preset size or a custom {width, height} dictionary. Max dimension 14142",
        "min": null,
        "max": null
      },
      {
        "name": "style",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "any",
            "realistic_image",
            "digital_illustration",
            "vector_illustration",
            "pixel_art",
            "flat_illustration",
            "isometric_illustration",
            "watercolor",
            "line_art",
            "pencil_drawing",
            "oil_painting",
            "anime",
            "comic_book",
            "retro",
            "sticker",
            "3d_render",
            "cinematic",
            "photographic",
            "clay",
            "cutout",
            "origami",
            "pattern",
            "pop_art",
            "renaissance",
            "studio_ghibli",
            "storybook"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.StylePreset"
        },
        "default": "realistic_image",
        "title": "Style",
        "description": "The style of the generated images. Vector images cost 2X as much.",
        "min": null,
        "max": null
      },
      {
        "name": "colors",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "color",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Colors",
        "description": "An array of preferable colors",
        "min": null,
        "max": null
      },
      {
        "name": "style_id",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Style Id",
        "description": "The ID of the custom style reference (optional)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image_size",
      "style"
    ]
  },
  {
    "title": "Switti",
    "description": "Switti is a scale-wise transformer for fast text-to-image generation that outperforms existing T2I AR models\n    and competes with state-of-the-art T2I diffusion models while being faster than distilled diffusion models.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.Switti",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Use it to address details that you don't want in the image",
        "min": null,
        "max": null
      },
      {
        "name": "sampling_top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 400,
        "title": "Sampling Top K",
        "description": "The number of top-k tokens to sample from",
        "min": null,
        "max": null
      },
      {
        "name": "sampling_top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.95,
        "title": "Sampling Top P",
        "description": "The top-p probability to sample from",
        "min": null,
        "max": null
      },
      {
        "name": "more_smooth",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "More Smooth",
        "description": "Smoothing with Gumbel softmax sampling",
        "min": null,
        "max": null
      },
      {
        "name": "more_diverse",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "More Diverse",
        "description": "More diverse sampling",
        "min": null,
        "max": null
      },
      {
        "name": "smooth_start_si",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Smooth Start Si",
        "description": "Smoothing starting scale",
        "min": null,
        "max": null
      },
      {
        "name": "turn_off_cfg_start_si",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8,
        "title": "Turn Off Cfg Start Si",
        "description": "Disable CFG starting scale",
        "min": null,
        "max": null
      },
      {
        "name": "last_scale_temp",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.1,
        "title": "Last Scale Temp",
        "description": "Temperature after disabling CFG",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 6.0,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "guidance_scale",
      "negative_prompt"
    ]
  },
  {
    "title": "Aura Flow V 03",
    "description": "AuraFlow v0.3 is an open-source flow-based text-to-image generation model that achieves\n    state-of-the-art results on GenEval.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.AuraFlowV03",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "num_images",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Images",
        "description": "The number of images to generate",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "Classifier free guidance scale",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to take",
        "min": 1.0,
        "max": null
      },
      {
        "name": "expand_prompt",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Expand Prompt",
        "description": "Whether to perform prompt expansion (recommended)",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The seed to use for generating images",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "guidance_scale",
      "num_inference_steps"
    ]
  },
  {
    "title": "Flux Dev",
    "description": "FLUX.1 [dev] is a 12 billion parameter flow transformer that generates high-quality images from text.\n    It is suitable for personal and commercial use.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.FluxDev",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "landscape_4_3",
        "title": "Image Size",
        "description": "Either a preset size or a custom {width, height} dictionary",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "num_images",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Images",
        "description": "The number of images to generate",
        "min": 1.0,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image_size",
      "guidance_scale"
    ]
  },
  {
    "title": "Flux Lora",
    "description": "FLUX.1 [dev] with LoRAs is a text-to-image model that supports LoRA adaptations,\n    enabling rapid and high-quality image generation with pre-trained LoRA weights for\n    personalization, specific styles, brand identities, and product-specific outputs.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.FluxLora",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "landscape_4_3",
        "title": "Image Size",
        "description": "Either a preset size or a custom {width, height} dictionary",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "The CFG scale to determine how closely the model follows the prompt",
        "min": null,
        "max": null
      },
      {
        "name": "loras",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "lora_weight",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Loras",
        "description": "List of LoRA weights to use for image generation",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image_size",
      "loras"
    ]
  },
  {
    "title": "Flux Lora Inpainting",
    "description": "FLUX.1 [dev] Inpainting with LoRAs is a text-to-image model that supports inpainting and LoRA adaptations,\n    enabling rapid and high-quality image inpainting using pre-trained LoRA weights for personalization,\n    specific styles, brand identities, and product-specific outputs.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.FluxLoraInpainting",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Image",
        "description": "The input image to inpaint",
        "min": null,
        "max": null
      },
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Mask",
        "description": "The mask indicating areas to inpaint (white=inpaint, black=keep)",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "The CFG scale to determine how closely the model follows the prompt",
        "min": null,
        "max": null
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.85,
        "title": "Strength",
        "description": "The strength to use for inpainting. 1.0 completely remakes the image while 0.0 preserves the original",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "loras",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "lora_weight",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Loras",
        "description": "List of LoRA weights to use for image generation",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image",
      "mask",
      "loras"
    ]
  },
  {
    "title": "Flux Schnell",
    "description": "FLUX.1 [schnell] is a 12 billion parameter flow transformer that generates high-quality images\n    from text in 1 to 4 steps, suitable for personal and commercial use.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.FluxSchnell",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "landscape_4_3",
        "title": "Image Size",
        "description": "Either a preset size or a custom {width, height} dictionary",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "num_images",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Images",
        "description": "The number of images to generate",
        "min": 1.0,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image_size",
      "num_inference_steps"
    ]
  },
  {
    "title": "Flux Subject",
    "description": "FLUX.1 Subject is a super fast endpoint for the FLUX.1 [schnell] model with subject input capabilities,\n    enabling rapid and high-quality image generation for personalization, specific styles, brand identities,\n    and product-specific outputs.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.FluxSubject",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Image",
        "description": "The image of the subject",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square_hd",
        "title": "Image Size",
        "description": "Either a preset size or a custom {width, height} dictionary",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "The CFG scale to determine how closely the model follows the prompt",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image",
      "image_size"
    ]
  },
  {
    "title": "Flux V 1 Pro New",
    "description": "FLUX.1 [pro] new is an accelerated version of FLUX.1 [pro], maintaining professional-grade\n    image quality while delivering significantly faster generation speeds.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.FluxV1ProNew",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "landscape_4_3",
        "title": "Image Size",
        "description": "Either a preset size or a custom {width, height} dictionary",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "The CFG scale to determine how closely the model follows the prompt",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "num_images",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Images",
        "description": "The number of images to generate",
        "min": 1.0,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "safety_tolerance",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Safety Tolerance",
        "description": "Safety tolerance level (1=strict, 6=permissive)",
        "min": 1.0,
        "max": 6.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image_size",
      "guidance_scale"
    ]
  },
  {
    "title": "Sana V 1",
    "description": "Sana can synthesize high-resolution, high-quality images with strong text-image alignment\n    at a remarkably fast speed, with the ability to generate 4K images in less than a second.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.SanaV1",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Use it to address details that you don't want in the image",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square_hd",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 18,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5.0,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "num_images",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Images",
        "description": "The number of images to generate",
        "min": 1.0,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image_size",
      "guidance_scale"
    ]
  },
  {
    "title": "Omni Gen V 1",
    "description": "OmniGen is a unified image generation model that can generate a wide range of images from multi-modal prompts.\n    It can be used for various tasks such as Image Editing, Personalized Image Generation, Virtual Try-On,\n    Multi Person Generation and more!",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.OmniGenV1",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "input_image_1",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Input Image 1",
        "description": "The first input image to use for generation",
        "min": null,
        "max": null
      },
      {
        "name": "input_image_2",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Input Image 2",
        "description": "The second input image to use for generation",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square_hd",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.0,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "img_guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.6,
        "title": "Img Guidance Scale",
        "description": "How closely the model should stick to your input image",
        "min": null,
        "max": null
      },
      {
        "name": "num_images",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Images",
        "description": "The number of images to generate",
        "min": 1.0,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "input_image_1",
      "image_size"
    ]
  },
  {
    "title": "Stable Diffusion V 35 Large",
    "description": "Stable Diffusion 3.5 Large is a Multimodal Diffusion Transformer (MMDiT) text-to-image model that features\n    improved performance in image quality, typography, complex prompt understanding, and resource-efficiency.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.StableDiffusionV35Large",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Use it to address details that you don't want in the image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "landscape_4_3",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "negative_prompt",
      "guidance_scale"
    ]
  },
  {
    "title": "Recraft 20 B",
    "description": "Recraft 20B is a new and affordable text-to-image model that delivers state-of-the-art results.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.Recraft20B",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square_hd",
        "title": "Image Size",
        "description": "Either a preset size or a custom {width, height} dictionary",
        "min": null,
        "max": null
      },
      {
        "name": "style",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "any",
            "realistic_image",
            "digital_illustration",
            "vector_illustration",
            "pixel_art",
            "flat_illustration",
            "isometric_illustration",
            "watercolor",
            "line_art",
            "pencil_drawing",
            "oil_painting",
            "anime",
            "comic_book",
            "retro",
            "sticker",
            "3d_render",
            "cinematic",
            "photographic",
            "clay",
            "cutout",
            "origami",
            "pattern",
            "pop_art",
            "renaissance",
            "studio_ghibli",
            "storybook"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.StylePreset"
        },
        "default": "realistic_image",
        "title": "Style",
        "description": "The style of the generated images. Vector images cost 2X as much.",
        "min": null,
        "max": null
      },
      {
        "name": "colors",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "color",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Colors",
        "description": "An array of preferable colors",
        "min": null,
        "max": null
      },
      {
        "name": "style_id",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Style Id",
        "description": "The ID of the custom style reference (optional)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image_size",
      "style"
    ]
  },
  {
    "title": "Bria V 1",
    "description": "Bria's Text-to-Image model, trained exclusively on licensed data for safe and risk-free commercial use.\n    Features exceptional image quality and commercial licensing safety.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.BriaV1",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "The negative prompt to avoid certain elements in the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_images",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Num Images",
        "description": "How many images to generate. When using guidance, value is set to 1",
        "min": 1.0,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "10:16",
            "16:10",
            "9:16",
            "16:9",
            "4:3",
            "3:4",
            "1:1",
            "1:3",
            "3:1",
            "3:2",
            "2:3",
            "4:5",
            "5:4"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "The aspect ratio of the image. Ignored when guidance is used",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Num Inference Steps",
        "description": "The number of iterations for refining the generated image",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5.0,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt (CFG scale)",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_enhancement",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Prompt Enhancement",
        "description": "When true, enhances the prompt with more descriptive variations",
        "min": null,
        "max": null
      },
      {
        "name": "medium",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Medium",
        "description": "Optional medium specification ('photography' or 'art')",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "negative_prompt",
      "aspect_ratio"
    ]
  },
  {
    "title": "Bria V 1 Fast",
    "description": "Bria's Text-to-Image model with perfect harmony of latency and quality.\n    Trained exclusively on licensed data for safe and risk-free commercial use.\n    Features faster inference times while maintaining high image quality.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.BriaV1Fast",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "The negative prompt to avoid certain elements in the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_images",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Num Images",
        "description": "How many images to generate. When using guidance, value is set to 1",
        "min": 1.0,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "10:16",
            "16:10",
            "9:16",
            "16:9",
            "4:3",
            "3:4",
            "1:1",
            "1:3",
            "3:1",
            "3:2",
            "2:3",
            "4:5",
            "5:4"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "The aspect ratio of the image. Ignored when guidance is used",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8,
        "title": "Num Inference Steps",
        "description": "The number of iterations for refining the generated image",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5.0,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt (CFG scale)",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_enhancement",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Prompt Enhancement",
        "description": "When true, enhances the prompt with more descriptive variations",
        "min": null,
        "max": null
      },
      {
        "name": "medium",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Medium",
        "description": "Optional medium specification ('photography' or 'art')",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "negative_prompt",
      "aspect_ratio"
    ]
  },
  {
    "title": "Bria V 1 HD",
    "description": "Bria's Text-to-Image model for HD images. Trained exclusively on licensed data for safe and\n    risk-free commercial use. Features exceptional image quality and commercial licensing safety.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.BriaV1HD",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "The negative prompt to avoid certain elements in the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_images",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Num Images",
        "description": "How many images to generate. When using guidance, value is set to 1",
        "min": 1.0,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "10:16",
            "16:10",
            "9:16",
            "16:9",
            "4:3",
            "3:4",
            "1:1",
            "1:3",
            "3:1",
            "3:2",
            "2:3",
            "4:5",
            "5:4"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "The aspect ratio of the image. Ignored when guidance is used",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Num Inference Steps",
        "description": "The number of iterations for refining the generated image",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5.0,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt (CFG scale)",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_enhancement",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Prompt Enhancement",
        "description": "When true, enhances the prompt with more descriptive variations",
        "min": null,
        "max": null
      },
      {
        "name": "medium",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Medium",
        "description": "Optional medium specification ('photography' or 'art')",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The seed to use for generating images",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "negative_prompt",
      "aspect_ratio"
    ]
  },
  {
    "title": "Flux General",
    "description": "FLUX.1 [dev] with Controlnets and Loras is a versatile text-to-image model that supports\n    multiple AI extensions including LoRA, ControlNet conditioning, and IP-Adapter integration,\n    enabling comprehensive control over image generation through various guidance methods.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.FluxGeneral",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square_hd",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt (CFG scale)",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "real_cfg_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Real Cfg Scale",
        "description": "Classical CFG scale as in SD1.5, SDXL, etc.",
        "min": null,
        "max": null
      },
      {
        "name": "use_real_cfg",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Use Real Cfg",
        "description": "Uses classical CFG. Increases generation times and price when true",
        "min": null,
        "max": null
      },
      {
        "name": "num_images",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Images",
        "description": "The number of images to generate",
        "min": 1.0,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      },
      {
        "name": "reference_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.65,
        "title": "Reference Strength",
        "description": "Strength of reference_only generation. Only used if a reference image is provided",
        "min": null,
        "max": null
      },
      {
        "name": "reference_end",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Reference End",
        "description": "The percentage of total timesteps when reference guidance should end",
        "min": null,
        "max": null
      },
      {
        "name": "base_shift",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Base Shift",
        "description": "Base shift for the scheduled timesteps",
        "min": null,
        "max": null
      },
      {
        "name": "max_shift",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.15,
        "title": "Max Shift",
        "description": "Max shift for the scheduled timesteps",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image_size",
      "guidance_scale"
    ]
  },
  {
    "title": "Stable Diffusion V 3 Medium",
    "description": "Stable Diffusion 3 Medium (Text to Image) is a Multimodal Diffusion Transformer (MMDiT) model\n    that improves image quality, typography, prompt understanding, and efficiency.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.StableDiffusionV3Medium",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "The negative prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_expansion",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Prompt Expansion",
        "description": "If set to true, prompt will be upsampled with more details",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square_hd",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5.0,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt (CFG scale)",
        "min": null,
        "max": null
      },
      {
        "name": "num_images",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Images",
        "description": "The number of images to generate",
        "min": 1.0,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "negative_prompt",
      "guidance_scale"
    ]
  },
  {
    "title": "Fast SDXL",
    "description": "Fast SDXL is a high-performance text-to-image model that runs SDXL at exceptional speeds\n    while maintaining high-quality output.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.FastSDXL",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Use it to address details that you don't want in the image",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square_hd",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt (CFG scale)",
        "min": null,
        "max": null
      },
      {
        "name": "num_images",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Images",
        "description": "The number of images to generate",
        "min": 1.0,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      },
      {
        "name": "expand_prompt",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Expand Prompt",
        "description": "If true, the prompt will be expanded with additional prompts",
        "min": null,
        "max": null
      },
      {
        "name": "loras",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "lora_weight",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Loras",
        "description": "The list of LoRA weights to use",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "negative_prompt",
      "guidance_scale"
    ]
  },
  {
    "title": "Flux Lora TTI",
    "description": "FLUX.1 with LoRAs is a text-to-image model that supports LoRA adaptations,\n    enabling high-quality image generation with customizable LoRA weights for\n    personalization, specific styles, and brand identities.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.FluxLoraTTI",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Use it to address details that you don't want in the image",
        "min": null,
        "max": null
      },
      {
        "name": "model_name",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "stabilityai/stable-diffusion-xl-base-1.0",
            "runwayml/stable-diffusion-v1-5",
            "stabilityai/stable-diffusion-2-1",
            "gsdf/Anything-V5.0",
            "lykon/dreamshaper-8",
            "XpucT/Deliberate_v3",
            "SG161222/Realistic_Vision_V5.1_noVAE"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.LoraModel"
        },
        "default": "stabilityai/stable-diffusion-xl-base-1.0",
        "title": "Model Name",
        "description": "The base model to use for generation",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square_hd",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "loras",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "lora_weight",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Loras",
        "description": "List of LoRA weights to use for image generation",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_weighting",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Prompt Weighting",
        "description": "If true, prompt weighting syntax will be used and 77 token limit lifted",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "model_name",
      "loras"
    ]
  },
  {
    "title": "Stable Cascade",
    "description": "Stable Cascade is a state-of-the-art text-to-image model that generates images on a smaller & cheaper\n    latent space while maintaining high quality output.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.StableCascade",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Use it to address details that you don't want in the image",
        "min": null,
        "max": null
      },
      {
        "name": "first_stage_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "First Stage Steps",
        "description": "Number of steps to run the first stage for",
        "min": null,
        "max": null
      },
      {
        "name": "second_stage_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10,
        "title": "Second Stage Steps",
        "description": "Number of steps to run the second stage for",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4.0,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "second_stage_guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4.0,
        "title": "Second Stage Guidance Scale",
        "description": "Guidance scale for the second stage of generation",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square_hd",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "negative_prompt",
      "guidance_scale"
    ]
  },
  {
    "title": "Luma Photon",
    "description": "Luma Photon is a creative and personalizable text-to-image model that brings a step-function\n    change in the cost of high-quality image generation, optimized for creatives.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.LumaPhoton",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "16:9",
            "9:16",
            "1:1",
            "4:3",
            "3:4",
            "21:9",
            "9:21"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.AspectRatioLuma"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "The aspect ratio of the generated image",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "aspect_ratio"
    ]
  },
  {
    "title": "Luma Photon Flash",
    "description": "Luma Photon Flash is the most creative, personalizable, and intelligent visual model for creatives,\n    bringing a step-function change in the cost of high-quality image generation with faster inference times.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.LumaPhotonFlash",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "16:9",
            "9:16",
            "1:1",
            "4:3",
            "3:4",
            "21:9",
            "9:21"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.AspectRatioLuma"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "The aspect ratio of the generated image",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "aspect_ratio"
    ]
  },
  {
    "title": "Fast Turbo Diffusion",
    "description": "Fast Turbo Diffusion runs SDXL at exceptional speeds while maintaining high-quality output.\n    Supports both SDXL Turbo and SD Turbo models for ultra-fast image generation.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.FastTurboDiffusion",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "model_name",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "stabilityai/sdxl-turbo",
            "stabilityai/sd-turbo"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ModelNameEnum"
        },
        "default": "stabilityai/sdxl-turbo",
        "title": "Model Name",
        "description": "The name of the model to use",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Use it to address details that you don't want in the image",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      },
      {
        "name": "expand_prompt",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Expand Prompt",
        "description": "If true, the prompt will be expanded with additional prompts",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "model_name",
      "guidance_scale"
    ]
  },
  {
    "title": "Fast LCMDiffusion",
    "description": "Fast Latent Consistency Models (v1.5/XL) Text to Image runs SDXL at the speed of light,\n    enabling rapid and high-quality image generation.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.FastLCMDiffusion",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "model_name",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "stabilityai/stable-diffusion-xl-base-1.0",
            "runwayml/stable-diffusion-v1-5"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ModelNameFastLCM"
        },
        "default": "stabilityai/stable-diffusion-xl-base-1.0",
        "title": "Model Name",
        "description": "The name of the model to use",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Use it to address details that you don't want in the image",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square_hd",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 6,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.5,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "sync_mode",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Sync Mode",
        "description": "If true, wait for image generation and upload before returning",
        "min": null,
        "max": null
      },
      {
        "name": "num_images",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Images",
        "description": "The number of images to generate",
        "min": 1.0,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      },
      {
        "name": "safety_checker_version",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "v1",
            "v2"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.SafetyCheckerVersion"
        },
        "default": "v1",
        "title": "Safety Checker Version",
        "description": "The version of the safety checker to use",
        "min": null,
        "max": null
      },
      {
        "name": "expand_prompt",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Expand Prompt",
        "description": "If true, the prompt will be expanded with additional prompts",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_rescale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Guidance Rescale",
        "description": "The rescale factor for the CFG",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "model_name",
      "guidance_scale"
    ]
  },
  {
    "title": "Fast Lightning SDXL",
    "description": "Stable Diffusion XL Lightning Text to Image runs SDXL at the speed of light, enabling\n    ultra-fast high-quality image generation.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.FastLightningSDXL",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square_hd",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform (1, 2, 4, or 8)",
        "min": 1.0,
        "max": 8.0
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      },
      {
        "name": "expand_prompt",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Expand Prompt",
        "description": "If true, the prompt will be expanded with additional prompts",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image_size",
      "num_inference_steps"
    ]
  },
  {
    "title": "Hyper SDXL",
    "description": "Hyper SDXL is a hyper-charged version of SDXL that delivers exceptional performance and creativity\n    while maintaining high-quality output and ultra-fast generation speeds.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.HyperSDXL",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square_hd",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform (1, 2, or 4)",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "sync_mode",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Sync Mode",
        "description": "If true, wait for image generation and upload before returning",
        "min": null,
        "max": null
      },
      {
        "name": "num_images",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Images",
        "description": "The number of images to generate",
        "min": 1.0,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      },
      {
        "name": "expand_prompt",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Expand Prompt",
        "description": "If true, the prompt will be expanded with additional prompts",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image_size",
      "num_inference_steps"
    ]
  },
  {
    "title": "Playground V 25",
    "description": "Playground v2.5 is a state-of-the-art open-source model that excels in aesthetic quality\n    for text-to-image generation.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.PlaygroundV25",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square_hd",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image_size",
      "guidance_scale"
    ]
  },
  {
    "title": "LCMDiffusion",
    "description": "Latent Consistency Models (SDXL & SDv1.5) Text to Image produces high-quality images\n    with minimal inference steps.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.LCMDiffusion",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "sdxl",
            "sdv1-5"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ModelNameLCM"
        },
        "default": "sdv1-5",
        "title": "Model",
        "description": "The model to use for generating the image",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Use it to address details that you don't want in the image",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "model",
      "guidance_scale"
    ]
  },
  {
    "title": "Fooocus",
    "description": "Fooocus is a text-to-image model with default parameters and automated optimizations\n    for quality improvements.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.Fooocus",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Use it to address details that you don't want in the image",
        "min": null,
        "max": null
      },
      {
        "name": "styles",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [
          "Fooocus Enhance",
          "Fooocus V2",
          "Fooocus Sharp"
        ],
        "title": "Styles",
        "description": "The styles to apply to the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "performance",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "Speed",
            "Quality",
            "Extreme Speed",
            "Lightning"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.PerformanceEnum"
        },
        "default": "Extreme Speed",
        "title": "Performance",
        "description": "You can choose Speed or Quality",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4.0,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "sharpness",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2.0,
        "title": "Sharpness",
        "description": "Higher value means image and texture are sharper",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "1024x1024",
        "title": "Aspect Ratio",
        "description": "The size of the generated image (must be multiples of 8)",
        "min": null,
        "max": null
      },
      {
        "name": "loras",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "lora_weight",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Loras",
        "description": "Up to 5 LoRAs that will be merged for generation",
        "min": null,
        "max": null
      },
      {
        "name": "refiner_model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "None",
            "realisticVisionV60B1_v51VAE.safetensors"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.RefinerModelEnum"
        },
        "default": "None",
        "title": "Refiner Model",
        "description": "Refiner model to use (SDXL or SD 1.5)",
        "min": null,
        "max": null
      },
      {
        "name": "refiner_switch",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Refiner Switch",
        "description": "Switch point for refiner (0.4 for SD1.5 realistic, 0.667 for SD1.5 anime, 0.8 for XL)",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "control_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Control Image",
        "description": "Reference image for generation",
        "min": null,
        "max": null
      },
      {
        "name": "control_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "ImagePrompt",
            "PyraCanny",
            "CPDS",
            "FaceSwap"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ControlTypeEnum"
        },
        "default": "PyraCanny",
        "title": "Control Type",
        "description": "The type of image control",
        "min": null,
        "max": null
      },
      {
        "name": "control_image_weight",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Control Image Weight",
        "description": "Strength of the control image influence",
        "min": null,
        "max": null
      },
      {
        "name": "control_image_stop_at",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Control Image Stop At",
        "description": "When to stop applying control image influence",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If false, the safety checker will be disabled",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "negative_prompt",
      "styles"
    ]
  },
  {
    "title": "Illusion Diffusion",
    "description": "Illusion Diffusion is a model that creates illusions conditioned on an input image.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.IllusionDiffusion",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Use it to address details that you don't want in the image",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image URL for conditioning the generation",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 40,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square_hd",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image",
      "guidance_scale"
    ]
  },
  {
    "title": "Fast SDXLControl Net Canny",
    "description": "Fast SDXL ControlNet Canny is a model that generates images using ControlNet with SDXL.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.FastSDXLControlNetCanny",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "control_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Control Image",
        "description": "The control image to use for generation",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Use it to address details that you don't want in the image",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "square_hd",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "control_image",
      "guidance_scale"
    ]
  },
  {
    "title": "Flux Dev Image To Image",
    "description": "FLUX.1 [dev] Image-to-Image is a high-performance endpoint that enables rapid transformation\n    of existing images, delivering high-quality style transfers and image modifications with\n    the core FLUX capabilities.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.FluxDevImageToImage",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image to transform",
        "min": null,
        "max": null
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.95,
        "title": "Strength",
        "description": "The strength of the initial image. Higher strength values are better for this model",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 40,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed and prompt will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image",
      "strength"
    ]
  },
  {
    "title": "Diffusion Edge",
    "description": "Diffusion Edge is a diffusion-based high-quality edge detection model that generates\n    edge maps from input images.",
    "namespace": "fal.text_to_image",
    "node_type": "fal.text_to_image.DiffusionEdge",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image to detect edges from",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "MMAudio V2",
    "description": "MMAudio V2 generates synchronized audio given text inputs.\n    It can generate sounds described by a prompt.",
    "namespace": "fal.text_to_audio",
    "node_type": "fal.text_to_audio.MMAudioV2",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate the audio for",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "The negative prompt to avoid certain elements in the generated audio",
        "min": null,
        "max": null
      },
      {
        "name": "num_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Steps",
        "description": "The number of steps to generate the audio for",
        "min": 1.0,
        "max": null
      },
      {
        "name": "duration",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8.0,
        "title": "Duration",
        "description": "The duration of the audio to generate in seconds",
        "min": 1.0,
        "max": null
      },
      {
        "name": "cfg_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4.5,
        "title": "Cfg Strength",
        "description": "The strength of Classifier Free Guidance",
        "min": null,
        "max": null
      },
      {
        "name": "mask_away_clip",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Mask Away Clip",
        "description": "Whether to mask away the clip",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same audio every time",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "duration",
      "num_steps"
    ]
  },
  {
    "title": "Stable Audio",
    "description": "Stable Audio generates audio from text prompts.\n    Open source text-to-audio model from fal.ai.",
    "namespace": "fal.text_to_audio",
    "node_type": "fal.text_to_audio.StableAudio",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate the audio from",
        "min": null,
        "max": null
      },
      {
        "name": "seconds_start",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Seconds Start",
        "description": "The start point of the audio clip to generate",
        "min": null,
        "max": null
      },
      {
        "name": "seconds_total",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Seconds Total",
        "description": "The duration of the audio clip to generate in seconds",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Steps",
        "description": "The number of steps to denoise the audio for",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "seconds_total",
      "steps"
    ]
  },
  {
    "title": "F5 TTS",
    "description": "F5 TTS converts text to speech using a reference audio for voice cloning.\n    Uses fal.ai's F5 TTS model for high-quality voice synthesis.",
    "namespace": "fal.text_to_audio",
    "node_type": "fal.text_to_audio.F5TTS",
    "layout": "default",
    "properties": [
      {
        "name": "gen_text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Gen Text",
        "description": "The text to be converted to speech",
        "min": null,
        "max": null
      },
      {
        "name": "ref_audio_url",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Ref Audio Url",
        "description": "URL of the reference audio file to clone the voice from",
        "min": null,
        "max": null
      },
      {
        "name": "ref_text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Ref Text",
        "description": "Optional reference text. If not provided, ASR will be used",
        "min": null,
        "max": null
      },
      {
        "name": "model_type",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "F5-TTS",
        "title": "Model Type",
        "description": "Model type to use (F5-TTS or E2-TTS)",
        "min": null,
        "max": null
      },
      {
        "name": "remove_silence",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Remove Silence",
        "description": "Whether to remove silence from the generated audio",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "gen_text",
      "ref_audio_url",
      "model_type"
    ]
  },
  {
    "title": "Whisper",
    "description": "Whisper is a model for speech transcription and translation.\n    It can transcribe audio in multiple languages and optionally translate to English.",
    "namespace": "fal.speech_to_text",
    "node_type": "fal.speech_to_text.Whisper",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to transcribe",
        "min": null,
        "max": null
      },
      {
        "name": "task",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "transcribe",
            "translate"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.speech_to_text.TaskEnum"
        },
        "default": "transcribe",
        "title": "Task",
        "description": "Task to perform on the audio file",
        "min": null,
        "max": null
      },
      {
        "name": "language",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "af",
            "am",
            "ar",
            "as",
            "az",
            "ba",
            "be",
            "bg",
            "bn",
            "bo",
            "br",
            "bs",
            "ca",
            "cs",
            "cy",
            "da",
            "de",
            "el",
            "en",
            "es",
            "et",
            "eu",
            "fa",
            "fi",
            "fo",
            "fr",
            "gl",
            "gu",
            "ha",
            "haw",
            "he",
            "hi",
            "hr",
            "ht",
            "hu",
            "hy",
            "id",
            "is",
            "it",
            "ja",
            "jw",
            "ka",
            "kk",
            "km",
            "kn",
            "ko",
            "la",
            "lb",
            "ln",
            "lo",
            "lt",
            "lv",
            "mg",
            "mi",
            "mk",
            "ml",
            "mn",
            "mr",
            "ms",
            "mt",
            "my",
            "ne",
            "nl",
            "nn",
            "no",
            "oc",
            "pa",
            "pl",
            "ps",
            "pt",
            "ro",
            "ru",
            "sa",
            "sd",
            "si",
            "sk",
            "sl",
            "sn",
            "so",
            "sq",
            "sr",
            "su",
            "sv",
            "sw",
            "ta",
            "te",
            "tg",
            "th",
            "tk",
            "tl",
            "tr",
            "tt",
            "uk",
            "ur",
            "uz",
            "vi",
            "yi",
            "yo",
            "yue",
            "zh"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.speech_to_text.LanguageEnum"
        },
        "default": "en",
        "title": "Language",
        "description": "Language of the audio file. If not set, will be auto-detected",
        "min": null,
        "max": null
      },
      {
        "name": "diarize",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Diarize",
        "description": "Whether to perform speaker diarization",
        "min": null,
        "max": null
      },
      {
        "name": "chunk_level",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "segment",
            "word"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.speech_to_text.ChunkLevelEnum"
        },
        "default": "segment",
        "title": "Chunk Level",
        "description": "Level of detail for timestamp chunks",
        "min": null,
        "max": null
      },
      {
        "name": "num_speakers",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Speakers",
        "description": "Number of speakers in the audio. If not set, will be auto-detected",
        "min": 1.0,
        "max": 10.0
      },
      {
        "name": "batch_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 64,
        "title": "Batch Size",
        "description": "Batch size for processing",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "Optional prompt to guide the transcription",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "text",
        "stream": false
      },
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "chunks",
        "stream": false
      },
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "inferred_languages",
        "stream": false
      },
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "diarization_segments",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "task",
      "diarize"
    ]
  },
  {
    "title": "Flux Schnell Redux",
    "description": "FLUX.1 [schnell] Redux is a high-performance endpoint that enables rapid transformation \n    of existing images, delivering high-quality style transfers and image modifications with \n    the core FLUX capabilities.",
    "namespace": "fal.image_to_image",
    "node_type": "fal.image_to_image.FluxSchnellRedux",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image to transform",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "landscape_4_3",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "image_size",
      "num_inference_steps"
    ]
  },
  {
    "title": "Flux Dev Redux",
    "description": "FLUX.1 [dev] Redux is a high-performance endpoint that enables rapid transformation \n    of existing images, delivering high-quality style transfers and image modifications.",
    "namespace": "fal.image_to_image",
    "node_type": "fal.image_to_image.FluxDevRedux",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image to transform",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "landscape_4_3",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "enable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Safety Checker",
        "description": "If true, the safety checker will be enabled",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "image_size",
      "guidance_scale"
    ]
  },
  {
    "title": "Flux Pro Redux",
    "description": "FLUX.1 [pro] Redux is a high-performance endpoint that enables rapid transformation \n    of existing images, delivering high-quality style transfers and image modifications.",
    "namespace": "fal.image_to_image",
    "node_type": "fal.image_to_image.FluxProRedux",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image to transform",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "landscape_4_3",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "safety_tolerance",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "2",
        "title": "Safety Tolerance",
        "description": "Safety tolerance level (1-6, 1 being most strict)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "image_size",
      "guidance_scale"
    ]
  },
  {
    "title": "Flux Pro Ultra Redux",
    "description": "FLUX1.1 [pro] ultra Redux is a high-performance endpoint that enables rapid transformation \n    of existing images, delivering high-quality style transfers and image modifications with \n    the core FLUX capabilities.",
    "namespace": "fal.image_to_image",
    "node_type": "fal.image_to_image.FluxProUltraRedux",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image to transform",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "landscape_4_3",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "safety_tolerance",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "2",
        "title": "Safety Tolerance",
        "description": "Safety tolerance level (1-6, 1 being most strict)",
        "min": null,
        "max": null
      },
      {
        "name": "image_prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.1,
        "title": "Image Prompt Strength",
        "description": "The strength of the image prompt, between 0 and 1",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "image_size",
      "guidance_scale"
    ]
  },
  {
    "title": "Flux Pro Fill",
    "description": "FLUX.1 [pro] Fill is a high-performance endpoint that enables rapid transformation \n    of existing images with inpainting/outpainting capabilities.",
    "namespace": "fal.image_to_image",
    "node_type": "fal.image_to_image.FluxProFill",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image to transform",
        "min": null,
        "max": null
      },
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask",
        "description": "The mask for inpainting",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to fill the masked part of the image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "safety_tolerance",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "2",
        "title": "Safety Tolerance",
        "description": "Safety tolerance level (1-6, 1 being most strict)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "mask",
      "prompt"
    ]
  },
  {
    "title": "Flux Pro Canny",
    "description": "FLUX.1 [pro] Canny enables precise control over composition, style, and structure \n    through advanced edge detection and guidance mechanisms.",
    "namespace": "fal.image_to_image",
    "node_type": "fal.image_to_image.FluxProCanny",
    "layout": "default",
    "properties": [
      {
        "name": "control_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Control Image",
        "description": "The control image to generate the Canny edge map from",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "landscape_4_3",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "safety_tolerance",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "2",
        "title": "Safety Tolerance",
        "description": "Safety tolerance level (1-6, 1 being most strict)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "control_image",
      "prompt",
      "image_size"
    ]
  },
  {
    "title": "Flux Pro Depth",
    "description": "FLUX.1 [pro] Depth enables precise control over composition and structure through \n    depth map detection and guidance mechanisms.",
    "namespace": "fal.image_to_image",
    "node_type": "fal.image_to_image.FluxProDepth",
    "layout": "default",
    "properties": [
      {
        "name": "control_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Control Image",
        "description": "The control image to generate the depth map from",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "landscape_4_3",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "safety_tolerance",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "2",
        "title": "Safety Tolerance",
        "description": "Safety tolerance level (1-6, 1 being most strict)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "control_image",
      "prompt",
      "image_size"
    ]
  },
  {
    "title": "Flux Lora Canny",
    "description": "FLUX LoRA Canny enables precise control over composition and style through \n    edge detection and LoRA-based guidance mechanisms.",
    "namespace": "fal.image_to_image",
    "node_type": "fal.image_to_image.FluxLoraCanny",
    "layout": "default",
    "properties": [
      {
        "name": "control_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Control Image",
        "description": "The control image to generate the Canny edge map from",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "landscape_4_3",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.6,
        "title": "Lora Scale",
        "description": "The strength of the LoRA adaptation",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "control_image",
      "prompt",
      "image_size"
    ]
  },
  {
    "title": "Flux Lora Depth",
    "description": "FLUX LoRA Depth enables precise control over composition and structure through \n    depth map detection and LoRA-based guidance mechanisms.",
    "namespace": "fal.image_to_image",
    "node_type": "fal.image_to_image.FluxLoraDepth",
    "layout": "default",
    "properties": [
      {
        "name": "control_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Control Image",
        "description": "The control image to generate the depth map from",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate an image from",
        "min": null,
        "max": null
      },
      {
        "name": "image_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
        },
        "default": "landscape_4_3",
        "title": "Image Size",
        "description": "The size of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "The number of inference steps to perform",
        "min": 1.0,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "How closely the model should stick to your prompt",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same image every time",
        "min": null,
        "max": null
      },
      {
        "name": "lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.6,
        "title": "Lora Scale",
        "description": "The strength of the LoRA adaptation",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "control_image",
      "prompt",
      "image_size"
    ]
  },
  {
    "title": "Ideogram V 2 Edit",
    "description": "Transform existing images with Ideogram V2's editing capabilities. Modify, adjust, and refine \n    images while maintaining high fidelity and realistic outputs with precise prompt control.",
    "namespace": "fal.image_to_image",
    "node_type": "fal.image_to_image.IdeogramV2Edit",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to fill the masked part of the image",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to edit",
        "min": null,
        "max": null
      },
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask",
        "description": "The mask for editing",
        "min": null,
        "max": null
      },
      {
        "name": "style",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "auto",
        "title": "Style",
        "description": "Style of generated image (auto, general, realistic, design, render_3D, anime)",
        "min": null,
        "max": null
      },
      {
        "name": "expand_prompt",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Expand Prompt",
        "description": "Whether to expand the prompt with MagicPrompt functionality",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same image every time",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image",
      "mask"
    ]
  },
  {
    "title": "Ideogram V 2 Remix",
    "description": "Reimagine existing images with Ideogram V2's remix feature. Create variations and adaptations \n    while preserving core elements and adding new creative directions through prompt guidance.",
    "namespace": "fal.image_to_image",
    "node_type": "fal.image_to_image.IdeogramV2Remix",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to remix the image with",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to remix",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "The aspect ratio of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Strength",
        "description": "Strength of the input image in the remix",
        "min": null,
        "max": null
      },
      {
        "name": "expand_prompt",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Expand Prompt",
        "description": "Whether to expand the prompt with MagicPrompt functionality",
        "min": null,
        "max": null
      },
      {
        "name": "style",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "auto",
        "title": "Style",
        "description": "Style of generated image (auto, general, realistic, design, render_3D, anime)",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same image every time",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image",
      "strength"
    ]
  },
  {
    "title": "Bria Eraser",
    "description": "Bria Eraser enables precise removal of unwanted objects from images while maintaining \n    high-quality outputs. Trained exclusively on licensed data for safe and risk-free commercial use.",
    "namespace": "fal.image_to_image",
    "node_type": "fal.image_to_image.BriaEraser",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image to erase from",
        "min": null,
        "max": null
      },
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask",
        "description": "The mask for areas to be cleaned",
        "min": null,
        "max": null
      },
      {
        "name": "mask_type",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "manual",
        "title": "Mask Type",
        "description": "Type of mask - 'manual' for user-created or 'automatic' for algorithm-generated",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "mask"
    ]
  },
  {
    "title": "Bria Product Shot",
    "description": "Place any product in any scenery with just a prompt or reference image while maintaining high \n    integrity of the product. Trained exclusively on licensed data for safe and risk-free commercial \n    use and optimized for eCommerce.",
    "namespace": "fal.image_to_image",
    "node_type": "fal.image_to_image.BriaProductShot",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The product image to be placed",
        "min": null,
        "max": null
      },
      {
        "name": "scene_description",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Scene Description",
        "description": "Text description of the new scene/background",
        "min": null,
        "max": null
      },
      {
        "name": "ref_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Ref Image",
        "description": "Reference image for the new scene/background",
        "min": null,
        "max": null
      },
      {
        "name": "optimize_description",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Optimize Description",
        "description": "Whether to optimize the scene description",
        "min": null,
        "max": null
      },
      {
        "name": "placement_type",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "manual_placement",
        "title": "Placement Type",
        "description": "How to position the product (original, automatic, manual_placement, manual_padding)",
        "min": null,
        "max": null
      },
      {
        "name": "manual_placement_selection",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "bottom_center",
        "title": "Manual Placement Selection",
        "description": "Specific placement position when using manual_placement",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "scene_description"
    ]
  },
  {
    "title": "Bria Background Replace",
    "description": "Bria Background Replace allows for efficient swapping of backgrounds in images via text prompts \n    or reference image, delivering realistic and polished results. Trained exclusively on licensed \n    data for safe and risk-free commercial use.",
    "namespace": "fal.image_to_image",
    "node_type": "fal.image_to_image.BriaBackgroundReplace",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image to replace background",
        "min": null,
        "max": null
      },
      {
        "name": "ref_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Ref Image",
        "description": "Reference image for the new background",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "Prompt to generate new background",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Negative prompt for background generation",
        "min": null,
        "max": null
      },
      {
        "name": "refine_prompt",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Refine Prompt",
        "description": "Whether to refine the prompt",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same image every time",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "prompt"
    ]
  },
  {
    "title": "Bria Gen Fill",
    "description": "Bria GenFill enables high-quality object addition or visual transformation. \n    Trained exclusively on licensed data for safe and risk-free commercial use.",
    "namespace": "fal.image_to_image",
    "node_type": "fal.image_to_image.BriaGenFill",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image to erase from",
        "min": null,
        "max": null
      },
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask",
        "description": "The mask for areas to be cleaned",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to generate images",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "The negative prompt to use when generating images",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same image every time",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "mask",
      "prompt"
    ]
  },
  {
    "title": "Bria Expand",
    "description": "Bria Expand expands images beyond their borders in high quality. \n    Trained exclusively on licensed data for safe and risk-free commercial use.",
    "namespace": "fal.image_to_image",
    "node_type": "fal.image_to_image.BriaExpand",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The input image to expand",
        "min": null,
        "max": null
      },
      {
        "name": "canvas_width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1200,
        "title": "Canvas Width",
        "description": "The desired width of the final image, after the expansion",
        "min": null,
        "max": null
      },
      {
        "name": "canvas_height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 674,
        "title": "Canvas Height",
        "description": "The desired height of the final image, after the expansion",
        "min": null,
        "max": null
      },
      {
        "name": "original_image_width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 610,
        "title": "Original Image Width",
        "description": "The desired width of the original image, inside the full canvas",
        "min": null,
        "max": null
      },
      {
        "name": "original_image_height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 855,
        "title": "Original Image Height",
        "description": "The desired height of the original image, inside the full canvas",
        "min": null,
        "max": null
      },
      {
        "name": "original_image_x",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 301,
        "title": "Original Image X",
        "description": "The desired x-coordinate of the original image, inside the full canvas",
        "min": null,
        "max": null
      },
      {
        "name": "original_image_y",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -66,
        "title": "Original Image Y",
        "description": "The desired y-coordinate of the original image, inside the full canvas",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "Text on which you wish to base the image expansion",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "The negative prompt to use when generating images",
        "min": null,
        "max": null
      },
      {
        "name": "num_images",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Images",
        "description": "Number of images to generate",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same image every time",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "canvas_width",
      "canvas_height",
      "prompt"
    ]
  },
  {
    "title": "Bria Background Remove",
    "description": "Bria RMBG 2.0 enables seamless removal of backgrounds from images, ideal for professional editing tasks. \n    Trained exclusively on licensed data for safe and risk-free commercial use.",
    "namespace": "fal.image_to_image",
    "node_type": "fal.image_to_image.BriaBackgroundRemove",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image to remove background from",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Haiper Image To Video",
    "description": "Transform images into hyper-realistic videos with Haiper 2.0. Experience industry-leading\n    resolution, fluid motion, and rapid generation for stunning AI videos.",
    "namespace": "fal.image_to_video",
    "node_type": "fal.image_to_video.HaiperImageToVideo",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to transform into a video",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "A description of the desired video motion and style",
        "min": null,
        "max": null
      },
      {
        "name": "duration",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            4,
            6
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.image_to_video.VideoDuration"
        },
        "default": 4,
        "title": "Duration",
        "description": "The duration of the generated video in seconds",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_enhancer",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Prompt Enhancer",
        "description": "Whether to use the model's prompt enhancer",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same video every time",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "prompt",
      "duration"
    ]
  },
  {
    "title": "Luma Dream Machine",
    "description": "Generate video clips from your images using Luma Dream Machine v1.5. Supports various aspect ratios\n    and optional end-frame blending.",
    "namespace": "fal.image_to_video",
    "node_type": "fal.image_to_video.LumaDreamMachine",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to transform into a video",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "A description of the desired video motion and style",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "16:9",
            "9:16",
            "4:3",
            "3:4",
            "21:9",
            "9:21",
            "1:1"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
        },
        "default": "16:9",
        "title": "Aspect Ratio",
        "description": "The aspect ratio of the generated video",
        "min": null,
        "max": null
      },
      {
        "name": "loop",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Loop",
        "description": "Whether the video should loop (end blends with beginning)",
        "min": null,
        "max": null
      },
      {
        "name": "end_image",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "End Image",
        "description": "Optional image to blend the end of the video with",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "prompt",
      "aspect_ratio"
    ]
  },
  {
    "title": "Kling Video",
    "description": "Generate video clips from your images using Kling 1.6. Supports multiple durations and aspect ratios.",
    "namespace": "fal.image_to_video",
    "node_type": "fal.image_to_video.KlingVideo",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to transform into a video",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "A description of the desired video motion and style",
        "min": null,
        "max": null
      },
      {
        "name": "duration",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "5",
            "10"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.image_to_video.KlingDuration"
        },
        "default": "5",
        "title": "Duration",
        "description": "The duration of the generated video",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "16:9",
            "9:16",
            "4:3",
            "3:4",
            "21:9",
            "9:21",
            "1:1"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
        },
        "default": "16:9",
        "title": "Aspect Ratio",
        "description": "The aspect ratio of the generated video frame",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "prompt",
      "duration"
    ]
  },
  {
    "title": "Kling Video Pro",
    "description": "Generate video clips from your images using Kling 1.6 Pro. The professional version offers\n    enhanced quality and performance compared to the standard version.",
    "namespace": "fal.image_to_video",
    "node_type": "fal.image_to_video.KlingVideoPro",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to transform into a video",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "A description of the desired video motion and style",
        "min": null,
        "max": null
      },
      {
        "name": "duration",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "5",
            "10"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.image_to_video.KlingDuration"
        },
        "default": "5",
        "title": "Duration",
        "description": "The duration of the generated video",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "16:9",
            "9:16",
            "4:3",
            "3:4",
            "21:9",
            "9:21",
            "1:1"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
        },
        "default": "16:9",
        "title": "Aspect Ratio",
        "description": "The aspect ratio of the generated video frame",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "prompt",
      "duration"
    ]
  },
  {
    "title": "Cog Video X",
    "description": "Generate videos from images using CogVideoX-5B. Features high-quality motion synthesis with\n    configurable parameters for fine-tuned control over the output.",
    "namespace": "fal.image_to_video",
    "node_type": "fal.image_to_video.CogVideoX",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to transform into a video",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "A description of the desired video motion and style",
        "min": null,
        "max": null
      },
      {
        "name": "video_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "square_hd",
            "square",
            "portrait_4_3",
            "portrait_16_9",
            "landscape_4_3",
            "landscape_16_9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.image_to_video.VideoSize"
        },
        "default": "landscape_16_9",
        "title": "Video Size",
        "description": "The size/aspect ratio of the generated video",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms",
        "title": "Negative Prompt",
        "description": "What to avoid in the generated video",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps (higher = better quality but slower)",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.0,
        "title": "Guidance Scale",
        "description": "How closely to follow the prompt (higher = more faithful but less creative)",
        "min": null,
        "max": null
      },
      {
        "name": "use_rife",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Use Rife",
        "description": "Whether to use RIFE for video interpolation",
        "min": null,
        "max": null
      },
      {
        "name": "export_fps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 16,
        "title": "Export Fps",
        "description": "Target frames per second for the output video",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same video every time",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "prompt",
      "video_size"
    ]
  },
  {
    "title": "Mini Max Video",
    "description": "Generate video clips from your images using MiniMax Video model. Transform static art into dynamic\n    masterpieces with enhanced smoothness and vivid motion.",
    "namespace": "fal.image_to_video",
    "node_type": "fal.image_to_video.MiniMaxVideo",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to transform into a video",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "A description of the desired video motion and style",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_optimizer",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Prompt Optimizer",
        "description": "Whether to use the model's prompt optimizer",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "prompt"
    ]
  },
  {
    "title": "LTXVideo",
    "description": "Generate videos from images using LTX Video. Best results with 768x512 images and detailed,\n    chronological descriptions of actions and scenes.",
    "namespace": "fal.image_to_video",
    "node_type": "fal.image_to_video.LTXVideo",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to transform into a video (768x512 recommended)",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "A detailed description of the desired video motion and style",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "low quality, worst quality, deformed, distorted, disfigured, motion smear, motion artifacts, fused fingers, bad anatomy, weird hand, ugly",
        "title": "Negative Prompt",
        "description": "What to avoid in the generated video",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Num Inference Steps",
        "description": "Number of inference steps (higher = better quality but slower)",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.0,
        "title": "Guidance Scale",
        "description": "How closely to follow the prompt (higher = more faithful)",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same video every time",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "prompt"
    ]
  },
  {
    "title": "Stable Video",
    "description": "Generate short video clips from your images using Stable Video Diffusion v1.1. Features high-quality\n    motion synthesis with configurable parameters.",
    "namespace": "fal.image_to_video",
    "node_type": "fal.image_to_video.StableVideo",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to transform into a video",
        "min": null,
        "max": null
      },
      {
        "name": "motion_bucket_id",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 127,
        "title": "Motion Bucket Id",
        "description": "Controls motion intensity (higher = more motion)",
        "min": null,
        "max": null
      },
      {
        "name": "cond_aug",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.02,
        "title": "Cond Aug",
        "description": "Amount of noise added to conditioning (higher = more motion)",
        "min": null,
        "max": null
      },
      {
        "name": "fps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Fps",
        "description": "Frames per second of the output video",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same video every time",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "motion_bucket_id",
      "fps"
    ]
  },
  {
    "title": "Fast SVD",
    "description": "Generate short video clips from your images using SVD v1.1 at Lightning Speed. Features high-quality\n    motion synthesis with configurable parameters for rapid video generation.",
    "namespace": "fal.image_to_video",
    "node_type": "fal.image_to_video.FastSVD",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to transform into a video",
        "min": null,
        "max": null
      },
      {
        "name": "motion_bucket_id",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 127,
        "title": "Motion Bucket Id",
        "description": "Controls motion intensity (higher = more motion)",
        "min": null,
        "max": null
      },
      {
        "name": "cond_aug",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.02,
        "title": "Cond Aug",
        "description": "Amount of noise added to conditioning (higher = more motion)",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Steps",
        "description": "Number of inference steps (higher = better quality but slower)",
        "min": null,
        "max": null
      },
      {
        "name": "fps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10,
        "title": "Fps",
        "description": "Frames per second of the output video (total length is 25 frames)",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "The same seed will output the same video every time",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "motion_bucket_id",
      "fps"
    ]
  },
  {
    "title": "AMTInterpolation",
    "description": "Interpolate between image frames to create smooth video transitions. Supports configurable FPS\n    and recursive interpolation passes for higher quality results.",
    "namespace": "fal.image_to_video",
    "node_type": "fal.image_to_video.AMTInterpolation",
    "layout": "default",
    "properties": [
      {
        "name": "frames",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "image",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [
          {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          }
        ],
        "title": "Frames",
        "description": "List of frames to interpolate between (minimum 2 frames required)",
        "min": null,
        "max": null
      },
      {
        "name": "output_fps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 24,
        "title": "Output Fps",
        "description": "Output frames per second",
        "min": null,
        "max": null
      },
      {
        "name": "recursive_interpolation_passes",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Recursive Interpolation Passes",
        "description": "Number of recursive interpolation passes (higher = smoother)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "frames",
      "output_fps"
    ]
  },
  {
    "title": "Sad Talker",
    "description": "Generate talking face animations from a single image and audio file. Features configurable\n    face model resolution and expression controls.",
    "namespace": "fal.image_to_video",
    "node_type": "fal.image_to_video.SadTalker",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The source image to animate",
        "min": null,
        "max": null
      },
      {
        "name": "audio",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Audio",
        "description": "URL of the audio file to drive the animation",
        "min": null,
        "max": null
      },
      {
        "name": "face_model_resolution",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "256",
            "512"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.image_to_video.FaceModelResolution"
        },
        "default": "256",
        "title": "Face Model Resolution",
        "description": "Resolution of the face model",
        "min": null,
        "max": null
      },
      {
        "name": "expression_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Expression Scale",
        "description": "Scale of the expression (1.0 = normal)",
        "min": null,
        "max": null
      },
      {
        "name": "still_mode",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Still Mode",
        "description": "Reduce head motion (works with preprocess 'full')",
        "min": null,
        "max": null
      },
      {
        "name": "preprocess",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "crop",
            "extcrop",
            "resize",
            "full",
            "extfull"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.fal.image_to_video.PreprocessType"
        },
        "default": "crop",
        "title": "Preprocess",
        "description": "Type of image preprocessing to apply",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "image",
      "audio",
      "face_model_resolution"
    ]
  },
  {
    "title": "Muse Talk",
    "description": "Real-time high quality audio-driven lip-syncing model. Animate a face video with custom audio\n    for natural-looking speech animation.",
    "namespace": "fal.image_to_video",
    "node_type": "fal.image_to_video.MuseTalk",
    "layout": "default",
    "properties": [
      {
        "name": "video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video",
        "description": "URL of the source video to animate",
        "min": null,
        "max": null
      },
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "URL of the audio file to drive the lip sync",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "video",
      "audio"
    ]
  },
  {
    "title": "Text To Speech",
    "description": "Converts text to speech using OpenAI TTS models.\n    audio, tts, text-to-speech, voice, synthesis\n\n    Use cases:\n    - Generate spoken content for videos or podcasts\n    - Create voice-overs for presentations\n    - Assist visually impaired users with text reading\n    - Produce audio versions of written content",
    "namespace": "openai.audio",
    "node_type": "openai.audio.TextToSpeech",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "tts-1",
            "tts-1-hd"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.openai.audio.TtsModel"
        },
        "default": "tts-1",
        "title": "Model",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "voice",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "alloy",
            "echo",
            "fable",
            "onyx",
            "nova",
            "shimmer"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.openai.audio.Voice"
        },
        "default": "alloy",
        "title": "Voice",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "input",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Input",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "speed",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Speed",
        "description": null,
        "min": 0.25,
        "max": 4.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input",
      "model",
      "voice"
    ]
  },
  {
    "title": "Transcribe",
    "description": "Transcribes speech from audio to text.\n    audio, transcription, speech-to-text, stt\n\n    Use cases:\n    - Convert recorded meetings or lectures to text\n    - Generate subtitles for videos\n    - Create searchable archives of audio content\n    - Assist hearing-impaired users with audio content",
    "namespace": "openai.audio",
    "node_type": "openai.audio.Transcribe",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to transcribe.",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Temperature",
        "description": "The temperature to use for the transcription.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "temperature"
    ]
  },
  {
    "title": "Translate",
    "description": "Translates speech in audio to English text.\n    audio, translation, speech-to-text, localization\n\n    Use cases:\n    - Translate foreign language audio content to English\n    - Create English transcripts of multilingual recordings\n    - Assist non-English speakers in understanding audio content\n    - Enable cross-language communication in audio formats",
    "namespace": "openai.audio",
    "node_type": "openai.audio.Translate",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "The audio file to translate.",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Temperature",
        "description": "The temperature to use for the translation.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "temperature"
    ]
  },
  {
    "title": "Agent",
    "description": "Agent node to plan tasks to achieve a goal.\n    task planning, goal decomposition, workflow generation\n\n    Use cases:\n    - Breaking down complex goals into manageable tasks\n    - Creating dependency graphs for multi-step processes\n    - Generating workflows for automated task execution",
    "namespace": "openai.agents",
    "node_type": "openai.agents.Agent",
    "layout": "default",
    "properties": [
      {
        "name": "goal",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Goal",
        "description": "The user prompt",
        "min": null,
        "max": null
      },
      {
        "name": "max_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4096,
        "title": "Max Tokens",
        "description": "The maximum number of tokens to generate.",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Temperature",
        "description": "The temperature to use for sampling.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "gpt-3.5-turbo-0125",
            "gpt-4o",
            "gpt-4o-mini",
            "o1-preview",
            "o1-mini"
          ],
          "type_args": [],
          "type_name": "nodetool.metadata.types.GPTModel"
        },
        "default": "gpt-4o-mini",
        "title": "Model",
        "description": "The GPT model to use for generating tasks.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "task",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "goal",
      "model",
      "temperature"
    ]
  },
  {
    "title": "Run Tasks",
    "description": "Process a task using specified models and tools.\n    task execution, model integration, tool coordination\n\n    Use cases:\n    - Executing tasks defined by AgentNode\n    - Coordinating between different AI models and tools\n    - Generating outputs based on task instructions",
    "namespace": "openai.agents",
    "node_type": "openai.agents.RunTasks",
    "layout": "default",
    "properties": [
      {
        "name": "tasks",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "task",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Tasks",
        "description": "The task to process.",
        "min": null,
        "max": null
      },
      {
        "name": "image_nodes",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "node",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Image Nodes",
        "description": "The image generation nodes to use.",
        "min": null,
        "max": null
      },
      {
        "name": "max_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1000,
        "title": "Max Tokens",
        "description": "The maximum number of tokens to generate.",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Temperature",
        "description": "The temperature to use for sampling.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "gpt-3.5-turbo-0125",
            "gpt-4o",
            "gpt-4o-mini",
            "o1-preview",
            "o1-mini"
          ],
          "type_args": [],
          "type_name": "nodetool.metadata.types.GPTModel"
        },
        "default": "gpt-4o-mini",
        "title": "Model",
        "description": "The GPT model to use for processing tasks.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "any",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "tasks",
      "model",
      "temperature"
    ]
  },
  {
    "title": "Data Generator",
    "description": "LLM Agent to create a dataframe based on a user prompt.\n    llm, dataframe creation, data structuring\n\n    Use cases:\n    - Generating structured data from natural language descriptions\n    - Creating sample datasets for testing or demonstration\n    - Converting unstructured text into tabular format",
    "namespace": "openai.agents",
    "node_type": "openai.agents.DataGenerator",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The user prompt",
        "min": null,
        "max": null
      },
      {
        "name": "input_text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Input Text",
        "description": "The input text to be analyzed by the agent.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to use in the prompt.",
        "min": null,
        "max": null
      },
      {
        "name": "max_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4096,
        "title": "Max Tokens",
        "description": "The maximum number of tokens to generate.",
        "min": 0.0,
        "max": 10000.0
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Temperature",
        "description": "The temperature to use for sampling.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "columns",
        "type": {
          "type": "record_type",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "record_type",
          "columns": []
        },
        "title": "Columns",
        "description": "The columns to use in the dataframe.",
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "gpt-3.5-turbo-0125",
            "gpt-4o",
            "gpt-4o-mini",
            "o1-preview",
            "o1-mini"
          ],
          "type_args": [],
          "type_name": "nodetool.metadata.types.GPTModel"
        },
        "default": "gpt-4o-mini",
        "title": "Model",
        "description": "The GPT model to use for data generation.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "model",
      "temperature"
    ]
  },
  {
    "title": "Chain Of Thought",
    "description": "Agent node that implements chain-of-thought reasoning to break down complex problems\n    into step-by-step solutions.\n\n    Use cases:\n    - Complex problem solving requiring multiple steps\n    - Mathematical calculations with intermediate steps\n    - Logical reasoning and deduction tasks\n    - Step-by-step analysis of scenarios",
    "namespace": "openai.agents",
    "node_type": "openai.agents.ChainOfThought",
    "layout": "default",
    "properties": [
      {
        "name": "messages",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "message",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Messages",
        "description": "The messages to use in the prompt.",
        "min": null,
        "max": null
      },
      {
        "name": "max_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4096,
        "title": "Max Tokens",
        "description": "The maximum number of tokens to generate.",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Temperature",
        "description": "The temperature to use for sampling.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "gpt-3.5-turbo-0125",
            "gpt-4o",
            "gpt-4o-mini",
            "o1-preview",
            "o1-mini"
          ],
          "type_args": [],
          "type_name": "nodetool.metadata.types.GPTModel"
        },
        "default": "gpt-4o-mini",
        "title": "Model",
        "description": "The GPT model to use for chain of thought reasoning.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "analysis",
        "stream": false
      },
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "thought_step",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "steps",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "messages",
      "model",
      "temperature"
    ]
  },
  {
    "title": "Process Thought",
    "description": "Agent node that implements iterative chain-of-thought reasoning, building upon previous steps\n    to solve complex problems incrementally.\n\n    Use cases:\n    - Complex problem solving requiring multiple iterations\n    - Mathematical proofs with multiple steps\n    - Logical deductions that build upon previous conclusions\n    - Iterative refinement of solutions",
    "namespace": "openai.agents",
    "node_type": "openai.agents.ProcessThought",
    "layout": "default",
    "properties": [
      {
        "name": "current_step",
        "type": {
          "type": "thought_step",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "thought_step",
          "step_number": 0,
          "instructions": "",
          "reasoning": "",
          "result": ""
        },
        "title": "Current Step",
        "description": "The current step or question to analyze",
        "min": null,
        "max": null
      },
      {
        "name": "max_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4096,
        "title": "Max Tokens",
        "description": "The maximum number of tokens to generate",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Temperature",
        "description": "The temperature to use for sampling",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "gpt-3.5-turbo-0125",
            "gpt-4o",
            "gpt-4o-mini",
            "o1-preview",
            "o1-mini"
          ],
          "type_args": [],
          "type_name": "nodetool.metadata.types.GPTModel"
        },
        "default": "gpt-4o-mini",
        "title": "Model",
        "description": "The GPT model to use for processing chain of thought steps.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "reasoning",
        "stream": false
      },
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "result",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "current_step",
      "model",
      "temperature"
    ]
  },
  {
    "title": "Chart Generator",
    "description": "LLM Agent to create chart configurations based on natural language descriptions.\n    llm, data visualization, charts\n\n    Use cases:\n    - Generating chart configurations from natural language descriptions\n    - Creating data visualizations programmatically\n    - Converting data analysis requirements into visual representations",
    "namespace": "openai.agents",
    "node_type": "openai.agents.ChartGenerator",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "gpt-3.5-turbo-0125",
            "gpt-4o",
            "gpt-4o-mini",
            "o1-preview",
            "o1-mini"
          ],
          "type_args": [],
          "type_name": "nodetool.metadata.types.GPTModel"
        },
        "default": "gpt-4o-mini",
        "title": "Model",
        "description": "The GPT model to use for chart generation.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "Natural language description of the desired chart",
        "min": null,
        "max": null
      },
      {
        "name": "data",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Data",
        "description": "The data to visualize",
        "min": null,
        "max": null
      },
      {
        "name": "max_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4096,
        "title": "Max Tokens",
        "description": "The maximum number of tokens to generate.",
        "min": 0.0,
        "max": 10000.0
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.7,
        "title": "Temperature",
        "description": "The temperature to use for sampling.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "columns",
        "type": {
          "type": "record_type",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "record_type",
          "columns": []
        },
        "title": "Columns",
        "description": "The columns available in the data.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "chart_config",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "data",
      "model"
    ]
  },
  {
    "title": "Regression Analyst",
    "description": "Agent that performs regression analysis on a given dataframe and provides insights.\n\n    Use cases:\n    - Performing linear regression on datasets\n    - Interpreting regression results like a data scientist\n    - Providing statistical summaries and insights",
    "namespace": "openai.agents",
    "node_type": "openai.agents.RegressionAnalyst",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The user prompt or question regarding the data analysis.",
        "min": null,
        "max": null
      },
      {
        "name": "data",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Data",
        "description": "The dataframe to perform regression on.",
        "min": null,
        "max": null
      },
      {
        "name": "max_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1000,
        "title": "Max Tokens",
        "description": "The maximum number of tokens to generate.",
        "min": 0.0,
        "max": 10000.0
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Temperature",
        "description": "The temperature to use for sampling.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "gpt-3.5-turbo-0125",
            "gpt-4o",
            "gpt-4o-mini",
            "o1-preview",
            "o1-mini"
          ],
          "type_args": [],
          "type_name": "nodetool.metadata.types.GPTModel"
        },
        "default": "gpt-4o-mini",
        "title": "Model",
        "description": "The GPT model to use for regression analysis.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "data",
      "model"
    ]
  },
  {
    "title": "Synthesizer Agent",
    "description": "Agent that interprets natural language descriptions to create sounds using basic synthesis algorithms.\n    llm, audio synthesis, sound design\n\n    Use cases:\n    - Creating sounds from text descriptions\n    - Automated sound design\n    - Converting musical ideas into synthesized audio",
    "namespace": "openai.agents",
    "node_type": "openai.agents.SynthesizerAgent",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "Natural language description of the desired sound",
        "min": null,
        "max": null
      },
      {
        "name": "max_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1000,
        "title": "Max Tokens",
        "description": "The maximum number of tokens to generate.",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Temperature",
        "description": "The temperature to use for sampling.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "duration",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Duration",
        "description": "Duration of the sound in seconds.",
        "min": 0.0,
        "max": 30.0
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "gpt-3.5-turbo-0125",
            "gpt-4o",
            "gpt-4o-mini",
            "o1-preview",
            "o1-mini"
          ],
          "type_args": [],
          "type_name": "nodetool.metadata.types.GPTModel"
        },
        "default": "gpt-4o-mini",
        "title": "Model",
        "description": "The GPT model to use for sound synthesis.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "duration",
      "model"
    ]
  },
  {
    "title": "Chain Of Thought Summarizer",
    "description": "Agent node that synthesizes the results from a chain of thought reasoning process\n    into a final, coherent conclusion.\n\n    Use cases:\n    - Summarizing multi-step reasoning processes\n    - Drawing final conclusions from step-by-step analysis\n    - Validating logical consistency across steps\n    - Generating executive summaries of complex reasoning",
    "namespace": "openai.agents",
    "node_type": "openai.agents.ChainOfThoughtSummarizer",
    "layout": "default",
    "properties": [
      {
        "name": "steps",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "thought_step",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Steps",
        "description": "The completed chain of thought steps with their results",
        "min": null,
        "max": null
      },
      {
        "name": "messages",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "message",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Messages",
        "description": "The messages used to generate the chain of thought steps",
        "min": null,
        "max": null
      },
      {
        "name": "max_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1000,
        "title": "Max Tokens",
        "description": "The maximum number of tokens to generate",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Temperature",
        "description": "The temperature to use for sampling",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "gpt-3.5-turbo-0125",
            "gpt-4o",
            "gpt-4o-mini",
            "o1-preview",
            "o1-mini"
          ],
          "type_args": [],
          "type_name": "nodetool.metadata.types.GPTModel"
        },
        "default": "gpt-4o-mini",
        "title": "Model",
        "description": "The GPT model to use for summarizing chain of thought results.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "logical_consistency",
        "stream": false
      },
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "consistency_issues",
        "stream": false
      },
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "final_answer",
        "stream": false
      },
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "assumptions",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "steps",
      "messages",
      "model"
    ]
  },
  {
    "title": "Dall E",
    "description": "Generates images from textual descriptions using DALL-E 3.\n    image, t2i, tti, text-to-image, create, generate, dall-e, picture, photo, art, drawing, illustration\n\n    Use cases:\n    1. Create custom illustrations for articles or presentations\n    2. Generate concept art for creative projects\n    3. Produce visual aids for educational content\n    4. Design unique marketing visuals or product mockups\n    5. Explore artistic ideas and styles programmatically",
    "namespace": "openai.image",
    "node_type": "openai.image.Dall_E",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The prompt to use.",
        "min": null,
        "max": null
      },
      {
        "name": "size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1024x1024",
            "1792x1024",
            "1024x1792"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.openai.image.Size"
        },
        "default": "1024x1024",
        "title": "Size",
        "description": "The size of the image to generate.",
        "min": null,
        "max": null
      },
      {
        "name": "quality",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "standard",
            "hd"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.openai.image.Quality"
        },
        "default": "standard",
        "title": "Quality",
        "description": "The quality of the image to generate.",
        "min": null,
        "max": null
      },
      {
        "name": "style",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "vivid",
            "natural"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.openai.image.Style"
        },
        "default": "natural",
        "title": "Style",
        "description": "The style to use.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "size",
      "quality",
      "style"
    ]
  },
  {
    "title": "Embedding",
    "description": "Generate vector representations of text for semantic analysis.\n    embeddings, similarity, search, clustering, classification\n\n    Uses OpenAI's embedding models to create dense vector representations of text.\n    These vectors capture semantic meaning, enabling:\n    - Semantic search\n    - Text clustering\n    - Document classification\n    - Recommendation systems\n    - Anomaly detection\n    - Measuring text similarity and diversity",
    "namespace": "openai.text",
    "node_type": "openai.text.Embedding",
    "layout": "default",
    "properties": [
      {
        "name": "input",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Input",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "text-embedding-3-large",
            "text-embedding-3-small"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.openai.text.EmbeddingModel"
        },
        "default": "text-embedding-3-small",
        "title": "Model",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "chunk_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4096,
        "title": "Chunk Size",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "input",
      "model",
      "chunk_size"
    ]
  },
  {
    "title": "GPT",
    "description": "Generate natural language responses using GPT models.\n    llm, text-generation, chatbot, question-answering\n\n    Leverages OpenAI's GPT models to:\n    - Generate human-like text responses\n    - Answer questions\n    - Complete prompts\n    - Engage in conversational interactions\n    - Assist with writing and editing tasks\n    - Perform text analysis and summarization",
    "namespace": "openai.text",
    "node_type": "openai.text.GPT",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "gpt-3.5-turbo-0125",
            "gpt-4o",
            "gpt-4o-mini",
            "o1-preview",
            "o1-mini"
          ],
          "type_args": [],
          "type_name": "nodetool.metadata.types.GPTModel"
        },
        "default": "gpt-3.5-turbo-0125",
        "title": "Model",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "system",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "You are a friendly assistant.",
        "title": "System",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "presence_penalty",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Presence Penalty",
        "description": null,
        "min": -2.0,
        "max": 2.0
      },
      {
        "name": "frequency_penalty",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Frequency Penalty",
        "description": null,
        "min": -2.0,
        "max": 2.0
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Temperature",
        "description": null,
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "max_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Max Tokens",
        "description": null,
        "min": 1.0,
        "max": 2048.0
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Top P",
        "description": null,
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "model",
      "temperature"
    ]
  },
  {
    "title": "Audio Super Resolution",
    "description": "AudioSR: Versatile Audio Super-resolution at Scale",
    "namespace": "replicate.audio.enhance",
    "node_type": "replicate.audio.enhance.AudioSuperResolution",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Leave blank to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "ddim_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Ddim Steps",
        "description": "Number of inference steps",
        "min": 10.0,
        "max": 500.0
      },
      {
        "name": "input_file",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Input File",
        "description": "Audio to upsample",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "Scale for classifier free guidance",
        "min": 1.0,
        "max": 20.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/6bc4e480-6695-451b-940d-48a3b83a1356/replicate-prediction-jvi5xvlbg4v4.png",
      "created_at": "2023-09-20T04:53:52.943393Z",
      "description": "AudioSR: Versatile Audio Super-resolution at Scale",
      "github_url": "https://github.com/haoheliu/versatile_audio_super_resolution",
      "license_url": "https://huggingface.co/haoheliu/wellsolve_audio_super_resolution_48k/blob/main/README.md",
      "name": "audio-super-resolution",
      "owner": "nateraw",
      "paper_url": "https://arxiv.org/abs/2309.07314",
      "run_count": 52785,
      "url": "https://replicate.com/nateraw/audio-super-resolution",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "ddim_steps",
      "input_file"
    ]
  },
  {
    "title": "Realistic Voice Cloning",
    "description": "Create song covers with any RVC v2 trained AI voice from audio files.",
    "namespace": "replicate.audio.generate",
    "node_type": "replicate.audio.generate.RealisticVoiceCloning",
    "layout": "default",
    "properties": [
      {
        "name": "protect",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.33,
        "title": "Protect",
        "description": "Control how much of the original vocals' breath and voiceless consonants to leave in the AI vocals. Set 0.5 to disable.",
        "min": 0.0,
        "max": 0.5
      },
      {
        "name": "rvc_model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "Squidward",
            "MrKrabs",
            "Plankton",
            "Drake",
            "Vader",
            "Trump",
            "Biden",
            "Obama",
            "Guitar",
            "Voilin",
            "CUSTOM"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.generate.Rvc_model"
        },
        "default": "Squidward",
        "title": "Rvc Model",
        "description": "RVC model for a specific voice. If using a custom model, this should match the name of the downloaded model. If a 'custom_rvc_model_download_url' is provided, this will be automatically set to the name of the downloaded model.",
        "min": null,
        "max": null
      },
      {
        "name": "index_rate",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Index Rate",
        "description": "Control how much of the AI's accent to leave in the vocals.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "song_input",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Song Input",
        "description": "Upload your audio file here.",
        "min": null,
        "max": null
      },
      {
        "name": "reverb_size",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.15,
        "title": "Reverb Size",
        "description": "The larger the room, the longer the reverb time.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "pitch_change",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "no-change",
            "male-to-female",
            "female-to-male"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.generate.Pitch_change"
        },
        "default": "no-change",
        "title": "Pitch Change",
        "description": "Adjust pitch of AI vocals. Options: `no-change`, `male-to-female`, `female-to-male`.",
        "min": null,
        "max": null
      },
      {
        "name": "rms_mix_rate",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.25,
        "title": "Rms Mix Rate",
        "description": "Control how much to use the original vocal's loudness (0) or a fixed loudness (1).",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "filter_radius",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Filter Radius",
        "description": "If >=3: apply median filtering median filtering to the harvested pitch results.",
        "min": 0.0,
        "max": 7.0
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "mp3",
            "wav"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.generate.Output_format"
        },
        "default": "mp3",
        "title": "Output Format",
        "description": "wav for best quality and large file size, mp3 for decent quality and small file size.",
        "min": null,
        "max": null
      },
      {
        "name": "reverb_damping",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.7,
        "title": "Reverb Damping",
        "description": "Absorption of high frequencies in the reverb.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "reverb_dryness",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Reverb Dryness",
        "description": "Level of AI vocals without reverb.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "reverb_wetness",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.2,
        "title": "Reverb Wetness",
        "description": "Level of AI vocals with reverb.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "crepe_hop_length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 128,
        "title": "Crepe Hop Length",
        "description": "When `pitch_detection_algo` is set to `mangio-crepe`, this controls how often it checks for pitch changes in milliseconds. Lower values lead to longer conversions and higher risk of voice cracks, but better pitch accuracy.",
        "min": null,
        "max": null
      },
      {
        "name": "pitch_change_all",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Pitch Change All",
        "description": "Change pitch/key of background music, backup vocals and AI vocals in semitones. Reduces sound quality slightly.",
        "min": null,
        "max": null
      },
      {
        "name": "main_vocals_volume_change",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Main Vocals Volume Change",
        "description": "Control volume of main AI vocals. Use -3 to decrease the volume by 3 decibels, or 3 to increase the volume by 3 decibels.",
        "min": null,
        "max": null
      },
      {
        "name": "pitch_detection_algorithm",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "rmvpe",
            "mangio-crepe"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.generate.Pitch_detection_algorithm"
        },
        "default": "rmvpe",
        "title": "Pitch Detection Algorithm",
        "description": "Best option is rmvpe (clarity in vocals), then mangio-crepe (smoother vocals).",
        "min": null,
        "max": null
      },
      {
        "name": "instrumental_volume_change",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Instrumental Volume Change",
        "description": "Control volume of the background music/instrumentals.",
        "min": null,
        "max": null
      },
      {
        "name": "backup_vocals_volume_change",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Backup Vocals Volume Change",
        "description": "Control volume of backup AI vocals.",
        "min": null,
        "max": null
      },
      {
        "name": "custom_rvc_model_download_url",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Custom Rvc Model Download Url",
        "description": "URL to download a custom RVC model. If provided, the model will be downloaded (if it doesn't already exist) and used for prediction, regardless of the 'rvc_model' value.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/ce3d3d2c-5a06-413c-96ff-546fc96c90e2/Out_0_1024x1024.png",
      "created_at": "2023-11-09T16:32:42.062982Z",
      "description": "Create song covers with any RVC v2 trained AI voice from audio files.",
      "github_url": "https://github.com/zsxkib/AICoverGen.git",
      "license_url": "https://github.com/SociallyIneptWeeb/AICoverGen/blob/main/LICENSE",
      "name": "realistic-voice-cloning",
      "owner": "zsxkib",
      "paper_url": null,
      "run_count": 530184,
      "url": "https://replicate.com/zsxkib/realistic-voice-cloning",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "protect",
      "rvc_model",
      "index_rate"
    ]
  },
  {
    "title": "Tortoise TTS",
    "description": "Generate speech from text, clone voices from mp3 files. From James Betker AKA \"neonbjb\".",
    "namespace": "replicate.audio.generate",
    "node_type": "replicate.audio.generate.TortoiseTTS",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Seed",
        "description": "Random seed which can be used to reproduce results.",
        "min": null,
        "max": null
      },
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "The expressiveness of autoregressive transformers is literally nuts! I absolutely adore them.",
        "title": "Text",
        "description": "Text to speak.",
        "min": null,
        "max": null
      },
      {
        "name": "preset",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "ultra_fast",
            "fast",
            "standard",
            "high_quality"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.generate.Preset"
        },
        "default": "fast",
        "title": "Preset",
        "description": "Which voice preset to use. See the documentation for more information.",
        "min": null,
        "max": null
      },
      {
        "name": "voice_a",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "angie",
            "cond_latent_example",
            "deniro",
            "freeman",
            "halle",
            "lj",
            "myself",
            "pat2",
            "snakes",
            "tom",
            "train_daws",
            "train_dreams",
            "train_grace",
            "train_lescault",
            "weaver",
            "applejack",
            "daniel",
            "emma",
            "geralt",
            "jlaw",
            "mol",
            "pat",
            "rainbow",
            "tim_reynolds",
            "train_atkins",
            "train_dotrice",
            "train_empire",
            "train_kennard",
            "train_mouse",
            "william",
            "random",
            "custom_voice",
            "disabled"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.generate.Voice_a"
        },
        "default": "random",
        "title": "Voice A",
        "description": "Selects the voice to use for generation. Use `random` to select a random voice. Use `custom_voice` to use a custom voice.",
        "min": null,
        "max": null
      },
      {
        "name": "voice_b",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "angie",
            "cond_latent_example",
            "deniro",
            "freeman",
            "halle",
            "lj",
            "myself",
            "pat2",
            "snakes",
            "tom",
            "train_daws",
            "train_dreams",
            "train_grace",
            "train_lescault",
            "weaver",
            "applejack",
            "daniel",
            "emma",
            "geralt",
            "jlaw",
            "mol",
            "pat",
            "rainbow",
            "tim_reynolds",
            "train_atkins",
            "train_dotrice",
            "train_empire",
            "train_kennard",
            "train_mouse",
            "william",
            "random",
            "custom_voice",
            "disabled"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.generate.Voice_b"
        },
        "default": "disabled",
        "title": "Voice B",
        "description": "(Optional) Create new voice from averaging the latents for `voice_a`, `voice_b` and `voice_c`. Use `disabled` to disable voice mixing.",
        "min": null,
        "max": null
      },
      {
        "name": "voice_c",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "angie",
            "cond_latent_example",
            "deniro",
            "freeman",
            "halle",
            "lj",
            "myself",
            "pat2",
            "snakes",
            "tom",
            "train_daws",
            "train_dreams",
            "train_grace",
            "train_lescault",
            "weaver",
            "applejack",
            "daniel",
            "emma",
            "geralt",
            "jlaw",
            "mol",
            "pat",
            "rainbow",
            "tim_reynolds",
            "train_atkins",
            "train_dotrice",
            "train_empire",
            "train_kennard",
            "train_mouse",
            "william",
            "random",
            "custom_voice",
            "disabled"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.generate.Voice_c"
        },
        "default": "disabled",
        "title": "Voice C",
        "description": "(Optional) Create new voice from averaging the latents for `voice_a`, `voice_b` and `voice_c`. Use `disabled` to disable voice mixing.",
        "min": null,
        "max": null
      },
      {
        "name": "cvvp_amount",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Cvvp Amount",
        "description": "How much the CVVP model should influence the output. Increasing this can in some cases reduce the likelyhood of multiple speakers. Defaults to 0 (disabled)",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "custom_voice",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Custom Voice",
        "description": "(Optional) Create a custom voice based on an mp3 file of a speaker. Audio should be at least 15 seconds, only contain one speaker, and be in mp3 format. Overrides the `voice_a` input.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": null,
      "created_at": "2022-08-02T02:01:54.555794Z",
      "description": "Generate speech from text, clone voices from mp3 files. From James Betker AKA \"neonbjb\".",
      "github_url": "https://github.com/afiaka87/tortoise-tts",
      "license_url": "https://github.com/afiaka87/tortoise-tts/blob/main/LICENSE",
      "name": "tortoise-tts",
      "owner": "afiaka87",
      "paper_url": "https://github.com/neonbjb/tortoise-tts",
      "run_count": 166639,
      "url": "https://replicate.com/afiaka87/tortoise-tts",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "text",
      "preset"
    ]
  },
  {
    "title": "Style TTS 2",
    "description": "Generates speech from text",
    "namespace": "replicate.audio.generate",
    "node_type": "replicate.audio.generate.StyleTTS2",
    "layout": "default",
    "properties": [
      {
        "name": "beta",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.7,
        "title": "Beta",
        "description": "Only used for long text inputs or in case of reference speaker,             determines the prosody of the speaker. Use lower values to sample style based             on previous or reference speech instead of text.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Seed",
        "description": "Seed for reproducibility",
        "min": null,
        "max": null
      },
      {
        "name": "text",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Text",
        "description": "Text to convert to speech",
        "min": null,
        "max": null
      },
      {
        "name": "alpha",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.3,
        "title": "Alpha",
        "description": "Only used for long text inputs or in case of reference speaker,             determines the timbre of the speaker. Use lower values to sample style based             on previous or reference speech instead of text.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "weights",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Weights",
        "description": "Replicate weights url for inference with model that is fine-tuned on new speakers.            If provided, a reference speech must also be provided.             If not provided, the default model will be used.",
        "min": null,
        "max": null
      },
      {
        "name": "reference",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Reference",
        "description": "Reference speech to copy style from",
        "min": null,
        "max": null
      },
      {
        "name": "diffusion_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10,
        "title": "Diffusion Steps",
        "description": "Number of diffusion steps",
        "min": 0.0,
        "max": 50.0
      },
      {
        "name": "embedding_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Embedding Scale",
        "description": "Embedding scale, use higher values for pronounced emotion",
        "min": 0.0,
        "max": 5.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/b3443880-411e-4b5f-b9f9-3db28c59b578/out-0.png",
      "created_at": "2023-11-20T19:22:15.416691Z",
      "description": "Generates speech from text",
      "github_url": "https://github.com/yl4579/StyleTTS2",
      "license_url": "https://github.com/yl4579/StyleTTS2/blob/main/LICENSE",
      "name": "styletts2",
      "owner": "adirik",
      "paper_url": "https://arxiv.org/abs/2306.07691",
      "run_count": 127679,
      "url": "https://replicate.com/adirik/styletts2",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "beta",
      "seed",
      "text"
    ]
  },
  {
    "title": "Riffusion",
    "description": "Stable diffusion for real-time music generation",
    "namespace": "replicate.audio.generate",
    "node_type": "replicate.audio.generate.Riffusion",
    "layout": "default",
    "properties": [
      {
        "name": "alpha",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Alpha",
        "description": "Interpolation alpha if using two prompts. A value of 0 uses prompt_a fully, a value of 1 uses prompt_b fully",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "prompt_a",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "funky synth solo",
        "title": "Prompt A",
        "description": "The prompt for your audio",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_b",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt B",
        "description": "The second prompt to interpolate with the first, leave blank if no interpolation",
        "min": null,
        "max": null
      },
      {
        "name": "denoising",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.75,
        "title": "Denoising",
        "description": "How much to transform input spectrogram",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "seed_image_id",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "agile",
            "marim",
            "mask_beat_lines_80",
            "mask_gradient_dark",
            "mask_gradient_top_70",
            "mask_graident_top_fifth_75",
            "mask_top_third_75",
            "mask_top_third_95",
            "motorway",
            "og_beat",
            "vibes"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.generate.Seed_image_id"
        },
        "default": "vibes",
        "title": "Seed Image Id",
        "description": "Seed spectrogram to use",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Num Inference Steps",
        "description": "Number of steps to run the diffusion model",
        "min": 1.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/4154e53a-5c5d-4ac5-9da8-62a1fec212bf/riffusion.gif",
      "created_at": "2022-12-16T07:31:34.983811Z",
      "description": "Stable diffusion for real-time music generation",
      "github_url": "https://github.com/riffusion/riffusion",
      "license_url": "https://github.com/riffusion/riffusion/blob/main/LICENSE",
      "name": "riffusion",
      "owner": "riffusion",
      "paper_url": "https://www.riffusion.com/about",
      "run_count": 984529,
      "url": "https://replicate.com/riffusion/riffusion",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "alpha",
      "prompt_a",
      "prompt_b"
    ]
  },
  {
    "title": "Music Gen",
    "description": "Generate music from a prompt or melody",
    "namespace": "replicate.audio.generate",
    "node_type": "replicate.audio.generate.MusicGen",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Seed for random number generator. If None or -1, a random seed will be used.",
        "min": null,
        "max": null
      },
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 250,
        "title": "Top K",
        "description": "Reduces sampling to the k most likely tokens.",
        "min": null,
        "max": null
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Top P",
        "description": "Reduces sampling to tokens with cumulative probability of p. When set to  `0` (default), top_k sampling is used.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "A description of the music you want to generate.",
        "min": null,
        "max": null
      },
      {
        "name": "duration",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8,
        "title": "Duration",
        "description": "Duration of the generated audio in seconds.",
        "min": null,
        "max": null
      },
      {
        "name": "input_audio",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Input Audio",
        "description": "An audio file that will influence the generated music. If `continuation` is `True`, the generated music will be a continuation of the audio file. Otherwise, the generated music will mimic the audio file's melody.",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Temperature",
        "description": "Controls the 'conservativeness' of the sampling process. Higher temperature means more diversity.",
        "min": null,
        "max": null
      },
      {
        "name": "continuation",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Continuation",
        "description": "If `True`, generated music will continue from `input_audio`. Otherwise, generated music will mimic `input_audio`'s melody.",
        "min": null,
        "max": null
      },
      {
        "name": "model_version",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "stereo-melody-large",
            "stereo-large",
            "melody-large",
            "large"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.generate.Model_version"
        },
        "default": "stereo-melody-large",
        "title": "Model Version",
        "description": "Model to use for generation",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "wav",
            "mp3"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.generate.Output_format"
        },
        "default": "wav",
        "title": "Output Format",
        "description": "Output format for generated audio.",
        "min": null,
        "max": null
      },
      {
        "name": "continuation_end",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Continuation End",
        "description": "End time of the audio file to use for continuation. If -1 or None, will default to the end of the audio clip.",
        "min": 0.0,
        "max": null
      },
      {
        "name": "continuation_start",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Continuation Start",
        "description": "Start time of the audio file to use for continuation.",
        "min": 0.0,
        "max": null
      },
      {
        "name": "multi_band_diffusion",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Multi Band Diffusion",
        "description": "If `True`, the EnCodec tokens will be decoded with MultiBand Diffusion. Only works with non-stereo models.",
        "min": null,
        "max": null
      },
      {
        "name": "normalization_strategy",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "loudness",
            "clip",
            "peak",
            "rms"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.generate.Normalization_strategy"
        },
        "default": "loudness",
        "title": "Normalization Strategy",
        "description": "Strategy for normalizing audio.",
        "min": null,
        "max": null
      },
      {
        "name": "classifier_free_guidance",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Classifier Free Guidance",
        "description": "Increases the influence of inputs on the output. Higher values produce lower-varience outputs that adhere more closely to inputs.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/a921a8b3-3e9e-48ef-995c-29143ea11bec/musicgen.jpeg",
      "created_at": "2023-06-12T19:22:05.525230Z",
      "description": "Generate music from a prompt or melody",
      "github_url": "https://github.com/replicate/cog-musicgen",
      "license_url": "https://github.com/facebookresearch/audiocraft/blob/main/LICENSE_weights",
      "name": "musicgen",
      "owner": "meta",
      "paper_url": "https://arxiv.org/abs/2306.05284",
      "run_count": 2217440,
      "url": "https://replicate.com/meta/musicgen",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "top_k",
      "top_p"
    ]
  },
  {
    "title": "MMAudio",
    "description": "Add sound to video. An advanced AI model that synthesizes high-quality audio from video content, enabling seamless video-to-audio transformation",
    "namespace": "replicate.audio.generate",
    "node_type": "replicate.audio.generate.MMAudio",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "Random seed. Use -1 to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "video",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Video",
        "description": "Optional video file for video-to-audio generation",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "Text prompt for generated audio",
        "min": null,
        "max": null
      },
      {
        "name": "duration",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8,
        "title": "Duration",
        "description": "Duration of output in seconds",
        "min": null,
        "max": null
      },
      {
        "name": "num_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Steps",
        "description": "Number of inference steps",
        "min": null,
        "max": null
      },
      {
        "name": "cfg_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4.5,
        "title": "Cfg Strength",
        "description": "Guidance strength (CFG)",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "music",
        "title": "Negative Prompt",
        "description": "Negative prompt to avoid certain sounds",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/34262841-19bf-443c-9892-72488fec1ef2/mmaudio-cover.webp",
      "created_at": "2024-12-11T14:46:16.273908Z",
      "description": "Add sound to video. An advanced AI model that synthesizes high-quality audio from video content, enabling seamless video-to-audio transformation",
      "github_url": "https://github.com/hkchengrex/MMAudio",
      "license_url": "https://github.com/hkchengrex/MMAudio#MIT-1-ov-file",
      "name": "mmaudio",
      "owner": "zsxkib",
      "paper_url": "https://hkchengrex.github.io/MMAudio",
      "run_count": 39507,
      "url": "https://replicate.com/zsxkib/mmaudio",
      "visibility": "public",
      "weights_url": "https://huggingface.co/hkchengrex/MMAudio/tree/main"
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "video",
      "prompt"
    ]
  },
  {
    "title": "Incredibly Fast Whisper",
    "description": "whisper-large-v3, incredibly fast, powered by Hugging Face Transformers! \ud83e\udd17",
    "namespace": "replicate.audio.transcribe",
    "node_type": "replicate.audio.transcribe.IncrediblyFastWhisper",
    "layout": "default",
    "properties": [
      {
        "name": "task",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "transcribe",
            "translate"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.transcribe.Task"
        },
        "default": "transcribe",
        "title": "Task",
        "description": "Task to perform: transcribe or translate to another language.",
        "min": null,
        "max": null
      },
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "Audio file",
        "min": null,
        "max": null
      },
      {
        "name": "hf_token",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Hf Token",
        "description": "Provide a hf.co/settings/token for Pyannote.audio to diarise the audio clips. You need to agree to the terms in 'https://huggingface.co/pyannote/speaker-diarization-3.1' and 'https://huggingface.co/pyannote/segmentation-3.0' first.",
        "min": null,
        "max": null
      },
      {
        "name": "language",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "None",
            "afrikaans",
            "albanian",
            "amharic",
            "arabic",
            "armenian",
            "assamese",
            "azerbaijani",
            "bashkir",
            "basque",
            "belarusian",
            "bengali",
            "bosnian",
            "breton",
            "bulgarian",
            "cantonese",
            "catalan",
            "chinese",
            "croatian",
            "czech",
            "danish",
            "dutch",
            "english",
            "estonian",
            "faroese",
            "finnish",
            "french",
            "galician",
            "georgian",
            "german",
            "greek",
            "gujarati",
            "haitian creole",
            "hausa",
            "hawaiian",
            "hebrew",
            "hindi",
            "hungarian",
            "icelandic",
            "indonesian",
            "italian",
            "japanese",
            "javanese",
            "kannada",
            "kazakh",
            "khmer",
            "korean",
            "lao",
            "latin",
            "latvian",
            "lingala",
            "lithuanian",
            "luxembourgish",
            "macedonian",
            "malagasy",
            "malay",
            "malayalam",
            "maltese",
            "maori",
            "marathi",
            "mongolian",
            "myanmar",
            "nepali",
            "norwegian",
            "nynorsk",
            "occitan",
            "pashto",
            "persian",
            "polish",
            "portuguese",
            "punjabi",
            "romanian",
            "russian",
            "sanskrit",
            "serbian",
            "shona",
            "sindhi",
            "sinhala",
            "slovak",
            "slovenian",
            "somali",
            "spanish",
            "sundanese",
            "swahili",
            "swedish",
            "tagalog",
            "tajik",
            "tamil",
            "tatar",
            "telugu",
            "thai",
            "tibetan",
            "turkish",
            "turkmen",
            "ukrainian",
            "urdu",
            "uzbek",
            "vietnamese",
            "welsh",
            "yiddish",
            "yoruba"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.transcribe.Language"
        },
        "default": "None",
        "title": "Language",
        "description": "Language spoken in the audio, specify 'None' to perform language detection.",
        "min": null,
        "max": null
      },
      {
        "name": "timestamp",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "chunk",
            "word"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.transcribe.Timestamp"
        },
        "default": "chunk",
        "title": "Timestamp",
        "description": "Whisper supports both chunked as well as word level timestamps.",
        "min": null,
        "max": null
      },
      {
        "name": "batch_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 24,
        "title": "Batch Size",
        "description": "Number of parallel batches you want to compute. Reduce if you face OOMs.",
        "min": null,
        "max": null
      },
      {
        "name": "diarise_audio",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Diarise Audio",
        "description": "Use Pyannote.audio to diarise the audio clips. You will need to provide hf_token below too.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/4c5d637c-c441-4857-9791-7c11111b38b4/52ebbd85-50a7-4741-b398-30e31.webp",
      "created_at": "2023-11-13T13:28:53.689979Z",
      "description": "whisper-large-v3, incredibly fast, powered by Hugging Face Transformers! \ud83e\udd17",
      "github_url": "https://github.com/chenxwh/insanely-fast-whisper",
      "license_url": "https://github.com/Vaibhavs10/insanely-fast-whisper/blob/main/LICENSE",
      "name": "incredibly-fast-whisper",
      "owner": "vaibhavs10",
      "paper_url": null,
      "run_count": 3043092,
      "url": "https://replicate.com/vaibhavs10/incredibly-fast-whisper",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "task",
      "audio",
      "hf_token"
    ]
  },
  {
    "title": "Demucs",
    "description": "Demucs is an audio source separator created by Facebook Research.",
    "namespace": "replicate.audio.separate",
    "node_type": "replicate.audio.separate.Demucs",
    "layout": "default",
    "properties": [
      {
        "name": "jobs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Jobs",
        "description": "Choose the number of parallel jobs to use for separation.",
        "min": null,
        "max": null
      },
      {
        "name": "stem",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "none",
            "drums",
            "bass",
            "other",
            "vocals",
            "guitar",
            "piano"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.separate.Stem"
        },
        "default": "none",
        "title": "Stem",
        "description": "If you just want to isolate one stem, you can choose it here.",
        "min": null,
        "max": null
      },
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "Upload the file to be processed here.",
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "htdemucs",
            "htdemucs_ft",
            "htdemucs_6s",
            "hdemucs_mmi",
            "mdx_q",
            "mdx_extra_q"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.separate.Model"
        },
        "default": "htdemucs",
        "title": "Model",
        "description": "Choose the demucs audio that proccesses your audio. The readme has more information on what to choose.",
        "min": null,
        "max": null
      },
      {
        "name": "split",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Split",
        "description": "Choose whether or not the audio should be split into chunks.",
        "min": null,
        "max": null
      },
      {
        "name": "shifts",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Shifts",
        "description": "Choose the amount random shifts for equivariant stabilization. This performs multiple predictions with random shifts of the input and averages them, which makes it x times slower.",
        "min": null,
        "max": null
      },
      {
        "name": "overlap",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.25,
        "title": "Overlap",
        "description": "Choose the amount of overlap between prediction windows.",
        "min": null,
        "max": null
      },
      {
        "name": "segment",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Segment",
        "description": "Choose the segment length to use for separation.",
        "min": null,
        "max": null
      },
      {
        "name": "clip_mode",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "rescale",
            "clamp",
            "none"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.separate.Clip_mode"
        },
        "default": "rescale",
        "title": "Clip Mode",
        "description": "Choose the strategy for avoiding clipping. Rescale will rescale entire signal if necessary or clamp will allow hard clipping.",
        "min": null,
        "max": null
      },
      {
        "name": "mp3_preset",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            2,
            3,
            4,
            5,
            6,
            7
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.separate.Mp3_preset"
        },
        "default": 2,
        "title": "Mp3 Preset",
        "description": "Choose the preset for the MP3 output. Higher is faster but worse quality. If MP3 is not selected as the output type, this has no effect.",
        "min": null,
        "max": null
      },
      {
        "name": "wav_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "int16",
            "int24",
            "float32"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.separate.Wav_format"
        },
        "default": "int24",
        "title": "Wav Format",
        "description": "Choose format for the WAV output. If WAV is not selected as the output type, this has no effect.",
        "min": null,
        "max": null
      },
      {
        "name": "mp3_bitrate",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 320,
        "title": "Mp3 Bitrate",
        "description": "Choose the bitrate for the MP3 output. Higher is better quality but larger file size. If MP3 is not selected as the output type, this has no effect.",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "mp3",
            "flac",
            "wav"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.audio.separate.Output_format"
        },
        "default": "mp3",
        "title": "Output Format",
        "description": "Choose the audio format you would like the result to be returned in.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "vocals",
        "stream": false
      },
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "drums",
        "stream": false
      },
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "bass",
        "stream": false
      },
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "other",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/c13b51bf-69a4-474e-ad73-d800466ca357/588ff17a-e9c9-49c7-b572-e1b189d87.png",
      "created_at": "2022-11-08T22:25:48.183283Z",
      "description": "Demucs is an audio source separator created by Facebook Research.",
      "github_url": "https://github.com/ryan5453/demucs-cog",
      "license_url": "https://github.com/ryan5453/demucs-cog/blob/main/LICENSE",
      "name": "demucs",
      "owner": "ryan5453",
      "paper_url": "https://arxiv.org/abs/2111.03600",
      "run_count": 349277,
      "url": "https://replicate.com/ryan5453/demucs",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "jobs",
      "stem",
      "audio"
    ]
  },
  {
    "title": "SDXLClip Interrogator",
    "description": "CLIP Interrogator for SDXL optimizes text prompts to match a given image",
    "namespace": "replicate.image.analyze",
    "node_type": "replicate.image.analyze.SDXLClipInterrogator",
    "layout": "default",
    "properties": [
      {
        "name": "mode",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "best",
            "fast"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.analyze.Mode"
        },
        "default": "best",
        "title": "Mode",
        "description": "Prompt Mode: fast takes 1-2 seconds, best takes 15-25 seconds.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/c200f919-4cc1-412b-8edf-e2863a5eef56/replicate-sdxl-inter.png",
      "created_at": "2023-08-14T20:06:38.402771Z",
      "description": "CLIP Interrogator for SDXL optimizes text prompts to match a given image",
      "github_url": "https://github.com/lucataco/cog-sdxl-clip-interrogator",
      "license_url": "https://github.com/pharmapsychotic/clip-interrogator/blob/main/LICENSE",
      "name": "sdxl-clip-interrogator",
      "owner": "lucataco",
      "paper_url": null,
      "run_count": 845652,
      "url": "https://replicate.com/lucataco/sdxl-clip-interrogator",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "mode",
      "image"
    ]
  },
  {
    "title": "Img 2 Prompt",
    "description": "Get an approximate text prompt, with style, matching an image.  (Optimized for stable-diffusion (clip ViT-L/14))",
    "namespace": "replicate.image.analyze",
    "node_type": "replicate.image.analyze.Img2Prompt",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/504b1747-8c67-438b-b02f-a6ea9254589d/a_high_detail_shot_of_a_cat_we.png",
      "created_at": "2022-08-24T08:53:28.614572Z",
      "description": "Get an approximate text prompt, with style, matching an image.  (Optimized for stable-diffusion (clip ViT-L/14))",
      "github_url": "https://github.com/pharmapsychotic/clip-interrogator",
      "license_url": "https://github.com/pharmapsychotic/clip-interrogator/blob/main/LICENSE",
      "name": "img2prompt",
      "owner": "methexis-inc",
      "paper_url": null,
      "run_count": 2640193,
      "url": "https://replicate.com/methexis-inc/img2prompt",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Moondream 2",
    "description": "moondream2 is a small vision language model designed to run efficiently on edge devices",
    "namespace": "replicate.image.analyze",
    "node_type": "replicate.image.analyze.Moondream2",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Describe this image",
        "title": "Prompt",
        "description": "Input prompt",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/dc0dc539-f592-4c34-b24f-2d112f742975/moondream2.png",
      "created_at": "2024-03-05T02:29:40.377800Z",
      "description": "moondream2 is a small vision language model designed to run efficiently on edge devices",
      "github_url": "https://github.com/lucataco/cog-moondream2",
      "license_url": "https://github.com/vikhyat/moondream?tab=Apache-2.0-1-ov-file#readme",
      "name": "moondream2",
      "owner": "lucataco",
      "paper_url": null,
      "run_count": 242366,
      "url": "https://replicate.com/lucataco/moondream2",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "image",
      "prompt"
    ]
  },
  {
    "title": "NSFWImage Detection",
    "description": "Fine-Tuned Vision Transformer (ViT) for NSFW Image Classification",
    "namespace": "replicate.image.analyze",
    "node_type": "replicate.image.analyze.NSFWImageDetection",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/pbxt/JurYNQcIfISvpS6WtaOcwZXw1ifEudlLyQqiLj5N1Zq977Q3/falcon.jpg",
      "created_at": "2023-11-21T14:53:34.798862Z",
      "description": "Fine-Tuned Vision Transformer (ViT) for NSFW Image Classification",
      "github_url": "https://github.com/lucataco/cog-nsfw_image_detection",
      "license_url": "https://huggingface.co/models?license=license:apache-2.0",
      "name": "nsfw_image_detection",
      "owner": "falcons-ai",
      "paper_url": "https://arxiv.org/abs/2010.11929",
      "run_count": 41917944,
      "url": "https://replicate.com/falcons-ai/nsfw_image_detection",
      "visibility": "public",
      "weights_url": "https://huggingface.co/Falconsai/nsfw_image_detection"
    },
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Blip",
    "description": "Generate image captions",
    "namespace": "replicate.image.analyze",
    "node_type": "replicate.image.analyze.Blip",
    "layout": "default",
    "properties": [
      {
        "name": "task",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "image_captioning",
            "visual_question_answering",
            "image_text_matching"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.analyze.Task"
        },
        "default": "image_captioning",
        "title": "Task",
        "description": "Choose a task.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      },
      {
        "name": "caption",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Caption",
        "description": "Type caption for the input image for image text matching task.",
        "min": null,
        "max": null
      },
      {
        "name": "question",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Question",
        "description": "Type question for the input image for visual question answering task.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/b59b459c-c475-414f-ba67-c424a7e6e6ca/demo.jpg",
      "created_at": "2022-02-06T17:40:38.855280Z",
      "description": "Generate image captions",
      "github_url": "https://github.com/salesforce/BLIP",
      "license_url": "https://github.com/salesforce/BLIP/blob/main/LICENSE.txt",
      "name": "blip",
      "owner": "salesforce",
      "paper_url": "https://arxiv.org/abs/2201.12086",
      "run_count": 122049964,
      "url": "https://replicate.com/salesforce/blip",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "task",
      "image",
      "caption"
    ]
  },
  {
    "title": "Blip 2",
    "description": "Answers questions about images",
    "namespace": "replicate.image.analyze",
    "node_type": "replicate.image.analyze.Blip2",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image to query or caption",
        "min": null,
        "max": null
      },
      {
        "name": "caption",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Caption",
        "description": "Select if you want to generate image captions instead of asking questions",
        "min": null,
        "max": null
      },
      {
        "name": "context",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Context",
        "description": "Optional - previous questions and answers to be used as context for answering current question",
        "min": null,
        "max": null
      },
      {
        "name": "question",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "What is this a picture of?",
        "title": "Question",
        "description": "Question to ask about this image. Leave blank for captioning",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Temperature",
        "description": "Temperature for use with nucleus sampling",
        "min": 0.5,
        "max": 1.0
      },
      {
        "name": "use_nucleus_sampling",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Use Nucleus Sampling",
        "description": "Toggles the model using nucleus sampling to generate responses",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/031b9aee-ed15-4429-a7e4-813b72e9edc5/gg_bridge.jpeg",
      "created_at": "2023-02-13T07:06:23.521189Z",
      "description": "Answers questions about images",
      "github_url": "https://github.com/daanelson/cog-blip-2",
      "license_url": null,
      "name": "blip-2",
      "owner": "andreasjansson",
      "paper_url": "https://arxiv.org/abs/2301.12597",
      "run_count": 29051671,
      "url": "https://replicate.com/andreasjansson/blip-2",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "image",
      "caption",
      "context"
    ]
  },
  {
    "title": "Clip Interrogator",
    "description": "The CLIP Interrogator is a prompt engineering tool that combines OpenAI's CLIP and Salesforce's BLIP to optimize text prompts to match a given image. Use the resulting prompts with text-to-image models like Stable Diffusion to create cool art!",
    "namespace": "replicate.image.analyze",
    "node_type": "replicate.image.analyze.ClipInterrogator",
    "layout": "default",
    "properties": [
      {
        "name": "mode",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "best",
            "classic",
            "fast",
            "negative"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.analyze.Mode"
        },
        "default": "best",
        "title": "Mode",
        "description": "Prompt mode (best takes 10-20 seconds, fast takes 1-2 seconds).",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      },
      {
        "name": "clip_model_name",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "ViT-L-14/openai",
            "ViT-H-14/laion2b_s32b_b79k",
            "ViT-bigG-14/laion2b_s39b_b160k"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.analyze.Clip_model_name"
        },
        "default": "ViT-L-14/openai",
        "title": "Clip Model Name",
        "description": "Choose ViT-L for Stable Diffusion 1, ViT-H for Stable Diffusion 2, or ViT-bigG for Stable Diffusion XL.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/pbxt/HrXsgowfhbZi3dImGZoIcvnz7oZfMtFY4UAEU8vBIakTd8JQ/watercolour-4799014_960_720.jpg",
      "created_at": "2022-10-28T17:47:38.473429Z",
      "description": "The CLIP Interrogator is a prompt engineering tool that combines OpenAI's CLIP and Salesforce's BLIP to optimize text prompts to match a given image. Use the resulting prompts with text-to-image models like Stable Diffusion to create cool art!",
      "github_url": "https://github.com/pharmapsychotic/clip-interrogator",
      "license_url": "https://github.com/pharmapsychotic/clip-interrogator/blob/main/LICENSE",
      "name": "clip-interrogator",
      "owner": "pharmapsychotic",
      "paper_url": null,
      "run_count": 2936158,
      "url": "https://replicate.com/pharmapsychotic/clip-interrogator",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "mode",
      "image",
      "clip_model_name"
    ]
  },
  {
    "title": "Llava 13 b",
    "description": "Visual instruction tuning towards large language and vision models with GPT-4 level capabilities",
    "namespace": "replicate.image.analyze",
    "node_type": "replicate.image.analyze.Llava13b",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Top P",
        "description": "When decoding text, samples from the top p percentage of most likely tokens; lower to ignore less likely tokens",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Prompt to use for text generation",
        "min": null,
        "max": null
      },
      {
        "name": "max_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Max Tokens",
        "description": "Maximum number of tokens to generate. A word is generally 2-3 tokens",
        "min": 0.0,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.2,
        "title": "Temperature",
        "description": "Adjusts randomness of outputs, greater than 1 is random and 0 is deterministic",
        "min": 0.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/454548d6-4978-4d85-bca3-d067dfc031bf/llava.png",
      "created_at": "2023-10-09T16:27:51.777748Z",
      "description": "Visual instruction tuning towards large language and vision models with GPT-4 level capabilities",
      "github_url": "https://github.com/haotian-liu/LLaVA",
      "license_url": "https://ai.meta.com/llama/license/",
      "name": "llava-13b",
      "owner": "yorickvp",
      "paper_url": "https://arxiv.org/abs/2310.03744",
      "run_count": 21141699,
      "url": "https://replicate.com/yorickvp/llava-13b",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "image",
      "top_p",
      "prompt"
    ]
  },
  {
    "title": "Clip Features",
    "description": "Return CLIP features for the clip-vit-large-patch14 model",
    "namespace": "replicate.image.analyze",
    "node_type": "replicate.image.analyze.ClipFeatures",
    "layout": "default",
    "properties": [
      {
        "name": "inputs",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "a\nb",
        "title": "Inputs",
        "description": "Newline-separated inputs. Can either be strings of text or image URIs starting with http[s]://",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "dict",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/07d242b3-4246-4da2-9522-b4ad134336fc/clip_image.png",
      "created_at": "2022-09-22T20:23:55.682616Z",
      "description": "Return CLIP features for the clip-vit-large-patch14 model",
      "github_url": "https://github.com/andreasjansson/cog-clip",
      "license_url": null,
      "name": "clip-features",
      "owner": "andreasjansson",
      "paper_url": null,
      "run_count": 71642394,
      "url": "https://replicate.com/andreasjansson/clip-features",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "inputs"
    ]
  },
  {
    "title": "Code Former",
    "description": "Robust face restoration algorithm for old photos/AI-generated faces",
    "namespace": "replicate.image.enhance",
    "node_type": "replicate.image.enhance.CodeFormer",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      },
      {
        "name": "upscale",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Upscale",
        "description": "The final upsampling scale of the image",
        "min": null,
        "max": null
      },
      {
        "name": "face_upsample",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Face Upsample",
        "description": "Upsample restored faces for high-resolution AI-created images",
        "min": null,
        "max": null
      },
      {
        "name": "background_enhance",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Background Enhance",
        "description": "Enhance background image with Real-ESRGAN",
        "min": null,
        "max": null
      },
      {
        "name": "codeformer_fidelity",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Codeformer Fidelity",
        "description": "Balance the quality (lower number) and fidelity (higher number).",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/cf736d61-411f-4301-89b3-16aff1a02ed1/codeformer_logo.png",
      "created_at": "2023-09-06T04:10:50.158696Z",
      "description": "Robust face restoration algorithm for old photos/AI-generated faces",
      "github_url": "https://github.com/sczhou/CodeFormer",
      "license_url": "https://github.com/sczhou/CodeFormer/blob/master/LICENSE",
      "name": "codeformer",
      "owner": "lucataco",
      "paper_url": "https://arxiv.org/abs/2206.11253",
      "run_count": 622371,
      "url": "https://replicate.com/lucataco/codeformer",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "image",
      "upscale",
      "face_upsample"
    ]
  },
  {
    "title": "Night Enhancement",
    "description": "Unsupervised Night Image Enhancement",
    "namespace": "replicate.image.enhance",
    "node_type": "replicate.image.enhance.Night_Enhancement",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/mgxm/60c4c0d8-c82f-42e0-96ee-71392d32b6fe/output.png",
      "created_at": "2022-08-13T15:54:02.662983Z",
      "description": "Unsupervised Night Image Enhancement",
      "github_url": "https://github.com/jinyeying/night-enhancement",
      "license_url": "https://github.com/jinyeying/night-enhancement/blob/main/LICENSE",
      "name": "night-enhancement",
      "owner": "cjwbw",
      "paper_url": "https://arxiv.org/pdf/2207.10564.pdf",
      "run_count": 41628,
      "url": "https://replicate.com/cjwbw/night-enhancement",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Supir V 0 Q",
    "description": "Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild. This is the SUPIR-v0Q model and does NOT use LLaVA-13b.",
    "namespace": "replicate.image.enhance",
    "node_type": "replicate.image.enhance.Supir_V0Q",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Leave blank to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Low quality input image.",
        "min": null,
        "max": null
      },
      {
        "name": "s_cfg",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "S Cfg",
        "description": " Classifier-free guidance scale for prompts.",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "s_churn",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5,
        "title": "S Churn",
        "description": "Original churn hy-param of EDM.",
        "min": null,
        "max": null
      },
      {
        "name": "s_noise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.003,
        "title": "S Noise",
        "description": "Original noise hy-param of EDM.",
        "min": null,
        "max": null
      },
      {
        "name": "upscale",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Upscale",
        "description": "Upsampling ratio of given inputs.",
        "min": null,
        "max": null
      },
      {
        "name": "a_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Cinematic, High Contrast, highly detailed, taken using a Canon EOS R camera, hyper detailed photo - realistic maximum detail, 32k, Color Grading, ultra HD, extreme meticulous detailing, skin pore detailing, hyper sharpness, perfect without deformations.",
        "title": "A Prompt",
        "description": "Additive positive prompt for the inputs.",
        "min": null,
        "max": null
      },
      {
        "name": "min_size",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Min Size",
        "description": "Minimum resolution of output images.",
        "min": null,
        "max": null
      },
      {
        "name": "n_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "painting, oil painting, illustration, drawing, art, sketch, oil painting, cartoon, CG Style, 3D render, unreal engine, blurring, dirty, messy, worst quality, low quality, frames, watermark, signature, jpeg artifacts, deformed, lowres, over-smooth",
        "title": "N Prompt",
        "description": "Negative prompt for the inputs.",
        "min": null,
        "max": null
      },
      {
        "name": "s_stage1",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "S Stage1",
        "description": "Control Strength of Stage1 (negative means invalid).",
        "min": null,
        "max": null
      },
      {
        "name": "s_stage2",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "S Stage2",
        "description": "Control Strength of Stage2.",
        "min": null,
        "max": null
      },
      {
        "name": "edm_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Edm Steps",
        "description": "Number of steps for EDM Sampling Schedule.",
        "min": 1.0,
        "max": 500.0
      },
      {
        "name": "linear_CFG",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Linear Cfg",
        "description": "Linearly (with sigma) increase CFG from 'spt_linear_CFG' to s_cfg.",
        "min": null,
        "max": null
      },
      {
        "name": "color_fix_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "None",
            "AdaIn",
            "Wavelet"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.enhance.Color_fix_type"
        },
        "default": "Wavelet",
        "title": "Color Fix Type",
        "description": "Color Fixing Type..",
        "min": null,
        "max": null
      },
      {
        "name": "spt_linear_CFG",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Spt Linear Cfg",
        "description": "Start point of linearly increasing CFG.",
        "min": null,
        "max": null
      },
      {
        "name": "linear_s_stage2",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Linear S Stage2",
        "description": "Linearly (with sigma) increase s_stage2 from 'spt_linear_s_stage2' to s_stage2.",
        "min": null,
        "max": null
      },
      {
        "name": "spt_linear_s_stage2",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Spt Linear S Stage2",
        "description": "Start point of linearly increasing s_stage2.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/pbxt/gYLkKNiBcnZDD9dnPxlUR4iurpbr1QANec0VmA2kv3Ol6zMJA/out.png",
      "created_at": "2024-02-23T16:26:24.376439Z",
      "description": "Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild. This is the SUPIR-v0Q model and does NOT use LLaVA-13b.",
      "github_url": "https://github.com/chenxwh/SUPIR",
      "license_url": "https://github.com/Fanghua-Yu/SUPIR/blob/master/LICENSE",
      "name": "supir-v0q",
      "owner": "cjwbw",
      "paper_url": "https://arxiv.org/abs/2401.13627",
      "run_count": 7856,
      "url": "https://replicate.com/cjwbw/supir-v0q",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "image",
      "s_cfg"
    ]
  },
  {
    "title": "Supir V 0 F",
    "description": "Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild. This is the SUPIR-v0F model and does NOT use LLaVA-13b.",
    "namespace": "replicate.image.enhance",
    "node_type": "replicate.image.enhance.Supir_V0F",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Leave blank to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Low quality input image.",
        "min": null,
        "max": null
      },
      {
        "name": "s_cfg",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "S Cfg",
        "description": " Classifier-free guidance scale for prompts.",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "s_churn",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5,
        "title": "S Churn",
        "description": "Original churn hy-param of EDM.",
        "min": null,
        "max": null
      },
      {
        "name": "s_noise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.003,
        "title": "S Noise",
        "description": "Original noise hy-param of EDM.",
        "min": null,
        "max": null
      },
      {
        "name": "upscale",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Upscale",
        "description": "Upsampling ratio of given inputs.",
        "min": null,
        "max": null
      },
      {
        "name": "a_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Cinematic, High Contrast, highly detailed, taken using a Canon EOS R camera, hyper detailed photo - realistic maximum detail, 32k, Color Grading, ultra HD, extreme meticulous detailing, skin pore detailing, hyper sharpness, perfect without deformations.",
        "title": "A Prompt",
        "description": "Additive positive prompt for the inputs.",
        "min": null,
        "max": null
      },
      {
        "name": "min_size",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Min Size",
        "description": "Minimum resolution of output images.",
        "min": null,
        "max": null
      },
      {
        "name": "n_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "painting, oil painting, illustration, drawing, art, sketch, oil painting, cartoon, CG Style, 3D render, unreal engine, blurring, dirty, messy, worst quality, low quality, frames, watermark, signature, jpeg artifacts, deformed, lowres, over-smooth",
        "title": "N Prompt",
        "description": "Negative prompt for the inputs.",
        "min": null,
        "max": null
      },
      {
        "name": "s_stage1",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "S Stage1",
        "description": "Control Strength of Stage1 (negative means invalid).",
        "min": null,
        "max": null
      },
      {
        "name": "s_stage2",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "S Stage2",
        "description": "Control Strength of Stage2.",
        "min": null,
        "max": null
      },
      {
        "name": "edm_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Edm Steps",
        "description": "Number of steps for EDM Sampling Schedule.",
        "min": 1.0,
        "max": 500.0
      },
      {
        "name": "linear_CFG",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Linear Cfg",
        "description": "Linearly (with sigma) increase CFG from 'spt_linear_CFG' to s_cfg.",
        "min": null,
        "max": null
      },
      {
        "name": "color_fix_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "None",
            "AdaIn",
            "Wavelet"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.enhance.Color_fix_type"
        },
        "default": "Wavelet",
        "title": "Color Fix Type",
        "description": "Color Fixing Type..",
        "min": null,
        "max": null
      },
      {
        "name": "spt_linear_CFG",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Spt Linear Cfg",
        "description": "Start point of linearly increasing CFG.",
        "min": null,
        "max": null
      },
      {
        "name": "linear_s_stage2",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Linear S Stage2",
        "description": "Linearly (with sigma) increase s_stage2 from 'spt_linear_s_stage2' to s_stage2.",
        "min": null,
        "max": null
      },
      {
        "name": "spt_linear_s_stage2",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Spt Linear S Stage2",
        "description": "Start point of linearly increasing s_stage2.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/pbxt/if3rev1GNfAB6IMsqqW8CqQtVP75pXvU3dLQeV6CFkVutgmJB/out.png",
      "created_at": "2024-02-23T16:38:51.414944Z",
      "description": "Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild. This is the SUPIR-v0F model and does NOT use LLaVA-13b.",
      "github_url": "https://github.com/chenxwh/SUPIR",
      "license_url": "https://github.com/Fanghua-Yu/SUPIR/blob/master/LICENSE",
      "name": "supir-v0f",
      "owner": "cjwbw",
      "paper_url": "https://arxiv.org/abs/2401.13627",
      "run_count": 11184,
      "url": "https://replicate.com/cjwbw/supir-v0f",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "image",
      "s_cfg"
    ]
  },
  {
    "title": "Maxim",
    "description": "Multi-Axis MLP for Image Processing",
    "namespace": "replicate.image.enhance",
    "node_type": "replicate.image.enhance.Maxim",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image.",
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "enum",
              "optional": false,
              "values": [
                "Image Denoising",
                "Image Deblurring (GoPro)",
                "Image Deblurring (REDS)",
                "Image Deblurring (RealBlur_R)",
                "Image Deblurring (RealBlur_J)",
                "Image Deraining (Rain streak)",
                "Image Deraining (Rain drop)",
                "Image Dehazing (Indoor)",
                "Image Dehazing (Outdoor)",
                "Image Enhancement (Low-light)",
                "Image Enhancement (Retouching)"
              ],
              "type_args": [],
              "type_name": "nodetool.nodes.replicate.image.enhance.Model"
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Model",
        "description": "Choose a model.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/df5769aa-0908-4a2e-9378-c582838461db/1fromGOPR0950.png",
      "created_at": "2022-04-20T16:32:30.049391Z",
      "description": "Multi-Axis MLP for Image Processing",
      "github_url": "https://github.com/google-research/maxim",
      "license_url": "https://github.com/google-research/maxim/blob/main/LICENSE",
      "name": "maxim",
      "owner": "google-research",
      "paper_url": "https://arxiv.org/abs/2201.02973",
      "run_count": 481512,
      "url": "https://replicate.com/google-research/maxim",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "image",
      "model"
    ]
  },
  {
    "title": "Old Photos Restoration",
    "description": "Bringing Old Photos Back to Life",
    "namespace": "replicate.image.enhance",
    "node_type": "replicate.image.enhance.OldPhotosRestoration",
    "layout": "default",
    "properties": [
      {
        "name": "HR",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Hr",
        "description": "whether the input image is high-resolution",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "input image.",
        "min": null,
        "max": null
      },
      {
        "name": "with_scratch",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "With Scratch",
        "description": "whether the input image is scratched",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/9f2124ae-ad0f-4a41-bf7e-c3173d0f7c9b/out.png",
      "created_at": "2021-09-11T14:44:30.681818Z",
      "description": "Bringing Old Photos Back to Life",
      "github_url": "https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life",
      "license_url": "https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life/blob/master/LICENSE",
      "name": "bringing-old-photos-back-to-life",
      "owner": "microsoft",
      "paper_url": "https://arxiv.org/abs/2004.09484",
      "run_count": 946942,
      "url": "https://replicate.com/microsoft/bringing-old-photos-back-to-life",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "HR",
      "image",
      "with_scratch"
    ]
  },
  {
    "title": "Face To Many",
    "description": "Turn a face into 3D, emoji, pixel art, video game, claymation or toy",
    "namespace": "replicate.image.face",
    "node_type": "replicate.image.face.FaceToMany",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Fix the random seed for reproducibility",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "An image of a person to be converted",
        "min": null,
        "max": null
      },
      {
        "name": "style",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "3D",
            "Emoji",
            "Video game",
            "Pixels",
            "Clay",
            "Toy"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.face.Style"
        },
        "default": "3D",
        "title": "Style",
        "description": "Style to convert to",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "a person",
        "title": "Prompt",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Lora Scale",
        "description": "How strong the LoRA will be",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "custom_lora_url",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Custom Lora Url",
        "description": "URL to a Replicate custom LoRA. Must be in the format https://replicate.delivery/pbxt/[id]/trained_model.tar or https://pbxt.replicate.delivery/[id]/trained_model.tar",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Things you do not want in the image",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4.5,
        "title": "Prompt Strength",
        "description": "Strength of the prompt. This is the CFG scale, higher numbers lead to stronger prompt, lower numbers will keep more of a likeness to the original.",
        "min": 0.0,
        "max": 20.0
      },
      {
        "name": "denoising_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.65,
        "title": "Denoising Strength",
        "description": "How much of the original image to keep. 1 is the complete destruction of the original image, 0 is the original image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "instant_id_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Instant Id Strength",
        "description": "How strong the InstantID will be.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "control_depth_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Control Depth Strength",
        "description": "Strength of depth controlnet. The bigger this is, the more controlnet affects the output.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/583bfb50-534d-4835-a856-80bd2abb332e/mona-list-emoji.webp",
      "created_at": "2024-03-05T13:01:03.163557Z",
      "description": "Turn a face into 3D, emoji, pixel art, video game, claymation or toy",
      "github_url": "https://github.com/fofr/cog-face-to-many",
      "license_url": "https://github.com/fofr/cog-face-to-many/blob/main/weights_licenses.md",
      "name": "face-to-many",
      "owner": "fofr",
      "paper_url": null,
      "run_count": 12183237,
      "url": "https://replicate.com/fofr/face-to-many",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "image",
      "style"
    ]
  },
  {
    "title": "Become Image",
    "description": "Adapt any picture of a face into another image",
    "namespace": "replicate.image.face",
    "node_type": "replicate.image.face.BecomeImage",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Fix the random seed for reproducibility",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "An image of a person to be converted",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "a person",
        "title": "Prompt",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "image_to_become",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image To Become",
        "description": "Any image to convert the person to",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Things you do not want in the image",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Prompt Strength",
        "description": "Strength of the prompt. This is the CFG scale, higher numbers lead to stronger prompt, lower numbers will keep more of a likeness to the original.",
        "min": 0.0,
        "max": 3.0
      },
      {
        "name": "number_of_images",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Number Of Images",
        "description": "Number of images to generate",
        "min": 1.0,
        "max": 10.0
      },
      {
        "name": "denoising_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Denoising Strength",
        "description": "How much of the original image of the person to keep. 1 is the complete destruction of the original image, 0 is the original image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "instant_id_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Instant Id Strength",
        "description": "How strong the InstantID will be.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "image_to_become_noise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.3,
        "title": "Image To Become Noise",
        "description": "How much noise to add to the style image before processing. An alternative way of controlling stength.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "control_depth_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Control Depth Strength",
        "description": "Strength of depth controlnet. The bigger this is, the more controlnet affects the output.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images",
        "min": null,
        "max": null
      },
      {
        "name": "image_to_become_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.75,
        "title": "Image To Become Strength",
        "description": "How strong the style will be applied",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/b37fc7b7-0cef-4895-9176-bf5bb0cb7011/pearl-earring-1.webp",
      "created_at": "2024-03-11T11:16:22.168373Z",
      "description": "Adapt any picture of a face into another image",
      "github_url": "https://github.com/fofr/cog-become-image",
      "license_url": "https://github.com/fofr/cog-become-image/blob/main/weights_licenses.md",
      "name": "become-image",
      "owner": "fofr",
      "paper_url": null,
      "run_count": 424153,
      "url": "https://replicate.com/fofr/become-image",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "image",
      "prompt"
    ]
  },
  {
    "title": "Photo Maker",
    "description": "Create photos, paintings and avatars for anyone in any style within seconds.",
    "namespace": "replicate.image.face",
    "node_type": "replicate.image.face.PhotoMaker",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Seed. Leave blank to use a random number",
        "min": 0.0,
        "max": 2147483647.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "A photo of a person img",
        "title": "Prompt",
        "description": "Prompt. Example: 'a photo of a man/woman img'. The phrase 'img' is the trigger word.",
        "min": null,
        "max": null
      },
      {
        "name": "num_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Num Steps",
        "description": "Number of sample steps",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "style_name",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "(No style)",
            "Cinematic",
            "Disney Charactor",
            "Digital Art",
            "Photographic (Default)",
            "Fantasy art",
            "Neonpunk",
            "Enhance",
            "Comic book",
            "Lowpoly",
            "Line art"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.face.Style_name"
        },
        "default": "Photographic (Default)",
        "title": "Style Name",
        "description": "Style template. The style template will add a style-specific prompt and negative prompt to the user's prompt.",
        "min": null,
        "max": null
      },
      {
        "name": "input_image",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Input Image",
        "description": "The input image, for example a photo of your face.",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of output images",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "input_image2",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Input Image2",
        "description": "Additional input image (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "input_image3",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Input Image3",
        "description": "Additional input image (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "input_image4",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Input Image4",
        "description": "Additional input image (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5,
        "title": "Guidance Scale",
        "description": "Guidance scale. A guidance scale of 1 corresponds to doing no classifier free guidance.",
        "min": 1.0,
        "max": 10.0
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "nsfw, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry",
        "title": "Negative Prompt",
        "description": "Negative Prompt. The negative prompt should NOT contain the trigger word.",
        "min": null,
        "max": null
      },
      {
        "name": "style_strength_ratio",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Style Strength Ratio",
        "description": "Style strength (%)",
        "min": 15.0,
        "max": 50.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/c10ac3c0-f86a-4249-9f3d-d7723cc93d45/photomaker.jpg",
      "created_at": "2024-01-16T15:42:17.882162Z",
      "description": "Create photos, paintings and avatars for anyone in any style within seconds.",
      "github_url": "https://github.com/datakami-models/PhotoMaker",
      "license_url": "https://github.com/TencentARC/PhotoMaker/blob/main/LICENSE",
      "name": "photomaker",
      "owner": "tencentarc",
      "paper_url": "https://huggingface.co/papers/2312.04461",
      "run_count": 5173177,
      "url": "https://replicate.com/tencentarc/photomaker",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "prompt",
      "num_steps"
    ]
  },
  {
    "title": "Photo Maker Style",
    "description": "Create photos, paintings and avatars for anyone in any style within seconds.  (Stylization version)",
    "namespace": "replicate.image.face",
    "node_type": "replicate.image.face.PhotoMakerStyle",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Seed. Leave blank to use a random number",
        "min": 0.0,
        "max": 2147483647.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "A photo of a person img",
        "title": "Prompt",
        "description": "Prompt. Example: 'a photo of a man/woman img'. The phrase 'img' is the trigger word.",
        "min": null,
        "max": null
      },
      {
        "name": "num_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Num Steps",
        "description": "Number of sample steps",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "style_name",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "(No style)",
            "Cinematic",
            "Disney Charactor",
            "Digital Art",
            "Photographic (Default)",
            "Fantasy art",
            "Neonpunk",
            "Enhance",
            "Comic book",
            "Lowpoly",
            "Line art"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.face.Style_name"
        },
        "default": "(No style)",
        "title": "Style Name",
        "description": "Style template. The style template will add a style-specific prompt and negative prompt to the user's prompt.",
        "min": null,
        "max": null
      },
      {
        "name": "input_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Input Image",
        "description": "The input image, for example a photo of your face.",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of output images",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "input_image2",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Input Image2",
        "description": "Additional input image (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "input_image3",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Input Image3",
        "description": "Additional input image (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "input_image4",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Input Image4",
        "description": "Additional input image (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5,
        "title": "Guidance Scale",
        "description": "Guidance scale. A guidance scale of 1 corresponds to doing no classifier free guidance.",
        "min": 1.0,
        "max": 10.0
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "nsfw, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry",
        "title": "Negative Prompt",
        "description": "Negative Prompt. The negative prompt should NOT contain the trigger word.",
        "min": null,
        "max": null
      },
      {
        "name": "style_strength_ratio",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Style Strength Ratio",
        "description": "Style strength (%)",
        "min": 15.0,
        "max": 50.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/8e85a287-826f-4c21-9079-22eac106dd6b/output.0.png",
      "created_at": "2024-01-18T14:28:51.763369Z",
      "description": "Create photos, paintings and avatars for anyone in any style within seconds.  (Stylization version)",
      "github_url": "https://github.com/TencentARC/PhotoMaker",
      "license_url": "https://github.com/TencentARC/PhotoMaker/blob/main/LICENSE",
      "name": "photomaker-style",
      "owner": "tencentarc",
      "paper_url": "https://huggingface.co/papers/2312.04461",
      "run_count": 1036542,
      "url": "https://replicate.com/tencentarc/photomaker-style",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "prompt",
      "num_steps"
    ]
  },
  {
    "title": "Face To Sticker",
    "description": "Turn a face into a sticker",
    "namespace": "replicate.image.face",
    "node_type": "replicate.image.face.FaceToSticker",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Fix the random seed for reproducibility",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "An image of a person to be converted to a sticker",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Steps",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "a person",
        "title": "Prompt",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "upscale",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Upscale",
        "description": "2x upscale the sticker",
        "min": null,
        "max": null
      },
      {
        "name": "upscale_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10,
        "title": "Upscale Steps",
        "description": "Number of steps to upscale",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Things you do not want in the image",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7,
        "title": "Prompt Strength",
        "description": "Strength of the prompt. This is the CFG scale, higher numbers lead to stronger prompt, lower numbers will keep more of a likeness to the original.",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_noise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Ip Adapter Noise",
        "description": "How much noise is added to the IP adapter input",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "ip_adapter_weight",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.2,
        "title": "Ip Adapter Weight",
        "description": "How much the IP adapter will influence the image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "instant_id_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Instant Id Strength",
        "description": "How strong the InstantID will be.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/xezq/vvHSs2p5vPJtPRNW7ffCYt54fwP43r8I3kG4LPfoCCMaMBWPB/ComfyUI_00002_.png",
      "created_at": "2024-02-28T15:14:15.687345Z",
      "description": "Turn a face into a sticker",
      "github_url": "https://github.com/fofr/cog-face-to-sticker",
      "license_url": "https://github.com/fofr/cog-face-to-sticker/blob/main/weights_licenses.md",
      "name": "face-to-sticker",
      "owner": "fofr",
      "paper_url": null,
      "run_count": 1300693,
      "url": "https://replicate.com/fofr/face-to-sticker",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "image",
      "steps"
    ]
  },
  {
    "title": "Instant Id",
    "description": "Make realistic images of real people instantly",
    "namespace": "replicate.image.face",
    "node_type": "replicate.image.face.InstantId",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Leave blank to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input face image",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "a person",
        "title": "Prompt",
        "description": "Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DEISMultistepScheduler",
            "HeunDiscreteScheduler",
            "EulerDiscreteScheduler",
            "DPMSolverMultistepScheduler",
            "DPMSolverMultistepScheduler-Karras",
            "DPMSolverMultistepScheduler-Karras-SDE"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.face.Scheduler"
        },
        "default": "EulerDiscreteScheduler",
        "title": "Scheduler",
        "description": "Scheduler",
        "min": null,
        "max": null
      },
      {
        "name": "enable_lcm",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Lcm",
        "description": "Enable Fast Inference with LCM (Latent Consistency Models) - speeds up inference steps, trade-off is the quality of the generated image. Performs better with close-up portrait face images",
        "min": null,
        "max": null
      },
      {
        "name": "pose_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Pose Image",
        "description": "(Optional) reference pose image",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of images to output",
        "min": 1.0,
        "max": 8.0
      },
      {
        "name": "sdxl_weights",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "stable-diffusion-xl-base-1.0",
            "juggernaut-xl-v8",
            "afrodite-xl-v2",
            "albedobase-xl-20",
            "albedobase-xl-v13",
            "animagine-xl-30",
            "anime-art-diffusion-xl",
            "anime-illust-diffusion-xl",
            "dreamshaper-xl",
            "dynavision-xl-v0610",
            "guofeng4-xl",
            "nightvision-xl-0791",
            "omnigen-xl",
            "pony-diffusion-v6-xl",
            "protovision-xl-high-fidel",
            "RealVisXL_V3.0_Turbo",
            "RealVisXL_V4.0_Lightning"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.face.Sdxl_weights"
        },
        "default": "stable-diffusion-xl-base-1.0",
        "title": "Sdxl Weights",
        "description": "Pick which base weights you want to use",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.face.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "pose_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.4,
        "title": "Pose Strength",
        "description": "Openpose ControlNet strength, effective only if `enable_pose_controlnet` is true",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "canny_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.3,
        "title": "Canny Strength",
        "description": "Canny ControlNet strength, effective only if `enable_canny_controlnet` is true",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "depth_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Depth Strength",
        "description": "Depth ControlNet strength, effective only if `enable_depth_controlnet` is true",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Scale for classifier-free guidance",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Output Quality",
        "description": "Quality of the output images, from 0 to 100. 100 is best quality, 0 is lowest quality.",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Input Negative Prompt",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Ip Adapter Scale",
        "description": "Scale for image adapter strength (for detail)",
        "min": 0.0,
        "max": 1.5
      },
      {
        "name": "lcm_guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.5,
        "title": "Lcm Guidance Scale",
        "description": "Only used when `enable_lcm` is set to True, Scale for classifier-free guidance when using LCM",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps",
        "min": 1.0,
        "max": 500.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images",
        "min": null,
        "max": null
      },
      {
        "name": "enable_pose_controlnet",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enable Pose Controlnet",
        "description": "Enable Openpose ControlNet, overrides strength if set to false",
        "min": null,
        "max": null
      },
      {
        "name": "enhance_nonface_region",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Enhance Nonface Region",
        "description": "Enhance non-face region",
        "min": null,
        "max": null
      },
      {
        "name": "enable_canny_controlnet",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Canny Controlnet",
        "description": "Enable Canny ControlNet, overrides strength if set to false",
        "min": null,
        "max": null
      },
      {
        "name": "enable_depth_controlnet",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Enable Depth Controlnet",
        "description": "Enable Depth ControlNet, overrides strength if set to false",
        "min": null,
        "max": null
      },
      {
        "name": "lcm_num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5,
        "title": "Lcm Num Inference Steps",
        "description": "Only used when `enable_lcm` is set to True, Number of denoising steps when using LCM",
        "min": 1.0,
        "max": 10.0
      },
      {
        "name": "face_detection_input_width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 640,
        "title": "Face Detection Input Width",
        "description": "Width of the input image for face detection",
        "min": 640.0,
        "max": 4096.0
      },
      {
        "name": "face_detection_input_height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 640,
        "title": "Face Detection Input Height",
        "description": "Height of the input image for face detection",
        "min": 640.0,
        "max": 4096.0
      },
      {
        "name": "controlnet_conditioning_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Controlnet Conditioning Scale",
        "description": "Scale for IdentityNet strength (for fidelity)",
        "min": 0.0,
        "max": 1.5
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/3bb0b275-5996-4382-b73f-5bccfbddde92/instantidcover.jpg",
      "created_at": "2024-01-22T21:00:49.120905Z",
      "description": "Make realistic images of real people instantly",
      "github_url": "https://github.com/zsxkib/InstantID",
      "license_url": "https://github.com/zsxkib/InstantID/blob/main/LICENSE",
      "name": "instant-id",
      "owner": "zsxkib",
      "paper_url": "https://arxiv.org/abs/2401.07519",
      "run_count": 751782,
      "url": "https://replicate.com/zsxkib/instant-id",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "image",
      "prompt"
    ]
  },
  {
    "title": "Instant ID Photorealistic",
    "description": "InstantID : Zero-shot Identity-Preserving Generation in Seconds. Using Juggernaut-XL v8 as the base model to encourage photorealism",
    "namespace": "replicate.image.face",
    "node_type": "replicate.image.face.Instant_ID_Photorealistic",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 640,
        "title": "Width",
        "description": "Width of output image",
        "min": 512.0,
        "max": 2048.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 640,
        "title": "Height",
        "description": "Height of output image",
        "min": 512.0,
        "max": 2048.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "analog film photo of a man. faded film, desaturated, 35mm photo, grainy, vignette, vintage, Kodachrome, Lomography, stained, highly detailed, found footage, masterpiece, best quality",
        "title": "Prompt",
        "description": "Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5,
        "title": "Guidance Scale",
        "description": "Scale for classifier-free guidance",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Input Negative Prompt",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Ip Adapter Scale",
        "description": "Scale for IP adapter",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps",
        "min": 1.0,
        "max": 500.0
      },
      {
        "name": "controlnet_conditioning_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Controlnet Conditioning Scale",
        "description": "Scale for ControlNet conditioning",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/0c6bd74f-6129-4323-8125-beb65871a8de/Screenshot_2024-01-24_at_15.24.13.png",
      "created_at": "2024-01-24T07:43:55.954510Z",
      "description": "InstantID : Zero-shot Identity-Preserving Generation in Seconds. Using Juggernaut-XL v8 as the base model to encourage photorealism",
      "github_url": "https://github.com/GrandlineAI/InstantID",
      "license_url": "https://github.com/InstantID/InstantID/blob/main/LICENSE",
      "name": "instant-id-photorealistic",
      "owner": "grandlineai",
      "paper_url": null,
      "run_count": 31760,
      "url": "https://replicate.com/grandlineai/instant-id-photorealistic",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "image",
      "width",
      "height"
    ]
  },
  {
    "title": "Instant ID Artistic",
    "description": "InstantID : Zero-shot Identity-Preserving Generation in Seconds. Using Dreamshaper-XL as the base model to encourage artistic generations",
    "namespace": "replicate.image.face",
    "node_type": "replicate.image.face.Instant_ID_Artistic",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 640,
        "title": "Width",
        "description": "Width of output image",
        "min": 512.0,
        "max": 2048.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 640,
        "title": "Height",
        "description": "Height of output image",
        "min": 512.0,
        "max": 2048.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "analog film photo of a man. faded film, desaturated, 35mm photo, grainy, vignette, vintage, Kodachrome, Lomography, stained, highly detailed, found footage, masterpiece, best quality",
        "title": "Prompt",
        "description": "Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5,
        "title": "Guidance Scale",
        "description": "Scale for classifier-free guidance",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Input Negative Prompt",
        "min": null,
        "max": null
      },
      {
        "name": "ip_adapter_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Ip Adapter Scale",
        "description": "Scale for IP adapter",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps",
        "min": 1.0,
        "max": 500.0
      },
      {
        "name": "controlnet_conditioning_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Controlnet Conditioning Scale",
        "description": "Scale for ControlNet conditioning",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/87b24249-b2c1-43f3-b3cf-a5005f23b21c/Screenshot_2024-01-24_at_15.24.13.png",
      "created_at": "2024-01-24T04:34:52.345779Z",
      "description": "InstantID : Zero-shot Identity-Preserving Generation in Seconds. Using Dreamshaper-XL as the base model to encourage artistic generations",
      "github_url": "https://github.com/GrandlineAI/InstantID",
      "license_url": "https://github.com/InstantID/InstantID/blob/main/LICENSE",
      "name": "instant-id-artistic",
      "owner": "grandlineai",
      "paper_url": null,
      "run_count": 2176,
      "url": "https://replicate.com/grandlineai/instant-id-artistic",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "image",
      "width",
      "height"
    ]
  },
  {
    "title": "Ad Inpaint",
    "description": "Product advertising image generator",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.AdInpaint",
    "layout": "default",
    "properties": [
      {
        "name": "pixel",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "512 * 512",
            "768 * 768",
            "1024 * 1024"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Pixel"
        },
        "default": "512 * 512",
        "title": "Pixel",
        "description": "image total pixel",
        "min": null,
        "max": null
      },
      {
        "name": "scale",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Scale",
        "description": "Factor to scale image by (maximum: 4)",
        "min": 0.0,
        "max": 4.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Product name or prompt",
        "min": null,
        "max": null
      },
      {
        "name": "image_num",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Image Num",
        "description": "Number of image to generate",
        "min": 0.0,
        "max": 4.0
      },
      {
        "name": "image_path",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image Path",
        "description": "input image",
        "min": null,
        "max": null
      },
      {
        "name": "manual_seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Manual Seed",
        "description": "Manual Seed",
        "min": null,
        "max": null
      },
      {
        "name": "product_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "Original",
            "0.6 * width",
            "0.5 * width",
            "0.4 * width",
            "0.3 * width",
            "0.2 * width"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Product_size"
        },
        "default": "Original",
        "title": "Product Size",
        "description": "Max product size",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Guidance Scale",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "low quality, out of frame, illustration, 3d, sepia, painting, cartoons, sketch, watermark, text, Logo, advertisement",
        "title": "Negative Prompt",
        "description": "Anything you don't want in the photo",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Num Inference Steps",
        "description": "Inference Steps",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/e21a425b-4cdb-445b-8b2f-5be1b26fb78d/ad_inpaint_2.jpg",
      "created_at": "2023-04-03T11:25:28.290524Z",
      "description": "Product advertising image generator",
      "github_url": null,
      "license_url": null,
      "name": "ad-inpaint",
      "owner": "logerzhu",
      "paper_url": null,
      "run_count": 487959,
      "url": "https://replicate.com/logerzhu/ad-inpaint",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "pixel",
      "scale",
      "prompt"
    ]
  },
  {
    "title": "Consistent Character",
    "description": "Create images of a given character in different poses",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.ConsistentCharacter",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Set a seed for reproducibility. Random by default.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "A headshot photo",
        "title": "Prompt",
        "description": "Describe the subject. Include clothes and hairstyle for more consistency.",
        "min": null,
        "max": null
      },
      {
        "name": "subject",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Subject",
        "description": "An image of a person. Best images are square close ups of a face, but they do not have to be.",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Output Quality",
        "description": "Quality of the output images, from 0 to 100. 100 is best quality, 0 is lowest quality.",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Things you do not want to see in your image",
        "min": null,
        "max": null
      },
      {
        "name": "randomise_poses",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Randomise Poses",
        "description": "Randomise the poses used.",
        "min": null,
        "max": null
      },
      {
        "name": "number_of_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Number Of Outputs",
        "description": "The number of images to generate.",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images.",
        "min": null,
        "max": null
      },
      {
        "name": "number_of_images_per_pose",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Number Of Images Per Pose",
        "description": "The number of images to generate for each pose.",
        "min": 1.0,
        "max": 4.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/xezq/TOVBIdLIP6rPLdn4HUtnZHyvHwBAaXzCNUWenllOPD8hBw6JA/ComfyUI_00005_.webp",
      "created_at": "2024-05-30T16:48:52.345721Z",
      "description": "Create images of a given character in different poses",
      "github_url": "https://github.com/fofr/cog-consistent-character",
      "license_url": "https://github.com/fofr/cog-consistent-character/blob/main/LICENSE",
      "name": "consistent-character",
      "owner": "fofr",
      "paper_url": null,
      "run_count": 790161,
      "url": "https://replicate.com/fofr/consistent-character",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "prompt",
      "subject"
    ]
  },
  {
    "title": "Pulid Base",
    "description": "Use a face to make images. Uses SDXL fine-tuned checkpoints.",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.PulidBase",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Set a seed for reproducibility. Random by default.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "Width of the output image (ignored if structure image given)",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "Height of the output image (ignored if structure image given)",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "A photo of a person",
        "title": "Prompt",
        "description": "You might need to include a gender in the prompt to get the desired result",
        "min": null,
        "max": null
      },
      {
        "name": "face_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Face Image",
        "description": "The face image to use for the generation",
        "min": null,
        "max": null
      },
      {
        "name": "face_style",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "high-fidelity",
            "stylized"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Face_style"
        },
        "default": "high-fidelity",
        "title": "Face Style",
        "description": "Style of the face",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Output Quality",
        "description": "Quality of the output images, from 0 to 100. 100 is best quality, 0 is lowest quality.",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Things you do not want to see in your image",
        "min": null,
        "max": null
      },
      {
        "name": "checkpoint_model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "general - albedobaseXL_v21",
            "general - dreamshaperXL_alpha2Xl10",
            "animated - starlightXLAnimated_v3",
            "animated - pixlAnimeCartoonComic_v10",
            "realistic - rundiffusionXL_beta",
            "realistic - RealVisXL_V4.0",
            "realistic - sdxlUnstableDiffusers_nihilmania",
            "cinematic - CinematicRedmond"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Checkpoint_model"
        },
        "default": "general - dreamshaperXL_alpha2Xl10",
        "title": "Checkpoint Model",
        "description": "Model to use for the generation",
        "min": null,
        "max": null
      },
      {
        "name": "number_of_images",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Number Of Images",
        "description": "Number of images to generate",
        "min": 1.0,
        "max": 10.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/fb4110a1-ae64-491f-8a3e-0fdd4ef991bb/pulid-base-cover.webp",
      "created_at": "2024-05-09T13:48:08.359715Z",
      "description": "Use a face to make images. Uses SDXL fine-tuned checkpoints.",
      "github_url": "https://github.com/fofr/cog-comfyui-pulid/tree/pulid-base",
      "license_url": null,
      "name": "pulid-base",
      "owner": "fofr",
      "paper_url": "https://arxiv.org/abs/2404.16022",
      "run_count": 147906,
      "url": "https://replicate.com/fofr/pulid-base",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "width",
      "height"
    ]
  },
  {
    "title": "Stable Diffusion",
    "description": "A latent text-to-image diffusion model capable of generating photo-realistic images given any text input",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.StableDiffusion",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Leave blank to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            64,
            128,
            192,
            256,
            320,
            384,
            448,
            512,
            576,
            640,
            704,
            768,
            832,
            896,
            960,
            1024
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Width"
        },
        "default": 768,
        "title": "Width",
        "description": "Width of generated image in pixels. Needs to be a multiple of 64",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            64,
            128,
            192,
            256,
            320,
            384,
            448,
            512,
            576,
            640,
            704,
            768,
            832,
            896,
            960,
            1024
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Height"
        },
        "default": 768,
        "title": "Height",
        "description": "Height of generated image in pixels. Needs to be a multiple of 64",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "a vision of paradise. unreal engine",
        "title": "Prompt",
        "description": "Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DDIM",
            "K_EULER",
            "DPMSolverMultistep",
            "K_EULER_ANCESTRAL",
            "PNDM",
            "KLMS"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Scheduler"
        },
        "default": "DPMSolverMultistep",
        "title": "Scheduler",
        "description": "Choose a scheduler.",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of images to generate.",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Scale for classifier-free guidance",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Negative Prompt",
        "description": "Specify things to not see in the output",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps",
        "min": 1.0,
        "max": 500.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/710f5e9f-9561-4e4f-9d1e-614205f62597/stable-diffusion.webp",
      "created_at": "2022-08-22T21:37:08.396208Z",
      "description": "A latent text-to-image diffusion model capable of generating photo-realistic images given any text input",
      "github_url": "https://github.com/replicate/cog-stable-diffusion",
      "license_url": "https://huggingface.co/spaces/CompVis/stable-diffusion-license",
      "name": "stable-diffusion",
      "owner": "stability-ai",
      "paper_url": "https://arxiv.org/abs/2112.10752",
      "run_count": 109891771,
      "url": "https://replicate.com/stability-ai/stable-diffusion",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "width",
      "height"
    ]
  },
  {
    "title": "Stable Diffusion 3 5 Medium",
    "description": "2.5 billion parameter image model with improved MMDiT-X architecture",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.StableDiffusion3_5_Medium",
    "layout": "default",
    "properties": [
      {
        "name": "cfg",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 5,
        "title": "Cfg",
        "description": "The guidance scale tells the model how similar the output should be to the prompt.",
        "min": 0.0,
        "max": 20.0
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Set a seed for reproducibility. Random by default.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image for image to image mode. The aspect ratio of your output will match this image.",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 40,
        "title": "Steps",
        "description": "Number of steps to run the sampler for.",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "Text prompt for image generation",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1:1",
            "16:9",
            "21:9",
            "3:2",
            "2:3",
            "4:5",
            "5:4",
            "3:4",
            "4:3",
            "9:16",
            "9:21"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Aspect_ratio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "The aspect ratio of your output image. This value is ignored if you are using an input image.",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 90,
        "title": "Output Quality",
        "description": "Quality of the output images, from 0 to 100. 100 is best quality, 0 is lowest quality.",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.85,
        "title": "Prompt Strength",
        "description": "Prompt strength (or denoising strength) when using image to image. 1.0 corresponds to full destruction of information in image.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/d65fc397-135b-4976-a84d-12980ab2c0bc/replicate-prediction-_4kWPYZu.webp",
      "created_at": "2024-10-29T12:55:45.899504Z",
      "description": "2.5 billion parameter image model with improved MMDiT-X architecture",
      "github_url": null,
      "license_url": "https://huggingface.co/stabilityai/stable-diffusion-3.5-medium/blob/main/LICENSE.md",
      "name": "stable-diffusion-3.5-medium",
      "owner": "stability-ai",
      "paper_url": "https://arxiv.org/abs/2403.03206",
      "run_count": 10311,
      "url": "https://replicate.com/stability-ai/stable-diffusion-3.5-medium",
      "visibility": "public",
      "weights_url": "https://huggingface.co/stabilityai/stable-diffusion-3.5-medium"
    },
    "recommended_models": [],
    "basic_fields": [
      "cfg",
      "seed",
      "image"
    ]
  },
  {
    "title": "Stable Diffusion 3 5 Large",
    "description": "A text-to-image model that generates high-resolution images with fine details. It supports various artistic styles and produces diverse outputs from the same prompt, thanks to Query-Key Normalization.",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.StableDiffusion3_5_Large",
    "layout": "default",
    "properties": [
      {
        "name": "cfg",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Cfg",
        "description": "The guidance scale tells the model how similar the output should be to the prompt.",
        "min": 0.0,
        "max": 20.0
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Set a seed for reproducibility. Random by default.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image for image to image mode. The aspect ratio of your output will match this image.",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 35,
        "title": "Steps",
        "description": "Number of steps to run the sampler for.",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "Text prompt for image generation",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1:1",
            "16:9",
            "21:9",
            "3:2",
            "2:3",
            "4:5",
            "5:4",
            "3:4",
            "4:3",
            "9:16",
            "9:21"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Aspect_ratio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "The aspect ratio of your output image. This value is ignored if you are using an input image.",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 90,
        "title": "Output Quality",
        "description": "Quality of the output images, from 0 to 100. 100 is best quality, 0 is lowest quality.",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.85,
        "title": "Prompt Strength",
        "description": "Prompt strength (or denoising strength) when using image to image. 1.0 corresponds to full destruction of information in image.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/4b03d178-eaf3-4458-a752-dbc76098396b/replicate-prediction-_ycGb1jN.webp",
      "created_at": "2024-10-21T20:53:39.435334Z",
      "description": "A text-to-image model that generates high-resolution images with fine details. It supports various artistic styles and produces diverse outputs from the same prompt, thanks to Query-Key Normalization.",
      "github_url": null,
      "license_url": "https://huggingface.co/stabilityai/stable-diffusion-3.5-large/blob/main/LICENSE.md",
      "name": "stable-diffusion-3.5-large",
      "owner": "stability-ai",
      "paper_url": "https://arxiv.org/abs/2403.03206",
      "run_count": 315059,
      "url": "https://replicate.com/stability-ai/stable-diffusion-3.5-large",
      "visibility": "public",
      "weights_url": "https://huggingface.co/stabilityai/stable-diffusion-3.5-large"
    },
    "recommended_models": [],
    "basic_fields": [
      "cfg",
      "seed",
      "image"
    ]
  },
  {
    "title": "Stable Diffusion 3 5 Large Turbo",
    "description": "A text-to-image model that generates high-resolution images with fine details. It supports various artistic styles and produces diverse outputs from the same prompt, with a focus on fewer inference steps",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.StableDiffusion3_5_Large_Turbo",
    "layout": "default",
    "properties": [
      {
        "name": "cfg",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Cfg",
        "description": "The guidance scale tells the model how similar the output should be to the prompt.",
        "min": 0.0,
        "max": 20.0
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Set a seed for reproducibility. Random by default.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image for image to image mode. The aspect ratio of your output will match this image.",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Steps",
        "description": "Number of steps to run the sampler for.",
        "min": 1.0,
        "max": 10.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "Text prompt for image generation",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1:1",
            "16:9",
            "21:9",
            "3:2",
            "2:3",
            "4:5",
            "5:4",
            "3:4",
            "4:3",
            "9:16",
            "9:21"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Aspect_ratio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "The aspect ratio of your output image. This value is ignored if you are using an input image.",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 90,
        "title": "Output Quality",
        "description": "Quality of the output images, from 0 to 100. 100 is best quality, 0 is lowest quality.",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.85,
        "title": "Prompt Strength",
        "description": "Prompt strength (or denoising strength) when using image to image. 1.0 corresponds to full destruction of information in image.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/9e1b4258-22bd-4a59-ba4a-ecac220a8a9b/replicate-prediction-_WU4XtaV.webp",
      "created_at": "2024-10-22T12:09:38.705615Z",
      "description": "A text-to-image model that generates high-resolution images with fine details. It supports various artistic styles and produces diverse outputs from the same prompt, with a focus on fewer inference steps",
      "github_url": null,
      "license_url": "https://huggingface.co/stabilityai/stable-diffusion-3.5-large-turbo/blob/main/LICENSE.md",
      "name": "stable-diffusion-3.5-large-turbo",
      "owner": "stability-ai",
      "paper_url": "https://arxiv.org/abs/2403.03206",
      "run_count": 27531,
      "url": "https://replicate.com/stability-ai/stable-diffusion-3.5-large-turbo",
      "visibility": "public",
      "weights_url": "https://huggingface.co/stabilityai/stable-diffusion-3.5-large-turbo"
    },
    "recommended_models": [],
    "basic_fields": [
      "cfg",
      "seed",
      "image"
    ]
  },
  {
    "title": "Photon Flash",
    "description": "Accelerated variant of Photon prioritizing speed while maintaining quality",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Photon_Flash",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Text prompt for image generation",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1:1",
            "3:4",
            "4:3",
            "9:16",
            "16:9",
            "9:21",
            "21:9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Aspect_ratio"
        },
        "default": "16:9",
        "title": "Aspect Ratio",
        "description": "Aspect ratio of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "image_reference_url",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image Reference Url",
        "description": "URL of a reference image to guide generation",
        "min": null,
        "max": null
      },
      {
        "name": "style_reference_url",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Style Reference Url",
        "description": "URL of a style reference image",
        "min": null,
        "max": null
      },
      {
        "name": "image_reference_weight",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.85,
        "title": "Image Reference Weight",
        "description": "Weight of the reference image. Larger values will make the reference image have a stronger influence on the generated image.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "style_reference_weight",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.85,
        "title": "Style Reference Weight",
        "description": "Weight of the style reference image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "character_reference_url",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Character Reference Url",
        "description": "URL of a character reference image",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/8459f7e9-7445-4046-82aa-917a0f561b80/tmpyf9dx02r.webp",
      "created_at": "2024-12-05T15:18:04.364421Z",
      "description": "Accelerated variant of Photon prioritizing speed while maintaining quality",
      "github_url": null,
      "license_url": "https://lumalabs.ai/dream-machine/api/terms",
      "name": "photon-flash",
      "owner": "luma",
      "paper_url": null,
      "run_count": 15471,
      "url": "https://replicate.com/luma/photon-flash",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "prompt",
      "aspect_ratio"
    ]
  },
  {
    "title": "Stable Diffusion XL",
    "description": "A text-to-image generative AI model that creates beautiful images",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.StableDiffusionXL",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask",
        "description": "Input mask for inpaint mode. Black areas will be preserved, white areas will be inpainted.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Leave blank to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image for img2img or inpaint mode",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "Width of output image",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "Height of output image",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "An astronaut riding a rainbow unicorn",
        "title": "Prompt",
        "description": "Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "refine",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "no_refiner",
            "expert_ensemble_refiner",
            "base_image_refiner"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Refine"
        },
        "default": "no_refiner",
        "title": "Refine",
        "description": "Which refine style to use",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DDIM",
            "DPMSolverMultistep",
            "HeunDiscrete",
            "KarrasDPM",
            "K_EULER_ANCESTRAL",
            "K_EULER",
            "PNDM"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Scheduler"
        },
        "default": "K_EULER",
        "title": "Scheduler",
        "description": "scheduler",
        "min": null,
        "max": null
      },
      {
        "name": "lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.6,
        "title": "Lora Scale",
        "description": "LoRA additive scale. Only applicable on trained models.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of images to output.",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "refine_steps",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Refine Steps",
        "description": "For base_image_refiner, the number of steps to refine, defaults to num_inference_steps",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Scale for classifier-free guidance",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "apply_watermark",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Apply Watermark",
        "description": "Applies a watermark to enable determining if an image is generated in downstream applications. If you have other provisions for generating or deploying images safely, you can use this to disable watermarking.",
        "min": null,
        "max": null
      },
      {
        "name": "high_noise_frac",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "High Noise Frac",
        "description": "For expert_ensemble_refiner, the fraction of noise to use",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Input Negative Prompt",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Prompt Strength",
        "description": "Prompt strength when using img2img / inpaint. 1.0 corresponds to full destruction of information in image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "replicate_weights",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Replicate Weights",
        "description": "Replicate LoRA weights to use. Leave blank to use the default weights.",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps",
        "min": 1.0,
        "max": 500.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images. This feature is only available through the API. See [https://replicate.com/docs/how-does-replicate-work#safety](https://replicate.com/docs/how-does-replicate-work#safety)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/9065f9e3-40da-4742-8cb8-adfa8e794c0d/sdxl_cover.jpg",
      "created_at": "2023-07-26T17:53:09.882651Z",
      "description": "A text-to-image generative AI model that creates beautiful images",
      "github_url": "https://github.com/replicate/cog-sdxl",
      "license_url": "https://github.com/Stability-AI/generative-models/blob/main/model_licenses/LICENSE-SDXL1.0",
      "name": "sdxl",
      "owner": "stability-ai",
      "paper_url": "https://arxiv.org/abs/2307.01952",
      "run_count": 73507016,
      "url": "https://replicate.com/stability-ai/sdxl",
      "visibility": "public",
      "weights_url": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0"
    },
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "seed",
      "image"
    ]
  },
  {
    "title": "SDXL Pixar",
    "description": "Create Pixar poster easily with SDXL Pixar.",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.SDXL_Pixar",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask",
        "description": "Input mask for inpaint mode. Black areas will be preserved, white areas will be inpainted.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Leave blank to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image for img2img or inpaint mode",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "Width of output image",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "Height of output image",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "An astronaut riding a rainbow unicorn",
        "title": "Prompt",
        "description": "Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "refine",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "no_refiner",
            "expert_ensemble_refiner",
            "base_image_refiner"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Refine"
        },
        "default": "no_refiner",
        "title": "Refine",
        "description": "Which refine style to use",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DDIM",
            "DPMSolverMultistep",
            "HeunDiscrete",
            "KarrasDPM",
            "K_EULER_ANCESTRAL",
            "K_EULER",
            "PNDM"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Scheduler"
        },
        "default": "K_EULER",
        "title": "Scheduler",
        "description": "scheduler",
        "min": null,
        "max": null
      },
      {
        "name": "lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.6,
        "title": "Lora Scale",
        "description": "LoRA additive scale. Only applicable on trained models.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of images to output.",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "refine_steps",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Refine Steps",
        "description": "For base_image_refiner, the number of steps to refine, defaults to num_inference_steps",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Scale for classifier-free guidance",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "apply_watermark",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Apply Watermark",
        "description": "Applies a watermark to enable determining if an image is generated in downstream applications. If you have other provisions for generating or deploying images safely, you can use this to disable watermarking.",
        "min": null,
        "max": null
      },
      {
        "name": "high_noise_frac",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "High Noise Frac",
        "description": "For expert_ensemble_refiner, the fraction of noise to use",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Input Negative Prompt",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Prompt Strength",
        "description": "Prompt strength when using img2img / inpaint. 1.0 corresponds to full destruction of information in image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "replicate_weights",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Replicate Weights",
        "description": "Replicate LoRA weights to use. Leave blank to use the default weights.",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps",
        "min": 1.0,
        "max": 500.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images. This feature is only available through the API. See https://replicate.com/docs/how-does-replicate-work#safety",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/68125b17-60d7-4949-8984-0d50d736a623/out-0_5.png",
      "created_at": "2023-10-21T10:32:49.911227Z",
      "description": "Create Pixar poster easily with SDXL Pixar.",
      "github_url": null,
      "license_url": null,
      "name": "sdxl-pixar",
      "owner": "swartype",
      "paper_url": null,
      "run_count": 620430,
      "url": "https://replicate.com/swartype/sdxl-pixar",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "seed",
      "image"
    ]
  },
  {
    "title": "SDXL Emoji",
    "description": "An SDXL fine-tune based on Apple Emojis",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.SDXL_Emoji",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask",
        "description": "Input mask for inpaint mode. Black areas will be preserved, white areas will be inpainted.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Leave blank to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image for img2img or inpaint mode",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "Width of output image",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "Height of output image",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "An astronaut riding a rainbow unicorn",
        "title": "Prompt",
        "description": "Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "refine",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "no_refiner",
            "expert_ensemble_refiner",
            "base_image_refiner"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Refine"
        },
        "default": "no_refiner",
        "title": "Refine",
        "description": "Which refine style to use",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DDIM",
            "DPMSolverMultistep",
            "HeunDiscrete",
            "KarrasDPM",
            "K_EULER_ANCESTRAL",
            "K_EULER",
            "PNDM"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Scheduler"
        },
        "default": "K_EULER",
        "title": "Scheduler",
        "description": "scheduler",
        "min": null,
        "max": null
      },
      {
        "name": "lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.6,
        "title": "Lora Scale",
        "description": "LoRA additive scale. Only applicable on trained models.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of images to output.",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "refine_steps",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Refine Steps",
        "description": "For base_image_refiner, the number of steps to refine, defaults to num_inference_steps",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Scale for classifier-free guidance",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "apply_watermark",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Apply Watermark",
        "description": "Applies a watermark to enable determining if an image is generated in downstream applications. If you have other provisions for generating or deploying images safely, you can use this to disable watermarking.",
        "min": null,
        "max": null
      },
      {
        "name": "high_noise_frac",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "High Noise Frac",
        "description": "For expert_ensemble_refiner, the fraction of noise to use",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Input Negative Prompt",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Prompt Strength",
        "description": "Prompt strength when using img2img / inpaint. 1.0 corresponds to full destruction of information in image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "replicate_weights",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Replicate Weights",
        "description": "Replicate LoRA weights to use. Leave blank to use the default weights.",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps",
        "min": 1.0,
        "max": 500.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images. This feature is only available through the API. See https://replicate.com/docs/how-does-replicate-work#safety",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/8629c6ba-b94c-4cbd-93aa-bda2b8ebecd9/F5Mg2KeXgAAkfre.jpg",
      "created_at": "2023-09-04T09:18:11.028708Z",
      "description": "An SDXL fine-tune based on Apple Emojis",
      "github_url": null,
      "license_url": null,
      "name": "sdxl-emoji",
      "owner": "fofr",
      "paper_url": null,
      "run_count": 8427919,
      "url": "https://replicate.com/fofr/sdxl-emoji",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "seed",
      "image"
    ]
  },
  {
    "title": "Stable Diffusion Inpainting",
    "description": "Fill in masked parts of images with Stable Diffusion",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.StableDiffusionInpainting",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask",
        "description": "Black and white image to use as mask for inpainting over the image provided. White pixels are inpainted and black pixels are preserved.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Leave blank to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Initial image to generate variations of. Will be resized to height x width",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            64,
            128,
            192,
            256,
            320,
            384,
            448,
            512,
            576,
            640,
            704,
            768,
            832,
            896,
            960,
            1024
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Width"
        },
        "default": 512,
        "title": "Width",
        "description": "Width of generated image in pixels. Needs to be a multiple of 64",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            64,
            128,
            192,
            256,
            320,
            384,
            448,
            512,
            576,
            640,
            704,
            768,
            832,
            896,
            960,
            1024
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Height"
        },
        "default": 512,
        "title": "Height",
        "description": "Height of generated image in pixels. Needs to be a multiple of 64",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "a vision of paradise. unreal engine",
        "title": "Prompt",
        "description": "Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DDIM",
            "K_EULER",
            "DPMSolverMultistep",
            "K_EULER_ANCESTRAL",
            "PNDM",
            "KLMS"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Scheduler"
        },
        "default": "DPMSolverMultistep",
        "title": "Scheduler",
        "description": "Choose a scheduler.",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of images to generate.",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Scale for classifier-free guidance",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Negative Prompt",
        "description": "Specify things to not see in the output",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps",
        "min": 1.0,
        "max": 500.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images. This feature is only available through the API. See [https://replicate.com/docs/how-does-replicate-work#safety](https://replicate.com/docs/how-does-replicate-work#safety)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/pbxt/xs0pPOUM6HKmPlJJBXqKfE1YsiMzgNsCuGedlX0VqvPYifLgA/out-0.png",
      "created_at": "2022-12-02T17:40:01.152489Z",
      "description": "Fill in masked parts of images with Stable Diffusion",
      "github_url": "https://github.com/replicate/cog-stable-diffusion-inpainting",
      "license_url": "https://huggingface.co/stabilityai/stable-diffusion-2/blob/main/LICENSE-MODEL",
      "name": "stable-diffusion-inpainting",
      "owner": "stability-ai",
      "paper_url": null,
      "run_count": 18918277,
      "url": "https://replicate.com/stability-ai/stable-diffusion-inpainting",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "seed",
      "image"
    ]
  },
  {
    "title": "Kandinsky 2 2",
    "description": "multilingual text2image latent diffusion model",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Kandinsky_2_2",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Leave blank to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            384,
            512,
            576,
            640,
            704,
            768,
            960,
            1024,
            1152,
            1280,
            1536,
            1792,
            2048
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Width"
        },
        "default": 512,
        "title": "Width",
        "description": "Width of output image. Lower the setting if hits memory limits.",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            384,
            512,
            576,
            640,
            704,
            768,
            960,
            1024,
            1152,
            1280,
            1536,
            1792,
            2048
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Height"
        },
        "default": 512,
        "title": "Height",
        "description": "Height of output image. Lower the setting if hits memory limits.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "A moss covered astronaut with a black background",
        "title": "Prompt",
        "description": "Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of images to output.",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpeg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Output image format",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Negative Prompt",
        "description": "Specify things to not see in the output",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 75,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps",
        "min": 1.0,
        "max": 500.0
      },
      {
        "name": "num_inference_steps_prior",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Inference Steps Prior",
        "description": "Number of denoising steps for priors",
        "min": 1.0,
        "max": 500.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/618e68d3-fba3-4fd0-a060-cdd46b2ab7cf/out-0_2.jpg",
      "created_at": "2023-07-12T21:53:29.439515Z",
      "description": "multilingual text2image latent diffusion model",
      "github_url": "https://github.com/chenxwh/Kandinsky-2/tree/v2.2",
      "license_url": "https://github.com/ai-forever/Kandinsky-2/blob/main/license",
      "name": "kandinsky-2.2",
      "owner": "ai-forever",
      "paper_url": null,
      "run_count": 10011590,
      "url": "https://replicate.com/ai-forever/kandinsky-2.2",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "width",
      "height"
    ]
  },
  {
    "title": "Flux Schnell",
    "description": "The fastest image generation model tailored for local development and personal use",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Flux_Schnell",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Prompt for generated image",
        "min": null,
        "max": null
      },
      {
        "name": "go_fast",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Go Fast",
        "description": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
        "min": null,
        "max": null
      },
      {
        "name": "megapixels",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1",
            "0.25"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Megapixels"
        },
        "default": "1",
        "title": "Megapixels",
        "description": "Approximate number of megapixels for generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of outputs to generate",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1:1",
            "16:9",
            "21:9",
            "3:2",
            "2:3",
            "4:5",
            "5:4",
            "3:4",
            "4:3",
            "9:16",
            "9:21"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Aspect_ratio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "Aspect ratio for the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Output Quality",
        "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. 4 is recommended, and lower number of steps produce lower quality outputs, faster.",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/67c990ba-bb67-4355-822f-2bd8c42b2f0d/flux-schnell.webp",
      "created_at": "2024-07-30T00:32:11.473557Z",
      "description": "The fastest image generation model tailored for local development and personal use",
      "github_url": "https://github.com/replicate/cog-flux",
      "license_url": "https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-schnell",
      "name": "flux-schnell",
      "owner": "black-forest-labs",
      "paper_url": null,
      "run_count": 187622281,
      "url": "https://replicate.com/black-forest-labs/flux-schnell",
      "visibility": "public",
      "weights_url": "https://huggingface.co/black-forest-labs/FLUX.1-schnell"
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "prompt",
      "go_fast"
    ]
  },
  {
    "title": "Flux Dev",
    "description": "A 12 billion parameter rectified flow transformer capable of generating images from text descriptions",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Flux_Dev",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Image",
        "description": "Input image for image to image mode. The aspect ratio of your output will match this image",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Prompt for generated image",
        "min": null,
        "max": null
      },
      {
        "name": "go_fast",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Go Fast",
        "description": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
        "min": null,
        "max": null
      },
      {
        "name": "guidance",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Guidance",
        "description": "Guidance for generated image",
        "min": 0.0,
        "max": 10.0
      },
      {
        "name": "megapixels",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1",
            "0.25"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Megapixels"
        },
        "default": "1",
        "title": "Megapixels",
        "description": "Approximate number of megapixels for generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of outputs to generate",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1:1",
            "16:9",
            "21:9",
            "3:2",
            "2:3",
            "4:5",
            "5:4",
            "3:4",
            "4:3",
            "9:16",
            "9:21"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Aspect_ratio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "Aspect ratio for the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Output Quality",
        "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Prompt Strength",
        "description": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. Recommended range is 28-50, and lower number of steps produce lower quality outputs, faster.",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/cb4203e5-9ece-42e7-b326-98ff3fa35c3a/Replicate_Prediction_15.webp",
      "created_at": "2024-07-29T23:25:06.100855Z",
      "description": "A 12 billion parameter rectified flow transformer capable of generating images from text descriptions",
      "github_url": "https://github.com/replicate/cog-flux",
      "license_url": "https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-dev",
      "name": "flux-dev",
      "owner": "black-forest-labs",
      "paper_url": null,
      "run_count": 8321235,
      "url": "https://replicate.com/black-forest-labs/flux-dev",
      "visibility": "public",
      "weights_url": "https://huggingface.co/black-forest-labs/FLUX.1-dev"
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "image",
      "prompt"
    ]
  },
  {
    "title": "Flux Pro",
    "description": "State-of-the-art image generation with top of the line prompt following, visual quality, image detail and output diversity.",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Flux_Pro",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Steps",
        "description": "Number of diffusion steps",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "width",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Width",
        "description": "Width of the generated image in text-to-image mode. Only used when aspect_ratio=custom. Must be a multiple of 32 (if it's not, it will be rounded to nearest multiple of 32). Note: Ignored in img2img and inpainting modes.",
        "min": 256.0,
        "max": 1440.0
      },
      {
        "name": "height",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Height",
        "description": "Height of the generated image in text-to-image mode. Only used when aspect_ratio=custom. Must be a multiple of 32 (if it's not, it will be rounded to nearest multiple of 32). Note: Ignored in img2img and inpainting modes.",
        "min": 256.0,
        "max": 1440.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Text prompt for image generation",
        "min": null,
        "max": null
      },
      {
        "name": "guidance",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Guidance",
        "description": "Controls the balance between adherence to the text prompt and image quality/diversity. Higher values make the output more closely match the prompt but may reduce overall image quality. Lower values allow for more creative freedom but might produce results less relevant to the prompt.",
        "min": 2.0,
        "max": 5.0
      },
      {
        "name": "interval",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Interval",
        "description": "Interval is a setting that increases the variance in possible outputs letting the model be a tad more dynamic in what outputs it may produce in terms of composition, color, detail, and prompt interpretation. Setting this value low will ensure strong prompt following with more consistent outputs, setting it higher will produce more dynamic or varied outputs.",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "custom",
            "1:1",
            "16:9",
            "3:2",
            "2:3",
            "4:5",
            "5:4",
            "9:16",
            "3:4",
            "4:3"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Aspect_ratio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "Aspect ratio for the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "image_prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Image Prompt",
        "description": "Image to use with Flux Redux. This is used together with the text prompt to guide the generation towards the composition of the image_prompt. Must be jpeg, png, gif, or webp.",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images.",
        "min": null,
        "max": null
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Output Quality",
        "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "safety_tolerance",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Safety Tolerance",
        "description": "Safety tolerance, 1 is most strict and 6 is most permissive",
        "min": 1.0,
        "max": 6.0
      },
      {
        "name": "prompt_upsampling",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Prompt Upsampling",
        "description": "Automatically modify the prompt for more creative generation",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/a36275e2-34d4-4b3d-83cd-f9aaf73c9386/https___replicate.delive_o40qpZl.webp",
      "created_at": "2024-08-01T09:32:10.863297Z",
      "description": "State-of-the-art image generation with top of the line prompt following, visual quality, image detail and output diversity.",
      "github_url": null,
      "license_url": "https://replicate.com/black-forest-labs/flux-pro#license",
      "name": "flux-pro",
      "owner": "black-forest-labs",
      "paper_url": null,
      "run_count": 8219214,
      "url": "https://replicate.com/black-forest-labs/flux-pro",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "steps",
      "width"
    ]
  },
  {
    "title": "Flux 1 1 Pro Ultra",
    "description": "FLUX1.1 [pro] in ultra and raw modes. Images are up to 4 megapixels. Use raw mode for realism.",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Flux_1_1_Pro_Ultra",
    "layout": "default",
    "properties": [
      {
        "name": "raw",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Raw",
        "description": "Generate less processed, more natural-looking images",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Text prompt for image generation",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "21:9",
            "16:9",
            "3:2",
            "4:3",
            "5:4",
            "1:1",
            "4:5",
            "3:4",
            "2:3",
            "9:16",
            "9:21"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Aspect_ratio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "Aspect ratio for the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "image_prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Image Prompt",
        "description": "Image to use with Flux Redux. This is used together with the text prompt to guide the generation towards the composition of the image_prompt. Must be jpeg, png, gif, or webp.",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "jpg",
        "title": "Output Format",
        "description": "Format of the output images.",
        "min": null,
        "max": null
      },
      {
        "name": "safety_tolerance",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Safety Tolerance",
        "description": "Safety tolerance, 1 is most strict and 6 is most permissive",
        "min": 1.0,
        "max": 6.0
      },
      {
        "name": "image_prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.1,
        "title": "Image Prompt Strength",
        "description": "Blend between the prompt and the image prompt.",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/8121c76b-fbff-41d9-834d-c70dea9d2191/flux-ultra-cover.jpg",
      "created_at": "2024-11-06T19:13:05.091037Z",
      "description": "FLUX1.1 [pro] in ultra and raw modes. Images are up to 4 megapixels. Use raw mode for realism.",
      "github_url": null,
      "license_url": "https://replicate.com/black-forest-labs/flux-pro#license",
      "name": "flux-1.1-pro-ultra",
      "owner": "black-forest-labs",
      "paper_url": "https://blackforestlabs.ai/flux-1-1-ultra/",
      "run_count": 3522148,
      "url": "https://replicate.com/black-forest-labs/flux-1.1-pro-ultra",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "raw",
      "seed",
      "prompt"
    ]
  },
  {
    "title": "Flux Dev Lora",
    "description": "A version of flux-dev, a text to image model, that supports fast fine-tuned lora inference",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Flux_Dev_Lora",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image for image to image mode. The aspect ratio of your output will match this image",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Prompt for generated image",
        "min": null,
        "max": null
      },
      {
        "name": "go_fast",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Go Fast",
        "description": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
        "min": null,
        "max": null
      },
      {
        "name": "guidance",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Guidance",
        "description": "Guidance for generated image",
        "min": 0.0,
        "max": 10.0
      },
      {
        "name": "lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Lora Scale",
        "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
        "min": -1.0,
        "max": 3.0
      },
      {
        "name": "megapixels",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1",
            "0.25"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Megapixels"
        },
        "default": "1",
        "title": "Megapixels",
        "description": "Approximate number of megapixels for generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of outputs to generate",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1:1",
            "16:9",
            "21:9",
            "3:2",
            "2:3",
            "4:5",
            "5:4",
            "3:4",
            "4:3",
            "9:16",
            "9:21"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Aspect_ratio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "Aspect ratio for the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "lora_weights",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Lora Weights",
        "description": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Output Quality",
        "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Prompt Strength",
        "description": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. Recommended range is 28-50",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/a79cc4a8-318c-4316-a800-097ef0bdce7a/https___replicate.del_25H5GQ7.webp",
      "created_at": "2024-11-11T23:03:07.000926Z",
      "description": "A version of flux-dev, a text to image model, that supports fast fine-tuned lora inference",
      "github_url": "https://github.com/replicate/cog-flux",
      "license_url": "https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-dev",
      "name": "flux-dev-lora",
      "owner": "black-forest-labs",
      "paper_url": null,
      "run_count": 103469,
      "url": "https://replicate.com/black-forest-labs/flux-dev-lora",
      "visibility": "public",
      "weights_url": "https://huggingface.co/black-forest-labs/FLUX.1-dev"
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "image",
      "prompt"
    ]
  },
  {
    "title": "Flux Schnell Lora",
    "description": "The fastest image generation model tailored for fine-tuned use",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Flux_Schnell_Lora",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Prompt for generated image",
        "min": null,
        "max": null
      },
      {
        "name": "go_fast",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Go Fast",
        "description": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
        "min": null,
        "max": null
      },
      {
        "name": "lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Lora Scale",
        "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
        "min": -1.0,
        "max": 3.0
      },
      {
        "name": "megapixels",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1",
            "0.25"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Megapixels"
        },
        "default": "1",
        "title": "Megapixels",
        "description": "Approximate number of megapixels for generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of outputs to generate",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1:1",
            "16:9",
            "21:9",
            "3:2",
            "2:3",
            "4:5",
            "5:4",
            "3:4",
            "4:3",
            "9:16",
            "9:21"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Aspect_ratio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "Aspect ratio for the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "lora_weights",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Lora Weights",
        "description": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Output Quality",
        "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. 4 is recommended, and lower number of steps produce lower quality outputs, faster.",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/98c9bf91-5bc0-4a2d-960f-8c3fcd69f1f3/https___replicate.deliver_a20JvIo.png",
      "created_at": "2024-11-11T23:07:50.986160Z",
      "description": "The fastest image generation model tailored for fine-tuned use",
      "github_url": "https://github.com/replicate/cog-flux",
      "license_url": "https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-schnell",
      "name": "flux-schnell-lora",
      "owner": "black-forest-labs",
      "paper_url": null,
      "run_count": 164770,
      "url": "https://replicate.com/black-forest-labs/flux-schnell-lora",
      "visibility": "public",
      "weights_url": "https://huggingface.co/black-forest-labs/FLUX.1-schnell"
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "prompt",
      "go_fast"
    ]
  },
  {
    "title": "Flux Depth Pro",
    "description": "Professional depth-aware image generation. Edit images while preserving spatial relationships.",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Flux_Depth_Pro",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Steps",
        "description": "Number of diffusion steps. Higher values yield finer details but increase processing time.",
        "min": 15.0,
        "max": 50.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Text prompt for image generation",
        "min": null,
        "max": null
      },
      {
        "name": "guidance",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10,
        "title": "Guidance",
        "description": "Controls the balance between adherence to the text as well as image prompt and image quality/diversity. Higher values make the output more closely match the prompt but may reduce overall image quality. Lower values allow for more creative freedom but might produce results less relevant to the prompt.",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "control_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Control Image",
        "description": "Image to use as control input. Must be jpeg, png, gif, or webp.",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "jpg",
        "title": "Output Format",
        "description": "Format of the output images.",
        "min": null,
        "max": null
      },
      {
        "name": "safety_tolerance",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Safety Tolerance",
        "description": "Safety tolerance, 1 is most strict and 6 is most permissive",
        "min": 1.0,
        "max": 6.0
      },
      {
        "name": "prompt_upsampling",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Prompt Upsampling",
        "description": "Automatically modify the prompt for more creative generation",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/e365ecff-4023-49f8-96ba-abd710c4bdd9/https___replicate.deliver_xWYu8lC.jpg",
      "created_at": "2024-11-21T09:53:00.631446Z",
      "description": "Professional depth-aware image generation. Edit images while preserving spatial relationships.",
      "github_url": null,
      "license_url": "https://replicate.com/black-forest-labs/flux-depth-pro#license",
      "name": "flux-depth-pro",
      "owner": "black-forest-labs",
      "paper_url": null,
      "run_count": 23334,
      "url": "https://replicate.com/black-forest-labs/flux-depth-pro",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "steps",
      "prompt"
    ]
  },
  {
    "title": "Flux Canny Pro",
    "description": "Professional edge-guided image generation. Control structure and composition using Canny edge detection",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Flux_Canny_Pro",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Steps",
        "description": "Number of diffusion steps. Higher values yield finer details but increase processing time.",
        "min": 15.0,
        "max": 50.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Text prompt for image generation",
        "min": null,
        "max": null
      },
      {
        "name": "guidance",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Guidance",
        "description": "Controls the balance between adherence to the text as well as image prompt and image quality/diversity. Higher values make the output more closely match the prompt but may reduce overall image quality. Lower values allow for more creative freedom but might produce results less relevant to the prompt.",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "control_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Control Image",
        "description": "Image to use as control input. Must be jpeg, png, gif, or webp.",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "jpg",
        "title": "Output Format",
        "description": "Format of the output images.",
        "min": null,
        "max": null
      },
      {
        "name": "safety_tolerance",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Safety Tolerance",
        "description": "Safety tolerance, 1 is most strict and 6 is most permissive",
        "min": 1.0,
        "max": 6.0
      },
      {
        "name": "prompt_upsampling",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Prompt Upsampling",
        "description": "Automatically modify the prompt for more creative generation",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/4c07cacc-d206-4587-9357-8e4e81cd761a/https___replicate.deli_lsMxQWe.jpg",
      "created_at": "2024-11-21T09:53:08.913764Z",
      "description": "Professional edge-guided image generation. Control structure and composition using Canny edge detection",
      "github_url": null,
      "license_url": "https://replicate.com/black-forest-labs/flux-canny-pro#license",
      "name": "flux-canny-pro",
      "owner": "black-forest-labs",
      "paper_url": null,
      "run_count": 37841,
      "url": "https://replicate.com/black-forest-labs/flux-canny-pro",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "steps",
      "prompt"
    ]
  },
  {
    "title": "Flux Fill Pro",
    "description": "Professional inpainting and outpainting model with state-of-the-art performance. Edit or extend images with natural, seamless results.",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Flux_Fill_Pro",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Mask",
        "description": "A black-and-white image that describes the part of the image to inpaint. Black areas will be preserved while white areas will be inpainted. Must have the same size as image. Optional if you provide an alpha mask in the original image. Must be jpeg, png, gif, or webp.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Image",
        "description": "The image to inpaint. Can contain an alpha mask. Must be jpeg, png, gif, or webp.",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Steps",
        "description": "Number of diffusion steps. Higher values yield finer details but increase processing time.",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Text prompt for image generation",
        "min": null,
        "max": null
      },
      {
        "name": "guidance",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Guidance",
        "description": "Controls the balance between adherence to the text prompt and image quality/diversity. Higher values make the output more closely match the prompt but may reduce overall image quality. Lower values allow for more creative freedom but might produce results less relevant to the prompt.",
        "min": 2.0,
        "max": 5.0
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "jpg",
        "title": "Output Format",
        "description": "Format of the output images.",
        "min": null,
        "max": null
      },
      {
        "name": "safety_tolerance",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Safety Tolerance",
        "description": "Safety tolerance, 1 is most strict and 6 is most permissive",
        "min": 1.0,
        "max": 6.0
      },
      {
        "name": "prompt_upsampling",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Prompt Upsampling",
        "description": "Automatically modify the prompt for more creative generation",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/13571f4b-d677-404f-bff0-ad44da9d5fa0/https___replicate.deli_llwvezd.jpg",
      "created_at": "2024-11-20T20:56:37.431006Z",
      "description": "Professional inpainting and outpainting model with state-of-the-art performance. Edit or extend images with natural, seamless results.",
      "github_url": null,
      "license_url": "https://replicate.com/black-forest-labs/flux-fill-pro#license",
      "name": "flux-fill-pro",
      "owner": "black-forest-labs",
      "paper_url": null,
      "run_count": 81453,
      "url": "https://replicate.com/black-forest-labs/flux-fill-pro",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "seed",
      "image"
    ]
  },
  {
    "title": "Flux Depth Dev",
    "description": "Open-weight depth-aware image generation. Edit images while preserving spatial relationships.",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Flux_Depth_Dev",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Prompt for generated image",
        "min": null,
        "max": null
      },
      {
        "name": "guidance",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10,
        "title": "Guidance",
        "description": "Guidance for generated image",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "megapixels",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1",
            "0.25",
            "match_input"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Megapixels"
        },
        "default": "1",
        "title": "Megapixels",
        "description": "Approximate number of megapixels for generated image. Use match_input to match the size of the input (with an upper limit of 1440x1440 pixels)",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of outputs to generate",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "control_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Control Image",
        "description": "Image used to control the generation. The depth map will be automatically generated.",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Output Quality",
        "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. Recommended range is 28-50, and lower number of steps produce lower quality outputs, faster.",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/4cfef8f5-5fcb-413c-bdaa-d6d4f41e5930/flux-depth-dev.jpg",
      "created_at": "2024-11-20T20:49:48.670385Z",
      "description": "Open-weight depth-aware image generation. Edit images while preserving spatial relationships.",
      "github_url": null,
      "license_url": "https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-dev",
      "name": "flux-depth-dev",
      "owner": "black-forest-labs",
      "paper_url": null,
      "run_count": 23922,
      "url": "https://replicate.com/black-forest-labs/flux-depth-dev",
      "visibility": "public",
      "weights_url": "https://huggingface.co/black-forest-labs/FLUX.1-Depth-dev"
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "prompt",
      "guidance"
    ]
  },
  {
    "title": "Hyper Flux 8 Step",
    "description": "Hyper FLUX 8-step by ByteDance",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Hyper_Flux_8Step",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Width",
        "description": "Width of the generated image. Optional, only used when aspect_ratio=custom. Must be a multiple of 16 (if it's not, it will be rounded to nearest multiple of 16)",
        "min": 256.0,
        "max": 1440.0
      },
      {
        "name": "height",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Height",
        "description": "Height of the generated image. Optional, only used when aspect_ratio=custom. Must be a multiple of 16 (if it's not, it will be rounded to nearest multiple of 16)",
        "min": 256.0,
        "max": 1440.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Prompt for generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of images to output.",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1:1",
            "16:9",
            "21:9",
            "3:2",
            "2:3",
            "4:5",
            "5:4",
            "3:4",
            "4:3",
            "9:16",
            "9:21",
            "custom"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Aspect_ratio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "Aspect ratio for the generated image. The size will always be 1 megapixel, i.e. 1024x1024 if aspect ratio is 1:1. To use arbitrary width and height, set aspect ratio to 'custom'.",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3.5,
        "title": "Guidance Scale",
        "description": "Guidance scale for the diffusion process",
        "min": 0.0,
        "max": 10.0
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Output Quality",
        "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8,
        "title": "Num Inference Steps",
        "description": "Number of inference steps",
        "min": 1.0,
        "max": 30.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images. This feature is only available through the API. See [https://replicate.com/docs/how-does-replicate-work#safety](https://replicate.com/docs/how-does-replicate-work#safety)",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/yhqm/bKCAFhWFtbafL6Q31fEkfzVUKDUxY3GcdU1KGtR1AfRhcHOOB/out-0.webp",
      "created_at": "2024-08-27T19:33:25.004679Z",
      "description": "Hyper FLUX 8-step by ByteDance",
      "github_url": "https://github.com/lucataco/cog-hyper-flux-8step",
      "license_url": "https://huggingface.co/black-forest-labs/FLUX.1-dev/blob/main/LICENSE.md",
      "name": "hyper-flux-8step",
      "owner": "bytedance",
      "paper_url": "https://arxiv.org/abs/2404.13686",
      "run_count": 4460406,
      "url": "https://replicate.com/bytedance/hyper-flux-8step",
      "visibility": "public",
      "weights_url": "https://huggingface.co/ByteDance/Hyper-SD"
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "width",
      "height"
    ]
  },
  {
    "title": "Flux Mona Lisa",
    "description": "Flux lora, use the term \"MNALSA\" to trigger generation",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Flux_Mona_Lisa",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask",
        "description": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "dev",
            "schnell"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Model"
        },
        "default": "dev",
        "title": "Model",
        "description": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Width",
        "description": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
        "min": 256.0,
        "max": 1440.0
      },
      {
        "name": "height",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Height",
        "description": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
        "min": 256.0,
        "max": 1440.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
        "min": null,
        "max": null
      },
      {
        "name": "go_fast",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Go Fast",
        "description": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
        "min": null,
        "max": null
      },
      {
        "name": "extra_lora",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Extra Lora",
        "description": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
        "min": null,
        "max": null
      },
      {
        "name": "lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Lora Scale",
        "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
        "min": -1.0,
        "max": 3.0
      },
      {
        "name": "megapixels",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1",
            "0.25"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Megapixels"
        },
        "default": "1",
        "title": "Megapixels",
        "description": "Approximate number of megapixels for generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of outputs to generate",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1:1",
            "16:9",
            "21:9",
            "3:2",
            "2:3",
            "4:5",
            "5:4",
            "3:4",
            "4:3",
            "9:16",
            "9:21",
            "custom"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Aspect_ratio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Guidance Scale",
        "description": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
        "min": 0.0,
        "max": 10.0
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Output Quality",
        "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Prompt Strength",
        "description": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "extra_lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Extra Lora Scale",
        "description": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
        "min": -1.0,
        "max": 3.0
      },
      {
        "name": "replicate_weights",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Replicate Weights",
        "description": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. More steps can give more detailed images, but take longer.",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/yhqm/apYK6kZFfZUYRyoJ11NzhHY2YXbrjCHajYIiN9EznGR4qVrJA/out-0.webp",
      "created_at": "2024-08-26T21:32:24.116430Z",
      "description": "Flux lora, use the term \"MNALSA\" to trigger generation",
      "github_url": null,
      "license_url": null,
      "name": "flux-mona-lisa",
      "owner": "fofr",
      "paper_url": null,
      "run_count": 2878,
      "url": "https://replicate.com/fofr/flux-mona-lisa",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "seed",
      "image"
    ]
  },
  {
    "title": "Flux Cinestill",
    "description": "Flux lora, use \"CNSTLL\" to trigger",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Flux_Cinestill",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask",
        "description": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "dev",
            "schnell"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Model"
        },
        "default": "dev",
        "title": "Model",
        "description": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Width",
        "description": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
        "min": 256.0,
        "max": 1440.0
      },
      {
        "name": "height",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Height",
        "description": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
        "min": 256.0,
        "max": 1440.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
        "min": null,
        "max": null
      },
      {
        "name": "go_fast",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Go Fast",
        "description": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
        "min": null,
        "max": null
      },
      {
        "name": "extra_lora",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Extra Lora",
        "description": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
        "min": null,
        "max": null
      },
      {
        "name": "lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Lora Scale",
        "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
        "min": -1.0,
        "max": 3.0
      },
      {
        "name": "megapixels",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1",
            "0.25"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Megapixels"
        },
        "default": "1",
        "title": "Megapixels",
        "description": "Approximate number of megapixels for generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of outputs to generate",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1:1",
            "16:9",
            "21:9",
            "3:2",
            "2:3",
            "4:5",
            "5:4",
            "3:4",
            "4:3",
            "9:16",
            "9:21",
            "custom"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Aspect_ratio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Guidance Scale",
        "description": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
        "min": 0.0,
        "max": 10.0
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Output Quality",
        "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Prompt Strength",
        "description": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "extra_lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Extra Lora Scale",
        "description": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
        "min": -1.0,
        "max": 3.0
      },
      {
        "name": "replicate_weights",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Replicate Weights",
        "description": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. More steps can give more detailed images, but take longer.",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/2838391b-a106-4d81-b0ff-68aa5a0b9367/cinestill.png",
      "created_at": "2024-08-24T10:28:41.876414Z",
      "description": "Flux lora, use \"CNSTLL\" to trigger",
      "github_url": null,
      "license_url": null,
      "name": "flux-cinestill",
      "owner": "adirik",
      "paper_url": null,
      "run_count": 70750,
      "url": "https://replicate.com/adirik/flux-cinestill",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "seed",
      "image"
    ]
  },
  {
    "title": "Flux Black Light",
    "description": "A flux lora fine-tuned on black light images",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Flux_Black_Light",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask",
        "description": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "dev",
            "schnell"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Model"
        },
        "default": "dev",
        "title": "Model",
        "description": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Width",
        "description": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
        "min": 256.0,
        "max": 1440.0
      },
      {
        "name": "height",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Height",
        "description": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
        "min": 256.0,
        "max": 1440.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
        "min": null,
        "max": null
      },
      {
        "name": "go_fast",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Go Fast",
        "description": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
        "min": null,
        "max": null
      },
      {
        "name": "extra_lora",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Extra Lora",
        "description": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
        "min": null,
        "max": null
      },
      {
        "name": "lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Lora Scale",
        "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
        "min": -1.0,
        "max": 3.0
      },
      {
        "name": "megapixels",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1",
            "0.25"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Megapixels"
        },
        "default": "1",
        "title": "Megapixels",
        "description": "Approximate number of megapixels for generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of outputs to generate",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1:1",
            "16:9",
            "21:9",
            "3:2",
            "2:3",
            "4:5",
            "5:4",
            "3:4",
            "4:3",
            "9:16",
            "9:21",
            "custom"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Aspect_ratio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Guidance Scale",
        "description": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
        "min": 0.0,
        "max": 10.0
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Output Quality",
        "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Prompt Strength",
        "description": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "extra_lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Extra Lora Scale",
        "description": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
        "min": -1.0,
        "max": 3.0
      },
      {
        "name": "replicate_weights",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Replicate Weights",
        "description": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. More steps can give more detailed images, but take longer.",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/yhqm/ZehHgBlLml30R64OxKegcYEHlzGgd0rcIrf5ejXaFK5VuPMNB/out-0.webp",
      "created_at": "2024-08-15T22:48:12.421764Z",
      "description": "A flux lora fine-tuned on black light images",
      "github_url": null,
      "license_url": null,
      "name": "flux-black-light",
      "owner": "fofr",
      "paper_url": null,
      "run_count": 713938,
      "url": "https://replicate.com/fofr/flux-black-light",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "seed",
      "image"
    ]
  },
  {
    "title": "Flux 360",
    "description": "Generate 360 panorama images.",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Flux_360",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask",
        "description": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "dev",
            "schnell"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Model"
        },
        "default": "dev",
        "title": "Model",
        "description": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Width",
        "description": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
        "min": 256.0,
        "max": 1440.0
      },
      {
        "name": "height",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Height",
        "description": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
        "min": 256.0,
        "max": 1440.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
        "min": null,
        "max": null
      },
      {
        "name": "go_fast",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Go Fast",
        "description": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
        "min": null,
        "max": null
      },
      {
        "name": "extra_lora",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Extra Lora",
        "description": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
        "min": null,
        "max": null
      },
      {
        "name": "lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Lora Scale",
        "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
        "min": -1.0,
        "max": 3.0
      },
      {
        "name": "megapixels",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1",
            "0.25"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Megapixels"
        },
        "default": "1",
        "title": "Megapixels",
        "description": "Approximate number of megapixels for generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of outputs to generate",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1:1",
            "16:9",
            "21:9",
            "3:2",
            "2:3",
            "4:5",
            "5:4",
            "3:4",
            "4:3",
            "9:16",
            "9:21",
            "custom"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Aspect_ratio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Guidance Scale",
        "description": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
        "min": 0.0,
        "max": 10.0
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Output Quality",
        "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Prompt Strength",
        "description": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "extra_lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Extra Lora Scale",
        "description": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
        "min": -1.0,
        "max": 3.0
      },
      {
        "name": "replicate_weights",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Replicate Weights",
        "description": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. More steps can give more detailed images, but take longer.",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/3731b4ae-b13e-44e8-a12e-6d02627cbd23/forest.png",
      "created_at": "2024-08-26T15:51:12.459480Z",
      "description": "Generate 360 panorama images.",
      "github_url": "https://github.com/igorriti/pi",
      "license_url": null,
      "name": "flux-360",
      "owner": "igorriti",
      "paper_url": null,
      "run_count": 9918,
      "url": "https://replicate.com/igorriti/flux-360",
      "visibility": "public",
      "weights_url": "https://huggingface.co/igorriti/flux-360"
    },
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "seed",
      "image"
    ]
  },
  {
    "title": "Recraft V 3",
    "description": "Recraft V3 (code-named red_panda) is a text-to-image model with the ability to generate long texts, and images in a wide list of styles. As of today, it is SOTA in image generation, proven by the Text-to-Image Benchmark by Artificial Analysis",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Recraft_V3",
    "layout": "default",
    "properties": [
      {
        "name": "size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1024x1024",
            "1365x1024",
            "1024x1365",
            "1536x1024",
            "1024x1536",
            "1820x1024",
            "1024x1820",
            "1024x2048",
            "2048x1024",
            "1434x1024",
            "1024x1434",
            "1024x1280",
            "1280x1024",
            "1024x1707",
            "1707x1024"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Size"
        },
        "default": "1024x1024",
        "title": "Size",
        "description": "Width and height of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "style",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "any",
            "realistic_image",
            "digital_illustration",
            "digital_illustration/pixel_art",
            "digital_illustration/hand_drawn",
            "digital_illustration/grain",
            "digital_illustration/infantile_sketch",
            "digital_illustration/2d_art_poster",
            "digital_illustration/handmade_3d",
            "digital_illustration/hand_drawn_outline",
            "digital_illustration/engraving_color",
            "digital_illustration/2d_art_poster_2",
            "realistic_image/b_and_w",
            "realistic_image/hard_flash",
            "realistic_image/hdr",
            "realistic_image/natural_light",
            "realistic_image/studio_portrait",
            "realistic_image/enterprise",
            "realistic_image/motion_blur"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Style"
        },
        "default": "any",
        "title": "Style",
        "description": "Style of the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Text prompt for image generation",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/afce5fa4-5f8a-45db-95c0-bf62ec6958e7/output-59.webp",
      "created_at": "2024-10-30T12:41:06.099624Z",
      "description": "Recraft V3 (code-named red_panda) is a text-to-image model with the ability to generate long texts, and images in a wide list of styles. As of today, it is SOTA in image generation, proven by the Text-to-Image Benchmark by Artificial Analysis",
      "github_url": null,
      "license_url": "https://www.recraft.ai/terms",
      "name": "recraft-v3",
      "owner": "recraft-ai",
      "paper_url": "https://recraft.ai",
      "run_count": 724069,
      "url": "https://replicate.com/recraft-ai/recraft-v3",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "size",
      "style",
      "prompt"
    ]
  },
  {
    "title": "Recraft 20 B",
    "description": "Affordable and fast images",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Recraft_20B",
    "layout": "default",
    "properties": [
      {
        "name": "size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1024x1024",
            "1365x1024",
            "1024x1365",
            "1536x1024",
            "1024x1536",
            "1820x1024",
            "1024x1820",
            "1024x2048",
            "2048x1024",
            "1434x1024",
            "1024x1434",
            "1024x1280",
            "1280x1024",
            "1024x1707",
            "1707x1024"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Size"
        },
        "default": "1024x1024",
        "title": "Size",
        "description": "Width and height of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "style",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "realistic_image",
            "realistic_image/b_and_w",
            "realistic_image/enterprise",
            "realistic_image/hard_flash",
            "realistic_image/hdr",
            "realistic_image/motion_blur",
            "realistic_image/natural_light",
            "realistic_image/studio_portrait",
            "digital_illustration",
            "digital_illustration/2d_art_poster",
            "digital_illustration/2d_art_poster_2",
            "digital_illustration/3d",
            "digital_illustration/80s",
            "digital_illustration/engraving_color",
            "digital_illustration/glow",
            "digital_illustration/grain",
            "digital_illustration/hand_drawn",
            "digital_illustration/hand_drawn_outline",
            "digital_illustration/handmade_3d",
            "digital_illustration/infantile_sketch",
            "digital_illustration/kawaii",
            "digital_illustration/pixel_art",
            "digital_illustration/psychedelic",
            "digital_illustration/seamless",
            "digital_illustration/voxel",
            "digital_illustration/watercolor"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Style"
        },
        "default": "realistic_image",
        "title": "Style",
        "description": "Style of the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Text prompt for image generation",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/2a808913-4306-43d4-b9da-db154e2faeab/recraft-cover-1.webp",
      "created_at": "2024-12-12T13:39:48.189902Z",
      "description": "Affordable and fast images",
      "github_url": null,
      "license_url": "https://www.recraft.ai/terms",
      "name": "recraft-20b",
      "owner": "recraft-ai",
      "paper_url": "https://recraft.ai",
      "run_count": 42887,
      "url": "https://replicate.com/recraft-ai/recraft-20b",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "size",
      "style",
      "prompt"
    ]
  },
  {
    "title": "Recraft 20 B SVG",
    "description": "Affordable and fast vector images",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Recraft_20B_SVG",
    "layout": "default",
    "properties": [
      {
        "name": "size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1024x1024",
            "1365x1024",
            "1024x1365",
            "1536x1024",
            "1024x1536",
            "1820x1024",
            "1024x1820",
            "1024x2048",
            "2048x1024",
            "1434x1024",
            "1024x1434",
            "1024x1280",
            "1280x1024",
            "1024x1707",
            "1707x1024"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Size"
        },
        "default": "1024x1024",
        "title": "Size",
        "description": "Width and height of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "style",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "vector_illustration",
            "vector_illustration/cartoon",
            "vector_illustration/doodle_line_art",
            "vector_illustration/engraving",
            "vector_illustration/flat_2",
            "vector_illustration/kawaii",
            "vector_illustration/line_art",
            "vector_illustration/line_circuit",
            "vector_illustration/linocut",
            "vector_illustration/seamless",
            "icon",
            "icon/broken_line",
            "icon/colored_outline",
            "icon/colored_shapes",
            "icon/colored_shapes_gradient",
            "icon/doodle_fill",
            "icon/doodle_offset_fill",
            "icon/offset_fill",
            "icon/outline",
            "icon/outline_gradient",
            "icon/uneven_fill"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Style"
        },
        "default": "vector_illustration",
        "title": "Style",
        "description": "Style of the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Text prompt for image generation",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "svg",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/4993bd89-af70-43da-be68-18cc43437746/recraft-svg-20b-cover.webp",
      "created_at": "2024-12-12T13:39:54.180287Z",
      "description": "Affordable and fast vector images",
      "github_url": null,
      "license_url": "https://www.recraft.ai/terms",
      "name": "recraft-20b-svg",
      "owner": "recraft-ai",
      "paper_url": "https://recraft.ai/",
      "run_count": 3222,
      "url": "https://replicate.com/recraft-ai/recraft-20b-svg",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "size",
      "style",
      "prompt"
    ]
  },
  {
    "title": "Recraft V 3 SVG",
    "description": "Recraft V3 SVG (code-named red_panda) is a text-to-image model with the ability to generate high quality SVG images including logotypes, and icons. The model supports a wide list of styles.",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Recraft_V3_SVG",
    "layout": "default",
    "properties": [
      {
        "name": "size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1024x1024",
            "1365x1024",
            "1024x1365",
            "1536x1024",
            "1024x1536",
            "1820x1024",
            "1024x1820",
            "1024x2048",
            "2048x1024",
            "1434x1024",
            "1024x1434",
            "1024x1280",
            "1280x1024",
            "1024x1707",
            "1707x1024"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Size"
        },
        "default": "1024x1024",
        "title": "Size",
        "description": "Width and height of the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "style",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "any",
            "engraving",
            "line_art",
            "line_circuit",
            "linocut"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Style"
        },
        "default": "any",
        "title": "Style",
        "description": "Style of the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Text prompt for image generation",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "svg",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/223c73a9-0347-4daa-9710-3878f95479e3/svg-cover.webp",
      "created_at": "2024-10-30T13:59:33.006694Z",
      "description": "Recraft V3 SVG (code-named red_panda) is a text-to-image model with the ability to generate high quality SVG images including logotypes, and icons. The model supports a wide list of styles.",
      "github_url": null,
      "license_url": "https://recraft.ai/terms",
      "name": "recraft-v3-svg",
      "owner": "recraft-ai",
      "paper_url": "https://recraft.ai",
      "run_count": 44463,
      "url": "https://replicate.com/recraft-ai/recraft-v3-svg",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "size",
      "style",
      "prompt"
    ]
  },
  {
    "title": "Flux Canny Dev",
    "description": "Open-weight edge-guided image generation. Control structure and composition using Canny edge detection.",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Flux_Canny_Dev",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Prompt for generated image",
        "min": null,
        "max": null
      },
      {
        "name": "guidance",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Guidance",
        "description": "Guidance for generated image",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "megapixels",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1",
            "0.25",
            "match_input"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Megapixels"
        },
        "default": "1",
        "title": "Megapixels",
        "description": "Approximate number of megapixels for generated image. Use match_input to match the size of the input (with an upper limit of 1440x1440 pixels)",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of outputs to generate",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "control_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Control Image",
        "description": "Image used to control the generation. The canny edge detection will be automatically generated.",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Output Quality",
        "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. Recommended range is 28-50, and lower number of steps produce lower quality outputs, faster.",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/788cf228-ae38-473a-a992-1e650aab0519/flux-canny-dev.jpg",
      "created_at": "2024-11-20T20:49:32.818286Z",
      "description": "Open-weight edge-guided image generation. Control structure and composition using Canny edge detection.",
      "github_url": null,
      "license_url": "https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-dev",
      "name": "flux-canny-dev",
      "owner": "black-forest-labs",
      "paper_url": null,
      "run_count": 21647,
      "url": "https://replicate.com/black-forest-labs/flux-canny-dev",
      "visibility": "public",
      "weights_url": "https://huggingface.co/black-forest-labs/FLUX.1-Canny-dev"
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "prompt",
      "guidance"
    ]
  },
  {
    "title": "Flux Fill Dev",
    "description": "Open-weight inpainting model for editing and extending images. Guidance-distilled from FLUX.1 Fill [pro].",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Flux_Fill_Dev",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Mask",
        "description": "A black-and-white image that describes the part of the image to inpaint. Black areas will be preserved while white areas will be inpainted.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Image",
        "description": "The image to inpaint. Can contain alpha mask. If the image width or height are not multiples of 32, they will be scaled to the closest multiple of 32. If the image dimensions don't fit within 1440x1440, it will be scaled down to fit.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Prompt for generated image",
        "min": null,
        "max": null
      },
      {
        "name": "guidance",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Guidance",
        "description": "Guidance for generated image",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "megapixels",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1",
            "0.25",
            "match_input"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Megapixels"
        },
        "default": "1",
        "title": "Megapixels",
        "description": "Approximate number of megapixels for generated image. Use match_input to match the size of the input (with an upper limit of 1440x1440 pixels)",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of outputs to generate",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Output Quality",
        "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. Recommended range is 28-50, and lower number of steps produce lower quality outputs, faster.",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/b109cc9e-f3c2-4899-8428-df46a988c3f0/https___replicate.deliver_tmlMO9j.jpg",
      "created_at": "2024-11-20T20:49:17.667435Z",
      "description": "Open-weight inpainting model for editing and extending images. Guidance-distilled from FLUX.1 Fill [pro].",
      "github_url": null,
      "license_url": "https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-dev",
      "name": "flux-fill-dev",
      "owner": "black-forest-labs",
      "paper_url": null,
      "run_count": 53266,
      "url": "https://replicate.com/black-forest-labs/flux-fill-dev",
      "visibility": "public",
      "weights_url": "https://huggingface.co/black-forest-labs/FLUX.1-Fill-dev"
    },
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "seed",
      "image"
    ]
  },
  {
    "title": "Flux Redux Schnell",
    "description": "Fast, efficient image variation model for rapid iteration and experimentation.",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Flux_Redux_Schnell",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "megapixels",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1",
            "0.25"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Megapixels"
        },
        "default": "1",
        "title": "Megapixels",
        "description": "Approximate number of megapixels for generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of outputs to generate",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "redux_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Redux Image",
        "description": "Input image to condition your output on. This replaces prompt for FLUX.1 Redux models",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1:1",
            "16:9",
            "21:9",
            "3:2",
            "2:3",
            "4:5",
            "5:4",
            "3:4",
            "4:3",
            "9:16",
            "9:21"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Aspect_ratio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "Aspect ratio for the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Output Quality",
        "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. 4 is recommended, and lower number of steps produce lower quality outputs, faster.",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/828d2d38-465e-4a65-a979-1f661000e978/https___replicate.deliver_018es9x.jpg",
      "created_at": "2024-11-20T22:30:41.021241Z",
      "description": "Fast, efficient image variation model for rapid iteration and experimentation.",
      "github_url": null,
      "license_url": "https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-schnell",
      "name": "flux-redux-schnell",
      "owner": "black-forest-labs",
      "paper_url": null,
      "run_count": 13100,
      "url": "https://replicate.com/black-forest-labs/flux-redux-schnell",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "megapixels",
      "num_outputs"
    ]
  },
  {
    "title": "Flux Redux Dev",
    "description": "Open-weight image variation model. Create new versions while preserving key elements of your original.",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Flux_Redux_Dev",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "guidance",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Guidance",
        "description": "Guidance for generated image",
        "min": 0.0,
        "max": 10.0
      },
      {
        "name": "megapixels",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1",
            "0.25"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Megapixels"
        },
        "default": "1",
        "title": "Megapixels",
        "description": "Approximate number of megapixels for generated image",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of outputs to generate",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "redux_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Redux Image",
        "description": "Input image to condition your output on. This replaces prompt for FLUX.1 Redux models",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1:1",
            "16:9",
            "21:9",
            "3:2",
            "2:3",
            "4:5",
            "5:4",
            "3:4",
            "4:3",
            "9:16",
            "9:21"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Aspect_ratio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "Aspect ratio for the generated image",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Output Quality",
        "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 28,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. Recommended range is 28-50",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/daff59ba-540d-4111-a969-9119ee814f26/redux-cover.jpg",
      "created_at": "2024-11-20T22:29:45.623102Z",
      "description": "Open-weight image variation model. Create new versions while preserving key elements of your original.",
      "github_url": null,
      "license_url": "https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-dev",
      "name": "flux-redux-dev",
      "owner": "black-forest-labs",
      "paper_url": null,
      "run_count": 20587,
      "url": "https://replicate.com/black-forest-labs/flux-redux-dev",
      "visibility": "public",
      "weights_url": "https://huggingface.co/black-forest-labs/FLUX.1-Redux-dev"
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "guidance",
      "megapixels"
    ]
  },
  {
    "title": "SDXL Controlnet",
    "description": "SDXL ControlNet - Canny",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.SDXL_Controlnet",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Seed",
        "description": "Random seed. Set to 0 to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image for img2img or inpaint mode",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "aerial view, a futuristic research complex in a bright foggy jungle, hard lighting",
        "title": "Prompt",
        "description": "Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "condition_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Condition Scale",
        "description": "controlnet conditioning scale for generalization",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "low quality, bad quality, sketches",
        "title": "Negative Prompt",
        "description": "Input Negative Prompt",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps",
        "min": 1.0,
        "max": 500.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/7edf6f87-bd0d-4a4f-9e11-d944bb07a3ea/output.png",
      "created_at": "2023-08-14T07:15:37.417194Z",
      "description": "SDXL ControlNet - Canny",
      "github_url": "https://github.com/lucataco/cog-sdxl-controlnet",
      "license_url": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/LICENSE.md",
      "name": "sdxl-controlnet",
      "owner": "lucataco",
      "paper_url": null,
      "run_count": 2053727,
      "url": "https://replicate.com/lucataco/sdxl-controlnet",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "image",
      "prompt"
    ]
  },
  {
    "title": "SDXL Ad Inpaint",
    "description": "Product advertising image generator using SDXL",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.SDXL_Ad_Inpaint",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Empty or 0 for a random image",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Remove background from this image",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Describe the new setting for your product",
        "min": null,
        "max": null
      },
      {
        "name": "img_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "512, 2048",
            "512, 1984",
            "512, 1920",
            "512, 1856",
            "576, 1792",
            "576, 1728",
            "576, 1664",
            "640, 1600",
            "640, 1536",
            "704, 1472",
            "704, 1408",
            "704, 1344",
            "768, 1344",
            "768, 1280",
            "832, 1216",
            "832, 1152",
            "896, 1152",
            "896, 1088",
            "960, 1088",
            "960, 1024",
            "1024, 1024",
            "1024, 960",
            "1088, 960",
            "1088, 896",
            "1152, 896",
            "1152, 832",
            "1216, 832",
            "1280, 768",
            "1344, 768",
            "1408, 704",
            "1472, 704",
            "1536, 640",
            "1600, 640",
            "1664, 576",
            "1728, 576",
            "1792, 576",
            "1856, 512",
            "1920, 512",
            "1984, 512",
            "2048, 512"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Img_size"
        },
        "default": "1024, 1024",
        "title": "Img Size",
        "description": "Possible SDXL image sizes",
        "min": null,
        "max": null
      },
      {
        "name": "apply_img",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Apply Img",
        "description": "Applies the original product image to the final result",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DDIM",
            "DPMSolverMultistep",
            "HeunDiscrete",
            "KarrasDPM",
            "K_EULER_ANCESTRAL",
            "K_EULER",
            "PNDM"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Scheduler"
        },
        "default": "K_EULER",
        "title": "Scheduler",
        "description": "scheduler",
        "min": null,
        "max": null
      },
      {
        "name": "product_fill",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "Original",
            "80",
            "70",
            "60",
            "50",
            "40",
            "30",
            "20"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Product_fill"
        },
        "default": "Original",
        "title": "Product Fill",
        "description": "What percentage of the image width to fill with product",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Guidance Scale",
        "min": null,
        "max": null
      },
      {
        "name": "condition_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.9,
        "title": "Condition Scale",
        "description": "controlnet conditioning scale for generalization",
        "min": 0.3,
        "max": 0.9
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "low quality, out of frame, illustration, 3d, sepia, painting, cartoons, sketch, watermark, text, Logo, advertisement",
        "title": "Negative Prompt",
        "description": "Describe what you do not want in your setting",
        "min": null,
        "max": null
      },
      {
        "name": "num_refine_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 10,
        "title": "Num Refine Steps",
        "description": "Number of steps to refine",
        "min": 0.0,
        "max": 40.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 40,
        "title": "Num Inference Steps",
        "description": "Inference Steps",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://pbxt.replicate.delivery/ORbuWtoy0y6NI9f4DrJ2fxs92LgviBaOlzOVdYTr3pT8eKJjA/7-out.png",
      "created_at": "2023-09-15T15:37:19.970710Z",
      "description": "Product advertising image generator using SDXL",
      "github_url": "https://github.com/CatacoLabs/cog-sdxl-ad-inpaint",
      "license_url": "https://github.com/huggingface/hfapi/blob/master/LICENSE",
      "name": "sdxl-ad-inpaint",
      "owner": "catacolabs",
      "paper_url": null,
      "run_count": 333522,
      "url": "https://replicate.com/catacolabs/sdxl-ad-inpaint",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "image",
      "prompt"
    ]
  },
  {
    "title": "Kandinsky",
    "description": "multilingual text2image latent diffusion model",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Kandinsky",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Leave blank to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            384,
            512,
            576,
            640,
            704,
            768,
            960,
            1024,
            1152,
            1280,
            1536,
            1792,
            2048
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Width"
        },
        "default": 512,
        "title": "Width",
        "description": "Width of output image. Lower the setting if hits memory limits.",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            384,
            512,
            576,
            640,
            704,
            768,
            960,
            1024,
            1152,
            1280,
            1536,
            1792,
            2048
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Height"
        },
        "default": 512,
        "title": "Height",
        "description": "Height of output image. Lower the setting if hits memory limits.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "A moss covered astronaut with a black background",
        "title": "Prompt",
        "description": "Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of images to output.",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpeg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Output image format",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Negative Prompt",
        "description": "Specify things to not see in the output",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 75,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps",
        "min": 1.0,
        "max": 500.0
      },
      {
        "name": "num_inference_steps_prior",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Inference Steps Prior",
        "description": "Number of denoising steps for priors",
        "min": 1.0,
        "max": 500.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/618e68d3-fba3-4fd0-a060-cdd46b2ab7cf/out-0_2.jpg",
      "created_at": "2023-07-12T21:53:29.439515Z",
      "description": "multilingual text2image latent diffusion model",
      "github_url": "https://github.com/chenxwh/Kandinsky-2/tree/v2.2",
      "license_url": "https://github.com/ai-forever/Kandinsky-2/blob/main/license",
      "name": "kandinsky-2.2",
      "owner": "ai-forever",
      "paper_url": null,
      "run_count": 10011590,
      "url": "https://replicate.com/ai-forever/kandinsky-2.2",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "width",
      "height"
    ]
  },
  {
    "title": "Stable Diffusion XLLightning",
    "description": "SDXL-Lightning by ByteDance: a fast text-to-image model that makes high-quality images in 4 steps",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.StableDiffusionXLLightning",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Leave blank to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "Width of output image. Recommended 1024 or 1280",
        "min": 256.0,
        "max": 1280.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "Height of output image. Recommended 1024 or 1280",
        "min": 256.0,
        "max": 1280.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "self-portrait of a woman, lightning in the background",
        "title": "Prompt",
        "description": "Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DDIM",
            "DPMSolverMultistep",
            "HeunDiscrete",
            "KarrasDPM",
            "K_EULER_ANCESTRAL",
            "K_EULER",
            "PNDM",
            "DPM++2MSDE"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Scheduler"
        },
        "default": "K_EULER",
        "title": "Scheduler",
        "description": "scheduler",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of images to output.",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Guidance Scale",
        "description": "Scale for classifier-free guidance",
        "min": 0.0,
        "max": 50.0
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "worst quality, low quality",
        "title": "Negative Prompt",
        "description": "Negative Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. 4 for best results",
        "min": 1.0,
        "max": 10.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/779f3f58-c3db-4403-a01b-3ffed97a1449/out-0-1.jpg",
      "created_at": "2024-02-21T07:36:15.534380Z",
      "description": "SDXL-Lightning by ByteDance: a fast text-to-image model that makes high-quality images in 4 steps",
      "github_url": "https://github.com/lucataco/cog-sdxl-lightning-4step",
      "license_url": "https://huggingface.co/ByteDance/SDXL-Lightning/blob/main/LICENSE.md",
      "name": "sdxl-lightning-4step",
      "owner": "bytedance",
      "paper_url": "https://huggingface.co/ByteDance/SDXL-Lightning/resolve/main/sdxl_lightning_report.pdf",
      "run_count": 689509556,
      "url": "https://replicate.com/bytedance/sdxl-lightning-4step",
      "visibility": "public",
      "weights_url": "https://huggingface.co/ByteDance/SDXL-Lightning"
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "width",
      "height"
    ]
  },
  {
    "title": "Playground V 2",
    "description": "Playground v2.5 is the state-of-the-art open-source model in aesthetic quality",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.PlaygroundV2",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Mask",
        "description": "Input mask for inpaint mode. Black areas will be preserved, white areas will be inpainted.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Leave blank to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image for img2img or inpaint mode",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "Width of output image",
        "min": 256.0,
        "max": 1536.0
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "Height of output image",
        "min": 256.0,
        "max": 1536.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k",
        "title": "Prompt",
        "description": "Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DDIM",
            "DPMSolverMultistep",
            "HeunDiscrete",
            "K_EULER_ANCESTRAL",
            "K_EULER",
            "PNDM",
            "DPM++2MKarras",
            "DPMSolver++"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Scheduler"
        },
        "default": "DPMSolver++",
        "title": "Scheduler",
        "description": "Scheduler. DPMSolver++ or DPM++2MKarras is recommended for most cases",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of images to output.",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Guidance Scale",
        "description": "Scale for classifier-free guidance",
        "min": 0.1,
        "max": 20.0
      },
      {
        "name": "apply_watermark",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Apply Watermark",
        "description": "Applies a watermark to enable determining if an image is generated in downstream applications. If you have other provisions for generating or deploying images safely, you can use this to disable watermarking.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "ugly, deformed, noisy, blurry, distorted",
        "title": "Negative Prompt",
        "description": "Negative Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Prompt Strength",
        "description": "Prompt strength when using img2img / inpaint. 1.0 corresponds to full destruction of information in image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 25,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps",
        "min": 1.0,
        "max": 60.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images. This feature is only available through the API. See https://replicate.com/docs/how-does-replicate-work#safety",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/b849582a-8699-4965-8016-3a51dc1da3d4/playground.jpeg",
      "created_at": "2024-02-27T22:20:16.107222Z",
      "description": "Playground v2.5 is the state-of-the-art open-source model in aesthetic quality",
      "github_url": "https://github.com/lucataco/cog-playground-v2.5-1024px-aesthetic",
      "license_url": "https://huggingface.co/playgroundai/playground-v2.5-1024px-aesthetic/blob/main/LICENSE.md",
      "name": "playground-v2.5-1024px-aesthetic",
      "owner": "playgroundai",
      "paper_url": "https://arxiv.org/abs/2206.00364",
      "run_count": 2055240,
      "url": "https://replicate.com/playgroundai/playground-v2.5-1024px-aesthetic",
      "visibility": "public",
      "weights_url": "https://huggingface.co/playgroundai/playground-v2.5-1024px-aesthetic"
    },
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "seed",
      "image"
    ]
  },
  {
    "title": "Proteus V 02",
    "description": "Proteus v0.2 shows subtle yet significant improvements over Version 0.1. It demonstrates enhanced prompt understanding that surpasses MJ6, while also approaching its stylistic capabilities.",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Proteus_V_02",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask",
        "description": "Input mask for inpaint mode. Black areas will be preserved, white areas will be inpainted.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Leave blank to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image for img2img or inpaint mode",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "Width of output image",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "Height of output image",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "black fluffy gorgeous dangerous cat animal creature, large orange eyes, big fluffy ears, piercing gaze, full moon, dark ambiance, best quality, extremely detailed",
        "title": "Prompt",
        "description": "Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DDIM",
            "DPMSolverMultistep",
            "HeunDiscrete",
            "KarrasDPM",
            "K_EULER_ANCESTRAL",
            "K_EULER",
            "PNDM"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Scheduler"
        },
        "default": "KarrasDPM",
        "title": "Scheduler",
        "description": "scheduler",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of images to output.",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Scale for classifier-free guidance. Recommended 7-8",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "apply_watermark",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Apply Watermark",
        "description": "Applies a watermark to enable determining if an image is generated in downstream applications. If you have other provisions for generating or deploying images safely, you can use this to disable watermarking.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "worst quality, low quality",
        "title": "Negative Prompt",
        "description": "Negative Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Prompt Strength",
        "description": "Prompt strength when using img2img / inpaint. 1.0 corresponds to full destruction of information in image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. 20 to 35 steps for more detail, 20 steps for faster results.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images. This feature is only available through the API. See https://replicate.com/docs/how-does-replicate-work#safety",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/pbxt/1nrcrEszpsb0Kpv0qNBJrtQjoefjHJ3xSh3whVOJcklSFxPSA/out-0.png",
      "created_at": "2024-01-24T17:45:49.361192Z",
      "description": "Proteus v0.2 shows subtle yet significant improvements over Version 0.1. It demonstrates enhanced prompt understanding that surpasses MJ6, while also approaching its stylistic capabilities.",
      "github_url": "https://github.com/lucataco/cog-proteus-v0.2",
      "license_url": "https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/gpl-3.0.md",
      "name": "proteus-v0.2",
      "owner": "datacte",
      "paper_url": null,
      "run_count": 8671991,
      "url": "https://replicate.com/datacte/proteus-v0.2",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "seed",
      "image"
    ]
  },
  {
    "title": "Proteus V 03",
    "description": "ProteusV0.3: The Anime Update",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Proteus_V_03",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask",
        "description": "Input mask for inpaint mode. Black areas will be preserved, white areas will be inpainted.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Leave blank to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image for img2img or inpaint mode",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "Width of output image. Recommended 1024 or 1280",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "Height of output image. Recommended 1024 or 1280",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Anime full body portrait of a swordsman holding his weapon in front of him. He is facing the camera with a fierce look on his face. Anime key visual (best quality, HD, ~+~aesthetic~+~:1.2)",
        "title": "Prompt",
        "description": "Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DDIM",
            "DPMSolverMultistep",
            "HeunDiscrete",
            "KarrasDPM",
            "K_EULER_ANCESTRAL",
            "K_EULER",
            "PNDM",
            "DPM++2MSDE"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Scheduler"
        },
        "default": "DPM++2MSDE",
        "title": "Scheduler",
        "description": "scheduler",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of images to output.",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Scale for classifier-free guidance. Recommended 7-8",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "apply_watermark",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Apply Watermark",
        "description": "Applies a watermark to enable determining if an image is generated in downstream applications. If you have other provisions for generating or deploying images safely, you can use this to disable watermarking.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "worst quality, low quality",
        "title": "Negative Prompt",
        "description": "Negative Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Prompt Strength",
        "description": "Prompt strength when using img2img / inpaint. 1.0 corresponds to full destruction of information in image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps. 20 to 60 steps for more detail, 20 steps for faster results.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "disable_safety_checker",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Disable Safety Checker",
        "description": "Disable safety checker for generated images. This feature is only available through the API. See https://replicate.com/docs/how-does-replicate-work#safety",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/pbxt/C3LYYa30997dKRdeNDSXNjIK01CH5q8CSto12eWundnPPtWSA/out-0.png",
      "created_at": "2024-02-14T20:02:04.901849Z",
      "description": "ProteusV0.3: The Anime Update",
      "github_url": "https://github.com/lucataco/cog-proteus-v0.3",
      "license_url": "https://huggingface.co/models?license=license:gpl-3.0",
      "name": "proteus-v0.3",
      "owner": "datacte",
      "paper_url": null,
      "run_count": 2701628,
      "url": "https://replicate.com/datacte/proteus-v0.3",
      "visibility": "public",
      "weights_url": "https://huggingface.co/dataautogpt3/ProteusV0.3"
    },
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "seed",
      "image"
    ]
  },
  {
    "title": "Sticker Maker",
    "description": "Make stickers with AI. Generates graphics with transparent backgrounds.",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.StickerMaker",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Fix the random seed for reproducibility",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 17,
        "title": "Steps",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1152,
        "title": "Width",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1152,
        "title": "Height",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "a cute cat",
        "title": "Prompt",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 90,
        "title": "Output Quality",
        "description": "Quality of the output images, from 0 to 100. 100 is best quality, 0 is lowest quality.",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Things you do not want in the image",
        "min": null,
        "max": null
      },
      {
        "name": "number_of_images",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Number Of Images",
        "description": "Number of images to generate",
        "min": 1.0,
        "max": 10.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/fb7cf2ea-aacd-458d-9d19-76dda21f9748/sticker-maker.webp",
      "created_at": "2024-02-23T11:59:22.452180Z",
      "description": "Make stickers with AI. Generates graphics with transparent backgrounds.",
      "github_url": "https://github.com/fofr/cog-stickers",
      "license_url": "https://github.com/fofr/cog-stickers/blob/main/LICENSE",
      "name": "sticker-maker",
      "owner": "fofr",
      "paper_url": null,
      "run_count": 604752,
      "url": "https://replicate.com/fofr/sticker-maker",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "steps",
      "width"
    ]
  },
  {
    "title": "Style Transfer",
    "description": "Transfer the style of one image to another",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.StyleTransfer",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Set a seed for reproducibility. Random by default.",
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "fast",
            "high-quality",
            "realistic",
            "cinematic",
            "animated"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Model"
        },
        "default": "fast",
        "title": "Model",
        "description": "Model to use for the generation",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Width",
        "description": "Width of the output image (ignored if structure image given)",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Height",
        "description": "Height of the output image (ignored if structure image given)",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "An astronaut riding a unicorn",
        "title": "Prompt",
        "description": "Prompt for the image",
        "min": null,
        "max": null
      },
      {
        "name": "style_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Style Image",
        "description": "Copy the style from this image",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Output_format"
        },
        "default": "webp",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "output_quality",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 80,
        "title": "Output Quality",
        "description": "Quality of the output images, from 0 to 100. 100 is best quality, 0 is lowest quality.",
        "min": 0.0,
        "max": 100.0
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Things you do not want to see in your image",
        "min": null,
        "max": null
      },
      {
        "name": "structure_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Structure Image",
        "description": "An optional image to copy structure from. Output images will use the same aspect ratio.",
        "min": null,
        "max": null
      },
      {
        "name": "number_of_images",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Number Of Images",
        "description": "Number of images to generate",
        "min": 1.0,
        "max": 10.0
      },
      {
        "name": "structure_depth_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Structure Depth Strength",
        "description": "Strength of the depth controlnet",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "structure_denoising_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.65,
        "title": "Structure Denoising Strength",
        "description": "How much of the original image (and colors) to preserve (0 is all, 1 is none, 0.65 is a good balance)",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/fd0ac369-c6ac-4927-b882-ece29cffc45d/cover.webp",
      "created_at": "2024-04-17T20:34:49.861066Z",
      "description": "Transfer the style of one image to another",
      "github_url": "https://github.com/fofr/cog-style-transfer",
      "license_url": "https://github.com/fofr/cog-style-transfer/blob/main/LICENSE",
      "name": "style-transfer",
      "owner": "fofr",
      "paper_url": null,
      "run_count": 542109,
      "url": "https://replicate.com/fofr/style-transfer",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "model",
      "width"
    ]
  },
  {
    "title": "Illusions",
    "description": "Create illusions with img2img and masking support",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Illusions",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Optional img2img",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 768,
        "title": "Width",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 768,
        "title": "Height",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "a painting of a 19th century town",
        "title": "Prompt",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "mask_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask Image",
        "description": "Optional mask for inpainting",
        "min": null,
        "max": null
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of outputs",
        "min": null,
        "max": null
      },
      {
        "name": "control_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Control Image",
        "description": "Control image",
        "min": null,
        "max": null
      },
      {
        "name": "controlnet_end",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Controlnet End",
        "description": "When controlnet conditioning ends",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Scale for classifier-free guidance",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "ugly, disfigured, low quality, blurry, nsfw",
        "title": "Negative Prompt",
        "description": "The negative prompt to guide image generation.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.8,
        "title": "Prompt Strength",
        "description": "Prompt strength when using img2img / inpaint. 1.0 corresponds to full destruction of information in image",
        "min": null,
        "max": null
      },
      {
        "name": "sizing_strategy",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "width/height",
            "input_image",
            "control_image"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Sizing_strategy"
        },
        "default": "width/height",
        "title": "Sizing Strategy",
        "description": "Decide how to resize images \u2013 use width/height, resize based on input image or control image",
        "min": null,
        "max": null
      },
      {
        "name": "controlnet_start",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Controlnet Start",
        "description": "When controlnet conditioning starts",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 40,
        "title": "Num Inference Steps",
        "description": "Number of diffusion steps",
        "min": null,
        "max": null
      },
      {
        "name": "controlnet_conditioning_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.75,
        "title": "Controlnet Conditioning Scale",
        "description": "How strong the controlnet conditioning is",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/xezq/iA3MUV1f533LXqi4sHVlAerJhr03uES9OlBHAHrqaeq92ArnA/output-0.png",
      "created_at": "2023-11-03T17:24:31.993569Z",
      "description": "Create illusions with img2img and masking support",
      "github_url": "https://github.com/fofr/cog-illusion",
      "license_url": null,
      "name": "illusions",
      "owner": "fofr",
      "paper_url": null,
      "run_count": 39343,
      "url": "https://replicate.com/fofr/illusions",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "image",
      "width"
    ]
  },
  {
    "title": "Ideogram V 2",
    "description": "An excellent image model with state of the art inpainting, prompt comprehension and text rendering",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Ideogram_V2",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask",
        "description": "A black and white image. Black pixels are inpainted, white pixels are preserved. The mask will be resized to match the image size.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "An image file to use for inpainting.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Text prompt for image generation",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "None",
            "512x1536",
            "576x1408",
            "576x1472",
            "576x1536",
            "640x1024",
            "640x1344",
            "640x1408",
            "640x1472",
            "640x1536",
            "704x1152",
            "704x1216",
            "704x1280",
            "704x1344",
            "704x1408",
            "704x1472",
            "720x1280",
            "736x1312",
            "768x1024",
            "768x1088",
            "768x1152",
            "768x1216",
            "768x1232",
            "768x1280",
            "768x1344",
            "832x960",
            "832x1024",
            "832x1088",
            "832x1152",
            "832x1216",
            "832x1248",
            "864x1152",
            "896x960",
            "896x1024",
            "896x1088",
            "896x1120",
            "896x1152",
            "960x832",
            "960x896",
            "960x1024",
            "960x1088",
            "1024x640",
            "1024x768",
            "1024x832",
            "1024x896",
            "1024x960",
            "1024x1024",
            "1088x768",
            "1088x832",
            "1088x896",
            "1088x960",
            "1120x896",
            "1152x704",
            "1152x768",
            "1152x832",
            "1152x864",
            "1152x896",
            "1216x704",
            "1216x768",
            "1216x832",
            "1232x768",
            "1248x832",
            "1280x704",
            "1280x720",
            "1280x768",
            "1280x800",
            "1312x736",
            "1344x640",
            "1344x704",
            "1344x768",
            "1408x576",
            "1408x640",
            "1408x704",
            "1472x576",
            "1472x640",
            "1472x704",
            "1536x512",
            "1536x576",
            "1536x640"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Resolution"
        },
        "default": "None",
        "title": "Resolution",
        "description": "Resolution. Overrides aspect ratio. Ignored if an inpainting image is given.",
        "min": null,
        "max": null
      },
      {
        "name": "style_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "None",
            "Auto",
            "General",
            "Realistic",
            "Design",
            "Render 3D",
            "Anime"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Style_type"
        },
        "default": "None",
        "title": "Style Type",
        "description": "The styles help define the specific aesthetic of the image you want to generate.",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1:1",
            "16:9",
            "9:16",
            "4:3",
            "3:4",
            "3:2",
            "2:3",
            "16:10",
            "10:16",
            "3:1",
            "1:3"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Aspect_ratio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "Aspect ratio. Ignored if a resolution or inpainting image is given.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Negative Prompt",
        "description": "Things you do not want to see in the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "magic_prompt_option",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "Auto",
            "On",
            "Off"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Magic_prompt_option"
        },
        "default": "Auto",
        "title": "Magic Prompt Option",
        "description": "Magic Prompt will interpret your prompt and optimize it to maximize variety and quality of the images generated. You can also use it to write prompts in different languages.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/71c982a3-27f0-42a6-ad6a-769f25097c08/replicate-prediction-s_VROPz1s.png",
      "created_at": "2024-10-22T09:26:23.607119Z",
      "description": "An excellent image model with state of the art inpainting, prompt comprehension and text rendering",
      "github_url": null,
      "license_url": "https://about.ideogram.ai/legal/api-tos",
      "name": "ideogram-v2",
      "owner": "ideogram-ai",
      "paper_url": "https://ideogram.ai/",
      "run_count": 323579,
      "url": "https://replicate.com/ideogram-ai/ideogram-v2",
      "visibility": "public",
      "weights_url": "https://ideogram.ai/"
    },
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "seed",
      "image"
    ]
  },
  {
    "title": "Ideogram V 2 Turbo",
    "description": "A fast image model with state of the art inpainting, prompt comprehension and text rendering.",
    "namespace": "replicate.image.generate",
    "node_type": "replicate.image.generate.Ideogram_V2_Turbo",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask",
        "description": "A black and white image. Black pixels are inpainted, white pixels are preserved. The mask will be resized to match the image size.",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Set for reproducible generation",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "An image file to use for inpainting.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Text prompt for image generation",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "None",
            "512x1536",
            "576x1408",
            "576x1472",
            "576x1536",
            "640x1024",
            "640x1344",
            "640x1408",
            "640x1472",
            "640x1536",
            "704x1152",
            "704x1216",
            "704x1280",
            "704x1344",
            "704x1408",
            "704x1472",
            "720x1280",
            "736x1312",
            "768x1024",
            "768x1088",
            "768x1152",
            "768x1216",
            "768x1232",
            "768x1280",
            "768x1344",
            "832x960",
            "832x1024",
            "832x1088",
            "832x1152",
            "832x1216",
            "832x1248",
            "864x1152",
            "896x960",
            "896x1024",
            "896x1088",
            "896x1120",
            "896x1152",
            "960x832",
            "960x896",
            "960x1024",
            "960x1088",
            "1024x640",
            "1024x768",
            "1024x832",
            "1024x896",
            "1024x960",
            "1024x1024",
            "1088x768",
            "1088x832",
            "1088x896",
            "1088x960",
            "1120x896",
            "1152x704",
            "1152x768",
            "1152x832",
            "1152x864",
            "1152x896",
            "1216x704",
            "1216x768",
            "1216x832",
            "1232x768",
            "1248x832",
            "1280x704",
            "1280x720",
            "1280x768",
            "1280x800",
            "1312x736",
            "1344x640",
            "1344x704",
            "1344x768",
            "1408x576",
            "1408x640",
            "1408x704",
            "1472x576",
            "1472x640",
            "1472x704",
            "1536x512",
            "1536x576",
            "1536x640"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Resolution"
        },
        "default": "None",
        "title": "Resolution",
        "description": "Resolution. Overrides aspect ratio. Ignored if an inpainting image is given.",
        "min": null,
        "max": null
      },
      {
        "name": "style_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "None",
            "Auto",
            "General",
            "Realistic",
            "Design",
            "Render 3D",
            "Anime"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Style_type"
        },
        "default": "None",
        "title": "Style Type",
        "description": "The styles help define the specific aesthetic of the image you want to generate.",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1:1",
            "16:9",
            "9:16",
            "4:3",
            "3:4",
            "3:2",
            "2:3",
            "16:10",
            "10:16",
            "3:1",
            "1:3"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Aspect_ratio"
        },
        "default": "1:1",
        "title": "Aspect Ratio",
        "description": "Aspect ratio. Ignored if a resolution or inpainting image is given.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Negative Prompt",
        "description": "Things you do not want to see in the generated image.",
        "min": null,
        "max": null
      },
      {
        "name": "magic_prompt_option",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "Auto",
            "On",
            "Off"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.generate.Magic_prompt_option"
        },
        "default": "Auto",
        "title": "Magic Prompt Option",
        "description": "Magic Prompt will interpret your prompt and optimize it to maximize variety and quality of the images generated. You can also use it to write prompts in different languages.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/8b1df940-d741-4446-beb2-0d72c66abb91/replicate-prediction-f_iX48w8f.png",
      "created_at": "2024-10-22T09:29:41.547244Z",
      "description": "A fast image model with state of the art inpainting, prompt comprehension and text rendering.",
      "github_url": null,
      "license_url": "https://about.ideogram.ai/legal/api-tos",
      "name": "ideogram-v2-turbo",
      "owner": "ideogram-ai",
      "paper_url": "https://ideogram.ai/",
      "run_count": 214570,
      "url": "https://replicate.com/ideogram-ai/ideogram-v2-turbo",
      "visibility": "public",
      "weights_url": "https://ideogram.ai/"
    },
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "seed",
      "image"
    ]
  },
  {
    "title": "Text Extract OCR",
    "description": "A simple OCR Model that can easily extract text from an image.",
    "namespace": "replicate.image.ocr",
    "node_type": "replicate.image.ocr.TextExtractOCR",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Image to process",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/9d31603c-2266-4705-9d2d-01b4f6bff653/IM0077782.png",
      "created_at": "2023-10-19T13:20:00.740943Z",
      "description": "A simple OCR Model that can easily extract text from an image.",
      "github_url": null,
      "license_url": null,
      "name": "text-extract-ocr",
      "owner": "abiruyt",
      "paper_url": null,
      "run_count": 89578954,
      "url": "https://replicate.com/abiruyt/text-extract-ocr",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Latex OCR",
    "description": "Optical character recognition to turn images of latex equations into latex format.",
    "namespace": "replicate.image.ocr",
    "node_type": "replicate.image.ocr.LatexOCR",
    "layout": "default",
    "properties": [
      {
        "name": "image_path",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Image Path",
        "description": "Input image",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/980ae6b5-4ab8-417a-8148-b244f4ae0493/latex.png",
      "created_at": "2023-11-06T10:13:47.198885Z",
      "description": "Optical character recognition to turn images of latex equations into latex format.",
      "github_url": "https://github.com/mickeybeurskens/LaTeX-OCR",
      "license_url": "https://github.com/mickeybeurskens/LaTeX-OCR/blob/main/LICENSE",
      "name": "latex-ocr",
      "owner": "mickeybeurskens",
      "paper_url": null,
      "run_count": 808,
      "url": "https://replicate.com/mickeybeurskens/latex-ocr",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "image_path"
    ]
  },
  {
    "title": "Remove Background",
    "description": "Remove images background",
    "namespace": "replicate.image.process",
    "node_type": "replicate.image.process.RemoveBackground",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/pbxt/2hczaMwD9xrsIR8h3Cl8iYGbHaCdFhIOMZ0LfoYfHlKuuIBQA/out.png",
      "created_at": "2022-11-18T00:55:22.939155Z",
      "description": "Remove images background",
      "github_url": "https://github.com/chenxwh/rembg/tree/replicate",
      "license_url": "https://github.com/danielgatis/rembg/blob/main/LICENSE.txt",
      "name": "rembg",
      "owner": "cjwbw",
      "paper_url": null,
      "run_count": 7573408,
      "url": "https://replicate.com/cjwbw/rembg",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "Mod Net",
    "description": "A deep learning approach to remove background & adding new background image",
    "namespace": "replicate.image.process",
    "node_type": "replicate.image.process.ModNet",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "input image",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/bb0ab3e4-5efa-446f-939a-23e78f2b82de/output.png",
      "created_at": "2022-11-19T04:56:59.860128Z",
      "description": "A deep learning approach to remove background & adding new background image",
      "github_url": "https://github.com/pollinations/MODNet-BGRemover",
      "license_url": null,
      "name": "modnet",
      "owner": "pollinations",
      "paper_url": "https://arxiv.org/pdf/2011.11961.pdf",
      "run_count": 618937,
      "url": "https://replicate.com/pollinations/modnet",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "image"
    ]
  },
  {
    "title": "DD Color",
    "description": "Towards Photo-Realistic Image Colorization via Dual Decoders",
    "namespace": "replicate.image.process",
    "node_type": "replicate.image.process.DD_Color",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Image",
        "description": "Grayscale input image.",
        "min": null,
        "max": null
      },
      {
        "name": "model_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "large",
            "tiny"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.process.Model_size"
        },
        "default": "large",
        "title": "Model Size",
        "description": "Choose the model size.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/d8d3648a-044e-4474-8392-87d52c0c2c68/ddcolor.jpg",
      "created_at": "2024-01-12T15:02:06.387410Z",
      "description": "Towards Photo-Realistic Image Colorization via Dual Decoders",
      "github_url": "https://github.com/piddnad/DDColor",
      "license_url": "https://github.com/piddnad/DDColor/blob/master/LICENSE",
      "name": "ddcolor",
      "owner": "piddnad",
      "paper_url": "https://arxiv.org/abs/2212.11613",
      "run_count": 177834,
      "url": "https://replicate.com/piddnad/ddcolor",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "image",
      "model_size"
    ]
  },
  {
    "title": "Magic Style Transfer",
    "description": "Restyle an image with the style of another one. I strongly suggest to upscale the results with Clarity AI",
    "namespace": "replicate.image.process",
    "node_type": "replicate.image.process.Magic_Style_Transfer",
    "layout": "default",
    "properties": [
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Leave blank to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "An astronaut riding a rainbow unicorn",
        "title": "Prompt",
        "description": "Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "ip_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Ip Image",
        "description": "Input image for img2img or inpaint mode",
        "min": null,
        "max": null
      },
      {
        "name": "ip_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.3,
        "title": "Ip Scale",
        "description": "IP Adapter strength.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.9,
        "title": "Strength",
        "description": "When img2img is active, the denoising strength. 1 means total destruction of the input image.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DDIM",
            "DPMSolverMultistep",
            "HeunDiscrete",
            "KarrasDPM",
            "K_EULER_ANCESTRAL",
            "K_EULER",
            "PNDM"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.process.Scheduler"
        },
        "default": "K_EULER",
        "title": "Scheduler",
        "description": "scheduler",
        "min": null,
        "max": null
      },
      {
        "name": "lora_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.9,
        "title": "Lora Scale",
        "description": "LoRA additive scale. Only applicable on trained models.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "num_outputs",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Num Outputs",
        "description": "Number of images to output",
        "min": 1.0,
        "max": 4.0
      },
      {
        "name": "lora_weights",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Lora Weights",
        "description": "Replicate LoRA weights to use. Leave blank to use the default weights.",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Guidance Scale",
        "description": "Scale for classifier-free guidance",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "resizing_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Resizing Scale",
        "description": "If you want the image to have a solid margin. Scale of the solid margin. 1.0 means no resizing.",
        "min": 1.0,
        "max": 10.0
      },
      {
        "name": "apply_watermark",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Apply Watermark",
        "description": "Applies a watermark to enable determining if an image is generated in downstream applications. If you have other provisions for generating or deploying images safely, you can use this to disable watermarking.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Input Negative Prompt",
        "min": null,
        "max": null
      },
      {
        "name": "background_color",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "#A2A2A2",
        "title": "Background Color",
        "description": "When passing an image with alpha channel, it will be replaced with this color",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps",
        "min": 1.0,
        "max": 500.0
      },
      {
        "name": "condition_canny_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.15,
        "title": "Condition Canny Scale",
        "description": "The bigger this number is, the more ControlNet interferes",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "condition_depth_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.35,
        "title": "Condition Depth Scale",
        "description": "The bigger this number is, the more ControlNet interferes",
        "min": 0.0,
        "max": 2.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/pbxt/CgdTGuA9wdoWGhVUMgpPIv9mh4rpLnYYViUmeLKV8wF2QGRJA/out-0.png",
      "created_at": "2024-03-20T16:20:23.445929Z",
      "description": "Restyle an image with the style of another one. I strongly suggest to upscale the results with Clarity AI",
      "github_url": "https://github.com/BatouResearch/Cog-Face-to-Anything/tree/magic-style-transfer",
      "license_url": null,
      "name": "magic-style-transfer",
      "owner": "batouresearch",
      "paper_url": null,
      "run_count": 24650,
      "url": "https://replicate.com/batouresearch/magic-style-transfer",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "seed",
      "image",
      "prompt"
    ]
  },
  {
    "title": "Object Remover",
    "description": "None",
    "namespace": "replicate.image.process",
    "node_type": "replicate.image.process.ObjectRemover",
    "layout": "default",
    "properties": [
      {
        "name": "org_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Org Image",
        "description": "Original input image",
        "min": null,
        "max": null
      },
      {
        "name": "mask_image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask Image",
        "description": "Mask image",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/pbxt/PeUSD8TLKs0lXSTavj96kkOSfpoAKhRIG8LY5U0erX53QgskA/in-painted.png",
      "created_at": "2024-02-13T07:17:58.590961Z",
      "description": null,
      "github_url": null,
      "license_url": null,
      "name": "object_remover",
      "owner": "codeplugtech",
      "paper_url": null,
      "run_count": 5365,
      "url": "https://replicate.com/codeplugtech/object_remover",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "org_image",
      "mask_image"
    ]
  },
  {
    "title": "Real Esr Gan",
    "description": "Real-ESRGAN for image upscaling on an A100",
    "namespace": "replicate.image.upscale",
    "node_type": "replicate.image.upscale.RealEsrGan",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      },
      {
        "name": "scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4,
        "title": "Scale",
        "description": "Factor to scale image by",
        "min": 0.0,
        "max": 10.0
      },
      {
        "name": "face_enhance",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Face Enhance",
        "description": "Run GFPGAN face enhancement along with upscaling",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/pbxt/lv0iOW3u6DrNOd30ybfmufqWebiuW10YjILw05YZGbeipZZCB/output.png",
      "created_at": "2023-03-10T22:36:15.201038Z",
      "description": "Real-ESRGAN for image upscaling on an A100",
      "github_url": "https://github.com/replicate/cog-real-esrgan",
      "license_url": "https://github.com/replicate/cog-real-esrgan/blob/main/LICENSE",
      "name": "real-esrgan-a100",
      "owner": "daanelson",
      "paper_url": null,
      "run_count": 12694507,
      "url": "https://replicate.com/daanelson/real-esrgan-a100",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "image",
      "scale",
      "face_enhance"
    ]
  },
  {
    "title": "GFPGAN",
    "description": "Practical face restoration algorithm for *old photos* or *AI-generated faces*",
    "namespace": "replicate.image.upscale",
    "node_type": "replicate.image.upscale.GFPGAN",
    "layout": "default",
    "properties": [
      {
        "name": "img",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Img",
        "description": "Input",
        "min": null,
        "max": null
      },
      {
        "name": "scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Scale",
        "description": "Rescaling factor",
        "min": null,
        "max": null
      },
      {
        "name": "version",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "v1.2",
            "v1.3",
            "v1.4",
            "RestoreFormer"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Version"
        },
        "default": "v1.4",
        "title": "Version",
        "description": "GFPGAN version. v1.3: better quality. v1.4: more details and better identity.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/40223a51-a460-4f27-b13a-bf5d6429b686/output_1.png",
      "created_at": "2021-09-15T22:08:48.809672Z",
      "description": "Practical face restoration algorithm for *old photos* or *AI-generated faces*",
      "github_url": "https://github.com/replicate/GFPGAN",
      "license_url": "https://github.com/TencentARC/GFPGAN/blob/master/LICENSE",
      "name": "gfpgan",
      "owner": "tencentarc",
      "paper_url": "https://arxiv.org/abs/2101.04061",
      "run_count": 84219663,
      "url": "https://replicate.com/tencentarc/gfpgan",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "img",
      "scale",
      "version"
    ]
  },
  {
    "title": "Clarity Upscaler",
    "description": "High resolution image Upscaler and Enhancer. Use at ClarityAI.co. A free Magnific alternative. Twitter/X: @philz1337x",
    "namespace": "replicate.image.upscale",
    "node_type": "replicate.image.upscale.ClarityUpscaler",
    "layout": "default",
    "properties": [
      {
        "name": "mask",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Mask",
        "description": "Mask image to mark areas that should be preserved during upscaling",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1337,
        "title": "Seed",
        "description": "Random seed. Leave blank to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "input image",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "masterpiece, best quality, highres, <lora:more_details:0.5> <lora:SDXLrender_v2.0:1>",
        "title": "Prompt",
        "description": "Prompt",
        "min": null,
        "max": null
      },
      {
        "name": "dynamic",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 6,
        "title": "Dynamic",
        "description": "HDR, try from 3 - 9",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "handfix",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "disabled",
            "hands_only",
            "image_and_hands"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Handfix"
        },
        "default": "disabled",
        "title": "Handfix",
        "description": "Use clarity to fix hands in the image",
        "min": null,
        "max": null
      },
      {
        "name": "pattern",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Pattern",
        "description": "Upscale a pattern with seamless tiling",
        "min": null,
        "max": null
      },
      {
        "name": "sharpen",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Sharpen",
        "description": "Sharpen the image after upscaling. The higher the value, the more sharpening is applied. 0 for no sharpening",
        "min": 0.0,
        "max": 10.0
      },
      {
        "name": "sd_model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "epicrealism_naturalSinRC1VAE.safetensors [84d76a0328]",
            "juggernaut_reborn.safetensors [338b85bc4f]",
            "flat2DAnimerge_v45Sharp.safetensors"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Sd_model"
        },
        "default": "juggernaut_reborn.safetensors [338b85bc4f]",
        "title": "Sd Model",
        "description": "Stable Diffusion model checkpoint",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DPM++ 2M Karras",
            "DPM++ SDE Karras",
            "DPM++ 2M SDE Exponential",
            "DPM++ 2M SDE Karras",
            "Euler a",
            "Euler",
            "LMS",
            "Heun",
            "DPM2",
            "DPM2 a",
            "DPM++ 2S a",
            "DPM++ 2M",
            "DPM++ SDE",
            "DPM++ 2M SDE",
            "DPM++ 2M SDE Heun",
            "DPM++ 2M SDE Heun Karras",
            "DPM++ 2M SDE Heun Exponential",
            "DPM++ 3M SDE",
            "DPM++ 3M SDE Karras",
            "DPM++ 3M SDE Exponential",
            "DPM fast",
            "DPM adaptive",
            "LMS Karras",
            "DPM2 Karras",
            "DPM2 a Karras",
            "DPM++ 2S a Karras",
            "Restart",
            "DDIM",
            "PLMS",
            "UniPC"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Scheduler"
        },
        "default": "DPM++ 3M SDE Karras",
        "title": "Scheduler",
        "description": "scheduler",
        "min": null,
        "max": null
      },
      {
        "name": "creativity",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.35,
        "title": "Creativity",
        "description": "Creativity, try from 0.3 - 0.9",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "lora_links",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Lora Links",
        "description": "Link to a lora file you want to use in your upscaling. Multiple links possible, seperated by comma",
        "min": null,
        "max": null
      },
      {
        "name": "downscaling",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Downscaling",
        "description": "Downscale the image before upscaling. Can improve quality and speed for images with high resolution but lower quality",
        "min": null,
        "max": null
      },
      {
        "name": "resemblance",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.6,
        "title": "Resemblance",
        "description": "Resemblance, try from 0.3 - 1.6",
        "min": 0.0,
        "max": 3.0
      },
      {
        "name": "scale_factor",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Scale Factor",
        "description": "Scale factor",
        "min": null,
        "max": null
      },
      {
        "name": "tiling_width",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            16,
            32,
            48,
            64,
            80,
            96,
            112,
            128,
            144,
            160,
            176,
            192,
            208,
            224,
            240,
            256
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Tiling_width"
        },
        "default": 112,
        "title": "Tiling Width",
        "description": "Fractality, set lower tile width for a high Fractality",
        "min": null,
        "max": null
      },
      {
        "name": "output_format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "webp",
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Output_format"
        },
        "default": "png",
        "title": "Output Format",
        "description": "Format of the output images",
        "min": null,
        "max": null
      },
      {
        "name": "tiling_height",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            16,
            32,
            48,
            64,
            80,
            96,
            112,
            128,
            144,
            160,
            176,
            192,
            208,
            224,
            240,
            256
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Tiling_height"
        },
        "default": 144,
        "title": "Tiling Height",
        "description": "Fractality, set lower tile height for a high Fractality",
        "min": null,
        "max": null
      },
      {
        "name": "custom_sd_model",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Custom Sd Model",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "(worst quality, low quality, normal quality:2) JuggernautNegative-neg",
        "title": "Negative Prompt",
        "description": "Negative Prompt",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 18,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "downscaling_resolution",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 768,
        "title": "Downscaling Resolution",
        "description": "Downscaling resolution",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/76fbe6df-517d-480a-a6e4-dce383b40bbb/Bildschirmfoto_2024-03-30_um_09.2.png",
      "created_at": "2024-03-15T02:35:32.167345Z",
      "description": "High resolution image Upscaler and Enhancer. Use at ClarityAI.co. A free Magnific alternative. Twitter/X: @philz1337x",
      "github_url": "https://github.com/philz1337x/clarity-upscaler",
      "license_url": "https://github.com/philz1337x/clarity-upscaler/blob/main/LICENSE.txt",
      "name": "clarity-upscaler",
      "owner": "philz1337x",
      "paper_url": "https://clarityai.co",
      "run_count": 7768565,
      "url": "https://replicate.com/philz1337x/clarity-upscaler",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "mask",
      "seed",
      "image"
    ]
  },
  {
    "title": "Magic Image Refiner",
    "description": "A better alternative to SDXL refiners, providing a lot of quality and detail. Can also be used for inpainting or upscaling.",
    "namespace": "replicate.image.upscale",
    "node_type": "replicate.image.upscale.MagicImageRefiner",
    "layout": "default",
    "properties": [
      {
        "name": "hdr",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Hdr",
        "description": "HDR improvement over the original image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "mask",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Mask",
        "description": "When provided, refines some section of the image. Must be the same size as the image",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Seed",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Image to refine",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Steps",
        "description": "Steps",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Prompt for the model",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DDIM",
            "DPMSolverMultistep",
            "K_EULER_ANCESTRAL",
            "K_EULER"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Scheduler"
        },
        "default": "DDIM",
        "title": "Scheduler",
        "description": "Choose a scheduler.",
        "min": null,
        "max": null
      },
      {
        "name": "creativity",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.25,
        "title": "Creativity",
        "description": "Denoising strength. 1 means total destruction of the original image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "guess_mode",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Guess Mode",
        "description": "In this mode, the ControlNet encoder will try best to recognize the content of the input image even if you remove all prompts. The `guidance_scale` between 3.0 and 5.0 is recommended.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "original",
            "1024",
            "2048"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Resolution"
        },
        "default": "original",
        "title": "Resolution",
        "description": "Image resolution",
        "min": null,
        "max": null
      },
      {
        "name": "resemblance",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.75,
        "title": "Resemblance",
        "description": "Conditioning scale for controlnet",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7,
        "title": "Guidance Scale",
        "description": "Scale for classifier-free guidance",
        "min": 0.1,
        "max": 30.0
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "teeth, tooth, open mouth, longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, mutant",
        "title": "Negative Prompt",
        "description": "Negative prompt",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/pbxt/H3ZmqoAgsBonKFilPafiEsvYsc2FnjD8EW3vMt6KpkYfd0ISA/out-0.png",
      "created_at": "2024-01-03T16:55:24.594128Z",
      "description": "A better alternative to SDXL refiners, providing a lot of quality and detail. Can also be used for inpainting or upscaling.",
      "github_url": "https://github.com/BatouResearch/magic-image-refiner",
      "license_url": null,
      "name": "magic-image-refiner",
      "owner": "batouresearch",
      "paper_url": null,
      "run_count": 914817,
      "url": "https://replicate.com/batouresearch/magic-image-refiner",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "hdr",
      "mask",
      "seed"
    ]
  },
  {
    "title": "ru Dall E SR",
    "description": "Real-ESRGAN super-resolution model from ruDALL-E",
    "namespace": "replicate.image.upscale",
    "node_type": "replicate.image.upscale.ruDallE_SR",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      },
      {
        "name": "scale",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            2,
            4,
            8
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Scale"
        },
        "default": 4,
        "title": "Scale",
        "description": "Choose up-scaling factor",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://replicate.delivery/mgxm/588170af-559f-454e-967d-8fb6c7f8304b/out.png",
      "created_at": "2021-11-04T18:36:03.485750Z",
      "description": "Real-ESRGAN super-resolution model from ruDALL-E",
      "github_url": "https://github.com/CJWBW/rudalle-sr",
      "license_url": "https://github.com/chenxwh/rudalle-sr/blob/main/LICENSE.txt",
      "name": "rudalle-sr",
      "owner": "cjwbw",
      "paper_url": "https://arxiv.org/abs/2107.10833",
      "run_count": 482456,
      "url": "https://replicate.com/cjwbw/rudalle-sr",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "image",
      "scale"
    ]
  },
  {
    "title": "High Resolution Control Net Tile",
    "description": "UPDATE: new upscaling algorithm for a much improved image quality. Fermat.app open-source implementation of an efficient ControlNet 1.1 tile for high-quality upscales. Increase the creativity to encourage hallucination.",
    "namespace": "replicate.image.upscale",
    "node_type": "replicate.image.upscale.HighResolutionControlNetTile",
    "layout": "default",
    "properties": [
      {
        "name": "hdr",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Hdr",
        "description": "HDR improvement over the original image",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Seed",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Control image for scribble controlnet",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8,
        "title": "Steps",
        "description": "Steps",
        "min": null,
        "max": null
      },
      {
        "name": "format",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "jpg",
            "png"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Format"
        },
        "default": "jpg",
        "title": "Format",
        "description": "Format of the output.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Prompt for the model",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DDIM",
            "DPMSolverMultistep",
            "K_EULER_ANCESTRAL",
            "K_EULER"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Scheduler"
        },
        "default": "DDIM",
        "title": "Scheduler",
        "description": "Choose a scheduler.",
        "min": null,
        "max": null
      },
      {
        "name": "creativity",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.35,
        "title": "Creativity",
        "description": "Denoising strength. 1 means total destruction of the original image",
        "min": 0.1,
        "max": 1.0
      },
      {
        "name": "guess_mode",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Guess Mode",
        "description": "In this mode, the ControlNet encoder will try best to recognize the content of the input image even if you remove all prompts.",
        "min": null,
        "max": null
      },
      {
        "name": "resolution",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            2048,
            2560,
            4096
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Resolution"
        },
        "default": 2560,
        "title": "Resolution",
        "description": "Image resolution",
        "min": null,
        "max": null
      },
      {
        "name": "resemblance",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.85,
        "title": "Resemblance",
        "description": "Conditioning scale for controlnet",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Guidance Scale",
        "description": "Scale for classifier-free guidance, should be 0.",
        "min": 0.0,
        "max": 30.0
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "teeth, tooth, open mouth, longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, mutant",
        "title": "Negative Prompt",
        "description": "Negative prompt",
        "min": null,
        "max": null
      },
      {
        "name": "lora_details_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Lora Details Strength",
        "description": "Strength of the image's details",
        "min": -5.0,
        "max": 3.0
      },
      {
        "name": "lora_sharpness_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.25,
        "title": "Lora Sharpness Strength",
        "description": "Strength of the image's sharpness. We don't recommend values above 2.",
        "min": -5.0,
        "max": 10.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/db4434b4-7b0f-49f7-b78a-774fe9e630a7/batou.jpeg",
      "created_at": "2023-12-08T02:32:38.082772Z",
      "description": "UPDATE: new upscaling algorithm for a much improved image quality. Fermat.app open-source implementation of an efficient ControlNet 1.1 tile for high-quality upscales. Increase the creativity to encourage hallucination.",
      "github_url": null,
      "license_url": null,
      "name": "high-resolution-controlnet-tile",
      "owner": "batouresearch",
      "paper_url": null,
      "run_count": 592194,
      "url": "https://replicate.com/batouresearch/high-resolution-controlnet-tile",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "hdr",
      "seed",
      "image"
    ]
  },
  {
    "title": "Ultimate SDUpscale",
    "description": "Ultimate SD Upscale with ControlNet Tile",
    "namespace": "replicate.image.upscale",
    "node_type": "replicate.image.upscale.UltimateSDUpscale",
    "layout": "default",
    "properties": [
      {
        "name": "cfg",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8,
        "title": "Cfg",
        "description": "CFG",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Sampling seed, leave Empty for Random",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 20,
        "title": "Steps",
        "description": "Steps",
        "min": null,
        "max": null
      },
      {
        "name": "denoise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.2,
        "title": "Denoise",
        "description": "Denoise",
        "min": null,
        "max": null
      },
      {
        "name": "upscaler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "4x_NMKD-Siax_200k",
            "4x-UltraSharp",
            "RealESRGAN_x4plus",
            "RealESRGAN_x4plus_anime_6B"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Upscaler"
        },
        "default": "4x-UltraSharp",
        "title": "Upscaler",
        "description": "Upscaler",
        "min": null,
        "max": null
      },
      {
        "name": "mask_blur",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8,
        "title": "Mask Blur",
        "description": "Mask Blur",
        "min": null,
        "max": null
      },
      {
        "name": "mode_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "Linear",
            "Chess",
            "None"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Mode_type"
        },
        "default": "Linear",
        "title": "Mode Type",
        "description": "Mode Type",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "normal",
            "karras",
            "exponential",
            "sgm_uniform",
            "simple",
            "ddim_uniform"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Scheduler"
        },
        "default": "normal",
        "title": "Scheduler",
        "description": "Scheduler",
        "min": null,
        "max": null
      },
      {
        "name": "tile_width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Tile Width",
        "description": "Tile Width",
        "min": null,
        "max": null
      },
      {
        "name": "upscale_by",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Upscale By",
        "description": "Upscale By",
        "min": null,
        "max": null
      },
      {
        "name": "tile_height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Tile Height",
        "description": "Tile Height",
        "min": null,
        "max": null
      },
      {
        "name": "sampler_name",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "euler",
            "euler_ancestral",
            "heun",
            "dpm_2",
            "dpm_2_ancestral",
            "lms",
            "dpm_fast",
            "dpm_adaptive",
            "dpmpp_2s_ancestral",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "dpmpp_2m",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "dpmpp",
            "ddim",
            "uni_pc",
            "uni_pc_bh2"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Sampler_name"
        },
        "default": "euler",
        "title": "Sampler Name",
        "description": "Sampler",
        "min": null,
        "max": null
      },
      {
        "name": "tile_padding",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 32,
        "title": "Tile Padding",
        "description": "Tile Padding",
        "min": null,
        "max": null
      },
      {
        "name": "seam_fix_mode",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "None",
            "Band Pass",
            "Half Tile",
            "Half Tile + Intersections"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Seam_fix_mode"
        },
        "default": "None",
        "title": "Seam Fix Mode",
        "description": "Seam Fix Mode",
        "min": null,
        "max": null
      },
      {
        "name": "seam_fix_width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 64,
        "title": "Seam Fix Width",
        "description": "Seam Fix Width",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Negative Prompt",
        "description": "Negative Prompt",
        "min": null,
        "max": null
      },
      {
        "name": "positive_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Hey! Have a nice day :D",
        "title": "Positive Prompt",
        "description": "Positive Prompt",
        "min": null,
        "max": null
      },
      {
        "name": "seam_fix_denoise",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Seam Fix Denoise",
        "description": "Seam Fix Denoise",
        "min": null,
        "max": null
      },
      {
        "name": "seam_fix_padding",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 16,
        "title": "Seam Fix Padding",
        "description": "Seam Fix Padding",
        "min": null,
        "max": null
      },
      {
        "name": "seam_fix_mask_blur",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8,
        "title": "Seam Fix Mask Blur",
        "description": "Seam Fix Mask Blur",
        "min": null,
        "max": null
      },
      {
        "name": "controlnet_strength",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Controlnet Strength",
        "description": "ControlNet Strength",
        "min": null,
        "max": null
      },
      {
        "name": "force_uniform_tiles",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Force Uniform Tiles",
        "description": "Force Uniform Tiles",
        "min": null,
        "max": null
      },
      {
        "name": "use_controlnet_tile",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Use Controlnet Tile",
        "description": "Use ControlNet Tile",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/ec52df9a-be01-4c74-af9d-a14df03bf03a/output.png",
      "created_at": "2023-11-14T08:41:40.364739Z",
      "description": "Ultimate SD Upscale with ControlNet Tile",
      "github_url": "https://github.com/fewjative/cog-ultimate-sd-upscale",
      "license_url": null,
      "name": "ultimate-sd-upscale",
      "owner": "fewjative",
      "paper_url": null,
      "run_count": 157899,
      "url": "https://replicate.com/fewjative/ultimate-sd-upscale",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "cfg",
      "seed",
      "image"
    ]
  },
  {
    "title": "Swin IR",
    "description": "Image Restoration Using Swin Transformer",
    "namespace": "replicate.image.upscale",
    "node_type": "replicate.image.upscale.SwinIR",
    "layout": "default",
    "properties": [
      {
        "name": "jpeg",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 40,
        "title": "Jpeg",
        "description": "scale factor, activated for JPEG Compression Artifact Reduction. Leave it as default or arbitrary if other tasks are selected",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "input image",
        "min": null,
        "max": null
      },
      {
        "name": "noise",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            15,
            25,
            50
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Noise"
        },
        "default": 15,
        "title": "Noise",
        "description": "noise level, activated for Grayscale Image Denoising and Color Image Denoising. Leave it as default or arbitrary if other tasks are selected",
        "min": null,
        "max": null
      },
      {
        "name": "task_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "Real-World Image Super-Resolution-Large",
            "Real-World Image Super-Resolution-Medium",
            "Grayscale Image Denoising",
            "Color Image Denoising",
            "JPEG Compression Artifact Reduction"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Task_type"
        },
        "default": "Real-World Image Super-Resolution-Large",
        "title": "Task Type",
        "description": "Choose a task",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/c62290f9-ba1d-419b-95b8-eedfe5863122/out.png",
      "created_at": "2021-09-13T19:58:55.156216Z",
      "description": "Image Restoration Using Swin Transformer",
      "github_url": "https://github.com/JingyunLiang/SwinIR",
      "license_url": "https://github.com/JingyunLiang/SwinIR/blob/main/LICENSE",
      "name": "swinir",
      "owner": "jingyunliang",
      "paper_url": "https://arxiv.org/abs/2108.10257",
      "run_count": 5855107,
      "url": "https://replicate.com/jingyunliang/swinir",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "jpeg",
      "image",
      "noise"
    ]
  },
  {
    "title": "Swin 2 SR",
    "description": "3 Million Runs! AI Photorealistic Image Super-Resolution and Restoration",
    "namespace": "replicate.image.upscale",
    "node_type": "replicate.image.upscale.Swin2SR",
    "layout": "default",
    "properties": [
      {
        "name": "task",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "classical_sr",
            "real_sr",
            "compressed_sr"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.image.upscale.Task"
        },
        "default": "real_sr",
        "title": "Task",
        "description": "Choose a task",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Input image",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/aabde67b-bf5c-4fc8-a4bd-8b2dcba60be6/swin2sr-cover3.png",
      "created_at": "2022-10-28T22:59:05.692845Z",
      "description": "3 Million Runs! AI Photorealistic Image Super-Resolution and Restoration",
      "github_url": "https://github.com/mv-lab/swin2sr",
      "license_url": "https://github.com/mv-lab/swin2sr/blob/main/LICENSE",
      "name": "swin2sr",
      "owner": "mv-lab",
      "paper_url": "https://arxiv.org/abs/2209.11345",
      "run_count": 3555229,
      "url": "https://replicate.com/mv-lab/swin2sr",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "task",
      "image"
    ]
  },
  {
    "title": "Llama 3 8 B",
    "description": "Base version of Llama 3, an 8 billion parameter language model from Meta.",
    "namespace": "replicate.text.generate",
    "node_type": "replicate.text.generate.Llama3_8B",
    "layout": "default",
    "properties": [
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Top K",
        "description": "The number of highest probability tokens to consider for generating the output. If > 0, only keep the top k tokens with highest probability (top-k filtering).",
        "min": null,
        "max": null
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.9,
        "title": "Top P",
        "description": "A probability threshold for generating the output. If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering). Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751).",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "Prompt",
        "min": null,
        "max": null
      },
      {
        "name": "max_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Max Tokens",
        "description": "The maximum number of tokens the model should generate as output.",
        "min": null,
        "max": null
      },
      {
        "name": "min_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Min Tokens",
        "description": "The minimum number of tokens the model should generate as output.",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.6,
        "title": "Temperature",
        "description": "The value used to modulate the next token probabilities.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_template",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "{prompt}",
        "title": "Prompt Template",
        "description": "Prompt template. The string `{prompt}` will be substituted for the input prompt. If you want to generate dialog output, use this template as a starting point and construct the prompt string manually, leaving `prompt_template={prompt}`.",
        "min": null,
        "max": null
      },
      {
        "name": "presence_penalty",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.15,
        "title": "Presence Penalty",
        "description": "Presence penalty",
        "min": null,
        "max": null
      },
      {
        "name": "frequency_penalty",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.2,
        "title": "Frequency Penalty",
        "description": "Frequency penalty",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/dd9ac11a-edda-4d33-b413-6a721c44dfb0/meta-logo.png",
      "created_at": "2024-04-17T18:04:26.049832Z",
      "description": "Base version of Llama 3, an 8 billion parameter language model from Meta.",
      "github_url": "https://github.com/meta-llama/llama3",
      "license_url": "https://github.com/meta-llama/llama3/blob/main/LICENSE",
      "name": "meta-llama-3-8b",
      "owner": "meta",
      "paper_url": null,
      "run_count": 50720746,
      "url": "https://replicate.com/meta/meta-llama-3-8b",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "top_k",
      "top_p",
      "prompt"
    ]
  },
  {
    "title": "Llama 3 8 B Instruct",
    "description": "An 8 billion parameter language model from Meta, fine tuned for chat completions",
    "namespace": "replicate.text.generate",
    "node_type": "replicate.text.generate.Llama3_8B_Instruct",
    "layout": "default",
    "properties": [
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Top K",
        "description": "The number of highest probability tokens to consider for generating the output. If > 0, only keep the top k tokens with highest probability (top-k filtering).",
        "min": null,
        "max": null
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.9,
        "title": "Top P",
        "description": "A probability threshold for generating the output. If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering). Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751).",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "Prompt",
        "min": null,
        "max": null
      },
      {
        "name": "max_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Max Tokens",
        "description": "The maximum number of tokens the model should generate as output.",
        "min": null,
        "max": null
      },
      {
        "name": "min_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Min Tokens",
        "description": "The minimum number of tokens the model should generate as output.",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.6,
        "title": "Temperature",
        "description": "The value used to modulate the next token probabilities.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_template",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "{prompt}",
        "title": "Prompt Template",
        "description": "Prompt template. The string `{prompt}` will be substituted for the input prompt. If you want to generate dialog output, use this template as a starting point and construct the prompt string manually, leaving `prompt_template={prompt}`.",
        "min": null,
        "max": null
      },
      {
        "name": "presence_penalty",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.15,
        "title": "Presence Penalty",
        "description": "Presence penalty",
        "min": null,
        "max": null
      },
      {
        "name": "frequency_penalty",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.2,
        "title": "Frequency Penalty",
        "description": "Frequency penalty",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/68b7dc1a-4767-4353-b066-212b0126b5de/meta-logo.png",
      "created_at": "2024-04-17T21:44:58.480057Z",
      "description": "An 8 billion parameter language model from Meta, fine tuned for chat completions",
      "github_url": "https://github.com/meta-llama/llama3",
      "license_url": "https://github.com/meta-llama/llama3/blob/main/LICENSE",
      "name": "meta-llama-3-8b-instruct",
      "owner": "meta",
      "paper_url": null,
      "run_count": 274134002,
      "url": "https://replicate.com/meta/meta-llama-3-8b-instruct",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "top_k",
      "top_p",
      "prompt"
    ]
  },
  {
    "title": "Llama 3 70 B",
    "description": "Base version of Llama 3, a 70 billion parameter language model from Meta.",
    "namespace": "replicate.text.generate",
    "node_type": "replicate.text.generate.Llama3_70B",
    "layout": "default",
    "properties": [
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Top K",
        "description": "The number of highest probability tokens to consider for generating the output. If > 0, only keep the top k tokens with highest probability (top-k filtering).",
        "min": null,
        "max": null
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.9,
        "title": "Top P",
        "description": "A probability threshold for generating the output. If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering). Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751).",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "Prompt",
        "min": null,
        "max": null
      },
      {
        "name": "max_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Max Tokens",
        "description": "The maximum number of tokens the model should generate as output.",
        "min": null,
        "max": null
      },
      {
        "name": "min_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Min Tokens",
        "description": "The minimum number of tokens the model should generate as output.",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.6,
        "title": "Temperature",
        "description": "The value used to modulate the next token probabilities.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_template",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "{prompt}",
        "title": "Prompt Template",
        "description": "Prompt template. The string `{prompt}` will be substituted for the input prompt. If you want to generate dialog output, use this template as a starting point and construct the prompt string manually, leaving `prompt_template={prompt}`.",
        "min": null,
        "max": null
      },
      {
        "name": "presence_penalty",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.15,
        "title": "Presence Penalty",
        "description": "Presence penalty",
        "min": null,
        "max": null
      },
      {
        "name": "frequency_penalty",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.2,
        "title": "Frequency Penalty",
        "description": "Frequency penalty",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/8e044b4c-0b20-4717-83bd-a94d89fb0dbe/meta-logo.png",
      "created_at": "2024-04-17T18:05:18.044746Z",
      "description": "Base version of Llama 3, a 70 billion parameter language model from Meta.",
      "github_url": null,
      "license_url": "https://github.com/meta-llama/llama3/blob/main/LICENSE",
      "name": "meta-llama-3-70b",
      "owner": "meta",
      "paper_url": null,
      "run_count": 808500,
      "url": "https://replicate.com/meta/meta-llama-3-70b",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "top_k",
      "top_p",
      "prompt"
    ]
  },
  {
    "title": "Llama 3 70 B Instruct",
    "description": "A 70 billion parameter language model from Meta, fine tuned for chat completions",
    "namespace": "replicate.text.generate",
    "node_type": "replicate.text.generate.Llama3_70B_Instruct",
    "layout": "default",
    "properties": [
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Top K",
        "description": "The number of highest probability tokens to consider for generating the output. If > 0, only keep the top k tokens with highest probability (top-k filtering).",
        "min": null,
        "max": null
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.9,
        "title": "Top P",
        "description": "A probability threshold for generating the output. If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering). Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751).",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "Prompt",
        "min": null,
        "max": null
      },
      {
        "name": "max_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Max Tokens",
        "description": "The maximum number of tokens the model should generate as output.",
        "min": null,
        "max": null
      },
      {
        "name": "min_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Min Tokens",
        "description": "The minimum number of tokens the model should generate as output.",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.6,
        "title": "Temperature",
        "description": "The value used to modulate the next token probabilities.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_template",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "{prompt}",
        "title": "Prompt Template",
        "description": "Prompt template. The string `{prompt}` will be substituted for the input prompt. If you want to generate dialog output, use this template as a starting point and construct the prompt string manually, leaving `prompt_template={prompt}`.",
        "min": null,
        "max": null
      },
      {
        "name": "presence_penalty",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.15,
        "title": "Presence Penalty",
        "description": "Presence penalty",
        "min": null,
        "max": null
      },
      {
        "name": "frequency_penalty",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.2,
        "title": "Frequency Penalty",
        "description": "Frequency penalty",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/3dcb020b-1fad-4101-84cf-88af9b20ac21/meta-logo.png",
      "created_at": "2024-04-17T21:44:13.482460Z",
      "description": "A 70 billion parameter language model from Meta, fine tuned for chat completions",
      "github_url": "https://github.com/meta-llama/llama3",
      "license_url": "https://github.com/meta-llama/llama3/blob/main/LICENSE",
      "name": "meta-llama-3-70b-instruct",
      "owner": "meta",
      "paper_url": null,
      "run_count": 139352644,
      "url": "https://replicate.com/meta/meta-llama-3-70b-instruct",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "top_k",
      "top_p",
      "prompt"
    ]
  },
  {
    "title": "Llama 3 1 405 B Instruct",
    "description": "Meta's flagship 405 billion parameter language model, fine-tuned for chat completions",
    "namespace": "replicate.text.generate",
    "node_type": "replicate.text.generate.Llama3_1_405B_Instruct",
    "layout": "default",
    "properties": [
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Top K",
        "description": "The number of highest probability tokens to consider for generating the output. If > 0, only keep the top k tokens with highest probability (top-k filtering).",
        "min": null,
        "max": null
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.9,
        "title": "Top P",
        "description": "A probability threshold for generating the output. If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering). Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751).",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "Prompt",
        "min": null,
        "max": null
      },
      {
        "name": "max_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 512,
        "title": "Max Tokens",
        "description": "The maximum number of tokens the model should generate as output.",
        "min": null,
        "max": null
      },
      {
        "name": "min_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Min Tokens",
        "description": "The minimum number of tokens the model should generate as output.",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.6,
        "title": "Temperature",
        "description": "The value used to modulate the next token probabilities.",
        "min": null,
        "max": null
      },
      {
        "name": "system_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "You are a helpful assistant.",
        "title": "System Prompt",
        "description": "System prompt to send to the model. This is prepended to the prompt and helps guide system behavior. Ignored for non-chat models.",
        "min": null,
        "max": null
      },
      {
        "name": "stop_sequences",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Stop Sequences",
        "description": "A comma-separated list of sequences to stop generation at. For example, '<end>,<stop>' will stop generation at the first instance of 'end' or '<stop>'.",
        "min": null,
        "max": null
      },
      {
        "name": "presence_penalty",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Presence Penalty",
        "description": "Presence penalty",
        "min": null,
        "max": null
      },
      {
        "name": "frequency_penalty",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0,
        "title": "Frequency Penalty",
        "description": "Frequency penalty",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/81ca001f-6a0a-4bef-b2f1-32466887df20/meta-logo.png",
      "created_at": "2024-07-22T20:40:30.648238Z",
      "description": "Meta's flagship 405 billion parameter language model, fine-tuned for chat completions",
      "github_url": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_1",
      "license_url": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/LICENSE",
      "name": "meta-llama-3.1-405b-instruct",
      "owner": "meta",
      "paper_url": null,
      "run_count": 4564530,
      "url": "https://replicate.com/meta/meta-llama-3.1-405b-instruct",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "top_k",
      "top_p",
      "prompt"
    ]
  },
  {
    "title": "Llama Guard 3 11 B Vision",
    "description": "A Llama-3.2-11B pretrained model, fine-tuned for content safety classification",
    "namespace": "replicate.text.generate",
    "node_type": "replicate.text.generate.LlamaGuard_3_11B_Vision",
    "layout": "default",
    "properties": [
      {
        "name": "image",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Image",
        "description": "Image to moderate",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Which one should I buy?",
        "title": "Prompt",
        "description": "User message to moderate",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/d7d7e254-bf5a-458f-9754-791a7db8ba44/replicate-prediction-m8j_JCyBlXR.webp",
      "created_at": "2024-12-23T20:39:23.769654Z",
      "description": "A Llama-3.2-11B pretrained model, fine-tuned for content safety classification",
      "github_url": "https://github.com/lucataco/cog-Llama-Guard-3-11B-Vision",
      "license_url": "https://huggingface.co/meta-llama/Llama-3.2-1B/blob/main/LICENSE.txt",
      "name": "llama-guard-3-11b-vision",
      "owner": "meta",
      "paper_url": "https://arxiv.org/abs/2312.06674",
      "run_count": 11,
      "url": "https://replicate.com/meta/llama-guard-3-11b-vision",
      "visibility": "public",
      "weights_url": "https://huggingface.co/meta-llama/Llama-Guard-3-11B-Vision"
    },
    "recommended_models": [],
    "basic_fields": [
      "image",
      "prompt"
    ]
  },
  {
    "title": "Llama Guard 3 8 B",
    "description": "A Llama-3.1-8B pretrained model, fine-tuned for content safety classification",
    "namespace": "replicate.text.generate",
    "node_type": "replicate.text.generate.LlamaGuard_3_8B",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "I forgot how to kill a process in Linux, can you help?",
        "title": "Prompt",
        "description": "User message to moderate",
        "min": null,
        "max": null
      },
      {
        "name": "assistant",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Assistant",
        "description": "Assistant response to classify",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/b59edf5b-6571-4673-8cd8-87488501f5b7/replicate-prediction-d2c_9x54OXs.webp",
      "created_at": "2024-12-21T00:37:41.039448Z",
      "description": "A Llama-3.1-8B pretrained model, fine-tuned for content safety classification",
      "github_url": "https://github.com/lucataco/cog-Llama-Guard-3-8B",
      "license_url": "https://huggingface.co/meta-llama/Llama-3.1-70B-Instruct/blob/main/LICENSE",
      "name": "llama-guard-3-8b",
      "owner": "meta",
      "paper_url": "https://arxiv.org/abs/2407.21783",
      "run_count": 59,
      "url": "https://replicate.com/meta/llama-guard-3-8b",
      "visibility": "public",
      "weights_url": "https://huggingface.co/meta-llama/Llama-Guard-3-8B"
    },
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "assistant"
    ]
  },
  {
    "title": "Snowflake Arctic Instruct",
    "description": "An efficient, intelligent, and truly open-source language model",
    "namespace": "replicate.text.generate",
    "node_type": "replicate.text.generate.Snowflake_Arctic_Instruct",
    "layout": "default",
    "properties": [
      {
        "name": "name",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Name",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "name_file",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Name File",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/793e32b4-913c-4036-a847-4afb38e42fc1/Snowflake_Arctic_Opengraph_120.png",
      "created_at": "2024-04-24T00:08:29.300675Z",
      "description": "An efficient, intelligent, and truly open-source language model",
      "github_url": "https://github.com/Snowflake-Labs/snowflake-arctic",
      "license_url": "https://www.apache.org/licenses/LICENSE-2.0",
      "name": "snowflake-arctic-instruct",
      "owner": "snowflake",
      "paper_url": null,
      "run_count": 1861362,
      "url": "https://replicate.com/snowflake/snowflake-arctic-instruct",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "name",
      "name_file"
    ]
  },
  {
    "title": "Video Llava",
    "description": "Video-LLaVA: Learning United Visual Representation by Alignment Before Projection",
    "namespace": "replicate.video.analyze",
    "node_type": "replicate.video.analyze.VideoLlava",
    "layout": "default",
    "properties": [
      {
        "name": "image_path",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image Path",
        "description": "Path to image file.",
        "min": null,
        "max": null
      },
      {
        "name": "video_path",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Video Path",
        "description": "Path to video file.",
        "min": null,
        "max": null
      },
      {
        "name": "text_prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Text Prompt",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/132630f1-18c6-429e-bc5b-214775997065/video_llava.png",
      "created_at": "2023-11-20T21:16:55.794627Z",
      "description": "Video-LLaVA: Learning United Visual Representation by Alignment Before Projection",
      "github_url": "https://github.com/PKU-YuanGroup/Video-LLaVA",
      "license_url": "https://github.com/PKU-YuanGroup/Video-LLaVA#-license",
      "name": "video-llava",
      "owner": "nateraw",
      "paper_url": "https://arxiv.org/abs/2311.10122",
      "run_count": 369655,
      "url": "https://replicate.com/nateraw/video-llava",
      "visibility": "public",
      "hardware": "Nvidia A40 (Large) GPU"
    },
    "recommended_models": [],
    "basic_fields": [
      "image_path",
      "video_path",
      "text_prompt"
    ]
  },
  {
    "title": "Ray",
    "description": "Fast, high quality text-to-video and image-to-video (Also known as Dream Machine)",
    "namespace": "replicate.video.generate",
    "node_type": "replicate.video.generate.Ray",
    "layout": "default",
    "properties": [
      {
        "name": "loop",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Loop",
        "description": "Whether the video should loop",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Text prompt for video generation",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1:1",
            "3:4",
            "4:3",
            "9:16",
            "16:9",
            "9:21",
            "21:9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.video.generate.Aspect_ratio"
        },
        "default": "16:9",
        "title": "Aspect Ratio",
        "description": "Aspect ratio of the video (e.g. '16:9'). Ignored if a start or end frame or video ID is given.",
        "min": null,
        "max": null
      },
      {
        "name": "end_video_id",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "End Video Id",
        "description": "Prepend a new video generation to the beginning of an existing one (Also called 'reverse extend'). You can combine this with start_image_url, or start_video_id.",
        "min": null,
        "max": null
      },
      {
        "name": "end_image_url",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "End Image Url",
        "description": "URL of an image to use as the ending frame",
        "min": null,
        "max": null
      },
      {
        "name": "start_video_id",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Start Video Id",
        "description": "Continue or extend a video generation with a new generation. You can combine this with end_image_url, or end_video_id.",
        "min": null,
        "max": null
      },
      {
        "name": "start_image_url",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Start Image Url",
        "description": "URL of an image to use as the starting frame",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/496f8ab2-3a87-4fe7-9867-5572460c2b5e/ray-cover.webp",
      "created_at": "2024-12-12T16:30:42.287210Z",
      "description": "Fast, high quality text-to-video and image-to-video (Also known as Dream Machine)",
      "github_url": null,
      "license_url": "https://lumalabs.ai/dream-machine/api/terms",
      "name": "ray",
      "owner": "luma",
      "paper_url": "https://lumalabs.ai/dream-machine",
      "run_count": 6683,
      "url": "https://replicate.com/luma/ray",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "loop",
      "prompt",
      "aspect_ratio"
    ]
  },
  {
    "title": "Hotshot XL",
    "description": "\ud83d\ude0a Hotshot-XL is an AI text-to-GIF model trained to work alongside Stable Diffusion XL",
    "namespace": "replicate.video.generate",
    "node_type": "replicate.video.generate.HotshotXL",
    "layout": "default",
    "properties": [
      {
        "name": "mp4",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Mp4",
        "description": "Save as mp4, False for GIF",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Leave blank to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Steps",
        "description": "Number of denoising steps",
        "min": 1.0,
        "max": 500.0
      },
      {
        "name": "width",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            256,
            320,
            384,
            448,
            512,
            576,
            640,
            672,
            704,
            768,
            832,
            896,
            960,
            1024
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.video.generate.Width"
        },
        "default": 672,
        "title": "Width",
        "description": "Width of the output",
        "min": null,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            256,
            320,
            384,
            448,
            512,
            576,
            640,
            672,
            704,
            768,
            832,
            896,
            960,
            1024
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.video.generate.Height"
        },
        "default": 384,
        "title": "Height",
        "description": "Height of the output",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "a camel smoking a cigarette, hd, high quality",
        "title": "Prompt",
        "description": "Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "scheduler",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "DDIMScheduler",
            "DPMSolverMultistepScheduler",
            "HeunDiscreteScheduler",
            "KarrasDPM",
            "EulerAncestralDiscreteScheduler",
            "EulerDiscreteScheduler",
            "PNDMScheduler"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.video.generate.Scheduler"
        },
        "default": "EulerAncestralDiscreteScheduler",
        "title": "Scheduler",
        "description": "Select a Scheduler",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "blurry",
        "title": "Negative Prompt",
        "description": "Negative prompt",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/70393e62-deab-4f95-ace7-eaeb8a9800db/compressed.gif",
      "created_at": "2023-10-05T04:09:21.646870Z",
      "description": "\ud83d\ude0a Hotshot-XL is an AI text-to-GIF model trained to work alongside Stable Diffusion XL",
      "github_url": "https://github.com/lucataco/cog-hotshot-xl",
      "license_url": "https://github.com/hotshotco/Hotshot-XL/blob/main/LICENSE",
      "name": "hotshot-xl",
      "owner": "lucataco",
      "paper_url": "https://huggingface.co/hotshotco/SDXL-512",
      "run_count": 428229,
      "url": "https://replicate.com/lucataco/hotshot-xl",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "mp4",
      "seed",
      "steps"
    ]
  },
  {
    "title": "Zeroscope V 2 XL",
    "description": "Zeroscope V2 XL & 576w",
    "namespace": "replicate.video.generate",
    "node_type": "replicate.video.generate.Zeroscope_V2_XL",
    "layout": "default",
    "properties": [
      {
        "name": "fps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 8,
        "title": "Fps",
        "description": "fps for the output video",
        "min": null,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed. Leave blank to randomize the seed",
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "xl",
            "576w",
            "potat1",
            "animov-512x"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.video.generate.Model"
        },
        "default": "xl",
        "title": "Model",
        "description": "Model to use",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 576,
        "title": "Width",
        "description": "Width of the output video",
        "min": 256.0,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 320,
        "title": "Height",
        "description": "Height of the output video",
        "min": 256.0,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "An astronaut riding a horse",
        "title": "Prompt",
        "description": "Input prompt",
        "min": null,
        "max": null
      },
      {
        "name": "batch_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Batch Size",
        "description": "Batch size",
        "min": 1.0,
        "max": null
      },
      {
        "name": "init_video",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Init Video",
        "description": "URL of the initial video (optional)",
        "min": null,
        "max": null
      },
      {
        "name": "num_frames",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 24,
        "title": "Num Frames",
        "description": "Number of frames for the output video",
        "min": null,
        "max": null
      },
      {
        "name": "init_weight",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Init Weight",
        "description": "Strength of init_video",
        "min": null,
        "max": null
      },
      {
        "name": "guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 7.5,
        "title": "Guidance Scale",
        "description": "Guidance scale",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Negative Prompt",
        "description": "Negative prompt",
        "min": null,
        "max": null
      },
      {
        "name": "remove_watermark",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Remove Watermark",
        "description": "Remove watermark",
        "min": null,
        "max": null
      },
      {
        "name": "num_inference_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Num Inference Steps",
        "description": "Number of denoising steps",
        "min": 1.0,
        "max": 500.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/d56e8888-a591-4edd-a9d3-2285b2ab66b4/1mrNnh8.jpg",
      "created_at": "2023-06-24T18:30:41.874899Z",
      "description": "Zeroscope V2 XL & 576w",
      "github_url": "https://github.com/anotherjesse/cog-text2video",
      "license_url": "https://github.com/anotherjesse/cog-text2video/blob/main/LICENSE",
      "name": "zeroscope-v2-xl",
      "owner": "anotherjesse",
      "paper_url": "https://huggingface.co/cerspense/zeroscope_v2_576w",
      "run_count": 283226,
      "url": "https://replicate.com/anotherjesse/zeroscope-v2-xl",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "fps",
      "seed",
      "model"
    ]
  },
  {
    "title": "Robust Video Matting",
    "description": "extract foreground of a video",
    "namespace": "replicate.video.generate",
    "node_type": "replicate.video.generate.RobustVideoMatting",
    "layout": "default",
    "properties": [
      {
        "name": "input_video",
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "video",
          "uri": "",
          "asset_id": null,
          "data": null,
          "duration": null,
          "format": null
        },
        "title": "Input Video",
        "description": "Video to segment.",
        "min": null,
        "max": null
      },
      {
        "name": "output_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "green-screen",
            "alpha-mask",
            "foreground-mask"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.video.generate.Output_type"
        },
        "default": "green-screen",
        "title": "Output Type",
        "description": null,
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/1f92fd8f-2b90-4998-b5ae-1e23678ab004/showreel.gif",
      "created_at": "2022-11-25T14:06:18.152759Z",
      "description": "extract foreground of a video",
      "github_url": "https://github.com/PeterL1n/RobustVideoMatting",
      "license_url": "https://github.com/PeterL1n/RobustVideoMatting/blob/master/LICENSE",
      "name": "robust_video_matting",
      "owner": "arielreplicate",
      "paper_url": "https://arxiv.org/abs/2108.11515",
      "run_count": 48967,
      "url": "https://replicate.com/arielreplicate/robust_video_matting",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "input_video",
      "output_type"
    ]
  },
  {
    "title": "Audio To Waveform",
    "description": "Create a waveform video from audio",
    "namespace": "replicate.video.generate",
    "node_type": "replicate.video.generate.AudioToWaveform",
    "layout": "default",
    "properties": [
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "Audio file to create waveform from",
        "min": null,
        "max": null
      },
      {
        "name": "bg_color",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "#000000",
        "title": "Bg Color",
        "description": "Background color of waveform",
        "min": null,
        "max": null
      },
      {
        "name": "fg_alpha",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.75,
        "title": "Fg Alpha",
        "description": "Opacity of foreground waveform",
        "min": null,
        "max": null
      },
      {
        "name": "bar_count",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Bar Count",
        "description": "Number of bars in waveform",
        "min": null,
        "max": null
      },
      {
        "name": "bar_width",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.4,
        "title": "Bar Width",
        "description": "Width of bars in waveform. 1 represents full width, 0.5 represents half width, etc.",
        "min": null,
        "max": null
      },
      {
        "name": "bars_color",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "#ffffff",
        "title": "Bars Color",
        "description": "Color of waveform bars",
        "min": null,
        "max": null
      },
      {
        "name": "caption_text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Caption Text",
        "description": "Caption text for the video",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_cover_image/5d5cad9c-d4ba-44e1-8c4f-dc08648bbf5e/fofr_a_waveform_bar_chart_video_e.png",
      "created_at": "2023-06-13T15:26:38.672021Z",
      "description": "Create a waveform video from audio",
      "github_url": "https://github.com/fofr/audio-to-waveform",
      "license_url": "https://github.com/fofr/audio-to-waveform/blob/main/LICENSE",
      "name": "audio-to-waveform",
      "owner": "fofr",
      "paper_url": "https://gradio.app/docs/#make_waveform",
      "run_count": 381596,
      "url": "https://replicate.com/fofr/audio-to-waveform",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "audio",
      "bg_color",
      "fg_alpha"
    ]
  },
  {
    "title": "Hunyuan Video",
    "description": "A state-of-the-art text-to-video generation model capable of creating high-quality videos with realistic motion from text descriptions",
    "namespace": "replicate.video.generate",
    "node_type": "replicate.video.generate.Hunyuan_Video",
    "layout": "default",
    "properties": [
      {
        "name": "fps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 24,
        "title": "Fps",
        "description": "Frames per second of the output video",
        "min": 1.0,
        "max": null
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Random seed (leave empty for random)",
        "min": null,
        "max": null
      },
      {
        "name": "width",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 864,
        "title": "Width",
        "description": "Width of the video in pixels (must be divisible by 16)",
        "min": 16.0,
        "max": null
      },
      {
        "name": "height",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 480,
        "title": "Height",
        "description": "Height of the video in pixels (must be divisible by 16)",
        "min": 16.0,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "A cat walks on the grass, realistic style",
        "title": "Prompt",
        "description": "The prompt to guide the video generation",
        "min": null,
        "max": null
      },
      {
        "name": "infer_steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Infer Steps",
        "description": "Number of denoising steps",
        "min": 1.0,
        "max": null
      },
      {
        "name": "video_length",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 129,
        "title": "Video Length",
        "description": "Number of frames to generate (must be 4k+1, ex: 49 or 129)",
        "min": 1.0,
        "max": null
      },
      {
        "name": "embedded_guidance_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 6,
        "title": "Embedded Guidance Scale",
        "description": "Guidance scale",
        "min": 1.0,
        "max": 10.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/3bebc89d-37c7-47ea-9a7b-a334b76eea87/hunyuan-featured.webp",
      "created_at": "2024-12-03T14:21:37.443615Z",
      "description": "A state-of-the-art text-to-video generation model capable of creating high-quality videos with realistic motion from text descriptions",
      "github_url": "https://github.com/zsxkib/HunyuanVideo/tree/replicate",
      "license_url": "https://huggingface.co/tencent/HunyuanVideo/blob/main/LICENSE",
      "name": "hunyuan-video",
      "owner": "tencent",
      "paper_url": "https://github.com/Tencent/HunyuanVideo/blob/main/assets/hunyuanvideo.pdf",
      "run_count": 28316,
      "url": "https://replicate.com/tencent/hunyuan-video",
      "visibility": "public",
      "weights_url": "https://huggingface.co/tencent/HunyuanVideo"
    },
    "recommended_models": [],
    "basic_fields": [
      "fps",
      "seed",
      "width"
    ]
  },
  {
    "title": "Video 01 Live",
    "description": "An image-to-video (I2V) model specifically trained for Live2D and general animation use cases",
    "namespace": "replicate.video.generate",
    "node_type": "replicate.video.generate.Video_01_Live",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Text prompt for image generation",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_optimizer",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Prompt Optimizer",
        "description": "Use prompt optimizer",
        "min": null,
        "max": null
      },
      {
        "name": "first_frame_image",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "First Frame Image",
        "description": "First frame image for video generation",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/c202ad97-edd0-40b6-afaf-c99d71398d44/video-01-live-cover.webp",
      "created_at": "2024-12-16T20:27:52.715593Z",
      "description": "An image-to-video (I2V) model specifically trained for Live2D and general animation use cases",
      "github_url": null,
      "license_url": "https://intl.minimaxi.com/protocol/terms-of-service",
      "name": "video-01-live",
      "owner": "minimax",
      "paper_url": null,
      "run_count": 25499,
      "url": "https://replicate.com/minimax/video-01-live",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "prompt_optimizer",
      "first_frame_image"
    ]
  },
  {
    "title": "Video 01",
    "description": "Generate 6s videos with prompts or images. (Also known as Hailuo)",
    "namespace": "replicate.video.generate",
    "node_type": "replicate.video.generate.Video_01",
    "layout": "default",
    "properties": [
      {
        "name": "prompt",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Prompt",
        "description": "Text prompt for image generation",
        "min": null,
        "max": null
      },
      {
        "name": "prompt_optimizer",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": true,
        "title": "Prompt Optimizer",
        "description": "Use prompt optimizer",
        "min": null,
        "max": null
      },
      {
        "name": "first_frame_image",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "First Frame Image",
        "description": "First frame image for video generation",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/b56c831c-4c68-4443-b69e-b71b105afe7f/minimax.webp",
      "created_at": "2024-11-26T14:40:21.652537Z",
      "description": "Generate 6s videos with prompts or images. (Also known as Hailuo)",
      "github_url": null,
      "license_url": "https://intl.minimaxi.com/protocol/terms-of-service",
      "name": "video-01",
      "owner": "minimax",
      "paper_url": null,
      "run_count": 67585,
      "url": "https://replicate.com/minimax/video-01",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "prompt_optimizer",
      "first_frame_image"
    ]
  },
  {
    "title": "Music 01",
    "description": "Quickly generate up to 1 minute of music with lyrics and vocals in the style of a reference track",
    "namespace": "replicate.video.generate",
    "node_type": "replicate.video.generate.Music_01",
    "layout": "default",
    "properties": [
      {
        "name": "lyrics",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Lyrics",
        "description": "Lyrics with optional formatting. You can use a newline to separate each line of lyrics. You can use two newlines to add a pause between lines. You can use double hash marks (##) at the beginning and end of the lyrics to add accompaniment.",
        "min": null,
        "max": null
      },
      {
        "name": "bitrate",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            32000,
            64000,
            128000,
            256000
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.video.generate.Bitrate"
        },
        "default": 256000,
        "title": "Bitrate",
        "description": "Bitrate for the generated music",
        "min": null,
        "max": null
      },
      {
        "name": "voice_id",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Voice Id",
        "description": "Reuse a previously uploaded voice ID",
        "min": null,
        "max": null
      },
      {
        "name": "song_file",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Song File",
        "description": "Reference song, should contain music and vocals. Must be a .wav or .mp3 file longer than 15 seconds.",
        "min": null,
        "max": null
      },
      {
        "name": "voice_file",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Voice File",
        "description": "Voice reference. Must be a .wav or .mp3 file longer than 15 seconds. If only a voice reference is given, an a cappella vocal hum will be generated.",
        "min": null,
        "max": null
      },
      {
        "name": "sample_rate",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            16000,
            24000,
            32000,
            44100
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.video.generate.Sample_rate"
        },
        "default": 44100,
        "title": "Sample Rate",
        "description": "Sample rate for the generated music",
        "min": null,
        "max": null
      },
      {
        "name": "instrumental_id",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Instrumental Id",
        "description": "Reuse a previously uploaded instrumental ID",
        "min": null,
        "max": null
      },
      {
        "name": "instrumental_file",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Instrumental File",
        "description": "Instrumental reference. Must be a .wav or .mp3 file longer than 15 seconds. If only an instrumental reference is given, a track without vocals will be generated.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/1d2de931-15ff-48b0-9c4d-2f9200eb2913/music-01-cover.jpg",
      "created_at": "2024-12-17T12:40:30.320043Z",
      "description": "Quickly generate up to 1 minute of music with lyrics and vocals in the style of a reference track",
      "github_url": null,
      "license_url": "https://intl.minimaxi.com/protocol/terms-of-service",
      "name": "music-01",
      "owner": "minimax",
      "paper_url": null,
      "run_count": 12066,
      "url": "https://replicate.com/minimax/music-01",
      "visibility": "public",
      "weights_url": null
    },
    "recommended_models": [],
    "basic_fields": [
      "lyrics",
      "bitrate",
      "voice_id"
    ]
  },
  {
    "title": "LTX Video",
    "description": "LTX-Video is the first DiT-based video generation model capable of generating high-quality videos in real-time. It produces 24 FPS videos at a 768x512 resolution faster than they can be watched.",
    "namespace": "replicate.video.generate",
    "node_type": "replicate.video.generate.LTX_Video",
    "layout": "default",
    "properties": [
      {
        "name": "cfg",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 3,
        "title": "Cfg",
        "description": "How strongly the video follows the prompt",
        "min": 1.0,
        "max": 20.0
      },
      {
        "name": "seed",
        "type": {
          "type": "union",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "int",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            },
            {
              "type": "none",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Seed",
        "description": "Set a seed for reproducibility. Random by default.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Optional input image to use as the starting frame",
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "0.9.1",
            "0.9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.video.generate.Model"
        },
        "default": "0.9.1",
        "title": "Model",
        "description": "Model version to use",
        "min": null,
        "max": null
      },
      {
        "name": "steps",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 30,
        "title": "Steps",
        "description": "Number of steps",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "length",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            97,
            129,
            161,
            193,
            225,
            257
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.video.generate.Length"
        },
        "default": 97,
        "title": "Length",
        "description": "Length of the output video in frames",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "best quality, 4k, HDR, a tracking shot of a beautiful scene",
        "title": "Prompt",
        "description": "Text prompt for the video. This model needs long descriptive prompts, if the prompt is too short the quality won't be good.",
        "min": null,
        "max": null
      },
      {
        "name": "target_size",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            512,
            576,
            640,
            704,
            768,
            832,
            896,
            960,
            1024
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.video.generate.Target_size"
        },
        "default": 640,
        "title": "Target Size",
        "description": "Target size for the output video",
        "min": null,
        "max": null
      },
      {
        "name": "aspect_ratio",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "1:1",
            "1:2",
            "2:1",
            "2:3",
            "3:2",
            "3:4",
            "4:3",
            "4:5",
            "5:4",
            "9:16",
            "16:9",
            "9:21",
            "21:9"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.replicate.video.generate.Aspect_ratio"
        },
        "default": "3:2",
        "title": "Aspect Ratio",
        "description": "Aspect ratio of the output video. Ignored if an image is provided.",
        "min": null,
        "max": null
      },
      {
        "name": "negative_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "low quality, worst quality, deformed, distorted",
        "title": "Negative Prompt",
        "description": "Things you do not want to see in your video",
        "min": null,
        "max": null
      },
      {
        "name": "image_noise_scale",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.15,
        "title": "Image Noise Scale",
        "description": "Lower numbers stick more closely to the input image",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "video",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {
      "cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/184609cb-a0c5-47c9-8fec-987fb21cc977/replicate-prediction-_QTChmfY.webp",
      "created_at": "2024-11-29T14:15:01.460922Z",
      "description": "LTX-Video is the first DiT-based video generation model capable of generating high-quality videos in real-time. It produces 24 FPS videos at a 768x512 resolution faster than they can be watched.",
      "github_url": "https://github.com/Lightricks/LTX-Video",
      "license_url": "https://github.com/Lightricks/LTX-Video/blob/main/LICENSE",
      "name": "ltx-video",
      "owner": "lightricks",
      "paper_url": null,
      "run_count": 27132,
      "url": "https://replicate.com/lightricks/ltx-video",
      "visibility": "public",
      "weights_url": "https://huggingface.co/Lightricks/LTX-Video"
    },
    "recommended_models": [],
    "basic_fields": [
      "cfg",
      "seed",
      "image"
    ]
  },
  {
    "title": "Ollama",
    "description": "Run Llama models to generate text responses.\n    LLM, llama, text generation, language model, ai assistant\n\n    Use cases:\n    - Generate creative writing or stories\n    - Answer questions or provide explanations\n    - Assist with tasks like coding, analysis, or problem-solving\n    - Engage in open-ended dialogue on various topics",
    "namespace": "ollama.text",
    "node_type": "ollama.text.Ollama",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "llama_model",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "llama_model",
          "name": "",
          "repo_id": "",
          "modified_at": "",
          "size": 0,
          "digest": "",
          "details": {}
        },
        "title": "Model",
        "description": "The Llama model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "Prompt to send to the model.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "The image to analyze",
        "min": null,
        "max": null
      },
      {
        "name": "system_prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "You are an assistant.",
        "title": "System Prompt",
        "description": "System prompt to send to the model.",
        "min": null,
        "max": null
      },
      {
        "name": "messages",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "message",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Messages",
        "description": "History of messages to send to the model.",
        "min": null,
        "max": null
      },
      {
        "name": "context_window",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4096,
        "title": "Context Window",
        "description": "The context window size to use for the model.",
        "min": 64.0,
        "max": 65536.0
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.7,
        "title": "Temperature",
        "description": "The temperature to use for the model.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Top K",
        "description": "The number of highest probability tokens to keep for top-k sampling.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.95,
        "title": "Top P",
        "description": "The cumulative probability cutoff for nucleus/top-p sampling.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "keep_alive",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "300",
        "title": "Keep Alive",
        "description": "The number of seconds to keep the model alive.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "prompt",
      "image"
    ]
  },
  {
    "title": "Embedding",
    "description": "Generate vector representations of text for semantic similarity.\n    embeddings, semantic analysis, text similarity, search, clustering\n\n    Use cases:\n    - Power semantic search capabilities\n    - Enable text clustering and categorization\n    - Support recommendation systems\n    - Detect semantic anomalies or outliers\n    - Measure text diversity or similarity\n    - Aid in text classification tasks",
    "namespace": "ollama.text",
    "node_type": "ollama.text.Embedding",
    "layout": "default",
    "properties": [
      {
        "name": "input",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Input",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "llama_model",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "llama_model",
          "name": "",
          "repo_id": "",
          "modified_at": "",
          "size": 0,
          "digest": "",
          "details": {}
        },
        "title": "Model",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "context_window",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4096,
        "title": "Context Window",
        "description": "The context window size to use for the model.",
        "min": 1.0,
        "max": null
      },
      {
        "name": "chunk_size",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4096,
        "title": "Chunk Size",
        "description": "The size of the chunks to split the input into",
        "min": 64.0,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "tensor",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "input"
    ]
  },
  {
    "title": "Data Generator",
    "description": "LLM Agent to create a dataframe based on a user prompt.\n    llm, dataframe creation, data structuring\n\n    Use cases:\n    - Generating structured data from natural language descriptions\n    - Creating sample datasets for testing or demonstration\n    - Converting unstructured text into tabular format",
    "namespace": "ollama.agents",
    "node_type": "ollama.agents.DataGenerator",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "llama_model",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "llama_model",
          "name": "",
          "repo_id": "",
          "modified_at": "",
          "size": 0,
          "digest": "",
          "details": {}
        },
        "title": "Model",
        "description": "The Llama model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "context_window",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4096,
        "title": "Context Window",
        "description": "The context window size to use for the model.",
        "min": 1.0,
        "max": 8192.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The user prompt",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1.0,
        "title": "Temperature",
        "description": "The temperature to use for sampling.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Top K",
        "description": "The number of highest probability tokens to keep for top-k sampling.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.95,
        "title": "Top P",
        "description": "The cumulative probability cutoff for nucleus/top-p sampling.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "keep_alive",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "300",
        "title": "Keep Alive",
        "description": "The number of seconds to keep the model alive.",
        "min": null,
        "max": null
      },
      {
        "name": "columns",
        "type": {
          "type": "record_type",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "record_type",
          "columns": []
        },
        "title": "Columns",
        "description": "The columns to use in the dataframe.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "prompt",
      "columns"
    ]
  },
  {
    "title": "SVG Generator",
    "description": "LLM Agent to create SVG elements based on a user prompt.\n    llm, svg generation, vector graphics\n\n    Use cases:\n    - Generating SVG graphics from natural language descriptions\n    - Creating vector illustrations programmatically\n    - Converting text descriptions into visual elements",
    "namespace": "ollama.agents",
    "node_type": "ollama.agents.SVGGenerator",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "llama_model",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "llama_model",
          "name": "",
          "repo_id": "",
          "modified_at": "",
          "size": 0,
          "digest": "",
          "details": {}
        },
        "title": "Model",
        "description": "The Llama model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "context_window",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4096,
        "title": "Context Window",
        "description": "The context window size to use for the model.",
        "min": 1.0,
        "max": 8192.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The user prompt for SVG generation",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.7,
        "title": "Temperature",
        "description": "The temperature to use for sampling.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Top K",
        "description": "The number of highest probability tokens to keep for top-k sampling.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.95,
        "title": "Top P",
        "description": "The cumulative probability cutoff for nucleus/top-p sampling.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "keep_alive",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "300",
        "title": "Keep Alive",
        "description": "The number of seconds to keep the model alive.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "svg_element",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "prompt"
    ]
  },
  {
    "title": "Chart Generator",
    "description": "LLM Agent to create chart configurations based on natural language descriptions.\n    llm, data visualization, charts\n\n    Use cases:\n    - Generating chart configurations from natural language descriptions\n    - Creating data visualizations programmatically\n    - Converting data analysis requirements into visual representations",
    "namespace": "ollama.agents",
    "node_type": "ollama.agents.ChartGenerator",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "llama_model",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "llama_model",
          "name": "",
          "repo_id": "",
          "modified_at": "",
          "size": 0,
          "digest": "",
          "details": {}
        },
        "title": "Model",
        "description": "The Llama model to use for chart generation.",
        "min": null,
        "max": null
      },
      {
        "name": "context_window",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4096,
        "title": "Context Window",
        "description": "The context window size to use for the model.",
        "min": 1.0,
        "max": 8192.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "Natural language description of the desired chart",
        "min": null,
        "max": null
      },
      {
        "name": "plot_type",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "scatter",
            "line",
            "relplot",
            "histplot",
            "kdeplot",
            "ecdfplot",
            "rugplot",
            "distplot",
            "stripplot",
            "swarmplot",
            "boxplot",
            "violinplot",
            "boxenplot",
            "pointplot",
            "barplot",
            "countplot",
            "regplot",
            "lmplot",
            "residplot",
            "heatmap",
            "clustermap",
            "jointplot",
            "pairplot",
            "facetgrid"
          ],
          "type_args": [],
          "type_name": "nodetool.metadata.types.SeabornPlotType"
        },
        "default": "line",
        "title": "Plot Type",
        "description": "The type of plot to generate",
        "min": null,
        "max": null
      },
      {
        "name": "data",
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "dataframe",
          "uri": "",
          "asset_id": null,
          "data": null,
          "columns": null
        },
        "title": "Data",
        "description": "The data to visualize",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.7,
        "title": "Temperature",
        "description": "The temperature to use for sampling.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Top K",
        "description": "The number of highest probability tokens to keep for top-k sampling.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.95,
        "title": "Top P",
        "description": "The cumulative probability cutoff for nucleus/top-p sampling.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "keep_alive",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "300",
        "title": "Keep Alive",
        "description": "The number of seconds to keep the model alive.",
        "min": null,
        "max": null
      },
      {
        "name": "columns",
        "type": {
          "type": "record_type",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "record_type",
          "columns": []
        },
        "title": "Columns",
        "description": "The columns available in the data.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "chart_config",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "prompt",
      "data",
      "plot_type"
    ]
  },
  {
    "title": "Question Answer Agent",
    "description": "LLM Agent to generate answers based on a question and context from RAG results.\n    llm, question-answering, RAG\n\n    Use cases:\n    - Answering questions using retrieved context\n    - Generating coherent responses from multiple text sources\n    - Knowledge-based Q&A systems",
    "namespace": "ollama.agents",
    "node_type": "ollama.agents.QuestionAnswerAgent",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "llama_model",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "llama_model",
          "name": "",
          "repo_id": "",
          "modified_at": "",
          "size": 0,
          "digest": "",
          "details": {}
        },
        "title": "Model",
        "description": "The Llama model to use for answer generation.",
        "min": null,
        "max": null
      },
      {
        "name": "context_window",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4096,
        "title": "Context Window",
        "description": "The context window size to use for the model.",
        "min": 1.0,
        "max": 8192.0
      },
      {
        "name": "question",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Question",
        "description": "The question to answer",
        "min": null,
        "max": null
      },
      {
        "name": "context",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Context",
        "description": "List of context strings from RAG retrieval",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.7,
        "title": "Temperature",
        "description": "The temperature to use for sampling.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Top K",
        "description": "The number of highest probability tokens to keep for top-k sampling.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.95,
        "title": "Top P",
        "description": "The cumulative probability cutoff for nucleus/top-p sampling.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "keep_alive",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "300",
        "title": "Keep Alive",
        "description": "The number of seconds to keep the model alive.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "prompt"
    ]
  },
  {
    "title": "Schema Generator",
    "description": "LLM Agent to generate structured data based on a provided JSON schema.\n    llm, json schema, data generation, structured data\n\n    Use cases:\n    - Generate sample data matching a specific schema\n    - Create test data with specific structure\n    - Convert natural language to structured data\n    - Populate templates with generated content",
    "namespace": "ollama.agents",
    "node_type": "ollama.agents.SchemaGenerator",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "llama_model",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "llama_model",
          "name": "",
          "repo_id": "",
          "modified_at": "",
          "size": 0,
          "digest": "",
          "details": {}
        },
        "title": "Model",
        "description": "The Llama model to use.",
        "min": null,
        "max": null
      },
      {
        "name": "context_window",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4096,
        "title": "Context Window",
        "description": "The context window size to use for the model.",
        "min": 1.0,
        "max": 8192.0
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The user prompt for data generation",
        "min": null,
        "max": null
      },
      {
        "name": "schema",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Schema",
        "description": "The JSON schema that defines the structure of the output",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.7,
        "title": "Temperature",
        "description": "The temperature to use for sampling.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Top K",
        "description": "The number of highest probability tokens to keep for top-k sampling.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.95,
        "title": "Top P",
        "description": "The cumulative probability cutoff for nucleus/top-p sampling.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "keep_alive",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "300",
        "title": "Keep Alive",
        "description": "The number of seconds to keep the model alive.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "prompt",
      "schema"
    ]
  },
  {
    "title": "Classifier",
    "description": "LLM Agent to classify text into predefined categories.\n    llm, classification, text analysis\n\n    Use cases:\n    - Text categorization\n    - Sentiment analysis\n    - Topic classification\n    - Intent detection",
    "namespace": "ollama.agents",
    "node_type": "ollama.agents.Classifier",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "llama_model",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "llama_model",
          "name": "",
          "repo_id": "",
          "modified_at": "",
          "size": 0,
          "digest": "",
          "details": {}
        },
        "title": "Model",
        "description": "The Llama model to use for classification.",
        "min": null,
        "max": null
      },
      {
        "name": "context_window",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4096,
        "title": "Context Window",
        "description": "The context window size to use for the model.",
        "min": 1.0,
        "max": 8192.0
      },
      {
        "name": "input_text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Input Text",
        "description": "The text to classify",
        "min": null,
        "max": null
      },
      {
        "name": "labels",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Labels",
        "description": "Comma-separated list of possible classification labels",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Temperature",
        "description": "The temperature to use for sampling.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1,
        "title": "Top K",
        "description": "The number of highest probability tokens to keep for top-k sampling.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.95,
        "title": "Top P",
        "description": "The cumulative probability cutoff for nucleus/top-p sampling.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "keep_alive",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 300,
        "title": "Keep Alive",
        "description": "The number of seconds to keep the model alive.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "input_text",
      "labels"
    ]
  },
  {
    "title": "Summarize Chunks",
    "description": "LLM Agent to break down and summarize long text into manageable chunks.\n    llm, summarization, text processing\n\n    Use cases:\n    - Breaking down long documents\n    - Initial summarization of large texts\n    - Preparing content for final summarization",
    "namespace": "ollama.agents",
    "node_type": "ollama.agents.SummarizeChunks",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "llama_model",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "llama_model",
          "name": "",
          "repo_id": "",
          "modified_at": "",
          "size": 0,
          "digest": "",
          "details": {}
        },
        "title": "Model",
        "description": "The Llama model to use for summarization.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "\n        Create a summary following these rules:\n        \u2022 Focus ONLY on the key information from the source text\n        \u2022 Maintain a neutral, objective tone throughout\n        \u2022 Present information in a logical flow\n        \u2022 Remove any redundant points\n        \u2022 Keep only the most important ideas and relationships\n        * NO CONCLUSION\n        * NO INTRODUCTION\n        * NO EXPLANATION OR ADDITIONAL TEXT\n        * ONLY RESPOND WITH THE SUMMARY",
        "title": "Prompt",
        "description": "Instruction for summarizing individual chunks of text",
        "min": null,
        "max": null
      },
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "The text to summarize",
        "min": null,
        "max": null
      },
      {
        "name": "context_window",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4096,
        "title": "Context Window",
        "description": "The context window size to use for the model.",
        "min": 1.0,
        "max": 16384.0
      },
      {
        "name": "num_predict",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4096,
        "title": "Num Predict",
        "description": "Number of tokens to predict for each chunk",
        "min": 0.0,
        "max": 16384.0
      },
      {
        "name": "chunk_overlap",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 100,
        "title": "Chunk Overlap",
        "description": "Number of tokens to overlap between chunks",
        "min": 0.0,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Temperature",
        "description": "The temperature to use for sampling.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Top K",
        "description": "The number of highest probability tokens to keep for top-k sampling.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.95,
        "title": "Top P",
        "description": "The cumulative probability cutoff for nucleus/top-p sampling.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "keep_alive",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 300,
        "title": "Keep Alive",
        "description": "The number of seconds to keep the model alive.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "text",
      "prompt"
    ]
  },
  {
    "title": "Summarizer",
    "description": "LLM Agent to summarize text\n    llm, summarization, text processing\n\n    Use cases:\n    - Creating final summaries from multiple sources\n    - Combining chapter summaries\n    - Generating executive summaries",
    "namespace": "ollama.agents",
    "node_type": "ollama.agents.Summarizer",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "llama_model",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "llama_model",
          "name": "",
          "repo_id": "",
          "modified_at": "",
          "size": 0,
          "digest": "",
          "details": {}
        },
        "title": "Model",
        "description": "The Llama model to use for summarization.",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Create a summary following these rules:\n\u2022 Focus ONLY on the key information from the source text\n\u2022 Maintain a neutral, objective tone throughout\n\u2022 Present information in a logical flow\n\u2022 Remove any redundant points\n\u2022 Keep only the most important ideas and relationships\n* NO CONCLUSION\n* NO INTRODUCTION\n* NO EXPLANATION OR ADDITIONAL TEXT\n* ONLY RESPOND WITH THE SUMMARY",
        "title": "Prompt",
        "description": "Instruction for creating the final summary",
        "min": null,
        "max": null
      },
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "The text to summarize",
        "min": null,
        "max": null
      },
      {
        "name": "num_predict",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4096,
        "title": "Num Predict",
        "description": "Number of tokens to predict",
        "min": 0.0,
        "max": 16384.0
      },
      {
        "name": "context_window",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 4096,
        "title": "Context Window",
        "description": "The context window size to use for the model.",
        "min": 1.0,
        "max": 16384.0
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Temperature",
        "description": "The temperature to use for sampling.",
        "min": 0.0,
        "max": 2.0
      },
      {
        "name": "top_k",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Top K",
        "description": "The number of highest probability tokens to keep for top-k sampling.",
        "min": 1.0,
        "max": 100.0
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.95,
        "title": "Top P",
        "description": "The cumulative probability cutoff for nucleus/top-p sampling.",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "keep_alive",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 300,
        "title": "Keep Alive",
        "description": "The number of seconds to keep the model alive.",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "text",
      "prompt"
    ]
  },
  {
    "title": "Gmail Search",
    "description": "Searches Gmail using Gmail-specific search operators.\n    email, gmail, search\n\n    Returns emails with following fields:\n    - id: Message ID\n    - subject: Email subject\n    - from: Sender address\n    - date: Datetime of email\n    - body: Email body content\n\n    Use cases:\n    - Search for emails based on specific criteria\n    - Retrieve emails from a specific sender\n    - Filter emails by subject, sender, or date",
    "namespace": "google.mail",
    "node_type": "google.mail.GmailSearch",
    "layout": "default",
    "properties": [
      {
        "name": "email_address",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Email Address",
        "description": "Gmail address to connect to",
        "min": null,
        "max": null
      },
      {
        "name": "search_criteria",
        "type": {
          "type": "email_search_criteria",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "email_search_criteria",
          "from_address": null,
          "to_address": null,
          "subject": null,
          "body": null,
          "cc": null,
          "bcc": null,
          "date_condition": null,
          "flags": [],
          "keywords": [],
          "folder": null,
          "text": null
        },
        "title": "Search Criteria",
        "description": "Search criteria",
        "min": null,
        "max": null
      },
      {
        "name": "max_results",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 50,
        "title": "Max Results",
        "description": "Maximum number of emails to return",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "email",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "email_address",
      "search_criteria",
      "max_results"
    ]
  },
  {
    "title": "Move To Archive",
    "description": "Moves specified emails to Gmail archive.\n    email, gmail, archive",
    "namespace": "google.mail",
    "node_type": "google.mail.MoveToArchive",
    "layout": "default",
    "properties": [
      {
        "name": "email_address",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Email Address",
        "description": "Gmail address to connect to",
        "min": null,
        "max": null
      },
      {
        "name": "message_ids",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": null,
        "title": "Message Ids",
        "description": "List of message IDs to archive",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "str",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "email_address",
      "message_ids"
    ]
  },
  {
    "title": "Email Search Criteria",
    "description": "Comprehensive Email search criteria using IMAP search operators.\n    email, gmail, search",
    "namespace": "google.mail",
    "node_type": "google.mail.EmailSearchCriteria",
    "layout": "default",
    "properties": [
      {
        "name": "from_address",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "From Address",
        "description": "Sender's email address to search for.\n        - Case-insensitive\n        - Partial matches work (e.g., \"@company.com\")\n        - Use quotes for addresses with spaces\n        - Multiple addresses can be combined with OR operator\n        ",
        "min": null,
        "max": null
      },
      {
        "name": "to_address",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "To Address",
        "description": "Recipient's email address to search for.\n        - Case-insensitive\n        - Partial matches work (e.g., \"@company.com\")\n        - Use quotes for addresses with spaces\n        - Includes primary recipients only (not CC/BCC)\n        ",
        "min": null,
        "max": null
      },
      {
        "name": "subject",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Subject",
        "description": "Text to search for in email subject.\n        - Case-insensitive\n        - Partial word matches work\n        - Use quotes for phrases with spaces\n        - Special characters should be escaped\n        ",
        "min": null,
        "max": null
      },
      {
        "name": "body",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Body",
        "description": "Text to search for in email body.\n        - Case-insensitive\n        - Searches message body only\n        - Use quotes for phrases with spaces\n        - HTML and plain text content are searched\n        ",
        "min": null,
        "max": null
      },
      {
        "name": "date_filter",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "SINCE_ONE_HOUR",
            "SINCE_ONE_DAY",
            "SINCE_ONE_WEEK",
            "SINCE_ONE_MONTH",
            "SINCE_ONE_YEAR"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.google.mail.DateFilter"
        },
        "default": "SINCE_ONE_DAY",
        "title": "Date Filter",
        "description": "Date filter to search for.",
        "min": null,
        "max": null
      },
      {
        "name": "flags",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "SEEN",
            "UNSEEN",
            "ANSWERED",
            "UNANSWERED",
            "FLAGGED",
            "UNFLAGGED"
          ],
          "type_args": [],
          "type_name": "nodetool.metadata.types.EmailFlag"
        },
        "default": null,
        "title": "Flags",
        "description": "Email status flag to search for.\n        - SEEN/UNSEEN: Read/unread messages\n        - ANSWERED/UNANSWERED: Replied/unreplied messages\n        - FLAGGED/UNFLAGGED: Starred/unstarred messages\n        ",
        "min": null,
        "max": null
      },
      {
        "name": "keywords",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Keywords",
        "description": "Custom keywords or labels to search for.\n        - Case-sensitive\n        - Gmail labels are treated as keywords\n        - Custom labels are used as-is\n        ",
        "min": null,
        "max": null
      },
      {
        "name": "folder",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "INBOX",
            "[Gmail]/Sent Mail",
            "[Gmail]/Drafts",
            "[Gmail]/Spam",
            "[Gmail]/Trash"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.google.mail.GmailFolder"
        },
        "default": "INBOX",
        "title": "Folder",
        "description": "Email folder to search in.",
        "min": null,
        "max": null
      },
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Text",
        "description": "General text to search for anywhere in the email.\n        - Searches all text fields (subject, body, addresses)\n        - Case-insensitive\n        - Partial matches work\n        - Use quotes for phrases with spaces\n        - Most flexible but slower than specific field searches\n        ",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "email_search_criteria",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "from_address",
      "to_address",
      "subject",
      "body",
      "date_filter",
      "flags",
      "keywords",
      "folder",
      "text"
    ]
  },
  {
    "title": "Gemini",
    "description": "Generate text using Gemini.\n    google, llm, chat, vision, multimodal",
    "namespace": "google.gemini",
    "node_type": "google.gemini.Gemini",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "gemini-1.5-pro",
            "gemini-1.5-flash",
            "gemini-2.0-flash-exp"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.google.gemini.GeminiModel"
        },
        "default": "gemini-1.5-pro",
        "title": "Model",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "messages",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "message",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Messages",
        "description": "History of messages to send to the model.",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Image to use for generation",
        "min": null,
        "max": null
      },
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "Audio to use for generation",
        "min": null,
        "max": null
      },
      {
        "name": "system_instruction",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "You are a helpful assistant.",
        "title": "System Instruction",
        "description": "Instructions for the model to steer it toward better performance.\n        For example, \"Answer as concisely as possible\" or \"Don't use technical\n        terms in your response\".\n        ",
        "min": null,
        "max": null
      },
      {
        "name": "code_execution",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Code Execution",
        "description": "Whether to enable code execution tool. \n        You can use this code execution capability to build applications that \n        benefit from code-based reasoning and that produce text output.\n        ",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Temperature",
        "description": "Value that controls the degree of randomness in token selection.\n        Lower temperatures are good for prompts that require a less open-ended or\n        creative response, while higher temperatures can lead to more diverse or\n        creative results.\n        ",
        "min": null,
        "max": null
      },
      {
        "name": "top_p",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Top P",
        "description": "Tokens are selected from the most to least probable until the sum\n        of their probabilities equals this value. Use a lower value for less\n        random responses and a higher value for more random responses.\n        ",
        "min": null,
        "max": null
      },
      {
        "name": "top_k",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 40,
        "title": "Top K",
        "description": "For each token selection step, the ``top_k`` tokens with the\n        highest probabilities are sampled. Then tokens are further filtered based\n        on ``top_p`` with the final token selected using temperature sampling. Use\n        a lower number for less random responses and a higher number for more\n        random responses.\n        ",
        "min": 1.0,
        "max": 50.0
      },
      {
        "name": "max_output_tokens",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 1024,
        "title": "Max Output Tokens",
        "description": "Maximum number of tokens that can be generated in the response.\n      ",
        "min": null,
        "max": null
      },
      {
        "name": "presence_penalty",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Presence Penalty",
        "description": "Positive values penalize tokens that already appear in the\n        generated text, increasing the probability of generating more diverse\n        content.\n        ",
        "min": null,
        "max": null
      },
      {
        "name": "frequency_penalty",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Frequency Penalty",
        "description": "Positive values penalize tokens that repeatedly appear in the\n        generated text, increasing the probability of generating more diverse\n        content.\n        ",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "model",
      "prompt",
      "messages",
      "image",
      "audio",
      "system_instruction",
      "code_execution",
      "temperature",
      "top_p",
      "top_k",
      "max_output_tokens",
      "presence_penalty",
      "frequency_penalty"
    ]
  },
  {
    "title": "Gemini Agent",
    "description": "Gemini version of the Agent node for task planning and goal decomposition.\n    agent, planning, task, decomposition\n    Use cases:\n    - Breaking down complex tasks into smaller steps\n    - Creating task dependencies and workflows\n    - Planning multi-step processes",
    "namespace": "google.agents",
    "node_type": "google.agents.GeminiAgent",
    "layout": "default",
    "properties": [
      {
        "name": "goal",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Goal",
        "description": "The user prompt",
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "gemini-1.5-pro",
            "gemini-1.5-flash",
            "gemini-2.0-flash-exp"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.google.gemini.GeminiModel"
        },
        "default": "gemini-2.0-flash-exp",
        "title": "Model",
        "description": "The Gemini model to use",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Temperature",
        "description": "Temperature for sampling",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "task",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "goal",
      "model",
      "temperature"
    ]
  },
  {
    "title": "Chain Of Thought",
    "description": "Gemini version of chain-of-thought reasoning node for breaking down complex problems into clear steps.\n    agent, reasoning, analysis, problem-solving\n    Use cases:\n    - Analyzing complex problems step by step\n    - Breaking down solutions into logical steps\n    - Providing detailed reasoning for decisions",
    "namespace": "google.agents",
    "node_type": "google.agents.ChainOfThought",
    "layout": "default",
    "properties": [
      {
        "name": "messages",
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "message",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "default": [],
        "title": "Messages",
        "description": "The messages to analyze",
        "min": null,
        "max": null
      },
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "gemini-1.5-pro",
            "gemini-1.5-flash",
            "gemini-2.0-flash-exp"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.google.gemini.GeminiModel"
        },
        "default": "gemini-2.0-flash-exp",
        "title": "Model",
        "description": null,
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Temperature",
        "description": null,
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "messages"
    ]
  },
  {
    "title": "Data Generator",
    "description": "Gemini version of the data generator for creating dataframes based on user prompts. Supports multimodal inputs including images and audio.\n    data, generator, dataframe, multimodal\n    Use cases:\n    - Creating a dataset for a machine learning model\n    - Creating a dataset for a data visualization\n    - Creating a dataset for a data analysis",
    "namespace": "google.agents",
    "node_type": "google.agents.DataGenerator",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "gemini-1.5-pro",
            "gemini-1.5-flash",
            "gemini-2.0-flash-exp"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.google.gemini.GeminiModel"
        },
        "default": "gemini-2.0-flash-exp",
        "title": "Model",
        "description": "The Gemini model to use",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The user prompt",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Image to use for generation",
        "min": null,
        "max": null
      },
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "Audio to use for generation",
        "min": null,
        "max": null
      },
      {
        "name": "columns",
        "type": {
          "type": "record_type",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "record_type",
          "columns": []
        },
        "title": "Columns",
        "description": "The columns to use in the dataframe",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Temperature",
        "description": "Temperature for sampling",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "dataframe",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image",
      "audio",
      "columns"
    ]
  },
  {
    "title": "SVGGenerator",
    "description": "Gemini version of SVG generator for creating SVG elements based on user prompts.\n    svg, generator, vector, graphics\n    Use cases:\n    - Creating vector graphics from text descriptions\n    - Generating scalable illustrations\n    - Creating custom icons and diagrams",
    "namespace": "google.agents",
    "node_type": "google.agents.SVGGenerator",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "gemini-1.5-pro",
            "gemini-1.5-flash",
            "gemini-2.0-flash-exp"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.google.gemini.GeminiModel"
        },
        "default": "gemini-2.0-flash-exp",
        "title": "Model",
        "description": "The Gemini model to use",
        "min": null,
        "max": null
      },
      {
        "name": "prompt",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Prompt",
        "description": "The user prompt for SVG generation",
        "min": null,
        "max": null
      },
      {
        "name": "image",
        "type": {
          "type": "image",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "image",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Image",
        "description": "Image to use for generation",
        "min": null,
        "max": null
      },
      {
        "name": "audio",
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": {
          "type": "audio",
          "uri": "",
          "asset_id": null,
          "data": null
        },
        "title": "Audio",
        "description": "Audio to use for generation",
        "min": null,
        "max": null
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Temperature",
        "description": "Temperature for sampling",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "list",
          "optional": false,
          "values": null,
          "type_args": [
            {
              "type": "svg_element",
              "optional": false,
              "values": null,
              "type_args": [],
              "type_name": null
            }
          ],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "prompt",
      "image",
      "audio"
    ]
  },
  {
    "title": "Summarizer",
    "description": "Gemini version of the summarizer for creating concise summaries of text content.\n    text, summarization, nlp, content\n    Use cases:\n    - Condensing long documents into key points\n    - Creating executive summaries\n    - Extracting main ideas from text",
    "namespace": "google.agents",
    "node_type": "google.agents.Summarizer",
    "layout": "default",
    "properties": [
      {
        "name": "model",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "gemini-1.5-pro",
            "gemini-1.5-flash",
            "gemini-2.0-flash-exp"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.google.gemini.GeminiModel"
        },
        "default": "gemini-2.0-flash-exp",
        "title": "Model",
        "description": "The Gemini model to use",
        "min": null,
        "max": null
      },
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "",
        "title": "Text",
        "description": "The text to summarize",
        "min": null,
        "max": null
      },
      {
        "name": "max_words",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 150,
        "title": "Max Words",
        "description": "Target maximum number of words for the summary",
        "min": 50.0,
        "max": 500.0
      },
      {
        "name": "temperature",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Temperature",
        "description": "Temperature for sampling",
        "min": 0.0,
        "max": 1.0
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "text",
      "max_words"
    ]
  },
  {
    "title": "Text To Speech",
    "description": "Generates speech using ElevenLabs' text-to-speech API.\n    audio, generation, AI, text-to-speech, TTS, elevenlabs\n\n    Use cases:\n    - Generate natural-sounding speech from text\n    - Create voiceovers for videos or presentations\n    - Produce audio content with different voices and styles\n    - Create realistic AI-generated speech for various applications",
    "namespace": "elevenlabs.text_to_speech",
    "node_type": "elevenlabs.text_to_speech.TextToSpeech",
    "layout": "default",
    "properties": [
      {
        "name": "voice",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "Aria (American female, expressive)",
            "Roger (American male, confident)",
            "Sarah (American female, soft)",
            "Laura (American female, upbeat)",
            "Charlie (Australian male, natural)",
            "George (British male, warm)",
            "Callum (Transatlantic male, intense)",
            "River (American non-binary, confident)",
            "Liam (American male, articulate)",
            "Charlotte (Swedish female, seductive)",
            "Alice (British female, confident)",
            "Will (American male, friendly)",
            "Jessica (American female, expressive)",
            "Eric (American male, friendly)",
            "Chris (American male, casual)",
            "Brian (American male, deep)",
            "Daniel (British male, authoritative)",
            "Lily (British female, warm)",
            "Bill (American male, trustworthy)"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.elevenlabs.text_to_speech.VoiceIDEnum"
        },
        "default": "Aria (American female, expressive)",
        "title": "Voice",
        "description": "Voice ID to be used for generation",
        "min": null,
        "max": null
      },
      {
        "name": "text",
        "type": {
          "type": "str",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": "Hello, how are you?",
        "title": "Text",
        "description": "The text to convert to speech",
        "min": null,
        "max": null
      },
      {
        "name": "tts_model_id",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "eleven_multilingual_v2",
            "eleven_turbo_v2_5",
            "eleven_flash_v2_5",
            "eleven_turbo_v2",
            "eleven_flash_v2",
            "eleven_multilingual_sts_v2",
            "eleven_english_sts_v2",
            "eleven_monolingual_v1",
            "eleven_multilingual_v1"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.elevenlabs.text_to_speech.ModelID"
        },
        "default": "eleven_monolingual_v1",
        "title": "Tts Model Id",
        "description": "The TTS model to use for generation",
        "min": null,
        "max": null
      },
      {
        "name": "voice_settings",
        "type": {
          "type": "dict",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": null,
        "title": "Voice Settings",
        "description": "Optional voice settings to override defaults",
        "min": null,
        "max": null
      },
      {
        "name": "language_code",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "none",
            "en",
            "ja",
            "zh",
            "de",
            "hi",
            "fr",
            "ko",
            "pt",
            "it",
            "es",
            "ru",
            "id",
            "nl",
            "tr",
            "fil",
            "pl",
            "sv",
            "bg",
            "ro",
            "ar",
            "cs",
            "el",
            "fi",
            "hr",
            "ms",
            "sk",
            "da",
            "ta",
            "uk",
            "vi",
            "no",
            "hu"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.elevenlabs.text_to_speech.LanguageID"
        },
        "default": "none",
        "title": "Language Code",
        "description": "Language code to enforce (only works with Turbo v2.5)",
        "min": null,
        "max": null
      },
      {
        "name": "optimize_streaming_latency",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 2,
        "title": "Optimize Streaming Latency",
        "description": "Latency optimization level (0-4). Higher values trade quality for speed",
        "min": 0.0,
        "max": 4.0
      },
      {
        "name": "seed",
        "type": {
          "type": "int",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": -1,
        "title": "Seed",
        "description": "Seed for deterministic generation (0-4294967295). -1 means random",
        "min": -1.0,
        "max": 4294967295.0
      },
      {
        "name": "text_normalization",
        "type": {
          "type": "enum",
          "optional": false,
          "values": [
            "auto",
            "on",
            "off"
          ],
          "type_args": [],
          "type_name": "nodetool.nodes.elevenlabs.text_to_speech.TextNormalization"
        },
        "default": "auto",
        "title": "Text Normalization",
        "description": "Controls text normalization behavior",
        "min": null,
        "max": null
      },
      {
        "name": "stability",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.5,
        "title": "Stability",
        "description": "Voice stability (0-1). Higher values make output more consistent, lower values more varied",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "similarity_boost",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.75,
        "title": "Similarity Boost",
        "description": "Similarity to original voice (0-1). Higher values make output closer to original voice",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "style",
        "type": {
          "type": "float",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": 0.0,
        "title": "Style",
        "description": "Speaking style emphasis (0-1). Higher values increase style expression",
        "min": 0.0,
        "max": 1.0
      },
      {
        "name": "use_speaker_boost",
        "type": {
          "type": "bool",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "default": false,
        "title": "Use Speaker Boost",
        "description": "Whether to use speaker boost for clearer, more consistent output",
        "min": null,
        "max": null
      }
    ],
    "outputs": [
      {
        "type": {
          "type": "audio",
          "optional": false,
          "values": null,
          "type_args": [],
          "type_name": null
        },
        "name": "output",
        "stream": false
      }
    ],
    "the_model_info": {},
    "recommended_models": [],
    "basic_fields": [
      "voice",
      "text"
    ]
  }
]