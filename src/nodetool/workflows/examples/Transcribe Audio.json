{
  "id": "transcribe_audio",
  "access": "public",
  "created_at": "2025-01-26T18:27:06.589798",
  "updated_at": "2025-01-26T18:27:06.589809",
  "name": "Transcribe Audio",
  "description": "Convert speech to text using Whisper model with word-level timestamps",
  "tags": [
    "start",
    "audio"
  ],
  "thumbnail": null,
  "thumbnail_url": "/examples/transcribe_audio.jpg",
  "graph": {
    "nodes": [
      {
        "id": "5",
        "parent_id": null,
        "type": "nodetool.workflows.base_node.Comment",
        "data": {
          "comment": [
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "- Record your voice"
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "- Hit the run button"
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "- Read the transcription"
                }
              ]
            }
          ]
        },
        "ui_properties": {
          "selected": false,
          "position": {
            "x": 26,
            "y": -146
          },
          "zIndex": 0,
          "width": 306,
          "height": 136,
          "selectable": true
        },
        "dynamic_properties": {}
      },
      {
        "id": "6",
        "parent_id": null,
        "type": "huggingface.automatic_speech_recognition.Whisper",
        "data": {
          "model": {
            "type": "hf.automatic_speech_recognition",
            "repo_id": "openai/whisper-small"
          },
          "task": "transcribe",
          "language": "auto_detect",
          "chunk_length_s": 30,
          "timestamps": "word"
        },
        "ui_properties": {
          "selected": false,
          "position": {
            "x": 244,
            "y": 50
          },
          "zIndex": 0,
          "width": 198,
          "selectable": true
        },
        "dynamic_properties": {}
      },
      {
        "id": "7",
        "parent_id": null,
        "type": "nodetool.input.AudioInput",
        "data": {
          "name": "audio",
          "description": "",
          "value": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null
          }
        },
        "ui_properties": {
          "selected": false,
          "position": {
            "x": 50,
            "y": 112
          },
          "zIndex": 0,
          "width": 164,
          "selectable": true
        },
        "dynamic_properties": {}
      },
      {
        "id": "8",
        "parent_id": null,
        "type": "nodetool.output.StringOutput",
        "data": {
          "name": "transciption",
          "description": ""
        },
        "ui_properties": {
          "selected": false,
          "position": {
            "x": 472,
            "y": 98
          },
          "zIndex": 0,
          "width": 159,
          "selectable": true
        },
        "dynamic_properties": {}
      }
    ],
    "edges": [
      {
        "id": "1",
        "source": "7",
        "sourceHandle": "output",
        "target": "6",
        "targetHandle": "audio",
        "ui_properties": {
          "className": "audio"
        }
      },
      {
        "id": "2",
        "source": "6",
        "sourceHandle": "text",
        "target": "8",
        "targetHandle": "value",
        "ui_properties": {
          "className": "str"
        }
      }
    ]
  },
  "input_schema": null,
  "output_schema": null
}