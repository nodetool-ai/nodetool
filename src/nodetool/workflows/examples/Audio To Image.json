{
  "id": "01ddcf16e35711ef80af000038478aae",
  "access": "public",
  "created_at": "2025-02-05T15:50:13.803221",
  "updated_at": "2025-02-05T15:50:13.803234",
  "name": "Audio To Image",
  "description": "Transform spoken descriptions into images with this workflow. Record or upload audio, which is transcribed by Whisper and then visualized by Stable Diffusion. Perfect for quickly generating images from verbal ideas without typing.",
  "tags": [
    "huggingface",
    "multimodal",
    "start"
  ],
  "thumbnail": null,
  "thumbnail_url": "/examples/audio_to_image.jpg",
  "graph": {
    "nodes": [
      {
        "id": "11",
        "parent_id": null,
        "type": "nodetool.workflows.base_node.Comment",
        "data": {
          "headline": "Audio to Image",
          "comment": [
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "Audio To Image",
                  "size": "+",
                  "bold": "B"
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": ""
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "This workflow converts an audio description into an image through the following steps:"
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "\t1.\t"
                },
                {
                  "text": "Audio Input:",
                  "bold": true
                },
                {
                  "text": " The user records or uploads an audio file."
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "\t2.\t"
                },
                {
                  "text": "Whisper",
                  "bold": true
                },
                {
                  "text": ": Transcribes the audio into text using an automatic speech recognition model."
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "\t3.\t"
                },
                {
                  "text": "Stable Diffusion: ",
                  "bold": true
                },
                {
                  "text": "Uses the transcribed text as a prompt to generate an image."
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "\t4.\t"
                },
                {
                  "text": "Image Output: ",
                  "bold": true
                },
                {
                  "text": "Displays the generated image to the user."
                }
              ]
            }
          ],
          "title": [
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "Audio To Image",
                  "size": "+",
                  "bold": "B"
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "size": "+",
                  "bold": "B",
                  "text": ""
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "This workflow converts an audio description into an image through the following steps:"
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "\t1.\t"
                },
                {
                  "text": "Audio Input: ",
                  "bold": true
                },
                {
                  "text": "The user records or uploads an audio file."
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "\t2.\t"
                },
                {
                  "text": "Whisper: ",
                  "bold": true
                },
                {
                  "text": "Transcribes the audio into text using an automatic speech recognition model."
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "\t3.\t"
                },
                {
                  "text": "Stable Diffusion:",
                  "bold": true
                },
                {
                  "text": " Uses the transcribed text as a prompt to generate an image."
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "\t4.\tI"
                },
                {
                  "text": "mage Output: ",
                  "bold": true
                },
                {
                  "text": "Displays the generated image to the user."
                }
              ]
            }
          ]
        },
        "ui_properties": {
          "position": {
            "x": 42,
            "y": -135
          },
          "zIndex": 0,
          "width": 697,
          "height": 151,
          "selectable": true
        },
        "dynamic_properties": {}
      },
      {
        "id": "13",
        "parent_id": null,
        "type": "huggingface.text_to_image.StableDiffusion",
        "data": {
          "model": {
            "type": "hf.stable_diffusion",
            "repo_id": "SG161222/Realistic_Vision_V5.1_noVAE",
            "path": "Realistic_Vision_V5.1_fp16-no-ema.safetensors"
          },
          "negative_prompt": "",
          "seed": -1,
          "num_inference_steps": 20,
          "guidance_scale": 7.5,
          "scheduler": "EulerDiscreteScheduler",
          "loras": [],
          "lora_scale": 0.5,
          "ip_adapter_model": "",
          "ip_adapter_image": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "ip_adapter_scale": 0.5,
          "hires": true,
          "enable_tiling": false,
          "width": 512,
          "height": 512,
          "detail_level": 0.89,
          "enable_cpu_offload": false
        },
        "ui_properties": {
          "position": {
            "x": 443,
            "y": 50
          },
          "zIndex": 0,
          "width": 200,
          "title": "Generates an image from the transcribed text.",
          "selectable": true
        },
        "dynamic_properties": {}
      },
      {
        "id": "14",
        "parent_id": null,
        "type": "huggingface.automatic_speech_recognition.Whisper",
        "data": {
          "model": {
            "type": "hf.automatic_speech_recognition",
            "repo_id": "openai/whisper-small"
          },
          "task": "transcribe",
          "language": "auto_detect",
          "timestamps": "none"
        },
        "ui_properties": {
          "position": {
            "x": 213,
            "y": 53
          },
          "zIndex": 0,
          "width": 200,
          "title": "Transcribes audio file to text.",
          "selectable": true
        },
        "dynamic_properties": {}
      },
      {
        "id": "15",
        "parent_id": null,
        "type": "nodetool.input.AudioInput",
        "data": {
          "name": "description",
          "description": "",
          "value": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null
          }
        },
        "ui_properties": {
          "position": {
            "x": 50,
            "y": 68
          },
          "zIndex": 0,
          "width": 133,
          "title": "Records the user voice as audio file.",
          "selectable": true
        },
        "dynamic_properties": {}
      },
      {
        "id": "16",
        "parent_id": null,
        "type": "nodetool.output.ImageOutput",
        "data": {
          "name": "image",
          "description": ""
        },
        "ui_properties": {
          "position": {
            "x": 673,
            "y": 101
          },
          "zIndex": 0,
          "width": 134,
          "title": "Displays the generated image.",
          "selectable": true
        },
        "dynamic_properties": {}
      }
    ],
    "edges": [
      {
        "id": "fa76cf2f-55cc-433a-b738-c4ba79e283de",
        "source": "14",
        "sourceHandle": "text",
        "target": "13",
        "targetHandle": "prompt",
        "ui_properties": {
          "className": "str"
        }
      },
      {
        "id": "39781356",
        "source": "15",
        "sourceHandle": "output",
        "target": "14",
        "targetHandle": "audio",
        "ui_properties": null
      },
      {
        "id": "39781357",
        "source": "13",
        "sourceHandle": "output",
        "target": "16",
        "targetHandle": "value",
        "ui_properties": {
          "className": "image"
        }
      }
    ]
  },
  "input_schema": null,
  "output_schema": null
}