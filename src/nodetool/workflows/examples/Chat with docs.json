{
  "id": "8567b56cf3c511efa735000044b725cd",
  "access": "public",
  "created_at": "2025-02-25T23:12:46.570073",
  "updated_at": "2025-02-25T23:12:46.570077",
  "name": "Chat with Docs",
  "description": "An intelligent document retrieval and question-answering system that leverages vector search and local LLMs to provide accurate, context-aware responses based on your document collection.",
  "tags": [
    "chat",
    "rag"
  ],
  "thumbnail": null,
  "thumbnail_url": null,
  "graph": {
    "nodes": [
      {
        "id": "5",
        "parent_id": null,
        "type": "nodetool.input.ChatInput",
        "data": {
          "label": "Question",
          "name": "question",
          "value": {
            "type": "message",
            "id": null,
            "auth_token": null,
            "workflow_id": null,
            "graph": null,
            "thread_id": null,
            "user_id": null,
            "tool_call_id": null,
            "role": "",
            "name": "",
            "content": null,
            "tool_calls": null,
            "created_at": null
          }
        },
        "ui_properties": {
          "position": {
            "x": 50,
            "y": 215
          },
          "zIndex": 0,
          "width": 197,
          "title": "Capture user query or question for document search",
          "selectable": true
        },
        "dynamic_properties": {}
      },
      {
        "id": "6",
        "parent_id": null,
        "type": "nodetool.output.StringOutput",
        "data": {
          "label": "Answer",
          "name": "answer"
        },
        "ui_properties": {
          "position": {
            "x": 1181,
            "y": 244
          },
          "zIndex": 0,
          "width": 275,
          "title": "Return comprehensive answer to user's query",
          "selectable": true
        },
        "dynamic_properties": {}
      },
      {
        "id": "8",
        "parent_id": null,
        "type": "ollama.text.Ollama",
        "data": {
          "model": {
            "type": "llama_model",
            "repo_id": "deepseek-r1:7b"
          },
          "image": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "system_prompt": "You are an assistant.",
          "messages": [],
          "context_window": 50000,
          "num_predict": 4096,
          "temperature": 0.7,
          "top_k": 50,
          "top_p": 0.95,
          "keep_alive": 300
        },
        "ui_properties": {
          "position": {
            "x": 856,
            "y": 210
          },
          "zIndex": 0,
          "width": 295,
          "title": "Generate contextual response using local LLM with retrieved information",
          "selectable": true
        },
        "dynamic_properties": {}
      },
      {
        "id": "9",
        "parent_id": null,
        "type": "nodetool.text.FormatText",
        "data": {
          "template": "You are an expert assistant answering a user question based on retrieved documents. \nYour response must be accurate, well-structured, and grounded in the provided sources.\n\n### User Question:\n{{ text }}\n\n### Relevant Information from Retrieved Documents\nThese snippets can be incomplete or out of context. Ignore information that is not relevant.\n{% for doc in documents %}\n=====================\n**Document {{ loop.index }}\n** {{ doc }}\n{% endfor %}\n\n### **Instructions for Answering:**\n1. Analyze the user question carefully.\n2. Extract key insights from the retrieved documents.\n3. If multiple documents provide different perspectives, synthesize the most relevant and accurate information.\n4. If the documents lack sufficient information, state what is missing instead of guessing.\n5. Present the answer in a clear, concise, and structured manner."
        },
        "ui_properties": {
          "position": {
            "x": 490,
            "y": 50
          },
          "zIndex": 0,
          "width": 336,
          "title": "Construct comprehensive prompt with retrieved context and query",
          "selectable": true
        },
        "dynamic_properties": {
          "documents": "",
          "text": ""
        }
      },
      {
        "id": "11",
        "parent_id": null,
        "type": "chroma.query.HybridSearch",
        "data": {
          "collection": {
            "type": "collection",
            "name": "deepseek"
          },
          "n_results": 3,
          "k_constant": 60,
          "min_keyword_length": 3
        },
        "ui_properties": {
          "position": {
            "x": 307,
            "y": 61
          },
          "zIndex": 0,
          "width": 153,
          "title": "Perform hybrid vector and keyword search for relevant document chunks",
          "selectable": true
        },
        "dynamic_properties": {}
      },
      {
        "id": "12",
        "parent_id": null,
        "type": "nodetool.workflows.base_node.Comment",
        "data": {
          "comment": [
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "Retrieval-Augmented Generation (RAG) for Document Q&A",
                  "bold": "B",
                  "size": "+"
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": ""
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "This workflow implements a sophisticated RAG (Retrieval-Augmented Generation) system that enables natural language conversations with your document collection. It combines semantic search with local LLM inference to provide accurate, contextually relevant answers."
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "Here\u2019s how it works:"
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "\t1.\t"
                },
                {
                  "text": "User Input: ",
                  "bold": "B"
                },
                {
                  "text": "The user submits a question or text query."
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "\t2.\t"
                },
                {
                  "text": "Hybrid Search:",
                  "bold": true
                },
                {
                  "text": " Relevant documents are retrieved from a vector database to provide context for the query."
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "\t3.\t"
                },
                {
                  "text": "Text Formatting: ",
                  "bold": true
                },
                {
                  "text": "The retrieved documents and user question are formatted into a structured prompt for the LLM."
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "\t4.\t"
                },
                {
                  "text": "Ollama: ",
                  "bold": true
                },
                {
                  "text": "A local AI model processes the prompt, synthesizing information to generate an accurate and well-structured response."
                }
              ]
            },
            {
              "type": "paragraph",
              "children": [
                {
                  "text": "\t5.\t"
                },
                {
                  "text": "Output",
                  "bold": true
                },
                {
                  "text": ": The response is displayed back to the user in a clear format."
                }
              ]
            }
          ]
        },
        "ui_properties": {
          "position": {
            "x": 30,
            "y": -236
          },
          "zIndex": 0,
          "width": 930,
          "height": 212,
          "selectable": true
        },
        "dynamic_properties": {}
      }
    ],
    "edges": [
      {
        "id": "770948",
        "source": "5",
        "sourceHandle": "text",
        "target": "9",
        "targetHandle": "text",
        "ui_properties": null
      },
      {
        "id": "770949",
        "source": "9",
        "sourceHandle": "output",
        "target": "8",
        "targetHandle": "prompt",
        "ui_properties": null
      },
      {
        "id": "770950",
        "source": "8",
        "sourceHandle": "output",
        "target": "6",
        "targetHandle": "value",
        "ui_properties": null
      },
      {
        "id": "770953",
        "source": "5",
        "sourceHandle": "text",
        "target": "11",
        "targetHandle": "text",
        "ui_properties": null
      },
      {
        "id": "770954",
        "source": "11",
        "sourceHandle": "documents",
        "target": "9",
        "targetHandle": "documents",
        "ui_properties": null
      }
    ]
  },
  "input_schema": null,
  "output_schema": null,
  "settings": null
}